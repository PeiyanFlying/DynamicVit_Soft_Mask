| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 6): env://
| distributed init (rank 7): env://
| distributed init (rank 3): env://
| distributed init (rank 1): env://
| distributed init (rank 4): env://
| distributed init (rank 5): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp/checkpoint.pth', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000050 for BACKBONE, cosine lr = 0.0000568 for PREDICTOR
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Epoch: [24]  [   0/2001]  eta: 3:44:03  lr: 0.000057  loss: 3.5839 (3.5839)  time: 6.7183  data: 3.5126  max mem: 8604
Epoch: [24]  [  10/2001]  eta: 0:38:29  lr: 0.000057  loss: 3.3172 (3.3249)  time: 1.1600  data: 0.3194  max mem: 8681
Epoch: [24]  [  20/2001]  eta: 0:29:09  lr: 0.000057  loss: 3.2466 (3.2490)  time: 0.5914  data: 0.0001  max mem: 8681
Epoch: [24]  [  30/2001]  eta: 0:26:01  lr: 0.000057  loss: 3.2292 (3.2677)  time: 0.5896  data: 0.0002  max mem: 8681
Epoch: [24]  [  40/2001]  eta: 0:24:13  lr: 0.000057  loss: 3.1880 (3.2259)  time: 0.5916  data: 0.0002  max mem: 8681
Epoch: [24]  [  50/2001]  eta: 0:23:06  lr: 0.000057  loss: 3.1721 (3.2066)  time: 0.5849  data: 0.0001  max mem: 8681
Epoch: [24]  [  60/2001]  eta: 0:22:19  lr: 0.000057  loss: 3.2576 (3.1855)  time: 0.5854  data: 0.0002  max mem: 8681
Epoch: [24]  [  70/2001]  eta: 0:21:44  lr: 0.000057  loss: 3.2576 (3.1547)  time: 0.5856  data: 0.0002  max mem: 8681
Epoch: [24]  [  80/2001]  eta: 0:21:16  lr: 0.000057  loss: 3.0552 (3.1425)  time: 0.5858  data: 0.0001  max mem: 8681
Epoch: [24]  [  90/2001]  eta: 0:20:53  lr: 0.000057  loss: 3.0205 (3.1354)  time: 0.5861  data: 0.0002  max mem: 8681
loss info: cls_loss=3.0238, ratio_loss=0.0486, cls_kl=0.0656, token_kl=0.0938
Epoch: [24]  [ 100/2001]  eta: 0:20:34  lr: 0.000057  loss: 3.1999 (3.1385)  time: 0.5882  data: 0.0002  max mem: 8681
Epoch: [24]  [ 110/2001]  eta: 0:20:16  lr: 0.000057  loss: 3.1155 (3.1347)  time: 0.5874  data: 0.0001  max mem: 8681
Epoch: [24]  [ 120/2001]  eta: 0:20:01  lr: 0.000057  loss: 3.0817 (3.1388)  time: 0.5865  data: 0.0001  max mem: 8681
Epoch: [24]  [ 130/2001]  eta: 0:19:48  lr: 0.000057  loss: 3.0786 (3.1369)  time: 0.5885  data: 0.0001  max mem: 8681
Epoch: [24]  [ 140/2001]  eta: 0:19:36  lr: 0.000057  loss: 3.0764 (3.1282)  time: 0.5927  data: 0.0002  max mem: 8681
Epoch: [24]  [ 150/2001]  eta: 0:19:25  lr: 0.000057  loss: 3.1975 (3.1265)  time: 0.5927  data: 0.0002  max mem: 8681
Epoch: [24]  [ 160/2001]  eta: 0:19:14  lr: 0.000057  loss: 3.2017 (3.1335)  time: 0.5925  data: 0.0001  max mem: 8681
Epoch: [24]  [ 170/2001]  eta: 0:19:07  lr: 0.000057  loss: 3.2191 (3.1339)  time: 0.6033  data: 0.0001  max mem: 8681
Epoch: [24]  [ 180/2001]  eta: 0:18:59  lr: 0.000057  loss: 3.1253 (3.1249)  time: 0.6126  data: 0.0001  max mem: 8681
Epoch: [24]  [ 190/2001]  eta: 0:18:51  lr: 0.000057  loss: 2.9871 (3.1176)  time: 0.6091  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9689, ratio_loss=0.0422, cls_kl=0.0628, token_kl=0.0931
Epoch: [24]  [ 200/2001]  eta: 0:18:42  lr: 0.000057  loss: 2.9465 (3.1042)  time: 0.6034  data: 0.0001  max mem: 8681
Epoch: [24]  [ 210/2001]  eta: 0:18:34  lr: 0.000057  loss: 3.0487 (3.1003)  time: 0.6019  data: 0.0002  max mem: 8681
Epoch: [24]  [ 220/2001]  eta: 0:18:26  lr: 0.000057  loss: 3.1299 (3.0927)  time: 0.6021  data: 0.0002  max mem: 8681
Epoch: [24]  [ 230/2001]  eta: 0:18:19  lr: 0.000057  loss: 3.0886 (3.0843)  time: 0.6044  data: 0.0001  max mem: 8681
Epoch: [24]  [ 240/2001]  eta: 0:18:12  lr: 0.000057  loss: 3.1022 (3.0813)  time: 0.6071  data: 0.0001  max mem: 8681
Epoch: [24]  [ 250/2001]  eta: 0:18:05  lr: 0.000057  loss: 3.1449 (3.0748)  time: 0.6091  data: 0.0001  max mem: 8681
Epoch: [24]  [ 260/2001]  eta: 0:17:58  lr: 0.000057  loss: 2.9728 (3.0637)  time: 0.6101  data: 0.0001  max mem: 8681
Epoch: [24]  [ 270/2001]  eta: 0:17:51  lr: 0.000057  loss: 2.8140 (3.0584)  time: 0.6101  data: 0.0001  max mem: 8681
Epoch: [24]  [ 280/2001]  eta: 0:17:45  lr: 0.000057  loss: 3.2241 (3.0649)  time: 0.6097  data: 0.0001  max mem: 8681
Epoch: [24]  [ 290/2001]  eta: 0:17:38  lr: 0.000057  loss: 3.2214 (3.0577)  time: 0.6092  data: 0.0001  max mem: 8681
loss info: cls_loss=2.8246, ratio_loss=0.0421, cls_kl=0.0614, token_kl=0.0914
Epoch: [24]  [ 300/2001]  eta: 0:17:32  lr: 0.000057  loss: 2.7258 (3.0466)  time: 0.6147  data: 0.0001  max mem: 8681
Epoch: [24]  [ 310/2001]  eta: 0:17:26  lr: 0.000057  loss: 2.9125 (3.0451)  time: 0.6214  data: 0.0001  max mem: 8681
Epoch: [24]  [ 320/2001]  eta: 0:17:20  lr: 0.000057  loss: 3.2330 (3.0559)  time: 0.6232  data: 0.0001  max mem: 8681
Epoch: [24]  [ 330/2001]  eta: 0:17:13  lr: 0.000057  loss: 3.3470 (3.0566)  time: 0.6186  data: 0.0001  max mem: 8681
Epoch: [24]  [ 340/2001]  eta: 0:17:07  lr: 0.000057  loss: 3.2270 (3.0614)  time: 0.6164  data: 0.0001  max mem: 8681
Epoch: [24]  [ 350/2001]  eta: 0:17:01  lr: 0.000057  loss: 3.1747 (3.0635)  time: 0.6235  data: 0.0001  max mem: 8681
Epoch: [24]  [ 360/2001]  eta: 0:16:56  lr: 0.000057  loss: 3.0770 (3.0620)  time: 0.6288  data: 0.0001  max mem: 8681
Epoch: [24]  [ 370/2001]  eta: 0:16:50  lr: 0.000057  loss: 3.0759 (3.0604)  time: 0.6266  data: 0.0001  max mem: 8681
Epoch: [24]  [ 380/2001]  eta: 0:16:44  lr: 0.000057  loss: 3.0759 (3.0568)  time: 0.6251  data: 0.0001  max mem: 8681
Epoch: [24]  [ 390/2001]  eta: 0:16:38  lr: 0.000057  loss: 3.0659 (3.0504)  time: 0.6276  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9623, ratio_loss=0.0459, cls_kl=0.0633, token_kl=0.0935
Epoch: [24]  [ 400/2001]  eta: 0:16:32  lr: 0.000057  loss: 3.1312 (3.0546)  time: 0.6286  data: 0.0001  max mem: 8681
Epoch: [24]  [ 410/2001]  eta: 0:16:26  lr: 0.000057  loss: 3.2815 (3.0600)  time: 0.6283  data: 0.0001  max mem: 8681
Epoch: [24]  [ 420/2001]  eta: 0:16:20  lr: 0.000057  loss: 3.2299 (3.0594)  time: 0.6263  data: 0.0001  max mem: 8681
Epoch: [24]  [ 430/2001]  eta: 0:16:15  lr: 0.000057  loss: 3.2563 (3.0649)  time: 0.6312  data: 0.0001  max mem: 8681
Epoch: [24]  [ 440/2001]  eta: 0:16:09  lr: 0.000057  loss: 3.2348 (3.0645)  time: 0.6384  data: 0.0001  max mem: 8681
Epoch: [24]  [ 450/2001]  eta: 0:16:04  lr: 0.000057  loss: 3.0567 (3.0637)  time: 0.6404  data: 0.0001  max mem: 8681
Epoch: [24]  [ 460/2001]  eta: 0:15:58  lr: 0.000057  loss: 3.0522 (3.0593)  time: 0.6433  data: 0.0001  max mem: 8681
Epoch: [24]  [ 470/2001]  eta: 0:15:52  lr: 0.000057  loss: 2.5741 (3.0495)  time: 0.6391  data: 0.0001  max mem: 8681
Epoch: [24]  [ 480/2001]  eta: 0:15:47  lr: 0.000057  loss: 2.5890 (3.0477)  time: 0.6358  data: 0.0001  max mem: 8681
Epoch: [24]  [ 490/2001]  eta: 0:15:41  lr: 0.000057  loss: 3.1841 (3.0532)  time: 0.6376  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9386, ratio_loss=0.0465, cls_kl=0.0635, token_kl=0.0942
Epoch: [24]  [ 500/2001]  eta: 0:15:35  lr: 0.000057  loss: 3.1841 (3.0519)  time: 0.6356  data: 0.0001  max mem: 8681
Epoch: [24]  [ 510/2001]  eta: 0:15:29  lr: 0.000057  loss: 3.0513 (3.0538)  time: 0.6341  data: 0.0001  max mem: 8681
Epoch: [24]  [ 520/2001]  eta: 0:15:23  lr: 0.000057  loss: 3.2353 (3.0550)  time: 0.6399  data: 0.0002  max mem: 8681
Epoch: [24]  [ 530/2001]  eta: 0:15:18  lr: 0.000057  loss: 3.0549 (3.0500)  time: 0.6433  data: 0.0001  max mem: 8681
Epoch: [24]  [ 540/2001]  eta: 0:15:12  lr: 0.000057  loss: 3.1105 (3.0512)  time: 0.6386  data: 0.0001  max mem: 8681
Epoch: [24]  [ 550/2001]  eta: 0:15:06  lr: 0.000057  loss: 3.1949 (3.0494)  time: 0.6357  data: 0.0001  max mem: 8681
Epoch: [24]  [ 560/2001]  eta: 0:15:00  lr: 0.000057  loss: 3.2344 (3.0546)  time: 0.6373  data: 0.0001  max mem: 8681
Epoch: [24]  [ 570/2001]  eta: 0:14:54  lr: 0.000057  loss: 3.2806 (3.0578)  time: 0.6395  data: 0.0001  max mem: 8681
Epoch: [24]  [ 580/2001]  eta: 0:14:48  lr: 0.000057  loss: 3.2452 (3.0579)  time: 0.6382  data: 0.0001  max mem: 8681
Epoch: [24]  [ 590/2001]  eta: 0:14:42  lr: 0.000057  loss: 3.2588 (3.0599)  time: 0.6381  data: 0.0002  max mem: 8681
loss info: cls_loss=2.9897, ratio_loss=0.0477, cls_kl=0.0637, token_kl=0.0932
Epoch: [24]  [ 600/2001]  eta: 0:14:36  lr: 0.000057  loss: 3.2269 (3.0580)  time: 0.6369  data: 0.0001  max mem: 8681
Epoch: [24]  [ 610/2001]  eta: 0:14:30  lr: 0.000057  loss: 3.0821 (3.0585)  time: 0.6358  data: 0.0001  max mem: 8681
Epoch: [24]  [ 620/2001]  eta: 0:14:24  lr: 0.000057  loss: 3.2039 (3.0615)  time: 0.6422  data: 0.0001  max mem: 8681
Epoch: [24]  [ 630/2001]  eta: 0:14:18  lr: 0.000057  loss: 3.2635 (3.0625)  time: 0.6426  data: 0.0001  max mem: 8681
Epoch: [24]  [ 640/2001]  eta: 0:14:12  lr: 0.000057  loss: 3.0592 (3.0604)  time: 0.6373  data: 0.0001  max mem: 8681
Epoch: [24]  [ 650/2001]  eta: 0:14:06  lr: 0.000057  loss: 3.0399 (3.0597)  time: 0.6399  data: 0.0001  max mem: 8681
Epoch: [24]  [ 660/2001]  eta: 0:14:00  lr: 0.000057  loss: 2.7433 (3.0541)  time: 0.6386  data: 0.0001  max mem: 8681
Epoch: [24]  [ 670/2001]  eta: 0:13:54  lr: 0.000057  loss: 2.9922 (3.0573)  time: 0.6365  data: 0.0001  max mem: 8681
Epoch: [24]  [ 680/2001]  eta: 0:13:48  lr: 0.000057  loss: 3.1110 (3.0580)  time: 0.6396  data: 0.0001  max mem: 8681
Epoch: [24]  [ 690/2001]  eta: 0:13:42  lr: 0.000057  loss: 2.8482 (3.0553)  time: 0.6407  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9039, ratio_loss=0.0451, cls_kl=0.0635, token_kl=0.0946
Epoch: [24]  [ 700/2001]  eta: 0:13:36  lr: 0.000057  loss: 2.8994 (3.0535)  time: 0.6377  data: 0.0001  max mem: 8681
Epoch: [24]  [ 710/2001]  eta: 0:13:30  lr: 0.000057  loss: 3.0939 (3.0518)  time: 0.6370  data: 0.0001  max mem: 8681
Epoch: [24]  [ 720/2001]  eta: 0:13:24  lr: 0.000057  loss: 3.0021 (3.0496)  time: 0.6374  data: 0.0001  max mem: 8681
Epoch: [24]  [ 730/2001]  eta: 0:13:18  lr: 0.000057  loss: 3.0021 (3.0499)  time: 0.6356  data: 0.0001  max mem: 8681
Epoch: [24]  [ 740/2001]  eta: 0:13:11  lr: 0.000057  loss: 3.3738 (3.0560)  time: 0.6349  data: 0.0001  max mem: 8681
Epoch: [24]  [ 750/2001]  eta: 0:13:05  lr: 0.000057  loss: 3.3738 (3.0540)  time: 0.6333  data: 0.0001  max mem: 8681
Epoch: [24]  [ 760/2001]  eta: 0:12:59  lr: 0.000057  loss: 3.2522 (3.0541)  time: 0.6325  data: 0.0001  max mem: 8681
Epoch: [24]  [ 770/2001]  eta: 0:12:53  lr: 0.000057  loss: 3.3061 (3.0557)  time: 0.6332  data: 0.0001  max mem: 8681
Epoch: [24]  [ 780/2001]  eta: 0:12:47  lr: 0.000057  loss: 3.3056 (3.0563)  time: 0.6363  data: 0.0001  max mem: 8681
Epoch: [24]  [ 790/2001]  eta: 0:12:41  lr: 0.000057  loss: 3.1725 (3.0558)  time: 0.6345  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9660, ratio_loss=0.0445, cls_kl=0.0615, token_kl=0.0921
Epoch: [24]  [ 800/2001]  eta: 0:12:34  lr: 0.000057  loss: 3.1388 (3.0560)  time: 0.6317  data: 0.0001  max mem: 8681
Epoch: [24]  [ 810/2001]  eta: 0:12:28  lr: 0.000057  loss: 2.8442 (3.0486)  time: 0.6325  data: 0.0001  max mem: 8681
Epoch: [24]  [ 820/2001]  eta: 0:12:22  lr: 0.000057  loss: 2.8376 (3.0500)  time: 0.6341  data: 0.0001  max mem: 8681
Epoch: [24]  [ 830/2001]  eta: 0:12:16  lr: 0.000057  loss: 3.1239 (3.0463)  time: 0.6327  data: 0.0001  max mem: 8681
Epoch: [24]  [ 840/2001]  eta: 0:12:09  lr: 0.000057  loss: 2.7626 (3.0458)  time: 0.6343  data: 0.0001  max mem: 8681
Epoch: [24]  [ 850/2001]  eta: 0:12:03  lr: 0.000057  loss: 3.1253 (3.0447)  time: 0.6385  data: 0.0001  max mem: 8681
Epoch: [24]  [ 860/2001]  eta: 0:11:57  lr: 0.000057  loss: 2.9969 (3.0449)  time: 0.6349  data: 0.0001  max mem: 8681
Epoch: [24]  [ 870/2001]  eta: 0:11:51  lr: 0.000057  loss: 3.1138 (3.0453)  time: 0.6313  data: 0.0001  max mem: 8681
Epoch: [24]  [ 880/2001]  eta: 0:11:44  lr: 0.000057  loss: 3.0845 (3.0433)  time: 0.6280  data: 0.0001  max mem: 8681
Epoch: [24]  [ 890/2001]  eta: 0:11:38  lr: 0.000057  loss: 3.0592 (3.0407)  time: 0.6328  data: 0.0001  max mem: 8681
loss info: cls_loss=2.8052, ratio_loss=0.0444, cls_kl=0.0611, token_kl=0.0939
Epoch: [24]  [ 900/2001]  eta: 0:11:32  lr: 0.000057  loss: 3.0875 (3.0401)  time: 0.6341  data: 0.0001  max mem: 8681
Epoch: [24]  [ 910/2001]  eta: 0:11:26  lr: 0.000057  loss: 3.1436 (3.0396)  time: 0.6277  data: 0.0001  max mem: 8681
Epoch: [24]  [ 920/2001]  eta: 0:11:19  lr: 0.000057  loss: 3.2292 (3.0415)  time: 0.6283  data: 0.0001  max mem: 8681
Epoch: [24]  [ 930/2001]  eta: 0:11:13  lr: 0.000057  loss: 3.2855 (3.0443)  time: 0.6292  data: 0.0001  max mem: 8681
Epoch: [24]  [ 940/2001]  eta: 0:11:07  lr: 0.000057  loss: 3.1410 (3.0432)  time: 0.6278  data: 0.0001  max mem: 8681
Epoch: [24]  [ 950/2001]  eta: 0:11:01  lr: 0.000057  loss: 2.6109 (3.0377)  time: 0.6290  data: 0.0001  max mem: 8681
Epoch: [24]  [ 960/2001]  eta: 0:10:54  lr: 0.000057  loss: 2.6994 (3.0371)  time: 0.6287  data: 0.0001  max mem: 8681
Epoch: [24]  [ 970/2001]  eta: 0:10:48  lr: 0.000057  loss: 3.0787 (3.0380)  time: 0.6255  data: 0.0001  max mem: 8681
Epoch: [24]  [ 980/2001]  eta: 0:10:42  lr: 0.000057  loss: 3.2817 (3.0400)  time: 0.6256  data: 0.0001  max mem: 8681
Epoch: [24]  [ 990/2001]  eta: 0:10:35  lr: 0.000057  loss: 3.4423 (3.0392)  time: 0.6293  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9236, ratio_loss=0.0427, cls_kl=0.0628, token_kl=0.0921
Epoch: [24]  [1000/2001]  eta: 0:10:29  lr: 0.000057  loss: 3.0681 (3.0387)  time: 0.6290  data: 0.0001  max mem: 8681
Epoch: [24]  [1010/2001]  eta: 0:10:23  lr: 0.000057  loss: 3.1352 (3.0401)  time: 0.6262  data: 0.0001  max mem: 8681
Epoch: [24]  [1020/2001]  eta: 0:10:16  lr: 0.000057  loss: 3.2780 (3.0399)  time: 0.6269  data: 0.0001  max mem: 8681
Epoch: [24]  [1030/2001]  eta: 0:10:10  lr: 0.000057  loss: 2.9754 (3.0375)  time: 0.6269  data: 0.0001  max mem: 8681
Epoch: [24]  [1040/2001]  eta: 0:10:04  lr: 0.000057  loss: 3.0044 (3.0395)  time: 0.6335  data: 0.0001  max mem: 8681
Epoch: [24]  [1050/2001]  eta: 0:09:58  lr: 0.000057  loss: 3.1539 (3.0390)  time: 0.6335  data: 0.0001  max mem: 8681
Epoch: [24]  [1060/2001]  eta: 0:09:51  lr: 0.000057  loss: 3.2438 (3.0406)  time: 0.6268  data: 0.0001  max mem: 8681
Epoch: [24]  [1070/2001]  eta: 0:09:45  lr: 0.000057  loss: 3.2438 (3.0405)  time: 0.6270  data: 0.0001  max mem: 8681
Epoch: [24]  [1080/2001]  eta: 0:09:39  lr: 0.000057  loss: 3.1391 (3.0403)  time: 0.6266  data: 0.0001  max mem: 8681
Epoch: [24]  [1090/2001]  eta: 0:09:32  lr: 0.000057  loss: 3.1540 (3.0391)  time: 0.6305  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9254, ratio_loss=0.0452, cls_kl=0.0621, token_kl=0.0931
Epoch: [24]  [1100/2001]  eta: 0:09:26  lr: 0.000057  loss: 3.1495 (3.0386)  time: 0.6287  data: 0.0001  max mem: 8681
Epoch: [24]  [1110/2001]  eta: 0:09:20  lr: 0.000057  loss: 3.2787 (3.0397)  time: 0.6246  data: 0.0001  max mem: 8681
Epoch: [24]  [1120/2001]  eta: 0:09:13  lr: 0.000057  loss: 3.3325 (3.0412)  time: 0.6253  data: 0.0001  max mem: 8681
Epoch: [24]  [1130/2001]  eta: 0:09:07  lr: 0.000057  loss: 3.3325 (3.0431)  time: 0.6271  data: 0.0002  max mem: 8681
Epoch: [24]  [1140/2001]  eta: 0:09:01  lr: 0.000057  loss: 3.0891 (3.0426)  time: 0.6290  data: 0.0002  max mem: 8681
Epoch: [24]  [1150/2001]  eta: 0:08:55  lr: 0.000057  loss: 3.0080 (3.0418)  time: 0.6269  data: 0.0002  max mem: 8681
Epoch: [24]  [1160/2001]  eta: 0:08:48  lr: 0.000057  loss: 3.0080 (3.0411)  time: 0.6272  data: 0.0001  max mem: 8681
Epoch: [24]  [1170/2001]  eta: 0:08:42  lr: 0.000057  loss: 3.2009 (3.0408)  time: 0.6262  data: 0.0001  max mem: 8681
Epoch: [24]  [1180/2001]  eta: 0:08:36  lr: 0.000057  loss: 3.2640 (3.0437)  time: 0.6278  data: 0.0001  max mem: 8681
Epoch: [24]  [1190/2001]  eta: 0:08:29  lr: 0.000057  loss: 3.4313 (3.0455)  time: 0.6293  data: 0.0001  max mem: 8681
loss info: cls_loss=3.0330, ratio_loss=0.0474, cls_kl=0.0647, token_kl=0.0923
Epoch: [24]  [1200/2001]  eta: 0:08:23  lr: 0.000057  loss: 3.3010 (3.0470)  time: 0.6267  data: 0.0001  max mem: 8681
Epoch: [24]  [1210/2001]  eta: 0:08:17  lr: 0.000057  loss: 3.1872 (3.0463)  time: 0.6278  data: 0.0001  max mem: 8681
Epoch: [24]  [1220/2001]  eta: 0:08:11  lr: 0.000057  loss: 3.0114 (3.0456)  time: 0.6294  data: 0.0001  max mem: 8681
Epoch: [24]  [1230/2001]  eta: 0:08:04  lr: 0.000057  loss: 3.1230 (3.0461)  time: 0.6261  data: 0.0001  max mem: 8681
Epoch: [24]  [1240/2001]  eta: 0:07:58  lr: 0.000057  loss: 3.1701 (3.0463)  time: 0.6245  data: 0.0001  max mem: 8681
Epoch: [24]  [1250/2001]  eta: 0:07:52  lr: 0.000057  loss: 3.0050 (3.0447)  time: 0.6282  data: 0.0001  max mem: 8681
Epoch: [24]  [1260/2001]  eta: 0:07:45  lr: 0.000057  loss: 2.9893 (3.0458)  time: 0.6279  data: 0.0001  max mem: 8681
Epoch: [24]  [1270/2001]  eta: 0:07:39  lr: 0.000057  loss: 3.2609 (3.0466)  time: 0.6271  data: 0.0001  max mem: 8681
Epoch: [24]  [1280/2001]  eta: 0:07:33  lr: 0.000057  loss: 3.2720 (3.0487)  time: 0.6312  data: 0.0001  max mem: 8681
Epoch: [24]  [1290/2001]  eta: 0:07:27  lr: 0.000057  loss: 3.2449 (3.0502)  time: 0.6368  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9771, ratio_loss=0.0469, cls_kl=0.0644, token_kl=0.0936
Epoch: [24]  [1300/2001]  eta: 0:07:20  lr: 0.000057  loss: 3.1878 (3.0504)  time: 0.6385  data: 0.0001  max mem: 8681
Epoch: [24]  [1310/2001]  eta: 0:07:14  lr: 0.000057  loss: 3.1340 (3.0495)  time: 0.6384  data: 0.0001  max mem: 8681
Epoch: [24]  [1320/2001]  eta: 0:07:08  lr: 0.000057  loss: 2.9245 (3.0476)  time: 0.6347  data: 0.0001  max mem: 8681
Epoch: [24]  [1330/2001]  eta: 0:07:02  lr: 0.000057  loss: 3.0246 (3.0483)  time: 0.6303  data: 0.0001  max mem: 8681
Epoch: [24]  [1340/2001]  eta: 0:06:55  lr: 0.000057  loss: 3.2657 (3.0491)  time: 0.6278  data: 0.0001  max mem: 8681
Epoch: [24]  [1350/2001]  eta: 0:06:49  lr: 0.000057  loss: 3.1738 (3.0492)  time: 0.6278  data: 0.0001  max mem: 8681
Epoch: [24]  [1360/2001]  eta: 0:06:43  lr: 0.000057  loss: 3.2907 (3.0505)  time: 0.6309  data: 0.0001  max mem: 8681
Epoch: [24]  [1370/2001]  eta: 0:06:36  lr: 0.000057  loss: 3.2907 (3.0520)  time: 0.6311  data: 0.0001  max mem: 8681
Epoch: [24]  [1380/2001]  eta: 0:06:30  lr: 0.000057  loss: 3.1881 (3.0532)  time: 0.6312  data: 0.0001  max mem: 8681
Epoch: [24]  [1390/2001]  eta: 0:06:24  lr: 0.000057  loss: 3.1478 (3.0531)  time: 0.6313  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9747, ratio_loss=0.0434, cls_kl=0.0620, token_kl=0.0909
Epoch: [24]  [1400/2001]  eta: 0:06:18  lr: 0.000057  loss: 3.0780 (3.0521)  time: 0.6286  data: 0.0001  max mem: 8681
Epoch: [24]  [1410/2001]  eta: 0:06:11  lr: 0.000057  loss: 3.0865 (3.0532)  time: 0.6276  data: 0.0001  max mem: 8681
Epoch: [24]  [1420/2001]  eta: 0:06:05  lr: 0.000057  loss: 3.1549 (3.0532)  time: 0.6290  data: 0.0001  max mem: 8681
Epoch: [24]  [1430/2001]  eta: 0:05:59  lr: 0.000057  loss: 3.1793 (3.0537)  time: 0.6296  data: 0.0001  max mem: 8681
Epoch: [24]  [1440/2001]  eta: 0:05:52  lr: 0.000057  loss: 3.1947 (3.0536)  time: 0.6321  data: 0.0001  max mem: 8681
Epoch: [24]  [1450/2001]  eta: 0:05:46  lr: 0.000057  loss: 3.1947 (3.0536)  time: 0.6328  data: 0.0001  max mem: 8681
Epoch: [24]  [1460/2001]  eta: 0:05:40  lr: 0.000057  loss: 3.1920 (3.0539)  time: 0.6315  data: 0.0001  max mem: 8681
Epoch: [24]  [1470/2001]  eta: 0:05:34  lr: 0.000057  loss: 3.1230 (3.0532)  time: 0.6381  data: 0.0001  max mem: 8681
Epoch: [24]  [1480/2001]  eta: 0:05:27  lr: 0.000057  loss: 3.1230 (3.0522)  time: 0.6367  data: 0.0001  max mem: 8681
Epoch: [24]  [1490/2001]  eta: 0:05:21  lr: 0.000057  loss: 2.6800 (3.0491)  time: 0.6285  data: 0.0001  max mem: 8681
loss info: cls_loss=2.8881, ratio_loss=0.0445, cls_kl=0.0628, token_kl=0.0930
Epoch: [24]  [1500/2001]  eta: 0:05:15  lr: 0.000057  loss: 2.8022 (3.0483)  time: 0.6316  data: 0.0001  max mem: 8681
Epoch: [24]  [1510/2001]  eta: 0:05:08  lr: 0.000057  loss: 3.0954 (3.0495)  time: 0.6345  data: 0.0001  max mem: 8681
Epoch: [24]  [1520/2001]  eta: 0:05:02  lr: 0.000057  loss: 3.2879 (3.0510)  time: 0.6290  data: 0.0001  max mem: 8681
Epoch: [24]  [1530/2001]  eta: 0:04:56  lr: 0.000057  loss: 3.1647 (3.0500)  time: 0.6305  data: 0.0001  max mem: 8681
Epoch: [24]  [1540/2001]  eta: 0:04:50  lr: 0.000057  loss: 2.8994 (3.0505)  time: 0.6356  data: 0.0001  max mem: 8681
Epoch: [24]  [1550/2001]  eta: 0:04:43  lr: 0.000057  loss: 3.0649 (3.0495)  time: 0.6354  data: 0.0001  max mem: 8681
Epoch: [24]  [1560/2001]  eta: 0:04:37  lr: 0.000057  loss: 3.0649 (3.0489)  time: 0.6361  data: 0.0001  max mem: 8681
Epoch: [24]  [1570/2001]  eta: 0:04:31  lr: 0.000057  loss: 2.8148 (3.0473)  time: 0.6381  data: 0.0001  max mem: 8681
Epoch: [24]  [1580/2001]  eta: 0:04:24  lr: 0.000057  loss: 2.8148 (3.0475)  time: 0.6381  data: 0.0001  max mem: 8681
Epoch: [24]  [1590/2001]  eta: 0:04:18  lr: 0.000057  loss: 3.1416 (3.0485)  time: 0.6384  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9581, ratio_loss=0.0445, cls_kl=0.0613, token_kl=0.0916
Epoch: [24]  [1600/2001]  eta: 0:04:12  lr: 0.000057  loss: 3.2736 (3.0497)  time: 0.6406  data: 0.0001  max mem: 8681
Epoch: [24]  [1610/2001]  eta: 0:04:06  lr: 0.000057  loss: 3.2686 (3.0502)  time: 0.6401  data: 0.0001  max mem: 8681
Epoch: [24]  [1620/2001]  eta: 0:03:59  lr: 0.000057  loss: 3.1511 (3.0499)  time: 0.6344  data: 0.0001  max mem: 8681
Epoch: [24]  [1630/2001]  eta: 0:03:53  lr: 0.000057  loss: 3.2467 (3.0506)  time: 0.6349  data: 0.0001  max mem: 8681
Epoch: [24]  [1640/2001]  eta: 0:03:47  lr: 0.000057  loss: 3.2467 (3.0505)  time: 0.6349  data: 0.0001  max mem: 8681
Epoch: [24]  [1650/2001]  eta: 0:03:41  lr: 0.000057  loss: 2.9240 (3.0480)  time: 0.6291  data: 0.0001  max mem: 8681
Epoch: [24]  [1660/2001]  eta: 0:03:34  lr: 0.000057  loss: 2.5452 (3.0457)  time: 0.6299  data: 0.0001  max mem: 8681
Epoch: [24]  [1670/2001]  eta: 0:03:28  lr: 0.000057  loss: 2.7635 (3.0456)  time: 0.6353  data: 0.0001  max mem: 8681
Epoch: [24]  [1680/2001]  eta: 0:03:22  lr: 0.000057  loss: 3.1495 (3.0452)  time: 0.6394  data: 0.0001  max mem: 8681
Epoch: [24]  [1690/2001]  eta: 0:03:15  lr: 0.000057  loss: 3.2360 (3.0458)  time: 0.6385  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9111, ratio_loss=0.0453, cls_kl=0.0622, token_kl=0.0936
Epoch: [24]  [1700/2001]  eta: 0:03:09  lr: 0.000057  loss: 3.3611 (3.0479)  time: 0.6372  data: 0.0001  max mem: 8681
Epoch: [24]  [1710/2001]  eta: 0:03:03  lr: 0.000057  loss: 3.0728 (3.0468)  time: 0.6357  data: 0.0001  max mem: 8681
Epoch: [24]  [1720/2001]  eta: 0:02:57  lr: 0.000057  loss: 2.8859 (3.0464)  time: 0.6333  data: 0.0001  max mem: 8681
Epoch: [24]  [1730/2001]  eta: 0:02:50  lr: 0.000057  loss: 3.3803 (3.0479)  time: 0.6339  data: 0.0001  max mem: 8681
Epoch: [24]  [1740/2001]  eta: 0:02:44  lr: 0.000057  loss: 3.3118 (3.0475)  time: 0.6405  data: 0.0001  max mem: 8681
Epoch: [24]  [1750/2001]  eta: 0:02:38  lr: 0.000057  loss: 2.8187 (3.0468)  time: 0.6384  data: 0.0001  max mem: 8681
Epoch: [24]  [1760/2001]  eta: 0:02:31  lr: 0.000057  loss: 2.7197 (3.0466)  time: 0.6347  data: 0.0001  max mem: 8681
Epoch: [24]  [1770/2001]  eta: 0:02:25  lr: 0.000057  loss: 3.1644 (3.0469)  time: 0.6376  data: 0.0001  max mem: 8681
Epoch: [24]  [1780/2001]  eta: 0:02:19  lr: 0.000057  loss: 3.2503 (3.0474)  time: 0.6358  data: 0.0001  max mem: 8681
Epoch: [24]  [1790/2001]  eta: 0:02:12  lr: 0.000057  loss: 3.1981 (3.0470)  time: 0.6330  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9633, ratio_loss=0.0448, cls_kl=0.0626, token_kl=0.0927
Epoch: [24]  [1800/2001]  eta: 0:02:06  lr: 0.000057  loss: 3.2053 (3.0488)  time: 0.6342  data: 0.0001  max mem: 8681
Epoch: [24]  [1810/2001]  eta: 0:02:00  lr: 0.000057  loss: 3.2205 (3.0485)  time: 0.6358  data: 0.0001  max mem: 8681
Epoch: [24]  [1820/2001]  eta: 0:01:54  lr: 0.000057  loss: 3.0992 (3.0492)  time: 0.6380  data: 0.0001  max mem: 8681
Epoch: [24]  [1830/2001]  eta: 0:01:47  lr: 0.000057  loss: 3.1567 (3.0498)  time: 0.6377  data: 0.0001  max mem: 8681
Epoch: [24]  [1840/2001]  eta: 0:01:41  lr: 0.000057  loss: 3.1436 (3.0493)  time: 0.6361  data: 0.0001  max mem: 8681
Epoch: [24]  [1850/2001]  eta: 0:01:35  lr: 0.000057  loss: 2.8140 (3.0477)  time: 0.6348  data: 0.0001  max mem: 8681
Epoch: [24]  [1860/2001]  eta: 0:01:28  lr: 0.000057  loss: 2.9050 (3.0473)  time: 0.6339  data: 0.0001  max mem: 8681
Epoch: [24]  [1870/2001]  eta: 0:01:22  lr: 0.000057  loss: 2.9769 (3.0462)  time: 0.6343  data: 0.0001  max mem: 8681
Epoch: [24]  [1880/2001]  eta: 0:01:16  lr: 0.000057  loss: 3.2639 (3.0476)  time: 0.6362  data: 0.0001  max mem: 8681
Epoch: [24]  [1890/2001]  eta: 0:01:09  lr: 0.000057  loss: 3.2251 (3.0468)  time: 0.6367  data: 0.0001  max mem: 8681
loss info: cls_loss=2.8907, ratio_loss=0.0440, cls_kl=0.0591, token_kl=0.0908
Epoch: [24]  [1900/2001]  eta: 0:01:03  lr: 0.000057  loss: 2.9456 (3.0462)  time: 0.6406  data: 0.0001  max mem: 8681
Epoch: [24]  [1910/2001]  eta: 0:00:57  lr: 0.000057  loss: 3.0444 (3.0468)  time: 0.6444  data: 0.0001  max mem: 8681
Epoch: [24]  [1920/2001]  eta: 0:00:51  lr: 0.000057  loss: 2.9460 (3.0447)  time: 0.6410  data: 0.0001  max mem: 8681
Epoch: [24]  [1930/2001]  eta: 0:00:44  lr: 0.000057  loss: 2.8273 (3.0443)  time: 0.6371  data: 0.0001  max mem: 8681
Epoch: [24]  [1940/2001]  eta: 0:00:38  lr: 0.000057  loss: 2.9452 (3.0435)  time: 0.6389  data: 0.0001  max mem: 8681
Epoch: [24]  [1950/2001]  eta: 0:00:32  lr: 0.000057  loss: 3.0520 (3.0430)  time: 0.6392  data: 0.0001  max mem: 8681
Epoch: [24]  [1960/2001]  eta: 0:00:25  lr: 0.000057  loss: 3.0707 (3.0423)  time: 0.6374  data: 0.0001  max mem: 8681
Epoch: [24]  [1970/2001]  eta: 0:00:19  lr: 0.000057  loss: 3.0275 (3.0405)  time: 0.6407  data: 0.0001  max mem: 8681
Epoch: [24]  [1980/2001]  eta: 0:00:13  lr: 0.000057  loss: 2.7058 (3.0402)  time: 0.6424  data: 0.0001  max mem: 8681
Epoch: [24]  [1990/2001]  eta: 0:00:06  lr: 0.000057  loss: 3.2240 (3.0397)  time: 0.6386  data: 0.0004  max mem: 8681
loss info: cls_loss=2.7968, ratio_loss=0.0409, cls_kl=0.0595, token_kl=0.0906
Epoch: [24]  [2000/2001]  eta: 0:00:00  lr: 0.000057  loss: 3.1473 (3.0388)  time: 0.6344  data: 0.0003  max mem: 8681
Epoch: [24] Total time: 0:21:03 (0.6313 s / it)
Averaged stats: lr: 0.000057  loss: 3.1473 (3.0435)
Test:  [ 0/53]  eta: 0:04:26  loss: 0.3686 (0.3686)  acc1: 93.3333 (93.3333)  acc5: 99.1667 (99.1667)  time: 5.0202  data: 4.0900  max mem: 8681
Test:  [10/53]  eta: 0:00:36  loss: 0.7362 (0.7707)  acc1: 83.3333 (83.2576)  acc5: 96.6667 (96.6667)  time: 0.8550  data: 0.4014  max mem: 8681
Test:  [20/53]  eta: 0:00:20  loss: 0.7362 (0.7699)  acc1: 83.3333 (83.3730)  acc5: 96.6667 (96.5873)  time: 0.4101  data: 0.0164  max mem: 8681
Test:  [30/53]  eta: 0:00:12  loss: 0.8875 (0.8536)  acc1: 79.1667 (81.0753)  acc5: 95.0000 (95.4570)  time: 0.3551  data: 0.0003  max mem: 8681
Test:  [40/53]  eta: 0:00:06  loss: 1.0672 (0.9169)  acc1: 76.6667 (79.4715)  acc5: 92.5000 (94.7155)  time: 0.3073  data: 0.0002  max mem: 8681
Test:  [50/53]  eta: 0:00:01  loss: 1.0838 (0.9477)  acc1: 76.6667 (78.6765)  acc5: 92.5000 (94.5098)  time: 0.2720  data: 0.0001  max mem: 8681
Test:  [52/53]  eta: 0:00:00  loss: 1.0790 (0.9338)  acc1: 76.6667 (78.8480)  acc5: 92.5000 (94.5760)  time: 0.2554  data: 0.0001  max mem: 8681
Test: Total time: 0:00:22 (0.4221 s / it)
Sparsity0:0.2979280808080808,Sparsity1:0.5601818181818182,Sparsity2:0.7901066666666666,
* Acc@1 79.032 Acc@5 94.470 loss 0.940
Accuracy of the network on the 50000 test images: 79.0%
Max accuracy: 79.03%
## Using lr  0.0000050 for BACKBONE, cosine lr = 0.0000428 for PREDICTOR
Epoch: [25]  [   0/2001]  eta: 2:35:06  lr: 0.000043  loss: 2.8539 (2.8539)  time: 4.6510  data: 4.0321  max mem: 8683
Epoch: [25]  [  10/2001]  eta: 0:33:03  lr: 0.000043  loss: 3.3626 (3.2850)  time: 0.9964  data: 0.3667  max mem: 8683
Epoch: [25]  [  20/2001]  eta: 0:27:09  lr: 0.000043  loss: 3.1449 (3.1618)  time: 0.6313  data: 0.0001  max mem: 8683
Epoch: [25]  [  30/2001]  eta: 0:25:03  lr: 0.000043  loss: 3.1546 (3.2114)  time: 0.6346  data: 0.0002  max mem: 8683
Epoch: [25]  [  40/2001]  eta: 0:23:51  lr: 0.000043  loss: 3.2833 (3.1870)  time: 0.6324  data: 0.0002  max mem: 8683
Epoch: [25]  [  50/2001]  eta: 0:23:06  lr: 0.000043  loss: 3.1080 (3.1419)  time: 0.6294  data: 0.0002  max mem: 8683
Epoch: [25]  [  60/2001]  eta: 0:22:34  lr: 0.000043  loss: 2.9471 (3.0920)  time: 0.6325  data: 0.0002  max mem: 8683
Epoch: [25]  [  70/2001]  eta: 0:22:10  lr: 0.000043  loss: 3.0328 (3.1142)  time: 0.6346  data: 0.0002  max mem: 8683
Epoch: [25]  [  80/2001]  eta: 0:21:52  lr: 0.000043  loss: 3.1376 (3.0988)  time: 0.6373  data: 0.0002  max mem: 8683
Epoch: [25]  [  90/2001]  eta: 0:21:35  lr: 0.000043  loss: 3.1607 (3.1153)  time: 0.6381  data: 0.0002  max mem: 8683
loss info: cls_loss=2.9890, ratio_loss=0.0450, cls_kl=0.0635, token_kl=0.0940
Epoch: [25]  [ 100/2001]  eta: 0:21:20  lr: 0.000043  loss: 3.1748 (3.0977)  time: 0.6366  data: 0.0002  max mem: 8683
Epoch: [25]  [ 110/2001]  eta: 0:21:07  lr: 0.000043  loss: 3.0728 (3.1112)  time: 0.6360  data: 0.0002  max mem: 8683
Epoch: [25]  [ 120/2001]  eta: 0:20:56  lr: 0.000043  loss: 3.1096 (3.1003)  time: 0.6373  data: 0.0002  max mem: 8683
Epoch: [25]  [ 130/2001]  eta: 0:20:45  lr: 0.000043  loss: 3.1027 (3.0962)  time: 0.6388  data: 0.0002  max mem: 8683
Epoch: [25]  [ 140/2001]  eta: 0:20:35  lr: 0.000043  loss: 3.2480 (3.1057)  time: 0.6386  data: 0.0002  max mem: 8683
Epoch: [25]  [ 150/2001]  eta: 0:20:26  lr: 0.000043  loss: 3.3015 (3.1073)  time: 0.6417  data: 0.0002  max mem: 8683
Epoch: [25]  [ 160/2001]  eta: 0:20:17  lr: 0.000043  loss: 3.3155 (3.1118)  time: 0.6446  data: 0.0002  max mem: 8683
Epoch: [25]  [ 170/2001]  eta: 0:20:07  lr: 0.000043  loss: 3.2271 (3.1159)  time: 0.6395  data: 0.0002  max mem: 8683
Epoch: [25]  [ 180/2001]  eta: 0:19:58  lr: 0.000043  loss: 3.1632 (3.1128)  time: 0.6339  data: 0.0002  max mem: 8683
Epoch: [25]  [ 190/2001]  eta: 0:19:50  lr: 0.000043  loss: 3.1299 (3.1194)  time: 0.6350  data: 0.0001  max mem: 8683
loss info: cls_loss=3.0068, ratio_loss=0.0450, cls_kl=0.0636, token_kl=0.0931
Epoch: [25]  [ 200/2001]  eta: 0:19:41  lr: 0.000043  loss: 3.1299 (3.1081)  time: 0.6359  data: 0.0001  max mem: 8683
Epoch: [25]  [ 210/2001]  eta: 0:19:32  lr: 0.000043  loss: 3.0299 (3.1047)  time: 0.6334  data: 0.0001  max mem: 8683
Epoch: [25]  [ 220/2001]  eta: 0:19:24  lr: 0.000043  loss: 2.8722 (3.0965)  time: 0.6345  data: 0.0001  max mem: 8683
Epoch: [25]  [ 230/2001]  eta: 0:19:16  lr: 0.000043  loss: 2.8527 (3.0854)  time: 0.6347  data: 0.0001  max mem: 8683
Epoch: [25]  [ 240/2001]  eta: 0:19:08  lr: 0.000043  loss: 3.0478 (3.0801)  time: 0.6328  data: 0.0002  max mem: 8683
Epoch: [25]  [ 250/2001]  eta: 0:19:00  lr: 0.000043  loss: 3.0281 (3.0732)  time: 0.6322  data: 0.0002  max mem: 8683
Epoch: [25]  [ 260/2001]  eta: 0:18:52  lr: 0.000043  loss: 2.8091 (3.0677)  time: 0.6307  data: 0.0002  max mem: 8683
Epoch: [25]  [ 270/2001]  eta: 0:18:45  lr: 0.000043  loss: 3.0637 (3.0696)  time: 0.6314  data: 0.0002  max mem: 8683
Epoch: [25]  [ 280/2001]  eta: 0:18:37  lr: 0.000043  loss: 3.2321 (3.0749)  time: 0.6320  data: 0.0002  max mem: 8683
Epoch: [25]  [ 290/2001]  eta: 0:18:29  lr: 0.000043  loss: 3.2471 (3.0718)  time: 0.6288  data: 0.0001  max mem: 8683
loss info: cls_loss=2.8876, ratio_loss=0.0419, cls_kl=0.0617, token_kl=0.0922
Epoch: [25]  [ 300/2001]  eta: 0:18:22  lr: 0.000043  loss: 2.8941 (3.0633)  time: 0.6288  data: 0.0002  max mem: 8683
Epoch: [25]  [ 310/2001]  eta: 0:18:14  lr: 0.000043  loss: 2.9546 (3.0610)  time: 0.6326  data: 0.0002  max mem: 8683
Epoch: [25]  [ 320/2001]  eta: 0:18:07  lr: 0.000043  loss: 3.1186 (3.0664)  time: 0.6298  data: 0.0001  max mem: 8683
Epoch: [25]  [ 330/2001]  eta: 0:18:00  lr: 0.000043  loss: 3.1990 (3.0724)  time: 0.6284  data: 0.0001  max mem: 8683
Epoch: [25]  [ 340/2001]  eta: 0:17:52  lr: 0.000043  loss: 3.1546 (3.0713)  time: 0.6300  data: 0.0001  max mem: 8683
Epoch: [25]  [ 350/2001]  eta: 0:17:45  lr: 0.000043  loss: 3.0974 (3.0718)  time: 0.6326  data: 0.0002  max mem: 8683
Epoch: [25]  [ 360/2001]  eta: 0:17:38  lr: 0.000043  loss: 3.0220 (3.0679)  time: 0.6348  data: 0.0002  max mem: 8683
Epoch: [25]  [ 370/2001]  eta: 0:17:31  lr: 0.000043  loss: 2.9173 (3.0653)  time: 0.6331  data: 0.0002  max mem: 8683
Epoch: [25]  [ 380/2001]  eta: 0:17:24  lr: 0.000043  loss: 3.0706 (3.0658)  time: 0.6324  data: 0.0001  max mem: 8683
Epoch: [25]  [ 390/2001]  eta: 0:17:17  lr: 0.000043  loss: 3.1801 (3.0599)  time: 0.6283  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9174, ratio_loss=0.0437, cls_kl=0.0623, token_kl=0.0928
Epoch: [25]  [ 400/2001]  eta: 0:17:10  lr: 0.000043  loss: 2.7261 (3.0589)  time: 0.6276  data: 0.0002  max mem: 8683
Epoch: [25]  [ 410/2001]  eta: 0:17:03  lr: 0.000043  loss: 3.2629 (3.0634)  time: 0.6257  data: 0.0001  max mem: 8683
Epoch: [25]  [ 420/2001]  eta: 0:16:56  lr: 0.000043  loss: 3.2113 (3.0582)  time: 0.6299  data: 0.0002  max mem: 8683
Epoch: [25]  [ 430/2001]  eta: 0:16:49  lr: 0.000043  loss: 2.9795 (3.0585)  time: 0.6371  data: 0.0001  max mem: 8683
Epoch: [25]  [ 440/2001]  eta: 0:16:43  lr: 0.000043  loss: 3.0653 (3.0596)  time: 0.6324  data: 0.0001  max mem: 8683
Epoch: [25]  [ 450/2001]  eta: 0:16:36  lr: 0.000043  loss: 3.2437 (3.0649)  time: 0.6271  data: 0.0002  max mem: 8683
Epoch: [25]  [ 460/2001]  eta: 0:16:29  lr: 0.000043  loss: 3.1900 (3.0623)  time: 0.6263  data: 0.0002  max mem: 8683
Epoch: [25]  [ 470/2001]  eta: 0:16:22  lr: 0.000043  loss: 3.1571 (3.0618)  time: 0.6272  data: 0.0001  max mem: 8683
Epoch: [25]  [ 480/2001]  eta: 0:16:15  lr: 0.000043  loss: 2.8250 (3.0600)  time: 0.6264  data: 0.0001  max mem: 8683
Epoch: [25]  [ 490/2001]  eta: 0:16:08  lr: 0.000043  loss: 3.2509 (3.0660)  time: 0.6251  data: 0.0002  max mem: 8683
loss info: cls_loss=2.9656, ratio_loss=0.0448, cls_kl=0.0637, token_kl=0.0932
Epoch: [25]  [ 500/2001]  eta: 0:16:01  lr: 0.000043  loss: 3.0625 (3.0587)  time: 0.6261  data: 0.0002  max mem: 8683
Epoch: [25]  [ 510/2001]  eta: 0:15:54  lr: 0.000043  loss: 2.7280 (3.0577)  time: 0.6261  data: 0.0001  max mem: 8683
Epoch: [25]  [ 520/2001]  eta: 0:15:47  lr: 0.000043  loss: 2.9958 (3.0582)  time: 0.6267  data: 0.0002  max mem: 8683
Epoch: [25]  [ 530/2001]  eta: 0:15:41  lr: 0.000043  loss: 3.2327 (3.0604)  time: 0.6278  data: 0.0001  max mem: 8683
Epoch: [25]  [ 540/2001]  eta: 0:15:34  lr: 0.000043  loss: 3.0640 (3.0581)  time: 0.6287  data: 0.0002  max mem: 8683
Epoch: [25]  [ 550/2001]  eta: 0:15:27  lr: 0.000043  loss: 3.0076 (3.0610)  time: 0.6295  data: 0.0002  max mem: 8683
Epoch: [25]  [ 560/2001]  eta: 0:15:21  lr: 0.000043  loss: 3.3871 (3.0670)  time: 0.6301  data: 0.0001  max mem: 8683
Epoch: [25]  [ 570/2001]  eta: 0:15:14  lr: 0.000043  loss: 3.2264 (3.0679)  time: 0.6318  data: 0.0001  max mem: 8683
Epoch: [25]  [ 580/2001]  eta: 0:15:08  lr: 0.000043  loss: 3.1924 (3.0688)  time: 0.6361  data: 0.0001  max mem: 8683
Epoch: [25]  [ 590/2001]  eta: 0:15:01  lr: 0.000043  loss: 3.0885 (3.0666)  time: 0.6380  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9850, ratio_loss=0.0455, cls_kl=0.0627, token_kl=0.0925
Epoch: [25]  [ 600/2001]  eta: 0:14:55  lr: 0.000043  loss: 3.0959 (3.0666)  time: 0.6304  data: 0.0001  max mem: 8683
Epoch: [25]  [ 610/2001]  eta: 0:14:48  lr: 0.000043  loss: 3.0281 (3.0625)  time: 0.6256  data: 0.0002  max mem: 8683
Epoch: [25]  [ 620/2001]  eta: 0:14:41  lr: 0.000043  loss: 3.0281 (3.0637)  time: 0.6260  data: 0.0002  max mem: 8683
Epoch: [25]  [ 630/2001]  eta: 0:14:35  lr: 0.000043  loss: 3.0953 (3.0630)  time: 0.6253  data: 0.0002  max mem: 8683
Epoch: [25]  [ 640/2001]  eta: 0:14:28  lr: 0.000043  loss: 3.2438 (3.0643)  time: 0.6273  data: 0.0001  max mem: 8683
Epoch: [25]  [ 650/2001]  eta: 0:14:21  lr: 0.000043  loss: 3.1539 (3.0613)  time: 0.6277  data: 0.0001  max mem: 8683
Epoch: [25]  [ 660/2001]  eta: 0:14:15  lr: 0.000043  loss: 3.1539 (3.0626)  time: 0.6251  data: 0.0001  max mem: 8683
Epoch: [25]  [ 670/2001]  eta: 0:14:08  lr: 0.000043  loss: 3.2225 (3.0635)  time: 0.6270  data: 0.0001  max mem: 8683
Epoch: [25]  [ 680/2001]  eta: 0:14:02  lr: 0.000043  loss: 3.1610 (3.0649)  time: 0.6314  data: 0.0002  max mem: 8683
Epoch: [25]  [ 690/2001]  eta: 0:13:55  lr: 0.000043  loss: 3.1608 (3.0674)  time: 0.6298  data: 0.0002  max mem: 8683
loss info: cls_loss=2.9689, ratio_loss=0.0460, cls_kl=0.0633, token_kl=0.0916
Epoch: [25]  [ 700/2001]  eta: 0:13:49  lr: 0.000043  loss: 3.2552 (3.0680)  time: 0.6288  data: 0.0001  max mem: 8683
Epoch: [25]  [ 710/2001]  eta: 0:13:42  lr: 0.000043  loss: 3.3147 (3.0729)  time: 0.6321  data: 0.0002  max mem: 8683
Epoch: [25]  [ 720/2001]  eta: 0:13:36  lr: 0.000043  loss: 3.1513 (3.0713)  time: 0.6297  data: 0.0002  max mem: 8683
Epoch: [25]  [ 730/2001]  eta: 0:13:29  lr: 0.000043  loss: 3.1489 (3.0749)  time: 0.6258  data: 0.0002  max mem: 8683
Epoch: [25]  [ 740/2001]  eta: 0:13:23  lr: 0.000043  loss: 3.1296 (3.0712)  time: 0.6271  data: 0.0001  max mem: 8683
Epoch: [25]  [ 750/2001]  eta: 0:13:16  lr: 0.000043  loss: 2.9506 (3.0714)  time: 0.6273  data: 0.0001  max mem: 8683
Epoch: [25]  [ 760/2001]  eta: 0:13:09  lr: 0.000043  loss: 3.0950 (3.0689)  time: 0.6265  data: 0.0001  max mem: 8683
Epoch: [25]  [ 770/2001]  eta: 0:13:03  lr: 0.000043  loss: 3.2951 (3.0711)  time: 0.6290  data: 0.0001  max mem: 8683
Epoch: [25]  [ 780/2001]  eta: 0:12:56  lr: 0.000043  loss: 3.1153 (3.0702)  time: 0.6281  data: 0.0002  max mem: 8683
Epoch: [25]  [ 790/2001]  eta: 0:12:50  lr: 0.000043  loss: 2.8946 (3.0685)  time: 0.6273  data: 0.0002  max mem: 8683
loss info: cls_loss=2.9627, ratio_loss=0.0441, cls_kl=0.0618, token_kl=0.0920
Epoch: [25]  [ 800/2001]  eta: 0:12:44  lr: 0.000043  loss: 2.8797 (3.0671)  time: 0.6323  data: 0.0002  max mem: 8683
Epoch: [25]  [ 810/2001]  eta: 0:12:37  lr: 0.000043  loss: 3.2115 (3.0684)  time: 0.6335  data: 0.0001  max mem: 8683
Epoch: [25]  [ 820/2001]  eta: 0:12:31  lr: 0.000043  loss: 3.3967 (3.0702)  time: 0.6289  data: 0.0001  max mem: 8683
Epoch: [25]  [ 830/2001]  eta: 0:12:24  lr: 0.000043  loss: 3.2687 (3.0689)  time: 0.6283  data: 0.0001  max mem: 8683
Epoch: [25]  [ 840/2001]  eta: 0:12:18  lr: 0.000043  loss: 2.9604 (3.0684)  time: 0.6287  data: 0.0001  max mem: 8683
Epoch: [25]  [ 850/2001]  eta: 0:12:12  lr: 0.000043  loss: 2.9085 (3.0673)  time: 0.6362  data: 0.0001  max mem: 8683
Epoch: [25]  [ 860/2001]  eta: 0:12:05  lr: 0.000043  loss: 2.7186 (3.0601)  time: 0.6424  data: 0.0001  max mem: 8683
Epoch: [25]  [ 870/2001]  eta: 0:11:59  lr: 0.000043  loss: 2.5206 (3.0575)  time: 0.6347  data: 0.0001  max mem: 8683
Epoch: [25]  [ 880/2001]  eta: 0:11:52  lr: 0.000043  loss: 3.0937 (3.0571)  time: 0.6301  data: 0.0001  max mem: 8683
Loss is nan, stopping training
Traceback (most recent call last):
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 256, in main
    cmd=cmd)
subprocess.CalledProcessError: Command '['/home/zlkong/anaconda3/envs/DynamicVit/bin/python3', '-u', 'main_l2_vit.py', '--output_dir', 'logs/no-amp', '--arch', 'deit_small', '--input-size', '224', '--batch-size', '80', '--data-path', '/data/ImageNet_new/', '--epochs', '30', '--dist-eval', '--distill', '--base_rate', '0.7', '--resume', 'logs/no-amp/checkpoint.pth']' returned non-zero exit status 1.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 3): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 4): env://
| distributed init (rank 2): env://
| distributed init (rank 6): env://
| distributed init (rank 5): env://
| distributed init (rank 7): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp/checkpoint.pth', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
Traceback (most recent call last):
  File "main_l2_vit.py", line 569, in <module>
    main(args)
  File "main_l2_vit.py", line 414, in main
    model.to(device)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 612, in to
    return self._apply(convert)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 359, in _apply
    module._apply(fn)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 359, in _apply
    module._apply(fn)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 359, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 381, in _apply
    param_applied = fn(param)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 610, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 4; 10.76 GiB total capacity; 103.92 MiB already allocated; 13.56 MiB free; 110.00 MiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "main_l2_vit.py", line 569, in <module>
    main(args)
  File "main_l2_vit.py", line 414, in main
    model.to(device)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 612, in to
    return self._apply(convert)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 359, in _apply
    module._apply(fn)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 359, in _apply
    module._apply(fn)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 359, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 381, in _apply
    param_applied = fn(param)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 610, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 5; 10.76 GiB total capacity; 103.92 MiB already allocated; 13.56 MiB free; 110.00 MiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "main_l2_vit.py", line 569, in <module>
    main(args)
  File "main_l2_vit.py", line 414, in main
    model.to(device)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 612, in to
    return self._apply(convert)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 359, in _apply
    module._apply(fn)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 359, in _apply
    module._apply(fn)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 359, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 381, in _apply
    param_applied = fn(param)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 610, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 1; 10.76 GiB total capacity; 103.92 MiB already allocated; 13.56 MiB free; 110.00 MiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "main_l2_vit.py", line 569, in <module>
    main(args)
  File "main_l2_vit.py", line 414, in main
    model.to(device)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 612, in to
    return self._apply(convert)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 359, in _apply
    module._apply(fn)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 359, in _apply
    module._apply(fn)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 359, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 381, in _apply
    param_applied = fn(param)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 610, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 7; 10.76 GiB total capacity; 103.92 MiB already allocated; 13.56 MiB free; 110.00 MiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "main_l2_vit.py", line 569, in <module>
    main(args)
  File "main_l2_vit.py", line 414, in main
    model.to(device)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 612, in to
    return self._apply(convert)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 359, in _apply
    module._apply(fn)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 359, in _apply
    module._apply(fn)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 359, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 381, in _apply
    param_applied = fn(param)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 610, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 2; 10.76 GiB total capacity; 103.92 MiB already allocated; 13.56 MiB free; 110.00 MiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "main_l2_vit.py", line 569, in <module>
    main(args)
  File "main_l2_vit.py", line 414, in main
    model.to(device)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 612, in to
    return self._apply(convert)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 359, in _apply
    module._apply(fn)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 359, in _apply
    module._apply(fn)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 359, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 381, in _apply
    param_applied = fn(param)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 610, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 3; 10.76 GiB total capacity; 103.92 MiB already allocated; 13.56 MiB free; 110.00 MiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "main_l2_vit.py", line 569, in <module>
    main(args)
  File "main_l2_vit.py", line 414, in main
    model.to(device)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 612, in to
    return self._apply(convert)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 359, in _apply
    module._apply(fn)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 359, in _apply
    module._apply(fn)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 359, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 381, in _apply
    param_applied = fn(param)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/nn/modules/module.py", line 610, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 6; 10.76 GiB total capacity; 103.92 MiB already allocated; 13.56 MiB free; 110.00 MiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 253, in main
    process.wait()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/subprocess.py", line 1477, in wait
    (pid, sts) = self._try_wait(0)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/subprocess.py", line 1424, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 5): env://
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
| distributed init (rank 4): env://
| distributed init (rank 6): env://
| distributed init (rank 1): env://
| distributed init (rank 7): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp/checkpoint.pth', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000050 for BACKBONE, cosine lr = 0.0000428 for PREDICTOR
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Epoch: [25]  [   0/2001]  eta: 3:43:41  lr: 0.000043  loss: 3.7515 (3.7515)  time: 6.7076  data: 3.9511  max mem: 8604
Epoch: [25]  [  10/2001]  eta: 0:38:36  lr: 0.000043  loss: 3.5180 (3.3302)  time: 1.1636  data: 0.3593  max mem: 8681
Epoch: [25]  [  20/2001]  eta: 0:29:23  lr: 0.000043  loss: 3.3086 (3.2722)  time: 0.5991  data: 0.0001  max mem: 8681
Epoch: [25]  [  30/2001]  eta: 0:26:06  lr: 0.000043  loss: 3.3471 (3.3287)  time: 0.5923  data: 0.0001  max mem: 8681
Epoch: [25]  [  40/2001]  eta: 0:24:18  lr: 0.000043  loss: 3.2687 (3.2726)  time: 0.5899  data: 0.0001  max mem: 8681
Epoch: [25]  [  50/2001]  eta: 0:23:11  lr: 0.000043  loss: 3.2531 (3.2596)  time: 0.5867  data: 0.0001  max mem: 8681
Epoch: [25]  [  60/2001]  eta: 0:22:27  lr: 0.000043  loss: 3.2783 (3.2268)  time: 0.5927  data: 0.0001  max mem: 8681
Epoch: [25]  [  70/2001]  eta: 0:21:52  lr: 0.000043  loss: 3.1833 (3.1843)  time: 0.5939  data: 0.0001  max mem: 8681
Epoch: [25]  [  80/2001]  eta: 0:21:25  lr: 0.000043  loss: 3.1039 (3.1689)  time: 0.5933  data: 0.0001  max mem: 8681
Epoch: [25]  [  90/2001]  eta: 0:21:06  lr: 0.000043  loss: 3.0379 (3.1497)  time: 0.6015  data: 0.0001  max mem: 8681
loss info: cls_loss=3.0451, ratio_loss=0.0465, cls_kl=0.0645, token_kl=0.0946
Epoch: [25]  [ 100/2001]  eta: 0:20:48  lr: 0.000043  loss: 3.2746 (3.1585)  time: 0.6051  data: 0.0001  max mem: 8681
Epoch: [25]  [ 110/2001]  eta: 0:20:32  lr: 0.000043  loss: 3.3892 (3.1608)  time: 0.6037  data: 0.0001  max mem: 8681
Epoch: [25]  [ 120/2001]  eta: 0:20:19  lr: 0.000043  loss: 3.2249 (3.1540)  time: 0.6080  data: 0.0001  max mem: 8681
Epoch: [25]  [ 130/2001]  eta: 0:20:07  lr: 0.000043  loss: 3.0497 (3.1376)  time: 0.6101  data: 0.0001  max mem: 8681
Epoch: [25]  [ 140/2001]  eta: 0:19:56  lr: 0.000043  loss: 3.0146 (3.1292)  time: 0.6096  data: 0.0001  max mem: 8681
Epoch: [25]  [ 150/2001]  eta: 0:19:46  lr: 0.000043  loss: 3.1115 (3.1279)  time: 0.6128  data: 0.0001  max mem: 8681
Epoch: [25]  [ 160/2001]  eta: 0:19:37  lr: 0.000043  loss: 3.1115 (3.1331)  time: 0.6142  data: 0.0001  max mem: 8681
Epoch: [25]  [ 170/2001]  eta: 0:19:28  lr: 0.000043  loss: 3.1823 (3.1275)  time: 0.6131  data: 0.0001  max mem: 8681
Epoch: [25]  [ 180/2001]  eta: 0:19:19  lr: 0.000043  loss: 3.1403 (3.1117)  time: 0.6137  data: 0.0001  max mem: 8681
Epoch: [25]  [ 190/2001]  eta: 0:19:11  lr: 0.000043  loss: 2.8767 (3.1097)  time: 0.6185  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9393, ratio_loss=0.0425, cls_kl=0.0626, token_kl=0.0930
Epoch: [25]  [ 200/2001]  eta: 0:19:03  lr: 0.000043  loss: 2.9666 (3.0994)  time: 0.6186  data: 0.0001  max mem: 8681
Epoch: [25]  [ 210/2001]  eta: 0:18:55  lr: 0.000043  loss: 3.0201 (3.0921)  time: 0.6136  data: 0.0001  max mem: 8681
Epoch: [25]  [ 220/2001]  eta: 0:18:48  lr: 0.000043  loss: 3.0201 (3.0846)  time: 0.6193  data: 0.0001  max mem: 8681
Epoch: [25]  [ 230/2001]  eta: 0:18:40  lr: 0.000043  loss: 3.0744 (3.0804)  time: 0.6236  data: 0.0001  max mem: 8681
Epoch: [25]  [ 240/2001]  eta: 0:18:33  lr: 0.000043  loss: 3.0744 (3.0795)  time: 0.6191  data: 0.0001  max mem: 8681
Epoch: [25]  [ 250/2001]  eta: 0:18:25  lr: 0.000043  loss: 3.0269 (3.0710)  time: 0.6166  data: 0.0001  max mem: 8681
Epoch: [25]  [ 260/2001]  eta: 0:18:19  lr: 0.000043  loss: 2.8909 (3.0583)  time: 0.6212  data: 0.0001  max mem: 8681
Epoch: [25]  [ 270/2001]  eta: 0:18:12  lr: 0.000043  loss: 2.7923 (3.0523)  time: 0.6224  data: 0.0001  max mem: 8681
Epoch: [25]  [ 280/2001]  eta: 0:18:05  lr: 0.000043  loss: 3.0599 (3.0564)  time: 0.6211  data: 0.0001  max mem: 8681
Epoch: [25]  [ 290/2001]  eta: 0:17:58  lr: 0.000043  loss: 3.1223 (3.0480)  time: 0.6243  data: 0.0001  max mem: 8681
loss info: cls_loss=2.8049, ratio_loss=0.0415, cls_kl=0.0596, token_kl=0.0915
Epoch: [25]  [ 300/2001]  eta: 0:17:52  lr: 0.000043  loss: 2.7377 (3.0356)  time: 0.6250  data: 0.0001  max mem: 8681
Epoch: [25]  [ 310/2001]  eta: 0:17:45  lr: 0.000043  loss: 2.8996 (3.0349)  time: 0.6255  data: 0.0001  max mem: 8681
Epoch: [25]  [ 320/2001]  eta: 0:17:38  lr: 0.000043  loss: 3.2096 (3.0455)  time: 0.6241  data: 0.0001  max mem: 8681
Epoch: [25]  [ 330/2001]  eta: 0:17:32  lr: 0.000043  loss: 3.2862 (3.0446)  time: 0.6241  data: 0.0001  max mem: 8681
Epoch: [25]  [ 340/2001]  eta: 0:17:25  lr: 0.000043  loss: 3.1743 (3.0495)  time: 0.6276  data: 0.0001  max mem: 8681
Epoch: [25]  [ 350/2001]  eta: 0:17:19  lr: 0.000043  loss: 3.1743 (3.0528)  time: 0.6304  data: 0.0001  max mem: 8681
Epoch: [25]  [ 360/2001]  eta: 0:17:13  lr: 0.000043  loss: 3.0132 (3.0541)  time: 0.6326  data: 0.0001  max mem: 8681
Epoch: [25]  [ 370/2001]  eta: 0:17:07  lr: 0.000043  loss: 3.0980 (3.0508)  time: 0.6305  data: 0.0001  max mem: 8681
Epoch: [25]  [ 380/2001]  eta: 0:17:00  lr: 0.000043  loss: 3.1231 (3.0472)  time: 0.6284  data: 0.0001  max mem: 8681
Epoch: [25]  [ 390/2001]  eta: 0:16:54  lr: 0.000043  loss: 3.0396 (3.0414)  time: 0.6279  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9614, ratio_loss=0.0450, cls_kl=0.0640, token_kl=0.0934
Epoch: [25]  [ 400/2001]  eta: 0:16:48  lr: 0.000043  loss: 3.0396 (3.0459)  time: 0.6269  data: 0.0001  max mem: 8681
Epoch: [25]  [ 410/2001]  eta: 0:16:41  lr: 0.000043  loss: 3.2584 (3.0505)  time: 0.6260  data: 0.0001  max mem: 8681
Epoch: [25]  [ 420/2001]  eta: 0:16:35  lr: 0.000043  loss: 3.1277 (3.0462)  time: 0.6287  data: 0.0001  max mem: 8681
Epoch: [25]  [ 430/2001]  eta: 0:16:29  lr: 0.000043  loss: 3.1763 (3.0505)  time: 0.6309  data: 0.0001  max mem: 8681
Epoch: [25]  [ 440/2001]  eta: 0:16:22  lr: 0.000043  loss: 3.2757 (3.0539)  time: 0.6288  data: 0.0001  max mem: 8681
Epoch: [25]  [ 450/2001]  eta: 0:16:16  lr: 0.000043  loss: 3.0459 (3.0520)  time: 0.6277  data: 0.0001  max mem: 8681
Epoch: [25]  [ 460/2001]  eta: 0:16:10  lr: 0.000043  loss: 2.8520 (3.0460)  time: 0.6323  data: 0.0001  max mem: 8681
Epoch: [25]  [ 470/2001]  eta: 0:16:03  lr: 0.000043  loss: 2.6077 (3.0377)  time: 0.6318  data: 0.0001  max mem: 8681
Epoch: [25]  [ 480/2001]  eta: 0:15:57  lr: 0.000043  loss: 2.8764 (3.0360)  time: 0.6270  data: 0.0001  max mem: 8681
Epoch: [25]  [ 490/2001]  eta: 0:15:51  lr: 0.000043  loss: 3.1488 (3.0423)  time: 0.6276  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9042, ratio_loss=0.0455, cls_kl=0.0642, token_kl=0.0951
Epoch: [25]  [ 500/2001]  eta: 0:15:44  lr: 0.000043  loss: 3.0147 (3.0384)  time: 0.6283  data: 0.0001  max mem: 8681
Epoch: [25]  [ 510/2001]  eta: 0:15:38  lr: 0.000043  loss: 3.0480 (3.0422)  time: 0.6307  data: 0.0001  max mem: 8681
Epoch: [25]  [ 520/2001]  eta: 0:15:32  lr: 0.000043  loss: 3.2517 (3.0426)  time: 0.6302  data: 0.0001  max mem: 8681
Epoch: [25]  [ 530/2001]  eta: 0:15:26  lr: 0.000043  loss: 3.1435 (3.0379)  time: 0.6274  data: 0.0001  max mem: 8681
Epoch: [25]  [ 540/2001]  eta: 0:15:19  lr: 0.000043  loss: 2.9901 (3.0372)  time: 0.6297  data: 0.0001  max mem: 8681
Epoch: [25]  [ 550/2001]  eta: 0:15:13  lr: 0.000043  loss: 3.1660 (3.0365)  time: 0.6296  data: 0.0001  max mem: 8681
Epoch: [25]  [ 560/2001]  eta: 0:15:07  lr: 0.000043  loss: 3.2319 (3.0415)  time: 0.6277  data: 0.0001  max mem: 8681
Epoch: [25]  [ 570/2001]  eta: 0:15:00  lr: 0.000043  loss: 3.2280 (3.0428)  time: 0.6294  data: 0.0001  max mem: 8681
Epoch: [25]  [ 580/2001]  eta: 0:14:54  lr: 0.000043  loss: 3.1817 (3.0441)  time: 0.6328  data: 0.0001  max mem: 8681
Epoch: [25]  [ 590/2001]  eta: 0:14:48  lr: 0.000043  loss: 3.2889 (3.0461)  time: 0.6345  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9793, ratio_loss=0.0463, cls_kl=0.0629, token_kl=0.0930
Epoch: [25]  [ 600/2001]  eta: 0:14:42  lr: 0.000043  loss: 3.2104 (3.0447)  time: 0.6311  data: 0.0001  max mem: 8681
Epoch: [25]  [ 610/2001]  eta: 0:14:35  lr: 0.000043  loss: 3.1249 (3.0456)  time: 0.6287  data: 0.0001  max mem: 8681
Epoch: [25]  [ 620/2001]  eta: 0:14:29  lr: 0.000043  loss: 3.1355 (3.0483)  time: 0.6361  data: 0.0001  max mem: 8681
Epoch: [25]  [ 630/2001]  eta: 0:14:23  lr: 0.000043  loss: 3.1151 (3.0483)  time: 0.6395  data: 0.0001  max mem: 8681
Epoch: [25]  [ 640/2001]  eta: 0:14:17  lr: 0.000043  loss: 3.0665 (3.0466)  time: 0.6350  data: 0.0001  max mem: 8681
Epoch: [25]  [ 650/2001]  eta: 0:14:11  lr: 0.000043  loss: 3.0665 (3.0463)  time: 0.6350  data: 0.0001  max mem: 8681
Epoch: [25]  [ 660/2001]  eta: 0:14:05  lr: 0.000043  loss: 2.8738 (3.0410)  time: 0.6340  data: 0.0001  max mem: 8681
Epoch: [25]  [ 670/2001]  eta: 0:13:58  lr: 0.000043  loss: 3.0809 (3.0446)  time: 0.6336  data: 0.0001  max mem: 8681
Epoch: [25]  [ 680/2001]  eta: 0:13:52  lr: 0.000043  loss: 3.1322 (3.0444)  time: 0.6330  data: 0.0001  max mem: 8681
Epoch: [25]  [ 690/2001]  eta: 0:13:46  lr: 0.000043  loss: 2.8755 (3.0407)  time: 0.6320  data: 0.0001  max mem: 8681
loss info: cls_loss=2.8739, ratio_loss=0.0455, cls_kl=0.0647, token_kl=0.0944
Epoch: [25]  [ 700/2001]  eta: 0:13:40  lr: 0.000043  loss: 2.8730 (3.0384)  time: 0.6332  data: 0.0001  max mem: 8681
Epoch: [25]  [ 710/2001]  eta: 0:13:33  lr: 0.000043  loss: 3.2714 (3.0377)  time: 0.6331  data: 0.0001  max mem: 8681
Epoch: [25]  [ 720/2001]  eta: 0:13:27  lr: 0.000043  loss: 3.1892 (3.0348)  time: 0.6333  data: 0.0001  max mem: 8681
Epoch: [25]  [ 730/2001]  eta: 0:13:21  lr: 0.000043  loss: 3.0622 (3.0356)  time: 0.6335  data: 0.0001  max mem: 8681
Epoch: [25]  [ 740/2001]  eta: 0:13:15  lr: 0.000043  loss: 3.3336 (3.0397)  time: 0.6327  data: 0.0001  max mem: 8681
Epoch: [25]  [ 750/2001]  eta: 0:13:08  lr: 0.000043  loss: 3.2920 (3.0388)  time: 0.6317  data: 0.0001  max mem: 8681
Epoch: [25]  [ 760/2001]  eta: 0:13:02  lr: 0.000043  loss: 3.3652 (3.0394)  time: 0.6322  data: 0.0001  max mem: 8681
Epoch: [25]  [ 770/2001]  eta: 0:12:56  lr: 0.000043  loss: 3.3124 (3.0412)  time: 0.6326  data: 0.0001  max mem: 8681
Epoch: [25]  [ 780/2001]  eta: 0:12:49  lr: 0.000043  loss: 3.0531 (3.0412)  time: 0.6337  data: 0.0001  max mem: 8681
Epoch: [25]  [ 790/2001]  eta: 0:12:43  lr: 0.000043  loss: 3.0371 (3.0404)  time: 0.6346  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9510, ratio_loss=0.0450, cls_kl=0.0634, token_kl=0.0930
Epoch: [25]  [ 800/2001]  eta: 0:12:37  lr: 0.000043  loss: 3.0910 (3.0415)  time: 0.6339  data: 0.0001  max mem: 8681
Epoch: [25]  [ 810/2001]  eta: 0:12:31  lr: 0.000043  loss: 2.9392 (3.0362)  time: 0.6347  data: 0.0001  max mem: 8681
Epoch: [25]  [ 820/2001]  eta: 0:12:24  lr: 0.000043  loss: 2.9392 (3.0382)  time: 0.6355  data: 0.0001  max mem: 8681
Epoch: [25]  [ 830/2001]  eta: 0:12:18  lr: 0.000043  loss: 3.3087 (3.0347)  time: 0.6346  data: 0.0001  max mem: 8681
Epoch: [25]  [ 840/2001]  eta: 0:12:12  lr: 0.000043  loss: 2.6410 (3.0341)  time: 0.6324  data: 0.0001  max mem: 8681
Epoch: [25]  [ 850/2001]  eta: 0:12:06  lr: 0.000043  loss: 3.1964 (3.0342)  time: 0.6340  data: 0.0001  max mem: 8681
Epoch: [25]  [ 860/2001]  eta: 0:11:59  lr: 0.000043  loss: 3.2700 (3.0337)  time: 0.6387  data: 0.0001  max mem: 8681
Epoch: [25]  [ 870/2001]  eta: 0:11:53  lr: 0.000043  loss: 2.9734 (3.0338)  time: 0.6378  data: 0.0001  max mem: 8681
Epoch: [25]  [ 880/2001]  eta: 0:11:47  lr: 0.000043  loss: 2.9734 (3.0314)  time: 0.6338  data: 0.0001  max mem: 8681
Epoch: [25]  [ 890/2001]  eta: 0:11:41  lr: 0.000043  loss: 2.8597 (3.0296)  time: 0.6391  data: 0.0001  max mem: 8681
loss info: cls_loss=2.8294, ratio_loss=0.0439, cls_kl=0.0612, token_kl=0.0937
Epoch: [25]  [ 900/2001]  eta: 0:11:35  lr: 0.000043  loss: 2.9591 (3.0294)  time: 0.6385  data: 0.0001  max mem: 8681
Epoch: [25]  [ 910/2001]  eta: 0:11:28  lr: 0.000043  loss: 3.1174 (3.0292)  time: 0.6323  data: 0.0001  max mem: 8681
Epoch: [25]  [ 920/2001]  eta: 0:11:22  lr: 0.000043  loss: 3.1942 (3.0310)  time: 0.6340  data: 0.0001  max mem: 8681
Epoch: [25]  [ 930/2001]  eta: 0:11:16  lr: 0.000043  loss: 3.3084 (3.0338)  time: 0.6340  data: 0.0001  max mem: 8681
Epoch: [25]  [ 940/2001]  eta: 0:11:09  lr: 0.000043  loss: 3.1382 (3.0334)  time: 0.6335  data: 0.0001  max mem: 8681
Epoch: [25]  [ 950/2001]  eta: 0:11:03  lr: 0.000043  loss: 2.6618 (3.0280)  time: 0.6383  data: 0.0001  max mem: 8681
Epoch: [25]  [ 960/2001]  eta: 0:10:57  lr: 0.000043  loss: 2.7435 (3.0286)  time: 0.6380  data: 0.0001  max mem: 8681
Epoch: [25]  [ 970/2001]  eta: 0:10:51  lr: 0.000043  loss: 3.2359 (3.0300)  time: 0.6341  data: 0.0001  max mem: 8681
Epoch: [25]  [ 980/2001]  eta: 0:10:44  lr: 0.000043  loss: 3.1467 (3.0313)  time: 0.6374  data: 0.0001  max mem: 8681
Epoch: [25]  [ 990/2001]  eta: 0:10:38  lr: 0.000043  loss: 3.3512 (3.0318)  time: 0.6355  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9544, ratio_loss=0.0445, cls_kl=0.0632, token_kl=0.0917
Epoch: [25]  [1000/2001]  eta: 0:10:32  lr: 0.000043  loss: 3.2828 (3.0322)  time: 0.6335  data: 0.0001  max mem: 8681
Epoch: [25]  [1010/2001]  eta: 0:10:26  lr: 0.000043  loss: 3.2828 (3.0351)  time: 0.6362  data: 0.0001  max mem: 8681
Epoch: [25]  [1020/2001]  eta: 0:10:19  lr: 0.000043  loss: 3.2083 (3.0351)  time: 0.6356  data: 0.0001  max mem: 8681
Epoch: [25]  [1030/2001]  eta: 0:10:13  lr: 0.000043  loss: 3.0654 (3.0328)  time: 0.6357  data: 0.0001  max mem: 8681
Epoch: [25]  [1040/2001]  eta: 0:10:07  lr: 0.000043  loss: 3.1157 (3.0348)  time: 0.6420  data: 0.0001  max mem: 8681
Epoch: [25]  [1050/2001]  eta: 0:10:01  lr: 0.000043  loss: 3.1505 (3.0344)  time: 0.6424  data: 0.0001  max mem: 8681
Epoch: [25]  [1060/2001]  eta: 0:09:54  lr: 0.000043  loss: 3.2104 (3.0359)  time: 0.6374  data: 0.0001  max mem: 8681
Epoch: [25]  [1070/2001]  eta: 0:09:48  lr: 0.000043  loss: 3.2607 (3.0365)  time: 0.6391  data: 0.0001  max mem: 8681
Epoch: [25]  [1080/2001]  eta: 0:09:42  lr: 0.000043  loss: 3.0816 (3.0359)  time: 0.6386  data: 0.0001  max mem: 8681
Epoch: [25]  [1090/2001]  eta: 0:09:35  lr: 0.000043  loss: 3.0158 (3.0351)  time: 0.6376  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9452, ratio_loss=0.0433, cls_kl=0.0633, token_kl=0.0934
Epoch: [25]  [1100/2001]  eta: 0:09:29  lr: 0.000043  loss: 3.0158 (3.0343)  time: 0.6388  data: 0.0001  max mem: 8681
Epoch: [25]  [1110/2001]  eta: 0:09:23  lr: 0.000043  loss: 3.1309 (3.0343)  time: 0.6388  data: 0.0001  max mem: 8681
Epoch: [25]  [1120/2001]  eta: 0:09:17  lr: 0.000043  loss: 3.1919 (3.0355)  time: 0.6399  data: 0.0001  max mem: 8681
Epoch: [25]  [1130/2001]  eta: 0:09:10  lr: 0.000043  loss: 3.1919 (3.0367)  time: 0.6405  data: 0.0001  max mem: 8681
Epoch: [25]  [1140/2001]  eta: 0:09:04  lr: 0.000043  loss: 2.9702 (3.0359)  time: 0.6391  data: 0.0001  max mem: 8681
Epoch: [25]  [1150/2001]  eta: 0:08:58  lr: 0.000043  loss: 2.9702 (3.0359)  time: 0.6383  data: 0.0001  max mem: 8681
Epoch: [25]  [1160/2001]  eta: 0:08:52  lr: 0.000043  loss: 3.1202 (3.0356)  time: 0.6376  data: 0.0001  max mem: 8681
Epoch: [25]  [1170/2001]  eta: 0:08:45  lr: 0.000043  loss: 3.1730 (3.0356)  time: 0.6365  data: 0.0001  max mem: 8681
Epoch: [25]  [1180/2001]  eta: 0:08:39  lr: 0.000043  loss: 3.4141 (3.0387)  time: 0.6365  data: 0.0001  max mem: 8681
Epoch: [25]  [1190/2001]  eta: 0:08:33  lr: 0.000043  loss: 3.4436 (3.0406)  time: 0.6361  data: 0.0001  max mem: 8681
loss info: cls_loss=3.0093, ratio_loss=0.0451, cls_kl=0.0643, token_kl=0.0923
Epoch: [25]  [1200/2001]  eta: 0:08:26  lr: 0.000043  loss: 3.2021 (3.0411)  time: 0.6370  data: 0.0001  max mem: 8681
Epoch: [25]  [1210/2001]  eta: 0:08:20  lr: 0.000043  loss: 3.1135 (3.0404)  time: 0.6402  data: 0.0001  max mem: 8681
Epoch: [25]  [1220/2001]  eta: 0:08:14  lr: 0.000043  loss: 3.0354 (3.0394)  time: 0.6419  data: 0.0001  max mem: 8681
Epoch: [25]  [1230/2001]  eta: 0:08:08  lr: 0.000043  loss: 3.0354 (3.0396)  time: 0.6418  data: 0.0001  max mem: 8681
Epoch: [25]  [1240/2001]  eta: 0:08:01  lr: 0.000043  loss: 3.0908 (3.0391)  time: 0.6403  data: 0.0001  max mem: 8681
Epoch: [25]  [1250/2001]  eta: 0:07:55  lr: 0.000043  loss: 2.9918 (3.0370)  time: 0.6389  data: 0.0001  max mem: 8681
Epoch: [25]  [1260/2001]  eta: 0:07:49  lr: 0.000043  loss: 3.0755 (3.0382)  time: 0.6375  data: 0.0001  max mem: 8681
Epoch: [25]  [1270/2001]  eta: 0:07:42  lr: 0.000043  loss: 3.2147 (3.0388)  time: 0.6353  data: 0.0001  max mem: 8681
Epoch: [25]  [1280/2001]  eta: 0:07:36  lr: 0.000043  loss: 3.1651 (3.0398)  time: 0.6339  data: 0.0001  max mem: 8681
Epoch: [25]  [1290/2001]  eta: 0:07:30  lr: 0.000043  loss: 3.2299 (3.0415)  time: 0.6337  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9404, ratio_loss=0.0457, cls_kl=0.0629, token_kl=0.0936
Epoch: [25]  [1300/2001]  eta: 0:07:23  lr: 0.000043  loss: 3.2914 (3.0421)  time: 0.6346  data: 0.0001  max mem: 8681
Epoch: [25]  [1310/2001]  eta: 0:07:17  lr: 0.000043  loss: 2.7970 (3.0397)  time: 0.6414  data: 0.0001  max mem: 8681
Epoch: [25]  [1320/2001]  eta: 0:07:11  lr: 0.000043  loss: 2.7676 (3.0379)  time: 0.6417  data: 0.0001  max mem: 8681
Epoch: [25]  [1330/2001]  eta: 0:07:04  lr: 0.000043  loss: 3.0843 (3.0392)  time: 0.6340  data: 0.0001  max mem: 8681
Epoch: [25]  [1340/2001]  eta: 0:06:58  lr: 0.000043  loss: 3.2212 (3.0394)  time: 0.6334  data: 0.0001  max mem: 8681
Epoch: [25]  [1350/2001]  eta: 0:06:52  lr: 0.000043  loss: 3.1176 (3.0395)  time: 0.6355  data: 0.0001  max mem: 8681
Epoch: [25]  [1360/2001]  eta: 0:06:45  lr: 0.000043  loss: 3.1449 (3.0405)  time: 0.6375  data: 0.0001  max mem: 8681
Epoch: [25]  [1370/2001]  eta: 0:06:39  lr: 0.000043  loss: 3.2563 (3.0417)  time: 0.6343  data: 0.0001  max mem: 8681
Epoch: [25]  [1380/2001]  eta: 0:06:33  lr: 0.000043  loss: 3.2214 (3.0430)  time: 0.6315  data: 0.0001  max mem: 8681
Epoch: [25]  [1390/2001]  eta: 0:06:26  lr: 0.000043  loss: 3.1568 (3.0426)  time: 0.6329  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9490, ratio_loss=0.0452, cls_kl=0.0612, token_kl=0.0916
Epoch: [25]  [1400/2001]  eta: 0:06:20  lr: 0.000043  loss: 3.1568 (3.0429)  time: 0.6330  data: 0.0001  max mem: 8681
Epoch: [25]  [1410/2001]  eta: 0:06:14  lr: 0.000043  loss: 3.2511 (3.0451)  time: 0.6328  data: 0.0001  max mem: 8681
Epoch: [25]  [1420/2001]  eta: 0:06:07  lr: 0.000043  loss: 3.2511 (3.0453)  time: 0.6326  data: 0.0001  max mem: 8681
Epoch: [25]  [1430/2001]  eta: 0:06:01  lr: 0.000043  loss: 3.0685 (3.0456)  time: 0.6305  data: 0.0001  max mem: 8681
Epoch: [25]  [1440/2001]  eta: 0:05:55  lr: 0.000043  loss: 3.0400 (3.0451)  time: 0.6300  data: 0.0001  max mem: 8681
Epoch: [25]  [1450/2001]  eta: 0:05:48  lr: 0.000043  loss: 3.1368 (3.0460)  time: 0.6316  data: 0.0001  max mem: 8681
Epoch: [25]  [1460/2001]  eta: 0:05:42  lr: 0.000043  loss: 3.2820 (3.0471)  time: 0.6303  data: 0.0001  max mem: 8681
Epoch: [25]  [1470/2001]  eta: 0:05:36  lr: 0.000043  loss: 3.2148 (3.0467)  time: 0.6336  data: 0.0001  max mem: 8681
Epoch: [25]  [1480/2001]  eta: 0:05:29  lr: 0.000043  loss: 3.0167 (3.0450)  time: 0.6341  data: 0.0001  max mem: 8681
Epoch: [25]  [1490/2001]  eta: 0:05:23  lr: 0.000043  loss: 2.7519 (3.0424)  time: 0.6285  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9274, ratio_loss=0.0433, cls_kl=0.0621, token_kl=0.0932
Epoch: [25]  [1500/2001]  eta: 0:05:17  lr: 0.000043  loss: 2.9175 (3.0420)  time: 0.6271  data: 0.0001  max mem: 8681
Epoch: [25]  [1510/2001]  eta: 0:05:10  lr: 0.000043  loss: 3.1565 (3.0429)  time: 0.6280  data: 0.0001  max mem: 8681
Epoch: [25]  [1520/2001]  eta: 0:05:04  lr: 0.000043  loss: 3.2735 (3.0444)  time: 0.6268  data: 0.0001  max mem: 8681
Epoch: [25]  [1530/2001]  eta: 0:04:58  lr: 0.000043  loss: 3.1502 (3.0440)  time: 0.6257  data: 0.0001  max mem: 8681
Epoch: [25]  [1540/2001]  eta: 0:04:51  lr: 0.000043  loss: 3.1069 (3.0447)  time: 0.6257  data: 0.0001  max mem: 8681
Epoch: [25]  [1550/2001]  eta: 0:04:45  lr: 0.000043  loss: 3.0855 (3.0441)  time: 0.6298  data: 0.0001  max mem: 8681
Epoch: [25]  [1560/2001]  eta: 0:04:39  lr: 0.000043  loss: 3.0298 (3.0434)  time: 0.6320  data: 0.0001  max mem: 8681
Epoch: [25]  [1570/2001]  eta: 0:04:32  lr: 0.000043  loss: 2.9213 (3.0416)  time: 0.6292  data: 0.0001  max mem: 8681
Epoch: [25]  [1580/2001]  eta: 0:04:26  lr: 0.000043  loss: 3.0750 (3.0414)  time: 0.6279  data: 0.0001  max mem: 8681
Epoch: [25]  [1590/2001]  eta: 0:04:20  lr: 0.000043  loss: 3.2098 (3.0424)  time: 0.6262  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9605, ratio_loss=0.0429, cls_kl=0.0628, token_kl=0.0923
Epoch: [25]  [1600/2001]  eta: 0:04:13  lr: 0.000043  loss: 3.2162 (3.0441)  time: 0.6256  data: 0.0001  max mem: 8681
Epoch: [25]  [1610/2001]  eta: 0:04:07  lr: 0.000043  loss: 3.2162 (3.0455)  time: 0.6270  data: 0.0001  max mem: 8681
Epoch: [25]  [1620/2001]  eta: 0:04:01  lr: 0.000043  loss: 3.1988 (3.0450)  time: 0.6275  data: 0.0001  max mem: 8681
Epoch: [25]  [1630/2001]  eta: 0:03:54  lr: 0.000043  loss: 3.2142 (3.0458)  time: 0.6249  data: 0.0001  max mem: 8681
Epoch: [25]  [1640/2001]  eta: 0:03:48  lr: 0.000043  loss: 3.1624 (3.0455)  time: 0.6214  data: 0.0001  max mem: 8681
Epoch: [25]  [1650/2001]  eta: 0:03:42  lr: 0.000043  loss: 2.6696 (3.0423)  time: 0.6236  data: 0.0001  max mem: 8681
Epoch: [25]  [1660/2001]  eta: 0:03:35  lr: 0.000043  loss: 2.5269 (3.0400)  time: 0.6246  data: 0.0001  max mem: 8681
Epoch: [25]  [1670/2001]  eta: 0:03:29  lr: 0.000043  loss: 2.9607 (3.0404)  time: 0.6241  data: 0.0001  max mem: 8681
Epoch: [25]  [1680/2001]  eta: 0:03:23  lr: 0.000043  loss: 3.1387 (3.0403)  time: 0.6260  data: 0.0001  max mem: 8681
Epoch: [25]  [1690/2001]  eta: 0:03:16  lr: 0.000043  loss: 3.1635 (3.0408)  time: 0.6278  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9080, ratio_loss=0.0442, cls_kl=0.0631, token_kl=0.0949
Epoch: [25]  [1700/2001]  eta: 0:03:10  lr: 0.000043  loss: 3.2863 (3.0422)  time: 0.6261  data: 0.0001  max mem: 8681
Epoch: [25]  [1710/2001]  eta: 0:03:03  lr: 0.000043  loss: 3.1924 (3.0416)  time: 0.6240  data: 0.0001  max mem: 8681
Epoch: [25]  [1720/2001]  eta: 0:02:57  lr: 0.000043  loss: 3.0175 (3.0413)  time: 0.6232  data: 0.0001  max mem: 8681
Epoch: [25]  [1730/2001]  eta: 0:02:51  lr: 0.000043  loss: 3.2988 (3.0427)  time: 0.6233  data: 0.0001  max mem: 8681
Epoch: [25]  [1740/2001]  eta: 0:02:44  lr: 0.000043  loss: 3.2968 (3.0420)  time: 0.6277  data: 0.0001  max mem: 8681
Epoch: [25]  [1750/2001]  eta: 0:02:38  lr: 0.000043  loss: 2.8588 (3.0409)  time: 0.6290  data: 0.0001  max mem: 8681
Epoch: [25]  [1760/2001]  eta: 0:02:32  lr: 0.000043  loss: 2.8588 (3.0408)  time: 0.6309  data: 0.0001  max mem: 8681
Epoch: [25]  [1770/2001]  eta: 0:02:26  lr: 0.000043  loss: 3.0024 (3.0411)  time: 0.6383  data: 0.0001  max mem: 8681
Epoch: [25]  [1780/2001]  eta: 0:02:19  lr: 0.000043  loss: 3.2386 (3.0417)  time: 0.6356  data: 0.0001  max mem: 8681
Epoch: [25]  [1790/2001]  eta: 0:02:13  lr: 0.000043  loss: 3.2023 (3.0407)  time: 0.6267  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9384, ratio_loss=0.0434, cls_kl=0.0628, token_kl=0.0937
Epoch: [25]  [1800/2001]  eta: 0:02:07  lr: 0.000043  loss: 3.2023 (3.0420)  time: 0.6245  data: 0.0001  max mem: 8681
Epoch: [25]  [1810/2001]  eta: 0:02:00  lr: 0.000043  loss: 3.1600 (3.0417)  time: 0.6240  data: 0.0001  max mem: 8681
Epoch: [25]  [1820/2001]  eta: 0:01:54  lr: 0.000043  loss: 2.9144 (3.0420)  time: 0.6219  data: 0.0001  max mem: 8681
Epoch: [25]  [1830/2001]  eta: 0:01:48  lr: 0.000043  loss: 3.2331 (3.0428)  time: 0.6226  data: 0.0001  max mem: 8681
Epoch: [25]  [1840/2001]  eta: 0:01:41  lr: 0.000043  loss: 3.2655 (3.0431)  time: 0.6237  data: 0.0001  max mem: 8681
Epoch: [25]  [1850/2001]  eta: 0:01:35  lr: 0.000043  loss: 2.9284 (3.0412)  time: 0.6237  data: 0.0001  max mem: 8681
Epoch: [25]  [1860/2001]  eta: 0:01:29  lr: 0.000043  loss: 2.8616 (3.0410)  time: 0.6237  data: 0.0001  max mem: 8681
Epoch: [25]  [1870/2001]  eta: 0:01:22  lr: 0.000043  loss: 3.0128 (3.0399)  time: 0.6238  data: 0.0001  max mem: 8681
Epoch: [25]  [1880/2001]  eta: 0:01:16  lr: 0.000043  loss: 3.2549 (3.0421)  time: 0.6257  data: 0.0001  max mem: 8681
Epoch: [25]  [1890/2001]  eta: 0:01:10  lr: 0.000043  loss: 3.2731 (3.0415)  time: 0.6245  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9056, ratio_loss=0.0446, cls_kl=0.0607, token_kl=0.0916
Epoch: [25]  [1900/2001]  eta: 0:01:03  lr: 0.000043  loss: 3.0143 (3.0409)  time: 0.6314  data: 0.0001  max mem: 8681
Epoch: [25]  [1910/2001]  eta: 0:00:57  lr: 0.000043  loss: 3.1790 (3.0417)  time: 0.6350  data: 0.0001  max mem: 8681
Epoch: [25]  [1920/2001]  eta: 0:00:51  lr: 0.000043  loss: 2.9504 (3.0396)  time: 0.6280  data: 0.0001  max mem: 8681
Epoch: [25]  [1930/2001]  eta: 0:00:44  lr: 0.000043  loss: 2.7354 (3.0388)  time: 0.6242  data: 0.0001  max mem: 8681
Epoch: [25]  [1940/2001]  eta: 0:00:38  lr: 0.000043  loss: 2.8825 (3.0383)  time: 0.6251  data: 0.0001  max mem: 8681
Epoch: [25]  [1950/2001]  eta: 0:00:32  lr: 0.000043  loss: 2.9676 (3.0374)  time: 0.6281  data: 0.0001  max mem: 8681
Epoch: [25]  [1960/2001]  eta: 0:00:25  lr: 0.000043  loss: 2.9774 (3.0368)  time: 0.6268  data: 0.0001  max mem: 8681
Epoch: [25]  [1970/2001]  eta: 0:00:19  lr: 0.000043  loss: 2.9707 (3.0351)  time: 0.6254  data: 0.0001  max mem: 8681
Epoch: [25]  [1980/2001]  eta: 0:00:13  lr: 0.000043  loss: 2.9774 (3.0346)  time: 0.6241  data: 0.0001  max mem: 8681
Epoch: [25]  [1990/2001]  eta: 0:00:06  lr: 0.000043  loss: 3.1323 (3.0346)  time: 0.6243  data: 0.0002  max mem: 8681
loss info: cls_loss=2.8113, ratio_loss=0.0401, cls_kl=0.0583, token_kl=0.0902
Epoch: [25]  [2000/2001]  eta: 0:00:00  lr: 0.000043  loss: 3.0555 (3.0342)  time: 0.6220  data: 0.0002  max mem: 8681
Epoch: [25] Total time: 0:21:04 (0.6317 s / it)
Averaged stats: lr: 0.000043  loss: 3.0555 (3.0446)
Test:  [ 0/53]  eta: 0:05:22  loss: 0.3692 (0.3692)  acc1: 93.3333 (93.3333)  acc5: 100.0000 (100.0000)  time: 6.0859  data: 5.0933  max mem: 8681
Test:  [10/53]  eta: 0:00:37  loss: 0.7310 (0.7678)  acc1: 83.3333 (83.1061)  acc5: 96.6667 (96.6667)  time: 0.8696  data: 0.4632  max mem: 8681
Test:  [20/53]  eta: 0:00:20  loss: 0.7310 (0.7693)  acc1: 83.3333 (83.2937)  acc5: 96.6667 (96.5476)  time: 0.3420  data: 0.0002  max mem: 8681
Test:  [30/53]  eta: 0:00:11  loss: 0.8872 (0.8522)  acc1: 78.3333 (80.9409)  acc5: 95.0000 (95.4570)  time: 0.3304  data: 0.0002  max mem: 8681
Test:  [40/53]  eta: 0:00:05  loss: 1.0857 (0.9158)  acc1: 75.8333 (79.5122)  acc5: 92.5000 (94.7155)  time: 0.2910  data: 0.0001  max mem: 8681
Test:  [50/53]  eta: 0:00:01  loss: 1.0868 (0.9460)  acc1: 76.6667 (78.7582)  acc5: 92.5000 (94.4771)  time: 0.2560  data: 0.0001  max mem: 8681
Test:  [52/53]  eta: 0:00:00  loss: 1.0857 (0.9327)  acc1: 76.6667 (78.9280)  acc5: 92.5000 (94.5440)  time: 0.2434  data: 0.0000  max mem: 8681
Test: Total time: 0:00:21 (0.4092 s / it)
Sparsity0:0.2971426262626263,Sparsity1:0.5605365656565656,Sparsity2:0.7921325252525252,
* Acc@1 79.002 Acc@5 94.434 loss 0.938
Accuracy of the network on the 50000 test images: 79.0%
Max accuracy: 79.00%
## Using lr  0.0000050 for BACKBONE, cosine lr = 0.0000312 for PREDICTOR
Epoch: [26]  [   0/2001]  eta: 2:36:18  lr: 0.000031  loss: 3.0334 (3.0334)  time: 4.6867  data: 4.0851  max mem: 8683
Epoch: [26]  [  10/2001]  eta: 0:32:38  lr: 0.000031  loss: 3.3737 (3.3321)  time: 0.9839  data: 0.3715  max mem: 8683
Epoch: [26]  [  20/2001]  eta: 0:26:41  lr: 0.000031  loss: 3.3639 (3.1883)  time: 0.6145  data: 0.0001  max mem: 8683
Epoch: [26]  [  30/2001]  eta: 0:24:30  lr: 0.000031  loss: 3.2827 (3.2248)  time: 0.6153  data: 0.0001  max mem: 8683
Epoch: [26]  [  40/2001]  eta: 0:23:22  lr: 0.000031  loss: 3.2827 (3.1826)  time: 0.6171  data: 0.0001  max mem: 8683
Epoch: [26]  [  50/2001]  eta: 0:22:40  lr: 0.000031  loss: 2.9828 (3.1367)  time: 0.6217  data: 0.0001  max mem: 8683
Epoch: [26]  [  60/2001]  eta: 0:22:10  lr: 0.000031  loss: 2.9730 (3.0954)  time: 0.6246  data: 0.0001  max mem: 8683
Epoch: [26]  [  70/2001]  eta: 0:21:47  lr: 0.000031  loss: 3.0670 (3.0948)  time: 0.6255  data: 0.0001  max mem: 8683
Epoch: [26]  [  80/2001]  eta: 0:21:28  lr: 0.000031  loss: 3.0825 (3.0620)  time: 0.6256  data: 0.0001  max mem: 8683
Epoch: [26]  [  90/2001]  eta: 0:21:12  lr: 0.000031  loss: 3.1089 (3.0750)  time: 0.6254  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9512, ratio_loss=0.0455, cls_kl=0.0613, token_kl=0.0938
Epoch: [26]  [ 100/2001]  eta: 0:20:58  lr: 0.000031  loss: 3.2611 (3.0601)  time: 0.6264  data: 0.0001  max mem: 8683
Epoch: [26]  [ 110/2001]  eta: 0:20:46  lr: 0.000031  loss: 3.3074 (3.0803)  time: 0.6301  data: 0.0001  max mem: 8683
Epoch: [26]  [ 120/2001]  eta: 0:20:35  lr: 0.000031  loss: 3.3523 (3.0814)  time: 0.6320  data: 0.0001  max mem: 8683
Epoch: [26]  [ 130/2001]  eta: 0:20:25  lr: 0.000031  loss: 3.2634 (3.0871)  time: 0.6321  data: 0.0001  max mem: 8683
Epoch: [26]  [ 140/2001]  eta: 0:20:15  lr: 0.000031  loss: 3.2634 (3.0952)  time: 0.6319  data: 0.0001  max mem: 8683
Epoch: [26]  [ 150/2001]  eta: 0:20:08  lr: 0.000031  loss: 3.2394 (3.0944)  time: 0.6377  data: 0.0001  max mem: 8683
Epoch: [26]  [ 160/2001]  eta: 0:20:01  lr: 0.000031  loss: 3.1839 (3.0922)  time: 0.6458  data: 0.0001  max mem: 8683
Epoch: [26]  [ 170/2001]  eta: 0:19:51  lr: 0.000031  loss: 3.1369 (3.0985)  time: 0.6371  data: 0.0001  max mem: 8683
Epoch: [26]  [ 180/2001]  eta: 0:19:43  lr: 0.000031  loss: 3.1198 (3.1004)  time: 0.6279  data: 0.0001  max mem: 8683
Epoch: [26]  [ 190/2001]  eta: 0:19:35  lr: 0.000031  loss: 3.1683 (3.1017)  time: 0.6312  data: 0.0001  max mem: 8683
loss info: cls_loss=3.0011, ratio_loss=0.0465, cls_kl=0.0646, token_kl=0.0931
Epoch: [26]  [ 200/2001]  eta: 0:19:27  lr: 0.000031  loss: 3.1112 (3.0877)  time: 0.6340  data: 0.0001  max mem: 8683
Epoch: [26]  [ 210/2001]  eta: 0:19:19  lr: 0.000031  loss: 2.8915 (3.0878)  time: 0.6331  data: 0.0001  max mem: 8683
Epoch: [26]  [ 220/2001]  eta: 0:19:11  lr: 0.000031  loss: 2.8915 (3.0782)  time: 0.6324  data: 0.0001  max mem: 8683
Epoch: [26]  [ 230/2001]  eta: 0:19:04  lr: 0.000031  loss: 2.9472 (3.0682)  time: 0.6361  data: 0.0001  max mem: 8683
Epoch: [26]  [ 240/2001]  eta: 0:18:58  lr: 0.000031  loss: 3.0530 (3.0704)  time: 0.6421  data: 0.0001  max mem: 8683
Epoch: [26]  [ 250/2001]  eta: 0:18:51  lr: 0.000031  loss: 2.8501 (3.0614)  time: 0.6407  data: 0.0001  max mem: 8683
Epoch: [26]  [ 260/2001]  eta: 0:18:44  lr: 0.000031  loss: 2.7863 (3.0606)  time: 0.6379  data: 0.0001  max mem: 8683
Epoch: [26]  [ 270/2001]  eta: 0:18:36  lr: 0.000031  loss: 3.1128 (3.0662)  time: 0.6346  data: 0.0001  max mem: 8683
Epoch: [26]  [ 280/2001]  eta: 0:18:29  lr: 0.000031  loss: 3.2485 (3.0687)  time: 0.6307  data: 0.0001  max mem: 8683
Epoch: [26]  [ 290/2001]  eta: 0:18:22  lr: 0.000031  loss: 3.1461 (3.0653)  time: 0.6332  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9034, ratio_loss=0.0429, cls_kl=0.0627, token_kl=0.0911
Epoch: [26]  [ 300/2001]  eta: 0:18:15  lr: 0.000031  loss: 3.0374 (3.0565)  time: 0.6359  data: 0.0001  max mem: 8683
Epoch: [26]  [ 310/2001]  eta: 0:18:08  lr: 0.000031  loss: 3.0289 (3.0536)  time: 0.6331  data: 0.0001  max mem: 8683
Epoch: [26]  [ 320/2001]  eta: 0:18:01  lr: 0.000031  loss: 3.1880 (3.0594)  time: 0.6304  data: 0.0001  max mem: 8683
Epoch: [26]  [ 330/2001]  eta: 0:17:54  lr: 0.000031  loss: 3.2218 (3.0666)  time: 0.6319  data: 0.0001  max mem: 8683
Epoch: [26]  [ 340/2001]  eta: 0:17:47  lr: 0.000031  loss: 3.2027 (3.0639)  time: 0.6342  data: 0.0001  max mem: 8683
Epoch: [26]  [ 350/2001]  eta: 0:17:40  lr: 0.000031  loss: 3.1078 (3.0633)  time: 0.6361  data: 0.0001  max mem: 8683
Epoch: [26]  [ 360/2001]  eta: 0:17:33  lr: 0.000031  loss: 3.0889 (3.0614)  time: 0.6356  data: 0.0001  max mem: 8683
Epoch: [26]  [ 370/2001]  eta: 0:17:27  lr: 0.000031  loss: 2.8330 (3.0574)  time: 0.6350  data: 0.0001  max mem: 8683
Epoch: [26]  [ 380/2001]  eta: 0:17:20  lr: 0.000031  loss: 3.1563 (3.0589)  time: 0.6355  data: 0.0001  max mem: 8683
Epoch: [26]  [ 390/2001]  eta: 0:17:13  lr: 0.000031  loss: 2.9586 (3.0513)  time: 0.6350  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9113, ratio_loss=0.0437, cls_kl=0.0621, token_kl=0.0920
Epoch: [26]  [ 400/2001]  eta: 0:17:07  lr: 0.000031  loss: 2.8736 (3.0508)  time: 0.6358  data: 0.0001  max mem: 8683
Epoch: [26]  [ 410/2001]  eta: 0:17:00  lr: 0.000031  loss: 3.2018 (3.0522)  time: 0.6371  data: 0.0001  max mem: 8683
Epoch: [26]  [ 420/2001]  eta: 0:16:54  lr: 0.000031  loss: 3.0297 (3.0487)  time: 0.6389  data: 0.0001  max mem: 8683
Epoch: [26]  [ 430/2001]  eta: 0:16:47  lr: 0.000031  loss: 3.0872 (3.0515)  time: 0.6431  data: 0.0001  max mem: 8683
Epoch: [26]  [ 440/2001]  eta: 0:16:41  lr: 0.000031  loss: 3.1357 (3.0518)  time: 0.6424  data: 0.0001  max mem: 8683
Epoch: [26]  [ 450/2001]  eta: 0:16:34  lr: 0.000031  loss: 3.2504 (3.0541)  time: 0.6379  data: 0.0001  max mem: 8683
Epoch: [26]  [ 460/2001]  eta: 0:16:28  lr: 0.000031  loss: 3.2896 (3.0516)  time: 0.6373  data: 0.0001  max mem: 8683
Epoch: [26]  [ 470/2001]  eta: 0:16:21  lr: 0.000031  loss: 3.0924 (3.0494)  time: 0.6371  data: 0.0001  max mem: 8683
Epoch: [26]  [ 480/2001]  eta: 0:16:15  lr: 0.000031  loss: 2.9545 (3.0471)  time: 0.6343  data: 0.0001  max mem: 8683
Epoch: [26]  [ 490/2001]  eta: 0:16:08  lr: 0.000031  loss: 3.0577 (3.0526)  time: 0.6350  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9452, ratio_loss=0.0452, cls_kl=0.0627, token_kl=0.0932
Epoch: [26]  [ 500/2001]  eta: 0:16:02  lr: 0.000031  loss: 3.0577 (3.0488)  time: 0.6402  data: 0.0001  max mem: 8683
Epoch: [26]  [ 510/2001]  eta: 0:15:55  lr: 0.000031  loss: 2.8415 (3.0465)  time: 0.6399  data: 0.0001  max mem: 8683
Epoch: [26]  [ 520/2001]  eta: 0:15:49  lr: 0.000031  loss: 3.0857 (3.0491)  time: 0.6351  data: 0.0001  max mem: 8683
Epoch: [26]  [ 530/2001]  eta: 0:15:42  lr: 0.000031  loss: 3.2084 (3.0496)  time: 0.6346  data: 0.0001  max mem: 8683
Epoch: [26]  [ 540/2001]  eta: 0:15:36  lr: 0.000031  loss: 3.1208 (3.0476)  time: 0.6399  data: 0.0001  max mem: 8683
Epoch: [26]  [ 550/2001]  eta: 0:15:29  lr: 0.000031  loss: 3.0430 (3.0498)  time: 0.6433  data: 0.0001  max mem: 8683
Epoch: [26]  [ 560/2001]  eta: 0:15:23  lr: 0.000031  loss: 3.2433 (3.0548)  time: 0.6401  data: 0.0001  max mem: 8683
Epoch: [26]  [ 570/2001]  eta: 0:15:16  lr: 0.000031  loss: 3.2238 (3.0560)  time: 0.6384  data: 0.0001  max mem: 8683
Epoch: [26]  [ 580/2001]  eta: 0:15:10  lr: 0.000031  loss: 3.0425 (3.0563)  time: 0.6425  data: 0.0001  max mem: 8683
Epoch: [26]  [ 590/2001]  eta: 0:15:04  lr: 0.000031  loss: 2.9398 (3.0542)  time: 0.6476  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9766, ratio_loss=0.0450, cls_kl=0.0632, token_kl=0.0921
Epoch: [26]  [ 600/2001]  eta: 0:14:57  lr: 0.000031  loss: 3.1365 (3.0561)  time: 0.6428  data: 0.0001  max mem: 8683
Epoch: [26]  [ 610/2001]  eta: 0:14:51  lr: 0.000031  loss: 3.0216 (3.0509)  time: 0.6351  data: 0.0001  max mem: 8683
Epoch: [26]  [ 620/2001]  eta: 0:14:44  lr: 0.000031  loss: 2.9519 (3.0526)  time: 0.6340  data: 0.0001  max mem: 8683
Epoch: [26]  [ 630/2001]  eta: 0:14:38  lr: 0.000031  loss: 3.0863 (3.0536)  time: 0.6365  data: 0.0001  max mem: 8683
Epoch: [26]  [ 640/2001]  eta: 0:14:31  lr: 0.000031  loss: 3.2589 (3.0560)  time: 0.6364  data: 0.0001  max mem: 8683
Epoch: [26]  [ 650/2001]  eta: 0:14:25  lr: 0.000031  loss: 3.3369 (3.0544)  time: 0.6338  data: 0.0001  max mem: 8683
Epoch: [26]  [ 660/2001]  eta: 0:14:18  lr: 0.000031  loss: 3.2039 (3.0570)  time: 0.6347  data: 0.0001  max mem: 8683
Epoch: [26]  [ 670/2001]  eta: 0:14:12  lr: 0.000031  loss: 3.2897 (3.0577)  time: 0.6360  data: 0.0001  max mem: 8683
Epoch: [26]  [ 680/2001]  eta: 0:14:05  lr: 0.000031  loss: 3.2897 (3.0585)  time: 0.6349  data: 0.0001  max mem: 8683
Epoch: [26]  [ 690/2001]  eta: 0:13:59  lr: 0.000031  loss: 3.3397 (3.0607)  time: 0.6340  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9984, ratio_loss=0.0452, cls_kl=0.0634, token_kl=0.0922
Epoch: [26]  [ 700/2001]  eta: 0:13:52  lr: 0.000031  loss: 3.3618 (3.0641)  time: 0.6375  data: 0.0001  max mem: 8683
Epoch: [26]  [ 710/2001]  eta: 0:13:46  lr: 0.000031  loss: 3.2865 (3.0675)  time: 0.6411  data: 0.0001  max mem: 8683
Epoch: [26]  [ 720/2001]  eta: 0:13:39  lr: 0.000031  loss: 3.2592 (3.0665)  time: 0.6398  data: 0.0001  max mem: 8683
Epoch: [26]  [ 730/2001]  eta: 0:13:33  lr: 0.000031  loss: 3.1153 (3.0685)  time: 0.6381  data: 0.0001  max mem: 8683
Epoch: [26]  [ 740/2001]  eta: 0:13:26  lr: 0.000031  loss: 2.9080 (3.0644)  time: 0.6353  data: 0.0001  max mem: 8683
Epoch: [26]  [ 750/2001]  eta: 0:13:20  lr: 0.000031  loss: 2.9480 (3.0652)  time: 0.6336  data: 0.0001  max mem: 8683
Epoch: [26]  [ 760/2001]  eta: 0:13:14  lr: 0.000031  loss: 3.1479 (3.0615)  time: 0.6356  data: 0.0001  max mem: 8683
Epoch: [26]  [ 770/2001]  eta: 0:13:07  lr: 0.000031  loss: 3.2648 (3.0654)  time: 0.6347  data: 0.0001  max mem: 8683
Epoch: [26]  [ 780/2001]  eta: 0:13:01  lr: 0.000031  loss: 3.2940 (3.0653)  time: 0.6328  data: 0.0001  max mem: 8683
Epoch: [26]  [ 790/2001]  eta: 0:12:54  lr: 0.000031  loss: 2.9408 (3.0625)  time: 0.6317  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9514, ratio_loss=0.0430, cls_kl=0.0621, token_kl=0.0917
Epoch: [26]  [ 800/2001]  eta: 0:12:48  lr: 0.000031  loss: 2.9668 (3.0611)  time: 0.6344  data: 0.0001  max mem: 8683
Epoch: [26]  [ 810/2001]  eta: 0:12:41  lr: 0.000031  loss: 3.1283 (3.0608)  time: 0.6355  data: 0.0001  max mem: 8683
Epoch: [26]  [ 820/2001]  eta: 0:12:35  lr: 0.000031  loss: 3.1283 (3.0618)  time: 0.6332  data: 0.0001  max mem: 8683
Epoch: [26]  [ 830/2001]  eta: 0:12:28  lr: 0.000031  loss: 3.0241 (3.0610)  time: 0.6345  data: 0.0001  max mem: 8683
Epoch: [26]  [ 840/2001]  eta: 0:12:22  lr: 0.000031  loss: 3.0241 (3.0607)  time: 0.6337  data: 0.0001  max mem: 8683
Epoch: [26]  [ 850/2001]  eta: 0:12:15  lr: 0.000031  loss: 2.9067 (3.0591)  time: 0.6342  data: 0.0001  max mem: 8683
Epoch: [26]  [ 860/2001]  eta: 0:12:09  lr: 0.000031  loss: 2.5484 (3.0531)  time: 0.6372  data: 0.0001  max mem: 8683
Epoch: [26]  [ 870/2001]  eta: 0:12:02  lr: 0.000031  loss: 2.5029 (3.0510)  time: 0.6332  data: 0.0001  max mem: 8683
Epoch: [26]  [ 880/2001]  eta: 0:11:56  lr: 0.000031  loss: 3.2180 (3.0508)  time: 0.6298  data: 0.0001  max mem: 8683
Epoch: [26]  [ 890/2001]  eta: 0:11:49  lr: 0.000031  loss: 3.1366 (3.0486)  time: 0.6301  data: 0.0001  max mem: 8683
loss info: cls_loss=2.8511, ratio_loss=0.0408, cls_kl=0.0611, token_kl=0.0914
Epoch: [26]  [ 900/2001]  eta: 0:11:43  lr: 0.000031  loss: 2.9592 (3.0501)  time: 0.6318  data: 0.0001  max mem: 8683
Epoch: [26]  [ 910/2001]  eta: 0:11:36  lr: 0.000031  loss: 3.0473 (3.0484)  time: 0.6306  data: 0.0001  max mem: 8683
Epoch: [26]  [ 920/2001]  eta: 0:11:30  lr: 0.000031  loss: 2.9957 (3.0485)  time: 0.6332  data: 0.0001  max mem: 8683
Epoch: [26]  [ 930/2001]  eta: 0:11:23  lr: 0.000031  loss: 3.1337 (3.0503)  time: 0.6330  data: 0.0001  max mem: 8683
Epoch: [26]  [ 940/2001]  eta: 0:11:17  lr: 0.000031  loss: 3.3626 (3.0536)  time: 0.6295  data: 0.0001  max mem: 8683
Epoch: [26]  [ 950/2001]  eta: 0:11:10  lr: 0.000031  loss: 3.0938 (3.0504)  time: 0.6301  data: 0.0001  max mem: 8683
Epoch: [26]  [ 960/2001]  eta: 0:11:04  lr: 0.000031  loss: 2.7908 (3.0497)  time: 0.6274  data: 0.0001  max mem: 8683
Epoch: [26]  [ 970/2001]  eta: 0:10:57  lr: 0.000031  loss: 3.2084 (3.0514)  time: 0.6277  data: 0.0001  max mem: 8683
Epoch: [26]  [ 980/2001]  eta: 0:10:51  lr: 0.000031  loss: 3.2084 (3.0503)  time: 0.6264  data: 0.0001  max mem: 8683
Epoch: [26]  [ 990/2001]  eta: 0:10:44  lr: 0.000031  loss: 3.2976 (3.0526)  time: 0.6253  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9731, ratio_loss=0.0452, cls_kl=0.0620, token_kl=0.0926
Epoch: [26]  [1000/2001]  eta: 0:10:38  lr: 0.000031  loss: 3.2976 (3.0530)  time: 0.6256  data: 0.0001  max mem: 8683
Epoch: [26]  [1010/2001]  eta: 0:10:31  lr: 0.000031  loss: 3.0879 (3.0528)  time: 0.6279  data: 0.0001  max mem: 8683
Epoch: [26]  [1020/2001]  eta: 0:10:25  lr: 0.000031  loss: 3.0879 (3.0531)  time: 0.6316  data: 0.0001  max mem: 8683
Epoch: [26]  [1030/2001]  eta: 0:10:19  lr: 0.000031  loss: 2.9991 (3.0517)  time: 0.6269  data: 0.0001  max mem: 8683
Epoch: [26]  [1040/2001]  eta: 0:10:12  lr: 0.000031  loss: 3.1508 (3.0512)  time: 0.6226  data: 0.0001  max mem: 8683
Epoch: [26]  [1050/2001]  eta: 0:10:06  lr: 0.000031  loss: 3.2807 (3.0527)  time: 0.6320  data: 0.0001  max mem: 8683
Epoch: [26]  [1060/2001]  eta: 0:09:59  lr: 0.000031  loss: 3.1288 (3.0516)  time: 0.6368  data: 0.0001  max mem: 8683
Epoch: [26]  [1070/2001]  eta: 0:09:53  lr: 0.000031  loss: 2.9527 (3.0503)  time: 0.6272  data: 0.0001  max mem: 8683
Epoch: [26]  [1080/2001]  eta: 0:09:46  lr: 0.000031  loss: 2.9527 (3.0488)  time: 0.6202  data: 0.0001  max mem: 8683
Epoch: [26]  [1090/2001]  eta: 0:09:40  lr: 0.000031  loss: 3.1398 (3.0480)  time: 0.6211  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9023, ratio_loss=0.0420, cls_kl=0.0610, token_kl=0.0912
Epoch: [26]  [1100/2001]  eta: 0:09:33  lr: 0.000031  loss: 3.1518 (3.0486)  time: 0.6217  data: 0.0001  max mem: 8683
Epoch: [26]  [1110/2001]  eta: 0:09:27  lr: 0.000031  loss: 3.1481 (3.0490)  time: 0.6198  data: 0.0001  max mem: 8683
Epoch: [26]  [1120/2001]  eta: 0:09:20  lr: 0.000031  loss: 3.0482 (3.0491)  time: 0.6228  data: 0.0001  max mem: 8683
Epoch: [26]  [1130/2001]  eta: 0:09:14  lr: 0.000031  loss: 3.0487 (3.0489)  time: 0.6264  data: 0.0001  max mem: 8683
Epoch: [26]  [1140/2001]  eta: 0:09:07  lr: 0.000031  loss: 2.8427 (3.0460)  time: 0.6237  data: 0.0001  max mem: 8683
Epoch: [26]  [1150/2001]  eta: 0:09:01  lr: 0.000031  loss: 2.8602 (3.0465)  time: 0.6200  data: 0.0001  max mem: 8683
Epoch: [26]  [1160/2001]  eta: 0:08:54  lr: 0.000031  loss: 3.1869 (3.0450)  time: 0.6220  data: 0.0001  max mem: 8683
Epoch: [26]  [1170/2001]  eta: 0:08:48  lr: 0.000031  loss: 3.1054 (3.0459)  time: 0.6230  data: 0.0001  max mem: 8683
Epoch: [26]  [1180/2001]  eta: 0:08:42  lr: 0.000031  loss: 3.2666 (3.0466)  time: 0.6219  data: 0.0001  max mem: 8683
Epoch: [26]  [1190/2001]  eta: 0:08:35  lr: 0.000031  loss: 3.0643 (3.0434)  time: 0.6285  data: 0.0001  max mem: 8683
loss info: cls_loss=2.8919, ratio_loss=0.0428, cls_kl=0.0602, token_kl=0.0907
Epoch: [26]  [1200/2001]  eta: 0:08:29  lr: 0.000031  loss: 2.9457 (3.0446)  time: 0.6295  data: 0.0001  max mem: 8683
Epoch: [26]  [1210/2001]  eta: 0:08:22  lr: 0.000031  loss: 3.3048 (3.0462)  time: 0.6270  data: 0.0001  max mem: 8683
Epoch: [26]  [1220/2001]  eta: 0:08:16  lr: 0.000031  loss: 3.2198 (3.0458)  time: 0.6274  data: 0.0001  max mem: 8683
Epoch: [26]  [1230/2001]  eta: 0:08:09  lr: 0.000031  loss: 3.1808 (3.0469)  time: 0.6258  data: 0.0001  max mem: 8683
Epoch: [26]  [1240/2001]  eta: 0:08:03  lr: 0.000031  loss: 3.2543 (3.0494)  time: 0.6234  data: 0.0001  max mem: 8683
Epoch: [26]  [1250/2001]  eta: 0:07:57  lr: 0.000031  loss: 3.3001 (3.0498)  time: 0.6194  data: 0.0001  max mem: 8683
Epoch: [26]  [1260/2001]  eta: 0:07:50  lr: 0.000031  loss: 2.8604 (3.0494)  time: 0.6190  data: 0.0001  max mem: 8683
Epoch: [26]  [1270/2001]  eta: 0:07:44  lr: 0.000031  loss: 2.9471 (3.0484)  time: 0.6259  data: 0.0001  max mem: 8683
Epoch: [26]  [1280/2001]  eta: 0:07:37  lr: 0.000031  loss: 2.9471 (3.0473)  time: 0.6344  data: 0.0001  max mem: 8683
Epoch: [26]  [1290/2001]  eta: 0:07:31  lr: 0.000031  loss: 3.0093 (3.0471)  time: 0.6368  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9714, ratio_loss=0.0481, cls_kl=0.0638, token_kl=0.0960
Epoch: [26]  [1300/2001]  eta: 0:07:25  lr: 0.000031  loss: 3.0636 (3.0472)  time: 0.6316  data: 0.0001  max mem: 8683
Epoch: [26]  [1310/2001]  eta: 0:07:18  lr: 0.000031  loss: 3.2140 (3.0479)  time: 0.6285  data: 0.0001  max mem: 8683
Epoch: [26]  [1320/2001]  eta: 0:07:12  lr: 0.000031  loss: 3.1500 (3.0484)  time: 0.6289  data: 0.0001  max mem: 8683
Epoch: [26]  [1330/2001]  eta: 0:07:05  lr: 0.000031  loss: 3.0117 (3.0466)  time: 0.6246  data: 0.0001  max mem: 8683
Epoch: [26]  [1340/2001]  eta: 0:06:59  lr: 0.000031  loss: 2.8953 (3.0448)  time: 0.6204  data: 0.0001  max mem: 8683
Epoch: [26]  [1350/2001]  eta: 0:06:53  lr: 0.000031  loss: 3.1043 (3.0457)  time: 0.6204  data: 0.0001  max mem: 8683
Epoch: [26]  [1360/2001]  eta: 0:06:46  lr: 0.000031  loss: 3.1119 (3.0452)  time: 0.6233  data: 0.0001  max mem: 8683
Epoch: [26]  [1370/2001]  eta: 0:06:40  lr: 0.000031  loss: 3.0717 (3.0447)  time: 0.6241  data: 0.0001  max mem: 8683
Epoch: [26]  [1380/2001]  eta: 0:06:33  lr: 0.000031  loss: 3.0971 (3.0438)  time: 0.6240  data: 0.0001  max mem: 8683
Epoch: [26]  [1390/2001]  eta: 0:06:27  lr: 0.000031  loss: 3.1931 (3.0458)  time: 0.6239  data: 0.0001  max mem: 8683
loss info: cls_loss=2.8983, ratio_loss=0.0454, cls_kl=0.0641, token_kl=0.0936
Epoch: [26]  [1400/2001]  eta: 0:06:21  lr: 0.000031  loss: 3.1809 (3.0443)  time: 0.6226  data: 0.0001  max mem: 8683
Epoch: [26]  [1410/2001]  eta: 0:06:14  lr: 0.000031  loss: 3.0668 (3.0448)  time: 0.6221  data: 0.0001  max mem: 8683
Epoch: [26]  [1420/2001]  eta: 0:06:08  lr: 0.000031  loss: 3.2166 (3.0449)  time: 0.6219  data: 0.0001  max mem: 8683
Epoch: [26]  [1430/2001]  eta: 0:06:02  lr: 0.000031  loss: 3.0743 (3.0443)  time: 0.6251  data: 0.0001  max mem: 8683
Epoch: [26]  [1440/2001]  eta: 0:05:55  lr: 0.000031  loss: 2.8370 (3.0440)  time: 0.6294  data: 0.0001  max mem: 8683
Epoch: [26]  [1450/2001]  eta: 0:05:49  lr: 0.000031  loss: 3.0202 (3.0440)  time: 0.6270  data: 0.0001  max mem: 8683
Epoch: [26]  [1460/2001]  eta: 0:05:42  lr: 0.000031  loss: 3.1539 (3.0445)  time: 0.6241  data: 0.0001  max mem: 8683
Epoch: [26]  [1470/2001]  eta: 0:05:36  lr: 0.000031  loss: 3.0148 (3.0430)  time: 0.6238  data: 0.0001  max mem: 8683
Epoch: [26]  [1480/2001]  eta: 0:05:30  lr: 0.000031  loss: 3.0148 (3.0433)  time: 0.6246  data: 0.0001  max mem: 8683
Epoch: [26]  [1490/2001]  eta: 0:05:23  lr: 0.000031  loss: 3.0393 (3.0433)  time: 0.6261  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9047, ratio_loss=0.0429, cls_kl=0.0620, token_kl=0.0917
Epoch: [26]  [1500/2001]  eta: 0:05:17  lr: 0.000031  loss: 3.0393 (3.0426)  time: 0.6261  data: 0.0001  max mem: 8683
Epoch: [26]  [1510/2001]  eta: 0:05:11  lr: 0.000031  loss: 3.0740 (3.0425)  time: 0.6248  data: 0.0001  max mem: 8683
Epoch: [26]  [1520/2001]  eta: 0:05:04  lr: 0.000031  loss: 2.7926 (3.0412)  time: 0.6240  data: 0.0001  max mem: 8683
Epoch: [26]  [1530/2001]  eta: 0:04:58  lr: 0.000031  loss: 2.9868 (3.0417)  time: 0.6261  data: 0.0001  max mem: 8683
Epoch: [26]  [1540/2001]  eta: 0:04:52  lr: 0.000031  loss: 2.9868 (3.0411)  time: 0.6263  data: 0.0001  max mem: 8683
Epoch: [26]  [1550/2001]  eta: 0:04:45  lr: 0.000031  loss: 2.8790 (3.0402)  time: 0.6272  data: 0.0001  max mem: 8683
Epoch: [26]  [1560/2001]  eta: 0:04:39  lr: 0.000031  loss: 3.2436 (3.0423)  time: 0.6277  data: 0.0001  max mem: 8683
Epoch: [26]  [1570/2001]  eta: 0:04:32  lr: 0.000031  loss: 3.3712 (3.0421)  time: 0.6269  data: 0.0001  max mem: 8683
Epoch: [26]  [1580/2001]  eta: 0:04:26  lr: 0.000031  loss: 3.1168 (3.0429)  time: 0.6270  data: 0.0001  max mem: 8683
Epoch: [26]  [1590/2001]  eta: 0:04:20  lr: 0.000031  loss: 3.1200 (3.0438)  time: 0.6315  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9506, ratio_loss=0.0465, cls_kl=0.0634, token_kl=0.0949
Epoch: [26]  [1600/2001]  eta: 0:04:13  lr: 0.000031  loss: 3.1200 (3.0430)  time: 0.6355  data: 0.0001  max mem: 8683
Epoch: [26]  [1610/2001]  eta: 0:04:07  lr: 0.000031  loss: 3.2095 (3.0437)  time: 0.6321  data: 0.0001  max mem: 8683
Epoch: [26]  [1620/2001]  eta: 0:04:01  lr: 0.000031  loss: 3.2420 (3.0452)  time: 0.6291  data: 0.0001  max mem: 8683
Epoch: [26]  [1630/2001]  eta: 0:03:54  lr: 0.000031  loss: 3.2290 (3.0461)  time: 0.6330  data: 0.0001  max mem: 8683
Epoch: [26]  [1640/2001]  eta: 0:03:48  lr: 0.000031  loss: 3.1578 (3.0459)  time: 0.6337  data: 0.0001  max mem: 8683
Epoch: [26]  [1650/2001]  eta: 0:03:42  lr: 0.000031  loss: 3.1472 (3.0472)  time: 0.6288  data: 0.0001  max mem: 8683
Epoch: [26]  [1660/2001]  eta: 0:03:35  lr: 0.000031  loss: 3.1170 (3.0470)  time: 0.6275  data: 0.0001  max mem: 8683
Epoch: [26]  [1670/2001]  eta: 0:03:29  lr: 0.000031  loss: 3.2171 (3.0478)  time: 0.6284  data: 0.0001  max mem: 8683
Epoch: [26]  [1680/2001]  eta: 0:03:23  lr: 0.000031  loss: 3.2171 (3.0481)  time: 0.6280  data: 0.0001  max mem: 8683
Epoch: [26]  [1690/2001]  eta: 0:03:16  lr: 0.000031  loss: 3.0556 (3.0479)  time: 0.6267  data: 0.0001  max mem: 8683
loss info: cls_loss=3.0012, ratio_loss=0.0432, cls_kl=0.0618, token_kl=0.0916
Epoch: [26]  [1700/2001]  eta: 0:03:10  lr: 0.000031  loss: 3.0626 (3.0473)  time: 0.6300  data: 0.0001  max mem: 8683
Epoch: [26]  [1710/2001]  eta: 0:03:04  lr: 0.000031  loss: 3.0384 (3.0470)  time: 0.6344  data: 0.0001  max mem: 8683
Epoch: [26]  [1720/2001]  eta: 0:02:57  lr: 0.000031  loss: 3.1098 (3.0484)  time: 0.6318  data: 0.0001  max mem: 8683
Epoch: [26]  [1730/2001]  eta: 0:02:51  lr: 0.000031  loss: 3.3330 (3.0492)  time: 0.6281  data: 0.0001  max mem: 8683
Epoch: [26]  [1740/2001]  eta: 0:02:45  lr: 0.000031  loss: 3.1831 (3.0495)  time: 0.6289  data: 0.0001  max mem: 8683
Epoch: [26]  [1750/2001]  eta: 0:02:38  lr: 0.000031  loss: 3.1634 (3.0488)  time: 0.6308  data: 0.0001  max mem: 8683
Epoch: [26]  [1760/2001]  eta: 0:02:32  lr: 0.000031  loss: 3.2111 (3.0500)  time: 0.6301  data: 0.0001  max mem: 8683
Epoch: [26]  [1770/2001]  eta: 0:02:26  lr: 0.000031  loss: 3.2351 (3.0506)  time: 0.6298  data: 0.0001  max mem: 8683
Epoch: [26]  [1780/2001]  eta: 0:02:19  lr: 0.000031  loss: 3.2108 (3.0493)  time: 0.6359  data: 0.0001  max mem: 8683
Epoch: [26]  [1790/2001]  eta: 0:02:13  lr: 0.000031  loss: 3.1180 (3.0503)  time: 0.6357  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9973, ratio_loss=0.0467, cls_kl=0.0647, token_kl=0.0949
Epoch: [26]  [1800/2001]  eta: 0:02:07  lr: 0.000031  loss: 3.1180 (3.0505)  time: 0.6306  data: 0.0001  max mem: 8683
Epoch: [26]  [1810/2001]  eta: 0:02:00  lr: 0.000031  loss: 3.0140 (3.0501)  time: 0.6311  data: 0.0001  max mem: 8683
Epoch: [26]  [1820/2001]  eta: 0:01:54  lr: 0.000031  loss: 3.1088 (3.0497)  time: 0.6308  data: 0.0001  max mem: 8683
Epoch: [26]  [1830/2001]  eta: 0:01:48  lr: 0.000031  loss: 3.3023 (3.0503)  time: 0.6361  data: 0.0001  max mem: 8683
Epoch: [26]  [1840/2001]  eta: 0:01:41  lr: 0.000031  loss: 3.2416 (3.0489)  time: 0.6374  data: 0.0001  max mem: 8683
Epoch: [26]  [1850/2001]  eta: 0:01:35  lr: 0.000031  loss: 3.0890 (3.0499)  time: 0.6371  data: 0.0001  max mem: 8683
Epoch: [26]  [1860/2001]  eta: 0:01:29  lr: 0.000031  loss: 3.1353 (3.0488)  time: 0.6419  data: 0.0001  max mem: 8683
Epoch: [26]  [1870/2001]  eta: 0:01:22  lr: 0.000031  loss: 3.1086 (3.0490)  time: 0.6425  data: 0.0001  max mem: 8683
Epoch: [26]  [1880/2001]  eta: 0:01:16  lr: 0.000031  loss: 3.1086 (3.0480)  time: 0.6384  data: 0.0001  max mem: 8683
Epoch: [26]  [1890/2001]  eta: 0:01:10  lr: 0.000031  loss: 3.0196 (3.0474)  time: 0.6331  data: 0.0001  max mem: 8683
loss info: cls_loss=2.8680, ratio_loss=0.0430, cls_kl=0.0613, token_kl=0.0921
Epoch: [26]  [1900/2001]  eta: 0:01:03  lr: 0.000031  loss: 3.0939 (3.0461)  time: 0.6346  data: 0.0001  max mem: 8683
Epoch: [26]  [1910/2001]  eta: 0:00:57  lr: 0.000031  loss: 3.0939 (3.0469)  time: 0.6361  data: 0.0001  max mem: 8683
Epoch: [26]  [1920/2001]  eta: 0:00:51  lr: 0.000031  loss: 3.2105 (3.0473)  time: 0.6340  data: 0.0001  max mem: 8683
Epoch: [26]  [1930/2001]  eta: 0:00:44  lr: 0.000031  loss: 3.0585 (3.0467)  time: 0.6327  data: 0.0001  max mem: 8683
Epoch: [26]  [1940/2001]  eta: 0:00:38  lr: 0.000031  loss: 2.8396 (3.0461)  time: 0.6319  data: 0.0001  max mem: 8683
Epoch: [26]  [1950/2001]  eta: 0:00:32  lr: 0.000031  loss: 2.8396 (3.0450)  time: 0.6353  data: 0.0001  max mem: 8683
Epoch: [26]  [1960/2001]  eta: 0:00:25  lr: 0.000031  loss: 3.0481 (3.0456)  time: 0.6367  data: 0.0001  max mem: 8683
Epoch: [26]  [1970/2001]  eta: 0:00:19  lr: 0.000031  loss: 3.1391 (3.0468)  time: 0.6333  data: 0.0001  max mem: 8683
Epoch: [26]  [1980/2001]  eta: 0:00:13  lr: 0.000031  loss: 3.1397 (3.0466)  time: 0.6333  data: 0.0001  max mem: 8683
Epoch: [26]  [1990/2001]  eta: 0:00:06  lr: 0.000031  loss: 3.0041 (3.0467)  time: 0.6317  data: 0.0003  max mem: 8683
| distributed init (rank 3): env://
| distributed init (rank 1): env://
| distributed init (rank 7): env://
| distributed init (rank 6): env://
| distributed init (rank 4): env://
| distributed init (rank 0): env://
| distributed init (rank 5): env://
| distributed init (rank 2): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp/checkpoint.pth', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000050 for BACKBONE, cosine lr = 0.0000312 for PREDICTOR
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Epoch: [26]  [   0/2001]  eta: 3:41:13  lr: 0.000031  loss: 3.5740 (3.5740)  time: 6.6334  data: 3.2581  max mem: 8604
Epoch: [26]  [  10/2001]  eta: 0:38:31  lr: 0.000031  loss: 3.5491 (3.3057)  time: 1.1609  data: 0.2963  max mem: 8681
Epoch: [26]  [  20/2001]  eta: 0:29:13  lr: 0.000031  loss: 3.2792 (3.2335)  time: 0.5977  data: 0.0001  max mem: 8681
Epoch: [26]  [  30/2001]  eta: 0:26:05  lr: 0.000031  loss: 3.2750 (3.2834)  time: 0.5924  data: 0.0001  max mem: 8681
Epoch: [26]  [  40/2001]  eta: 0:24:20  lr: 0.000031  loss: 3.1580 (3.2381)  time: 0.5975  data: 0.0001  max mem: 8681
Epoch: [26]  [  50/2001]  eta: 0:23:16  lr: 0.000031  loss: 3.0973 (3.2086)  time: 0.5939  data: 0.0001  max mem: 8681
Epoch: [26]  [  60/2001]  eta: 0:22:32  lr: 0.000031  loss: 3.2288 (3.1905)  time: 0.5983  data: 0.0001  max mem: 8681
Epoch: [26]  [  70/2001]  eta: 0:22:00  lr: 0.000031  loss: 3.2288 (3.1579)  time: 0.6028  data: 0.0001  max mem: 8681
Epoch: [26]  [  80/2001]  eta: 0:21:36  lr: 0.000031  loss: 3.1733 (3.1513)  time: 0.6073  data: 0.0001  max mem: 8681
Epoch: [26]  [  90/2001]  eta: 0:21:15  lr: 0.000031  loss: 3.2254 (3.1392)  time: 0.6103  data: 0.0001  max mem: 8681
loss info: cls_loss=3.0339, ratio_loss=0.0468, cls_kl=0.0652, token_kl=0.0938
Epoch: [26]  [ 100/2001]  eta: 0:20:59  lr: 0.000031  loss: 3.2004 (3.1447)  time: 0.6128  data: 0.0001  max mem: 8681
Epoch: [26]  [ 110/2001]  eta: 0:20:44  lr: 0.000031  loss: 3.1537 (3.1477)  time: 0.6159  data: 0.0001  max mem: 8681
Epoch: [26]  [ 120/2001]  eta: 0:20:32  lr: 0.000031  loss: 3.1939 (3.1469)  time: 0.6189  data: 0.0001  max mem: 8681
Epoch: [26]  [ 130/2001]  eta: 0:20:20  lr: 0.000031  loss: 3.1939 (3.1370)  time: 0.6197  data: 0.0001  max mem: 8681
Epoch: [26]  [ 140/2001]  eta: 0:20:10  lr: 0.000031  loss: 3.0418 (3.1223)  time: 0.6212  data: 0.0001  max mem: 8681
Epoch: [26]  [ 150/2001]  eta: 0:20:00  lr: 0.000031  loss: 3.1600 (3.1236)  time: 0.6251  data: 0.0001  max mem: 8681
Epoch: [26]  [ 160/2001]  eta: 0:19:52  lr: 0.000031  loss: 3.2051 (3.1264)  time: 0.6283  data: 0.0001  max mem: 8681
Epoch: [26]  [ 170/2001]  eta: 0:19:43  lr: 0.000031  loss: 3.0953 (3.1222)  time: 0.6278  data: 0.0001  max mem: 8681
Epoch: [26]  [ 180/2001]  eta: 0:19:35  lr: 0.000031  loss: 3.0003 (3.1141)  time: 0.6294  data: 0.0001  max mem: 8681
Epoch: [26]  [ 190/2001]  eta: 0:19:28  lr: 0.000031  loss: 2.9691 (3.1078)  time: 0.6368  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9465, ratio_loss=0.0443, cls_kl=0.0625, token_kl=0.0913
Epoch: [26]  [ 200/2001]  eta: 0:19:20  lr: 0.000031  loss: 3.0190 (3.0986)  time: 0.6326  data: 0.0001  max mem: 8681
Epoch: [26]  [ 210/2001]  eta: 0:19:12  lr: 0.000031  loss: 3.0685 (3.0941)  time: 0.6271  data: 0.0001  max mem: 8681
Epoch: [26]  [ 220/2001]  eta: 0:19:05  lr: 0.000031  loss: 3.1831 (3.0859)  time: 0.6287  data: 0.0001  max mem: 8681
Epoch: [26]  [ 230/2001]  eta: 0:18:57  lr: 0.000031  loss: 3.1595 (3.0793)  time: 0.6274  data: 0.0001  max mem: 8681
Epoch: [26]  [ 240/2001]  eta: 0:18:49  lr: 0.000031  loss: 3.1873 (3.0756)  time: 0.6273  data: 0.0001  max mem: 8681
Epoch: [26]  [ 250/2001]  eta: 0:18:42  lr: 0.000031  loss: 3.0906 (3.0715)  time: 0.6268  data: 0.0001  max mem: 8681
Epoch: [26]  [ 260/2001]  eta: 0:18:35  lr: 0.000031  loss: 2.8611 (3.0615)  time: 0.6274  data: 0.0001  max mem: 8681
Epoch: [26]  [ 270/2001]  eta: 0:18:28  lr: 0.000031  loss: 2.8611 (3.0571)  time: 0.6289  data: 0.0001  max mem: 8681
Epoch: [26]  [ 280/2001]  eta: 0:18:21  lr: 0.000031  loss: 3.1759 (3.0613)  time: 0.6301  data: 0.0001  max mem: 8681
Epoch: [26]  [ 290/2001]  eta: 0:18:14  lr: 0.000031  loss: 3.0493 (3.0512)  time: 0.6311  data: 0.0001  max mem: 8681
loss info: cls_loss=2.8208, ratio_loss=0.0427, cls_kl=0.0612, token_kl=0.0910
Epoch: [26]  [ 300/2001]  eta: 0:18:07  lr: 0.000031  loss: 2.7486 (3.0400)  time: 0.6299  data: 0.0001  max mem: 8681
Epoch: [26]  [ 310/2001]  eta: 0:18:00  lr: 0.000031  loss: 2.7626 (3.0400)  time: 0.6294  data: 0.0001  max mem: 8681
Epoch: [26]  [ 320/2001]  eta: 0:17:53  lr: 0.000031  loss: 3.3795 (3.0522)  time: 0.6306  data: 0.0001  max mem: 8681
Epoch: [26]  [ 330/2001]  eta: 0:17:46  lr: 0.000031  loss: 3.3908 (3.0511)  time: 0.6289  data: 0.0001  max mem: 8681
Epoch: [26]  [ 340/2001]  eta: 0:17:39  lr: 0.000031  loss: 3.2348 (3.0559)  time: 0.6267  data: 0.0001  max mem: 8681
Epoch: [26]  [ 350/2001]  eta: 0:17:32  lr: 0.000031  loss: 3.2106 (3.0561)  time: 0.6273  data: 0.0001  max mem: 8681
Epoch: [26]  [ 360/2001]  eta: 0:17:25  lr: 0.000031  loss: 3.1114 (3.0579)  time: 0.6276  data: 0.0001  max mem: 8681
Epoch: [26]  [ 370/2001]  eta: 0:17:19  lr: 0.000031  loss: 3.0320 (3.0536)  time: 0.6277  data: 0.0001  max mem: 8681
Epoch: [26]  [ 380/2001]  eta: 0:17:12  lr: 0.000031  loss: 3.0320 (3.0515)  time: 0.6290  data: 0.0001  max mem: 8681
Epoch: [26]  [ 390/2001]  eta: 0:17:05  lr: 0.000031  loss: 3.0424 (3.0465)  time: 0.6275  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9738, ratio_loss=0.0447, cls_kl=0.0635, token_kl=0.0938
Epoch: [26]  [ 400/2001]  eta: 0:16:58  lr: 0.000031  loss: 3.2278 (3.0530)  time: 0.6257  data: 0.0001  max mem: 8681
Epoch: [26]  [ 410/2001]  eta: 0:16:52  lr: 0.000031  loss: 3.2650 (3.0584)  time: 0.6274  data: 0.0001  max mem: 8681
Epoch: [26]  [ 420/2001]  eta: 0:16:45  lr: 0.000031  loss: 3.1651 (3.0576)  time: 0.6272  data: 0.0001  max mem: 8681
Epoch: [26]  [ 430/2001]  eta: 0:16:38  lr: 0.000031  loss: 3.1651 (3.0606)  time: 0.6261  data: 0.0001  max mem: 8681
Epoch: [26]  [ 440/2001]  eta: 0:16:31  lr: 0.000031  loss: 3.1270 (3.0616)  time: 0.6249  data: 0.0001  max mem: 8681
Epoch: [26]  [ 450/2001]  eta: 0:16:25  lr: 0.000031  loss: 2.9964 (3.0612)  time: 0.6232  data: 0.0001  max mem: 8681
Epoch: [26]  [ 460/2001]  eta: 0:16:18  lr: 0.000031  loss: 2.9298 (3.0566)  time: 0.6293  data: 0.0001  max mem: 8681
Epoch: [26]  [ 470/2001]  eta: 0:16:11  lr: 0.000031  loss: 2.7312 (3.0481)  time: 0.6291  data: 0.0001  max mem: 8681
Epoch: [26]  [ 480/2001]  eta: 0:16:05  lr: 0.000031  loss: 2.7522 (3.0465)  time: 0.6231  data: 0.0001  max mem: 8681
Epoch: [26]  [ 490/2001]  eta: 0:15:58  lr: 0.000031  loss: 3.1899 (3.0522)  time: 0.6246  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9371, ratio_loss=0.0455, cls_kl=0.0647, token_kl=0.0947
Epoch: [26]  [ 500/2001]  eta: 0:15:51  lr: 0.000031  loss: 3.2088 (3.0510)  time: 0.6248  data: 0.0001  max mem: 8681
Epoch: [26]  [ 510/2001]  eta: 0:15:45  lr: 0.000031  loss: 3.1529 (3.0535)  time: 0.6248  data: 0.0001  max mem: 8681
Epoch: [26]  [ 520/2001]  eta: 0:15:38  lr: 0.000031  loss: 3.1701 (3.0556)  time: 0.6270  data: 0.0001  max mem: 8681
Epoch: [26]  [ 530/2001]  eta: 0:15:32  lr: 0.000031  loss: 3.0220 (3.0490)  time: 0.6262  data: 0.0001  max mem: 8681
Epoch: [26]  [ 540/2001]  eta: 0:15:25  lr: 0.000031  loss: 2.9856 (3.0489)  time: 0.6251  data: 0.0001  max mem: 8681
Epoch: [26]  [ 550/2001]  eta: 0:15:19  lr: 0.000031  loss: 3.2094 (3.0483)  time: 0.6253  data: 0.0001  max mem: 8681
Epoch: [26]  [ 560/2001]  eta: 0:15:12  lr: 0.000031  loss: 3.4356 (3.0532)  time: 0.6246  data: 0.0001  max mem: 8681
Epoch: [26]  [ 570/2001]  eta: 0:15:06  lr: 0.000031  loss: 3.3188 (3.0540)  time: 0.6243  data: 0.0001  max mem: 8681
Epoch: [26]  [ 580/2001]  eta: 0:14:59  lr: 0.000031  loss: 3.2277 (3.0552)  time: 0.6237  data: 0.0001  max mem: 8681
Epoch: [26]  [ 590/2001]  eta: 0:14:52  lr: 0.000031  loss: 3.1493 (3.0571)  time: 0.6246  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9935, ratio_loss=0.0450, cls_kl=0.0634, token_kl=0.0934
Epoch: [26]  [ 600/2001]  eta: 0:14:46  lr: 0.000031  loss: 3.2384 (3.0571)  time: 0.6256  data: 0.0001  max mem: 8681
Epoch: [26]  [ 610/2001]  eta: 0:14:40  lr: 0.000031  loss: 3.0628 (3.0573)  time: 0.6269  data: 0.0001  max mem: 8681
Epoch: [26]  [ 620/2001]  eta: 0:14:33  lr: 0.000031  loss: 3.1650 (3.0603)  time: 0.6307  data: 0.0001  max mem: 8681
Epoch: [26]  [ 630/2001]  eta: 0:14:27  lr: 0.000031  loss: 3.1650 (3.0617)  time: 0.6299  data: 0.0001  max mem: 8681
Epoch: [26]  [ 640/2001]  eta: 0:14:20  lr: 0.000031  loss: 2.9334 (3.0579)  time: 0.6257  data: 0.0001  max mem: 8681
Epoch: [26]  [ 650/2001]  eta: 0:14:14  lr: 0.000031  loss: 3.0676 (3.0606)  time: 0.6263  data: 0.0001  max mem: 8681
Epoch: [26]  [ 660/2001]  eta: 0:14:07  lr: 0.000031  loss: 3.0522 (3.0534)  time: 0.6260  data: 0.0001  max mem: 8681
Epoch: [26]  [ 670/2001]  eta: 0:14:01  lr: 0.000031  loss: 3.0522 (3.0559)  time: 0.6273  data: 0.0001  max mem: 8681
Epoch: [26]  [ 680/2001]  eta: 0:13:55  lr: 0.000031  loss: 3.1689 (3.0559)  time: 0.6290  data: 0.0001  max mem: 8681
Epoch: [26]  [ 690/2001]  eta: 0:13:48  lr: 0.000031  loss: 2.8891 (3.0529)  time: 0.6276  data: 0.0001  max mem: 8681
loss info: cls_loss=2.8952, ratio_loss=0.0448, cls_kl=0.0641, token_kl=0.0947
Epoch: [26]  [ 700/2001]  eta: 0:13:42  lr: 0.000031  loss: 2.9042 (3.0520)  time: 0.6272  data: 0.0001  max mem: 8681
Epoch: [26]  [ 710/2001]  eta: 0:13:35  lr: 0.000031  loss: 3.2318 (3.0507)  time: 0.6281  data: 0.0001  max mem: 8681
Epoch: [26]  [ 720/2001]  eta: 0:13:29  lr: 0.000031  loss: 3.1727 (3.0478)  time: 0.6264  data: 0.0001  max mem: 8681
Epoch: [26]  [ 730/2001]  eta: 0:13:22  lr: 0.000031  loss: 2.9648 (3.0477)  time: 0.6249  data: 0.0001  max mem: 8681
Epoch: [26]  [ 740/2001]  eta: 0:13:16  lr: 0.000031  loss: 3.2184 (3.0522)  time: 0.6271  data: 0.0001  max mem: 8681
Epoch: [26]  [ 750/2001]  eta: 0:13:10  lr: 0.000031  loss: 3.2184 (3.0513)  time: 0.6257  data: 0.0001  max mem: 8681
Epoch: [26]  [ 760/2001]  eta: 0:13:03  lr: 0.000031  loss: 3.1481 (3.0508)  time: 0.6242  data: 0.0001  max mem: 8681
Epoch: [26]  [ 770/2001]  eta: 0:12:57  lr: 0.000031  loss: 3.2967 (3.0534)  time: 0.6267  data: 0.0001  max mem: 8681
Epoch: [26]  [ 780/2001]  eta: 0:12:51  lr: 0.000031  loss: 3.2967 (3.0548)  time: 0.6290  data: 0.0001  max mem: 8681
Epoch: [26]  [ 790/2001]  eta: 0:12:44  lr: 0.000031  loss: 3.0058 (3.0533)  time: 0.6309  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9505, ratio_loss=0.0454, cls_kl=0.0639, token_kl=0.0925
Epoch: [26]  [ 800/2001]  eta: 0:12:38  lr: 0.000031  loss: 3.0043 (3.0527)  time: 0.6346  data: 0.0001  max mem: 8681
Epoch: [26]  [ 810/2001]  eta: 0:12:32  lr: 0.000031  loss: 2.6694 (3.0458)  time: 0.6305  data: 0.0001  max mem: 8681
Epoch: [26]  [ 820/2001]  eta: 0:12:25  lr: 0.000031  loss: 2.6727 (3.0478)  time: 0.6253  data: 0.0001  max mem: 8681
Epoch: [26]  [ 830/2001]  eta: 0:12:19  lr: 0.000031  loss: 3.2021 (3.0444)  time: 0.6252  data: 0.0001  max mem: 8681
Epoch: [26]  [ 840/2001]  eta: 0:12:12  lr: 0.000031  loss: 2.7246 (3.0427)  time: 0.6249  data: 0.0001  max mem: 8681
Epoch: [26]  [ 850/2001]  eta: 0:12:06  lr: 0.000031  loss: 3.1565 (3.0411)  time: 0.6270  data: 0.0001  max mem: 8681
Epoch: [26]  [ 860/2001]  eta: 0:12:00  lr: 0.000031  loss: 3.2493 (3.0417)  time: 0.6263  data: 0.0001  max mem: 8681
Epoch: [26]  [ 870/2001]  eta: 0:11:53  lr: 0.000031  loss: 3.2853 (3.0422)  time: 0.6270  data: 0.0001  max mem: 8681
Epoch: [26]  [ 880/2001]  eta: 0:11:47  lr: 0.000031  loss: 2.9825 (3.0397)  time: 0.6312  data: 0.0001  max mem: 8681
Epoch: [26]  [ 890/2001]  eta: 0:11:41  lr: 0.000031  loss: 2.9751 (3.0385)  time: 0.6349  data: 0.0001  max mem: 8681
loss info: cls_loss=2.8209, ratio_loss=0.0420, cls_kl=0.0618, token_kl=0.0935
Epoch: [26]  [ 900/2001]  eta: 0:11:34  lr: 0.000031  loss: 3.1060 (3.0385)  time: 0.6336  data: 0.0001  max mem: 8681
Epoch: [26]  [ 910/2001]  eta: 0:11:28  lr: 0.000031  loss: 3.1940 (3.0394)  time: 0.6299  data: 0.0001  max mem: 8681
Epoch: [26]  [ 920/2001]  eta: 0:11:22  lr: 0.000031  loss: 3.1881 (3.0396)  time: 0.6293  data: 0.0001  max mem: 8681
Epoch: [26]  [ 930/2001]  eta: 0:11:15  lr: 0.000031  loss: 3.1881 (3.0428)  time: 0.6299  data: 0.0001  max mem: 8681
Epoch: [26]  [ 940/2001]  eta: 0:11:09  lr: 0.000031  loss: 3.1717 (3.0428)  time: 0.6312  data: 0.0001  max mem: 8681
Epoch: [26]  [ 950/2001]  eta: 0:11:03  lr: 0.000031  loss: 2.8045 (3.0379)  time: 0.6296  data: 0.0001  max mem: 8681
Epoch: [26]  [ 960/2001]  eta: 0:10:56  lr: 0.000031  loss: 2.9793 (3.0385)  time: 0.6286  data: 0.0001  max mem: 8681
Epoch: [26]  [ 970/2001]  eta: 0:10:50  lr: 0.000031  loss: 3.2069 (3.0398)  time: 0.6302  data: 0.0001  max mem: 8681
Epoch: [26]  [ 980/2001]  eta: 0:10:44  lr: 0.000031  loss: 3.2484 (3.0406)  time: 0.6304  data: 0.0001  max mem: 8681
Epoch: [26]  [ 990/2001]  eta: 0:10:37  lr: 0.000031  loss: 3.4010 (3.0408)  time: 0.6293  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9566, ratio_loss=0.0433, cls_kl=0.0644, token_kl=0.0915
Epoch: [26]  [1000/2001]  eta: 0:10:31  lr: 0.000031  loss: 3.2787 (3.0403)  time: 0.6274  data: 0.0001  max mem: 8681
Epoch: [26]  [1010/2001]  eta: 0:10:25  lr: 0.000031  loss: 3.1036 (3.0417)  time: 0.6282  data: 0.0001  max mem: 8681
Epoch: [26]  [1020/2001]  eta: 0:10:19  lr: 0.000031  loss: 3.1036 (3.0413)  time: 0.6326  data: 0.0001  max mem: 8681
Epoch: [26]  [1030/2001]  eta: 0:10:12  lr: 0.000031  loss: 3.0568 (3.0386)  time: 0.6373  data: 0.0001  max mem: 8681
Epoch: [26]  [1040/2001]  eta: 0:10:06  lr: 0.000031  loss: 3.1319 (3.0404)  time: 0.6404  data: 0.0001  max mem: 8681
Epoch: [26]  [1050/2001]  eta: 0:10:00  lr: 0.000031  loss: 3.2726 (3.0402)  time: 0.6364  data: 0.0001  max mem: 8681
Epoch: [26]  [1060/2001]  eta: 0:09:53  lr: 0.000031  loss: 3.2726 (3.0414)  time: 0.6295  data: 0.0001  max mem: 8681
Epoch: [26]  [1070/2001]  eta: 0:09:47  lr: 0.000031  loss: 3.2689 (3.0415)  time: 0.6283  data: 0.0001  max mem: 8681
Epoch: [26]  [1080/2001]  eta: 0:09:41  lr: 0.000031  loss: 3.0609 (3.0410)  time: 0.6285  data: 0.0001  max mem: 8681
Epoch: [26]  [1090/2001]  eta: 0:09:35  lr: 0.000031  loss: 3.0626 (3.0399)  time: 0.6325  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9064, ratio_loss=0.0440, cls_kl=0.0618, token_kl=0.0925
Epoch: [26]  [1100/2001]  eta: 0:09:28  lr: 0.000031  loss: 2.9757 (3.0386)  time: 0.6336  data: 0.0001  max mem: 8681
Epoch: [26]  [1110/2001]  eta: 0:09:22  lr: 0.000031  loss: 3.1522 (3.0389)  time: 0.6300  data: 0.0001  max mem: 8681
Epoch: [26]  [1120/2001]  eta: 0:09:16  lr: 0.000031  loss: 3.1603 (3.0397)  time: 0.6295  data: 0.0001  max mem: 8681
Epoch: [26]  [1130/2001]  eta: 0:09:09  lr: 0.000031  loss: 3.1603 (3.0411)  time: 0.6295  data: 0.0001  max mem: 8681
Epoch: [26]  [1140/2001]  eta: 0:09:03  lr: 0.000031  loss: 3.0946 (3.0395)  time: 0.6310  data: 0.0001  max mem: 8681
Epoch: [26]  [1150/2001]  eta: 0:08:57  lr: 0.000031  loss: 3.0315 (3.0400)  time: 0.6333  data: 0.0001  max mem: 8681
Epoch: [26]  [1160/2001]  eta: 0:08:50  lr: 0.000031  loss: 3.1394 (3.0390)  time: 0.6321  data: 0.0001  max mem: 8681
Epoch: [26]  [1170/2001]  eta: 0:08:44  lr: 0.000031  loss: 3.2017 (3.0392)  time: 0.6324  data: 0.0001  max mem: 8681
Epoch: [26]  [1180/2001]  eta: 0:08:38  lr: 0.000031  loss: 3.2542 (3.0410)  time: 0.6331  data: 0.0001  max mem: 8681
Epoch: [26]  [1190/2001]  eta: 0:08:31  lr: 0.000031  loss: 3.2896 (3.0426)  time: 0.6321  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9900, ratio_loss=0.0468, cls_kl=0.0620, token_kl=0.0911
Epoch: [26]  [1200/2001]  eta: 0:08:25  lr: 0.000031  loss: 3.1671 (3.0433)  time: 0.6357  data: 0.0001  max mem: 8681
Epoch: [26]  [1210/2001]  eta: 0:08:19  lr: 0.000031  loss: 3.1241 (3.0429)  time: 0.6356  data: 0.0001  max mem: 8681
Epoch: [26]  [1220/2001]  eta: 0:08:13  lr: 0.000031  loss: 2.9635 (3.0419)  time: 0.6332  data: 0.0001  max mem: 8681
Epoch: [26]  [1230/2001]  eta: 0:08:06  lr: 0.000031  loss: 3.0425 (3.0418)  time: 0.6343  data: 0.0001  max mem: 8681
Epoch: [26]  [1240/2001]  eta: 0:08:00  lr: 0.000031  loss: 3.1433 (3.0418)  time: 0.6341  data: 0.0001  max mem: 8681
Epoch: [26]  [1250/2001]  eta: 0:07:54  lr: 0.000031  loss: 3.1928 (3.0405)  time: 0.6363  data: 0.0001  max mem: 8681
Epoch: [26]  [1260/2001]  eta: 0:07:47  lr: 0.000031  loss: 3.2134 (3.0422)  time: 0.6377  data: 0.0001  max mem: 8681
Epoch: [26]  [1270/2001]  eta: 0:07:41  lr: 0.000031  loss: 3.2780 (3.0436)  time: 0.6380  data: 0.0001  max mem: 8681
Epoch: [26]  [1280/2001]  eta: 0:07:35  lr: 0.000031  loss: 3.2780 (3.0457)  time: 0.6382  data: 0.0001  max mem: 8681
Epoch: [26]  [1290/2001]  eta: 0:07:29  lr: 0.000031  loss: 3.3497 (3.0475)  time: 0.6352  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9934, ratio_loss=0.0455, cls_kl=0.0645, token_kl=0.0935
Epoch: [26]  [1300/2001]  eta: 0:07:22  lr: 0.000031  loss: 3.2753 (3.0484)  time: 0.6374  data: 0.0001  max mem: 8681
Epoch: [26]  [1310/2001]  eta: 0:07:16  lr: 0.000031  loss: 3.0433 (3.0476)  time: 0.6417  data: 0.0001  max mem: 8681
Epoch: [26]  [1320/2001]  eta: 0:07:10  lr: 0.000031  loss: 2.8921 (3.0453)  time: 0.6381  data: 0.0001  max mem: 8681
Epoch: [26]  [1330/2001]  eta: 0:07:03  lr: 0.000031  loss: 2.9643 (3.0466)  time: 0.6336  data: 0.0001  max mem: 8681
Epoch: [26]  [1340/2001]  eta: 0:06:57  lr: 0.000031  loss: 3.1363 (3.0470)  time: 0.6375  data: 0.0001  max mem: 8681
Epoch: [26]  [1350/2001]  eta: 0:06:51  lr: 0.000031  loss: 3.0543 (3.0474)  time: 0.6401  data: 0.0001  max mem: 8681
Epoch: [26]  [1360/2001]  eta: 0:06:45  lr: 0.000031  loss: 3.1512 (3.0487)  time: 0.6376  data: 0.0001  max mem: 8681
Epoch: [26]  [1370/2001]  eta: 0:06:38  lr: 0.000031  loss: 3.2436 (3.0502)  time: 0.6373  data: 0.0001  max mem: 8681
Epoch: [26]  [1380/2001]  eta: 0:06:32  lr: 0.000031  loss: 3.1794 (3.0510)  time: 0.6398  data: 0.0001  max mem: 8681
Epoch: [26]  [1390/2001]  eta: 0:06:26  lr: 0.000031  loss: 3.1074 (3.0510)  time: 0.6391  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9867, ratio_loss=0.0436, cls_kl=0.0613, token_kl=0.0919
Epoch: [26]  [1400/2001]  eta: 0:06:19  lr: 0.000031  loss: 3.2141 (3.0512)  time: 0.6367  data: 0.0001  max mem: 8681
Epoch: [26]  [1410/2001]  eta: 0:06:13  lr: 0.000031  loss: 3.3512 (3.0533)  time: 0.6370  data: 0.0001  max mem: 8681
Epoch: [26]  [1420/2001]  eta: 0:06:07  lr: 0.000031  loss: 3.3664 (3.0533)  time: 0.6358  data: 0.0001  max mem: 8681
Epoch: [26]  [1430/2001]  eta: 0:06:00  lr: 0.000031  loss: 3.1390 (3.0537)  time: 0.6337  data: 0.0001  max mem: 8681
Epoch: [26]  [1440/2001]  eta: 0:05:54  lr: 0.000031  loss: 3.2186 (3.0531)  time: 0.6336  data: 0.0001  max mem: 8681
Epoch: [26]  [1450/2001]  eta: 0:05:48  lr: 0.000031  loss: 3.1602 (3.0535)  time: 0.6357  data: 0.0001  max mem: 8681
Epoch: [26]  [1460/2001]  eta: 0:05:42  lr: 0.000031  loss: 3.3577 (3.0548)  time: 0.6349  data: 0.0001  max mem: 8681
Epoch: [26]  [1470/2001]  eta: 0:05:35  lr: 0.000031  loss: 3.3793 (3.0542)  time: 0.6377  data: 0.0001  max mem: 8681
Epoch: [26]  [1480/2001]  eta: 0:05:29  lr: 0.000031  loss: 2.8484 (3.0528)  time: 0.6367  data: 0.0001  max mem: 8681
Epoch: [26]  [1490/2001]  eta: 0:05:23  lr: 0.000031  loss: 2.6396 (3.0498)  time: 0.6324  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9168, ratio_loss=0.0436, cls_kl=0.0630, token_kl=0.0943
Epoch: [26]  [1500/2001]  eta: 0:05:16  lr: 0.000031  loss: 2.8032 (3.0491)  time: 0.6364  data: 0.0001  max mem: 8681
Epoch: [26]  [1510/2001]  eta: 0:05:10  lr: 0.000031  loss: 3.1270 (3.0504)  time: 0.6363  data: 0.0001  max mem: 8681
Epoch: [26]  [1520/2001]  eta: 0:05:04  lr: 0.000031  loss: 3.2258 (3.0519)  time: 0.6388  data: 0.0001  max mem: 8681
Epoch: [26]  [1530/2001]  eta: 0:04:57  lr: 0.000031  loss: 3.1717 (3.0512)  time: 0.6379  data: 0.0001  max mem: 8681
Epoch: [26]  [1540/2001]  eta: 0:04:51  lr: 0.000031  loss: 3.0899 (3.0514)  time: 0.6319  data: 0.0001  max mem: 8681
Epoch: [26]  [1550/2001]  eta: 0:04:45  lr: 0.000031  loss: 3.0727 (3.0506)  time: 0.6346  data: 0.0001  max mem: 8681
Epoch: [26]  [1560/2001]  eta: 0:04:38  lr: 0.000031  loss: 2.9639 (3.0505)  time: 0.6346  data: 0.0001  max mem: 8681
Epoch: [26]  [1570/2001]  eta: 0:04:32  lr: 0.000031  loss: 2.8494 (3.0487)  time: 0.6325  data: 0.0001  max mem: 8681
Epoch: [26]  [1580/2001]  eta: 0:04:26  lr: 0.000031  loss: 2.8494 (3.0481)  time: 0.6349  data: 0.0001  max mem: 8681
Epoch: [26]  [1590/2001]  eta: 0:04:19  lr: 0.000031  loss: 3.2059 (3.0491)  time: 0.6351  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9556, ratio_loss=0.0442, cls_kl=0.0624, token_kl=0.0918
Epoch: [26]  [1600/2001]  eta: 0:04:13  lr: 0.000031  loss: 3.2939 (3.0504)  time: 0.6315  data: 0.0001  max mem: 8681
Epoch: [26]  [1610/2001]  eta: 0:04:07  lr: 0.000031  loss: 3.1593 (3.0516)  time: 0.6296  data: 0.0001  max mem: 8681
Epoch: [26]  [1620/2001]  eta: 0:04:00  lr: 0.000031  loss: 3.0672 (3.0511)  time: 0.6296  data: 0.0001  max mem: 8681
Epoch: [26]  [1630/2001]  eta: 0:03:54  lr: 0.000031  loss: 3.0668 (3.0513)  time: 0.6269  data: 0.0001  max mem: 8681
Epoch: [26]  [1640/2001]  eta: 0:03:48  lr: 0.000031  loss: 3.2453 (3.0515)  time: 0.6257  data: 0.0001  max mem: 8681
Epoch: [26]  [1650/2001]  eta: 0:03:41  lr: 0.000031  loss: 2.8911 (3.0487)  time: 0.6275  data: 0.0001  max mem: 8681
Epoch: [26]  [1660/2001]  eta: 0:03:35  lr: 0.000031  loss: 2.5674 (3.0465)  time: 0.6288  data: 0.0001  max mem: 8681
Epoch: [26]  [1670/2001]  eta: 0:03:29  lr: 0.000031  loss: 2.9392 (3.0471)  time: 0.6345  data: 0.0001  max mem: 8681
Epoch: [26]  [1680/2001]  eta: 0:03:22  lr: 0.000031  loss: 3.2986 (3.0472)  time: 0.6346  data: 0.0001  max mem: 8681
Epoch: [26]  [1690/2001]  eta: 0:03:16  lr: 0.000031  loss: 3.2593 (3.0478)  time: 0.6291  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9223, ratio_loss=0.0437, cls_kl=0.0630, token_kl=0.0940
Epoch: [26]  [1700/2001]  eta: 0:03:10  lr: 0.000031  loss: 3.2961 (3.0490)  time: 0.6300  data: 0.0001  max mem: 8681
Epoch: [26]  [1710/2001]  eta: 0:03:03  lr: 0.000031  loss: 3.0787 (3.0485)  time: 0.6272  data: 0.0001  max mem: 8681
Epoch: [26]  [1720/2001]  eta: 0:02:57  lr: 0.000031  loss: 2.9562 (3.0480)  time: 0.6253  data: 0.0001  max mem: 8681
Epoch: [26]  [1730/2001]  eta: 0:02:51  lr: 0.000031  loss: 3.1588 (3.0491)  time: 0.6270  data: 0.0001  max mem: 8681
Epoch: [26]  [1740/2001]  eta: 0:02:45  lr: 0.000031  loss: 3.1588 (3.0487)  time: 0.6317  data: 0.0001  max mem: 8681
Epoch: [26]  [1750/2001]  eta: 0:02:38  lr: 0.000031  loss: 3.0669 (3.0475)  time: 0.6308  data: 0.0001  max mem: 8681
Epoch: [26]  [1760/2001]  eta: 0:02:32  lr: 0.000031  loss: 3.0815 (3.0471)  time: 0.6246  data: 0.0001  max mem: 8681
Epoch: [26]  [1770/2001]  eta: 0:02:26  lr: 0.000031  loss: 3.1692 (3.0477)  time: 0.6240  data: 0.0001  max mem: 8681
Epoch: [26]  [1780/2001]  eta: 0:02:19  lr: 0.000031  loss: 3.2617 (3.0478)  time: 0.6257  data: 0.0001  max mem: 8681
Epoch: [26]  [1790/2001]  eta: 0:02:13  lr: 0.000031  loss: 3.0230 (3.0470)  time: 0.6287  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9343, ratio_loss=0.0438, cls_kl=0.0618, token_kl=0.0925
Epoch: [26]  [1800/2001]  eta: 0:02:07  lr: 0.000031  loss: 3.1230 (3.0482)  time: 0.6272  data: 0.0001  max mem: 8681
Epoch: [26]  [1810/2001]  eta: 0:02:00  lr: 0.000031  loss: 3.1230 (3.0467)  time: 0.6230  data: 0.0001  max mem: 8681
Epoch: [26]  [1820/2001]  eta: 0:01:54  lr: 0.000031  loss: 2.9817 (3.0476)  time: 0.6235  data: 0.0001  max mem: 8681
Epoch: [26]  [1830/2001]  eta: 0:01:48  lr: 0.000031  loss: 3.1479 (3.0477)  time: 0.6251  data: 0.0001  max mem: 8681
Epoch: [26]  [1840/2001]  eta: 0:01:41  lr: 0.000031  loss: 3.1308 (3.0474)  time: 0.6248  data: 0.0001  max mem: 8681
Epoch: [26]  [1850/2001]  eta: 0:01:35  lr: 0.000031  loss: 2.9666 (3.0458)  time: 0.6266  data: 0.0001  max mem: 8681
Epoch: [26]  [1860/2001]  eta: 0:01:29  lr: 0.000031  loss: 2.9459 (3.0455)  time: 0.6261  data: 0.0001  max mem: 8681
Epoch: [26]  [1870/2001]  eta: 0:01:22  lr: 0.000031  loss: 2.9700 (3.0445)  time: 0.6257  data: 0.0001  max mem: 8681
Epoch: [26]  [1880/2001]  eta: 0:01:16  lr: 0.000031  loss: 3.1411 (3.0460)  time: 0.6250  data: 0.0001  max mem: 8681
Epoch: [26]  [1890/2001]  eta: 0:01:10  lr: 0.000031  loss: 3.1964 (3.0450)  time: 0.6234  data: 0.0001  max mem: 8681
loss info: cls_loss=2.8640, ratio_loss=0.0435, cls_kl=0.0601, token_kl=0.0923
Epoch: [26]  [1900/2001]  eta: 0:01:03  lr: 0.000031  loss: 3.0259 (3.0444)  time: 0.6283  data: 0.0001  max mem: 8681
Epoch: [26]  [1910/2001]  eta: 0:00:57  lr: 0.000031  loss: 3.1147 (3.0453)  time: 0.6277  data: 0.0001  max mem: 8681
Epoch: [26]  [1920/2001]  eta: 0:00:51  lr: 0.000031  loss: 2.8462 (3.0433)  time: 0.6190  data: 0.0001  max mem: 8681
Epoch: [26]  [1930/2001]  eta: 0:00:44  lr: 0.000031  loss: 2.8462 (3.0430)  time: 0.6227  data: 0.0001  max mem: 8681
Epoch: [26]  [1940/2001]  eta: 0:00:38  lr: 0.000031  loss: 3.0286 (3.0425)  time: 0.6265  data: 0.0001  max mem: 8681
Epoch: [26]  [1950/2001]  eta: 0:00:32  lr: 0.000031  loss: 2.8970 (3.0418)  time: 0.6221  data: 0.0001  max mem: 8681
Epoch: [26]  [1960/2001]  eta: 0:00:25  lr: 0.000031  loss: 3.0067 (3.0414)  time: 0.6229  data: 0.0001  max mem: 8681
Epoch: [26]  [1970/2001]  eta: 0:00:19  lr: 0.000031  loss: 2.9626 (3.0397)  time: 0.6277  data: 0.0001  max mem: 8681
Epoch: [26]  [1980/2001]  eta: 0:00:13  lr: 0.000031  loss: 2.8012 (3.0388)  time: 0.6331  data: 0.0001  max mem: 8681
Epoch: [26]  [1990/2001]  eta: 0:00:06  lr: 0.000031  loss: 3.1015 (3.0388)  time: 0.6306  data: 0.0003  max mem: 8681
loss info: cls_loss=2.8142, ratio_loss=0.0404, cls_kl=0.0587, token_kl=0.0904
Epoch: [26]  [2000/2001]  eta: 0:00:00  lr: 0.000031  loss: 3.0257 (3.0379)  time: 0.6276  data: 0.0003  max mem: 8681
Epoch: [26] Total time: 0:21:03 (0.6316 s / it)
Averaged stats: lr: 0.000031  loss: 3.0257 (3.0432)
Test:  [ 0/53]  eta: 0:05:25  loss: 0.3626 (0.3626)  acc1: 93.3333 (93.3333)  acc5: 100.0000 (100.0000)  time: 6.1380  data: 5.3959  max mem: 8681
Test:  [10/53]  eta: 0:00:37  loss: 0.7377 (0.7683)  acc1: 83.3333 (83.0303)  acc5: 97.5000 (96.6667)  time: 0.8769  data: 0.5038  max mem: 8681
Test:  [20/53]  eta: 0:00:20  loss: 0.7377 (0.7695)  acc1: 83.3333 (83.0952)  acc5: 96.6667 (96.6667)  time: 0.3353  data: 0.0074  max mem: 8681
Test:  [30/53]  eta: 0:00:11  loss: 0.8791 (0.8516)  acc1: 79.1667 (80.8065)  acc5: 94.1667 (95.4839)  time: 0.3226  data: 0.0002  max mem: 8681
Test:  [40/53]  eta: 0:00:05  loss: 1.0716 (0.9140)  acc1: 76.6667 (79.5325)  acc5: 92.5000 (94.7358)  time: 0.2992  data: 0.0002  max mem: 8681
Test:  [50/53]  eta: 0:00:01  loss: 1.0862 (0.9433)  acc1: 76.6667 (78.8235)  acc5: 92.5000 (94.4935)  time: 0.2620  data: 0.0001  max mem: 8681
Test:  [52/53]  eta: 0:00:00  loss: 1.0747 (0.9296)  acc1: 76.6667 (78.9920)  acc5: 93.3333 (94.5600)  time: 0.2483  data: 0.0000  max mem: 8681
Test: Total time: 0:00:21 (0.4101 s / it)
Sparsity0:0.2976711111111111,Sparsity1:0.5588719191919191,Sparsity2:0.7916452525252525,
* Acc@1 79.004 Acc@5 94.462 loss 0.936
Accuracy of the network on the 50000 test images: 79.0%
Max accuracy: 79.00%
## Using lr  0.0000050 for BACKBONE, cosine lr = 0.0000220 for PREDICTOR
Epoch: [27]  [   0/2001]  eta: 2:41:48  lr: 0.000022  loss: 2.6158 (2.6158)  time: 4.8516  data: 4.2194  max mem: 8683
Epoch: [27]  [  10/2001]  eta: 0:32:51  lr: 0.000022  loss: 3.2851 (3.2283)  time: 0.9900  data: 0.3837  max mem: 8683
Epoch: [27]  [  20/2001]  eta: 0:26:39  lr: 0.000022  loss: 3.1769 (3.1326)  time: 0.6052  data: 0.0001  max mem: 8683
Epoch: [27]  [  30/2001]  eta: 0:24:26  lr: 0.000022  loss: 3.1843 (3.1755)  time: 0.6090  data: 0.0001  max mem: 8683
Epoch: [27]  [  40/2001]  eta: 0:23:17  lr: 0.000022  loss: 3.2689 (3.1500)  time: 0.6129  data: 0.0001  max mem: 8683
Epoch: [27]  [  50/2001]  eta: 0:22:33  lr: 0.000022  loss: 2.9533 (3.1154)  time: 0.6159  data: 0.0001  max mem: 8683
Epoch: [27]  [  60/2001]  eta: 0:22:01  lr: 0.000022  loss: 2.9472 (3.0784)  time: 0.6159  data: 0.0001  max mem: 8683
Epoch: [27]  [  70/2001]  eta: 0:21:37  lr: 0.000022  loss: 3.0875 (3.1001)  time: 0.6168  data: 0.0001  max mem: 8683
Epoch: [27]  [  80/2001]  eta: 0:21:20  lr: 0.000022  loss: 3.0875 (3.0775)  time: 0.6222  data: 0.0001  max mem: 8683
Epoch: [27]  [  90/2001]  eta: 0:21:04  lr: 0.000022  loss: 3.0540 (3.1044)  time: 0.6240  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9821, ratio_loss=0.0446, cls_kl=0.0641, token_kl=0.0935
Epoch: [27]  [ 100/2001]  eta: 0:20:50  lr: 0.000022  loss: 3.3006 (3.0866)  time: 0.6227  data: 0.0001  max mem: 8683
Epoch: [27]  [ 110/2001]  eta: 0:20:37  lr: 0.000022  loss: 3.0555 (3.0822)  time: 0.6231  data: 0.0001  max mem: 8683
Epoch: [27]  [ 120/2001]  eta: 0:20:27  lr: 0.000022  loss: 3.2395 (3.0814)  time: 0.6261  data: 0.0001  max mem: 8683
Epoch: [27]  [ 130/2001]  eta: 0:20:16  lr: 0.000022  loss: 3.2961 (3.0984)  time: 0.6260  data: 0.0001  max mem: 8683
Epoch: [27]  [ 140/2001]  eta: 0:20:07  lr: 0.000022  loss: 3.2718 (3.1041)  time: 0.6270  data: 0.0001  max mem: 8683
Epoch: [27]  [ 150/2001]  eta: 0:19:58  lr: 0.000022  loss: 3.1578 (3.0936)  time: 0.6311  data: 0.0001  max mem: 8683
Epoch: [27]  [ 160/2001]  eta: 0:19:51  lr: 0.000022  loss: 3.0868 (3.0935)  time: 0.6339  data: 0.0001  max mem: 8683
Epoch: [27]  [ 170/2001]  eta: 0:19:42  lr: 0.000022  loss: 3.3108 (3.0987)  time: 0.6303  data: 0.0001  max mem: 8683
Epoch: [27]  [ 180/2001]  eta: 0:19:33  lr: 0.000022  loss: 3.2279 (3.0940)  time: 0.6258  data: 0.0001  max mem: 8683
Epoch: [27]  [ 190/2001]  eta: 0:19:25  lr: 0.000022  loss: 3.1430 (3.0970)  time: 0.6251  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9648, ratio_loss=0.0454, cls_kl=0.0641, token_kl=0.0924
Epoch: [27]  [ 200/2001]  eta: 0:19:17  lr: 0.000022  loss: 3.0293 (3.0822)  time: 0.6240  data: 0.0001  max mem: 8683
Epoch: [27]  [ 210/2001]  eta: 0:19:09  lr: 0.000022  loss: 2.9257 (3.0767)  time: 0.6261  data: 0.0001  max mem: 8683
Epoch: [27]  [ 220/2001]  eta: 0:19:02  lr: 0.000022  loss: 2.9518 (3.0710)  time: 0.6280  data: 0.0001  max mem: 8683
Epoch: [27]  [ 230/2001]  eta: 0:18:54  lr: 0.000022  loss: 2.9791 (3.0651)  time: 0.6288  data: 0.0001  max mem: 8683
Epoch: [27]  [ 240/2001]  eta: 0:18:47  lr: 0.000022  loss: 3.0156 (3.0655)  time: 0.6279  data: 0.0001  max mem: 8683
Epoch: [27]  [ 250/2001]  eta: 0:18:40  lr: 0.000022  loss: 2.8950 (3.0561)  time: 0.6271  data: 0.0001  max mem: 8683
Epoch: [27]  [ 260/2001]  eta: 0:18:32  lr: 0.000022  loss: 2.7535 (3.0536)  time: 0.6262  data: 0.0001  max mem: 8683
Epoch: [27]  [ 270/2001]  eta: 0:18:25  lr: 0.000022  loss: 3.0994 (3.0588)  time: 0.6278  data: 0.0001  max mem: 8683
Epoch: [27]  [ 280/2001]  eta: 0:18:18  lr: 0.000022  loss: 3.2653 (3.0647)  time: 0.6295  data: 0.0001  max mem: 8683
Epoch: [27]  [ 290/2001]  eta: 0:18:11  lr: 0.000022  loss: 3.2671 (3.0577)  time: 0.6285  data: 0.0001  max mem: 8683
loss info: cls_loss=2.8831, ratio_loss=0.0423, cls_kl=0.0612, token_kl=0.0918
Epoch: [27]  [ 300/2001]  eta: 0:18:04  lr: 0.000022  loss: 2.7059 (3.0458)  time: 0.6272  data: 0.0001  max mem: 8683
Epoch: [27]  [ 310/2001]  eta: 0:17:57  lr: 0.000022  loss: 2.8898 (3.0463)  time: 0.6277  data: 0.0001  max mem: 8683
Epoch: [27]  [ 320/2001]  eta: 0:17:51  lr: 0.000022  loss: 3.1870 (3.0517)  time: 0.6291  data: 0.0001  max mem: 8683
Epoch: [27]  [ 330/2001]  eta: 0:17:44  lr: 0.000022  loss: 3.2512 (3.0619)  time: 0.6282  data: 0.0001  max mem: 8683
Epoch: [27]  [ 340/2001]  eta: 0:17:37  lr: 0.000022  loss: 3.1415 (3.0592)  time: 0.6280  data: 0.0001  max mem: 8683
Epoch: [27]  [ 350/2001]  eta: 0:17:30  lr: 0.000022  loss: 2.9921 (3.0595)  time: 0.6310  data: 0.0001  max mem: 8683
Epoch: [27]  [ 360/2001]  eta: 0:17:24  lr: 0.000022  loss: 2.8743 (3.0568)  time: 0.6320  data: 0.0001  max mem: 8683
Epoch: [27]  [ 370/2001]  eta: 0:17:17  lr: 0.000022  loss: 2.9111 (3.0541)  time: 0.6299  data: 0.0001  max mem: 8683
Epoch: [27]  [ 380/2001]  eta: 0:17:10  lr: 0.000022  loss: 3.1042 (3.0549)  time: 0.6287  data: 0.0001  max mem: 8683
Epoch: [27]  [ 390/2001]  eta: 0:17:04  lr: 0.000022  loss: 3.0172 (3.0458)  time: 0.6304  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9140, ratio_loss=0.0441, cls_kl=0.0629, token_kl=0.0924
Epoch: [27]  [ 400/2001]  eta: 0:16:57  lr: 0.000022  loss: 3.0253 (3.0453)  time: 0.6301  data: 0.0001  max mem: 8683
Epoch: [27]  [ 410/2001]  eta: 0:16:50  lr: 0.000022  loss: 3.1685 (3.0445)  time: 0.6268  data: 0.0001  max mem: 8683
Epoch: [27]  [ 420/2001]  eta: 0:16:44  lr: 0.000022  loss: 2.8101 (3.0377)  time: 0.6309  data: 0.0001  max mem: 8683
Epoch: [27]  [ 430/2001]  eta: 0:16:38  lr: 0.000022  loss: 2.9816 (3.0389)  time: 0.6381  data: 0.0001  max mem: 8683
Epoch: [27]  [ 440/2001]  eta: 0:16:31  lr: 0.000022  loss: 3.2020 (3.0417)  time: 0.6365  data: 0.0001  max mem: 8683
Epoch: [27]  [ 450/2001]  eta: 0:16:25  lr: 0.000022  loss: 3.2966 (3.0461)  time: 0.6297  data: 0.0001  max mem: 8683
Epoch: [27]  [ 460/2001]  eta: 0:16:18  lr: 0.000022  loss: 3.0862 (3.0421)  time: 0.6284  data: 0.0001  max mem: 8683
Epoch: [27]  [ 470/2001]  eta: 0:16:12  lr: 0.000022  loss: 3.0862 (3.0391)  time: 0.6309  data: 0.0001  max mem: 8683
Epoch: [27]  [ 480/2001]  eta: 0:16:05  lr: 0.000022  loss: 3.0076 (3.0397)  time: 0.6319  data: 0.0001  max mem: 8683
Epoch: [27]  [ 490/2001]  eta: 0:15:59  lr: 0.000022  loss: 3.1622 (3.0455)  time: 0.6321  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9293, ratio_loss=0.0436, cls_kl=0.0620, token_kl=0.0930
Epoch: [27]  [ 500/2001]  eta: 0:15:53  lr: 0.000022  loss: 3.1325 (3.0401)  time: 0.6326  data: 0.0001  max mem: 8683
Epoch: [27]  [ 510/2001]  eta: 0:15:46  lr: 0.000022  loss: 2.7771 (3.0399)  time: 0.6322  data: 0.0001  max mem: 8683
Epoch: [27]  [ 520/2001]  eta: 0:15:40  lr: 0.000022  loss: 3.2011 (3.0429)  time: 0.6313  data: 0.0001  max mem: 8683
Epoch: [27]  [ 530/2001]  eta: 0:15:33  lr: 0.000022  loss: 3.3208 (3.0463)  time: 0.6305  data: 0.0001  max mem: 8683
Epoch: [27]  [ 540/2001]  eta: 0:15:27  lr: 0.000022  loss: 3.1289 (3.0436)  time: 0.6335  data: 0.0001  max mem: 8683
Epoch: [27]  [ 550/2001]  eta: 0:15:21  lr: 0.000022  loss: 3.0386 (3.0446)  time: 0.6369  data: 0.0001  max mem: 8683
Epoch: [27]  [ 560/2001]  eta: 0:15:14  lr: 0.000022  loss: 3.2564 (3.0506)  time: 0.6345  data: 0.0001  max mem: 8683
Epoch: [27]  [ 570/2001]  eta: 0:15:08  lr: 0.000022  loss: 3.2564 (3.0527)  time: 0.6312  data: 0.0001  max mem: 8683
Epoch: [27]  [ 580/2001]  eta: 0:15:01  lr: 0.000022  loss: 3.1591 (3.0533)  time: 0.6351  data: 0.0001  max mem: 8683
Epoch: [27]  [ 590/2001]  eta: 0:14:55  lr: 0.000022  loss: 3.0613 (3.0517)  time: 0.6405  data: 0.0001  max mem: 8683
loss info: cls_loss=3.0035, ratio_loss=0.0435, cls_kl=0.0632, token_kl=0.0927
Epoch: [27]  [ 600/2001]  eta: 0:14:49  lr: 0.000022  loss: 3.0592 (3.0534)  time: 0.6388  data: 0.0001  max mem: 8683
Epoch: [27]  [ 610/2001]  eta: 0:14:43  lr: 0.000022  loss: 3.0474 (3.0499)  time: 0.6332  data: 0.0001  max mem: 8683
Epoch: [27]  [ 620/2001]  eta: 0:14:36  lr: 0.000022  loss: 2.9587 (3.0517)  time: 0.6322  data: 0.0001  max mem: 8683
Epoch: [27]  [ 630/2001]  eta: 0:14:30  lr: 0.000022  loss: 3.2451 (3.0515)  time: 0.6324  data: 0.0001  max mem: 8683
Epoch: [27]  [ 640/2001]  eta: 0:14:23  lr: 0.000022  loss: 3.2571 (3.0553)  time: 0.6302  data: 0.0001  max mem: 8683
Epoch: [27]  [ 650/2001]  eta: 0:14:17  lr: 0.000022  loss: 3.2836 (3.0523)  time: 0.6307  data: 0.0001  max mem: 8683
Epoch: [27]  [ 660/2001]  eta: 0:14:10  lr: 0.000022  loss: 3.3290 (3.0562)  time: 0.6322  data: 0.0001  max mem: 8683
Epoch: [27]  [ 670/2001]  eta: 0:14:04  lr: 0.000022  loss: 3.2787 (3.0579)  time: 0.6342  data: 0.0001  max mem: 8683
Epoch: [27]  [ 680/2001]  eta: 0:13:58  lr: 0.000022  loss: 3.2604 (3.0610)  time: 0.6347  data: 0.0001  max mem: 8683
Epoch: [27]  [ 690/2001]  eta: 0:13:51  lr: 0.000022  loss: 3.4039 (3.0646)  time: 0.6344  data: 0.0001  max mem: 8683
loss info: cls_loss=3.0290, ratio_loss=0.0453, cls_kl=0.0645, token_kl=0.0933
Epoch: [27]  [ 700/2001]  eta: 0:13:45  lr: 0.000022  loss: 3.3743 (3.0655)  time: 0.6364  data: 0.0001  max mem: 8683
Epoch: [27]  [ 710/2001]  eta: 0:13:39  lr: 0.000022  loss: 3.3597 (3.0689)  time: 0.6353  data: 0.0001  max mem: 8683
Epoch: [27]  [ 720/2001]  eta: 0:13:33  lr: 0.000022  loss: 3.2321 (3.0679)  time: 0.6355  data: 0.0001  max mem: 8683
Epoch: [27]  [ 730/2001]  eta: 0:13:26  lr: 0.000022  loss: 3.2321 (3.0702)  time: 0.6384  data: 0.0001  max mem: 8683
Epoch: [27]  [ 740/2001]  eta: 0:13:20  lr: 0.000022  loss: 3.1766 (3.0665)  time: 0.6395  data: 0.0001  max mem: 8683
Epoch: [27]  [ 750/2001]  eta: 0:13:14  lr: 0.000022  loss: 3.1321 (3.0676)  time: 0.6384  data: 0.0001  max mem: 8683
Epoch: [27]  [ 760/2001]  eta: 0:13:07  lr: 0.000022  loss: 3.1335 (3.0654)  time: 0.6352  data: 0.0001  max mem: 8683
Epoch: [27]  [ 770/2001]  eta: 0:13:01  lr: 0.000022  loss: 3.2458 (3.0680)  time: 0.6351  data: 0.0001  max mem: 8683
Epoch: [27]  [ 780/2001]  eta: 0:12:55  lr: 0.000022  loss: 3.3617 (3.0683)  time: 0.6367  data: 0.0001  max mem: 8683
Epoch: [27]  [ 790/2001]  eta: 0:12:48  lr: 0.000022  loss: 3.0006 (3.0656)  time: 0.6358  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9592, ratio_loss=0.0435, cls_kl=0.0630, token_kl=0.0921
Epoch: [27]  [ 800/2001]  eta: 0:12:42  lr: 0.000022  loss: 2.9018 (3.0648)  time: 0.6387  data: 0.0001  max mem: 8683
Epoch: [27]  [ 810/2001]  eta: 0:12:36  lr: 0.000022  loss: 3.2210 (3.0659)  time: 0.6389  data: 0.0001  max mem: 8683
Epoch: [27]  [ 820/2001]  eta: 0:12:29  lr: 0.000022  loss: 3.2262 (3.0656)  time: 0.6365  data: 0.0001  max mem: 8683
Epoch: [27]  [ 830/2001]  eta: 0:12:23  lr: 0.000022  loss: 3.2107 (3.0645)  time: 0.6387  data: 0.0001  max mem: 8683
Epoch: [27]  [ 840/2001]  eta: 0:12:17  lr: 0.000022  loss: 3.1435 (3.0661)  time: 0.6381  data: 0.0001  max mem: 8683
Epoch: [27]  [ 850/2001]  eta: 0:12:11  lr: 0.000022  loss: 3.0920 (3.0639)  time: 0.6396  data: 0.0001  max mem: 8683
Epoch: [27]  [ 860/2001]  eta: 0:12:04  lr: 0.000022  loss: 2.6110 (3.0570)  time: 0.6423  data: 0.0001  max mem: 8683
Epoch: [27]  [ 870/2001]  eta: 0:11:58  lr: 0.000022  loss: 2.5575 (3.0544)  time: 0.6389  data: 0.0001  max mem: 8683
Epoch: [27]  [ 880/2001]  eta: 0:11:52  lr: 0.000022  loss: 3.0186 (3.0547)  time: 0.6347  data: 0.0001  max mem: 8683
Epoch: [27]  [ 890/2001]  eta: 0:11:45  lr: 0.000022  loss: 2.9937 (3.0515)  time: 0.6331  data: 0.0001  max mem: 8683
loss info: cls_loss=2.8615, ratio_loss=0.0418, cls_kl=0.0605, token_kl=0.0913
Epoch: [27]  [ 900/2001]  eta: 0:11:39  lr: 0.000022  loss: 3.0704 (3.0540)  time: 0.6322  data: 0.0001  max mem: 8683
Epoch: [27]  [ 910/2001]  eta: 0:11:32  lr: 0.000022  loss: 3.1667 (3.0518)  time: 0.6320  data: 0.0001  max mem: 8683
Epoch: [27]  [ 920/2001]  eta: 0:11:26  lr: 0.000022  loss: 2.8703 (3.0521)  time: 0.6352  data: 0.0001  max mem: 8683
Epoch: [27]  [ 930/2001]  eta: 0:11:20  lr: 0.000022  loss: 3.1073 (3.0543)  time: 0.6396  data: 0.0001  max mem: 8683
Epoch: [27]  [ 940/2001]  eta: 0:11:13  lr: 0.000022  loss: 3.3602 (3.0575)  time: 0.6364  data: 0.0001  max mem: 8683
Epoch: [27]  [ 950/2001]  eta: 0:11:07  lr: 0.000022  loss: 3.0338 (3.0536)  time: 0.6337  data: 0.0001  max mem: 8683
Epoch: [27]  [ 960/2001]  eta: 0:11:01  lr: 0.000022  loss: 2.8717 (3.0537)  time: 0.6326  data: 0.0001  max mem: 8683
Epoch: [27]  [ 970/2001]  eta: 0:10:54  lr: 0.000022  loss: 3.1867 (3.0538)  time: 0.6314  data: 0.0001  max mem: 8683
Epoch: [27]  [ 980/2001]  eta: 0:10:48  lr: 0.000022  loss: 3.1875 (3.0532)  time: 0.6323  data: 0.0001  max mem: 8683
Epoch: [27]  [ 990/2001]  eta: 0:10:42  lr: 0.000022  loss: 3.2952 (3.0544)  time: 0.6328  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9580, ratio_loss=0.0444, cls_kl=0.0626, token_kl=0.0923
Epoch: [27]  [1000/2001]  eta: 0:10:35  lr: 0.000022  loss: 3.1737 (3.0548)  time: 0.6334  data: 0.0001  max mem: 8683
Epoch: [27]  [1010/2001]  eta: 0:10:29  lr: 0.000022  loss: 3.0725 (3.0552)  time: 0.6358  data: 0.0001  max mem: 8683
Epoch: [27]  [1020/2001]  eta: 0:10:23  lr: 0.000022  loss: 3.0974 (3.0560)  time: 0.6393  data: 0.0001  max mem: 8683
Epoch: [27]  [1030/2001]  eta: 0:10:16  lr: 0.000022  loss: 3.0451 (3.0540)  time: 0.6358  data: 0.0001  max mem: 8683
Epoch: [27]  [1040/2001]  eta: 0:10:10  lr: 0.000022  loss: 3.0686 (3.0528)  time: 0.6319  data: 0.0001  max mem: 8683
Epoch: [27]  [1050/2001]  eta: 0:10:03  lr: 0.000022  loss: 3.1667 (3.0538)  time: 0.6315  data: 0.0001  max mem: 8683
Epoch: [27]  [1060/2001]  eta: 0:09:57  lr: 0.000022  loss: 3.2145 (3.0530)  time: 0.6298  data: 0.0001  max mem: 8683
Epoch: [27]  [1070/2001]  eta: 0:09:51  lr: 0.000022  loss: 2.8864 (3.0515)  time: 0.6302  data: 0.0001  max mem: 8683
Epoch: [27]  [1080/2001]  eta: 0:09:44  lr: 0.000022  loss: 2.7482 (3.0492)  time: 0.6312  data: 0.0001  max mem: 8683
Epoch: [27]  [1090/2001]  eta: 0:09:38  lr: 0.000022  loss: 2.7482 (3.0476)  time: 0.6306  data: 0.0001  max mem: 8683
loss info: cls_loss=2.8839, ratio_loss=0.0404, cls_kl=0.0606, token_kl=0.0908
Epoch: [27]  [1100/2001]  eta: 0:09:31  lr: 0.000022  loss: 3.0849 (3.0484)  time: 0.6300  data: 0.0001  max mem: 8683
Epoch: [27]  [1110/2001]  eta: 0:09:25  lr: 0.000022  loss: 3.1744 (3.0491)  time: 0.6306  data: 0.0001  max mem: 8683
Epoch: [27]  [1120/2001]  eta: 0:09:19  lr: 0.000022  loss: 3.0470 (3.0493)  time: 0.6305  data: 0.0001  max mem: 8683
Epoch: [27]  [1130/2001]  eta: 0:09:12  lr: 0.000022  loss: 3.0803 (3.0498)  time: 0.6274  data: 0.0001  max mem: 8683
Epoch: [27]  [1140/2001]  eta: 0:09:06  lr: 0.000022  loss: 2.7985 (3.0469)  time: 0.6268  data: 0.0001  max mem: 8683
Epoch: [27]  [1150/2001]  eta: 0:08:59  lr: 0.000022  loss: 2.9260 (3.0460)  time: 0.6282  data: 0.0001  max mem: 8683
Epoch: [27]  [1160/2001]  eta: 0:08:53  lr: 0.000022  loss: 3.0511 (3.0451)  time: 0.6275  data: 0.0001  max mem: 8683
Epoch: [27]  [1170/2001]  eta: 0:08:47  lr: 0.000022  loss: 2.9343 (3.0459)  time: 0.6267  data: 0.0001  max mem: 8683
Epoch: [27]  [1180/2001]  eta: 0:08:40  lr: 0.000022  loss: 3.3298 (3.0476)  time: 0.6256  data: 0.0001  max mem: 8683
Epoch: [27]  [1190/2001]  eta: 0:08:34  lr: 0.000022  loss: 3.1944 (3.0436)  time: 0.6251  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9016, ratio_loss=0.0431, cls_kl=0.0615, token_kl=0.0917
Epoch: [27]  [1200/2001]  eta: 0:08:27  lr: 0.000022  loss: 3.1564 (3.0452)  time: 0.6239  data: 0.0001  max mem: 8683
Epoch: [27]  [1210/2001]  eta: 0:08:21  lr: 0.000022  loss: 3.3049 (3.0460)  time: 0.6239  data: 0.0001  max mem: 8683
Epoch: [27]  [1220/2001]  eta: 0:08:15  lr: 0.000022  loss: 3.2073 (3.0455)  time: 0.6255  data: 0.0001  max mem: 8683
Epoch: [27]  [1230/2001]  eta: 0:08:08  lr: 0.000022  loss: 3.2073 (3.0469)  time: 0.6259  data: 0.0001  max mem: 8683
Epoch: [27]  [1240/2001]  eta: 0:08:02  lr: 0.000022  loss: 3.2648 (3.0492)  time: 0.6273  data: 0.0001  max mem: 8683
Epoch: [27]  [1250/2001]  eta: 0:07:56  lr: 0.000022  loss: 3.2712 (3.0494)  time: 0.6269  data: 0.0001  max mem: 8683
Epoch: [27]  [1260/2001]  eta: 0:07:49  lr: 0.000022  loss: 2.9648 (3.0484)  time: 0.6252  data: 0.0001  max mem: 8683
Epoch: [27]  [1270/2001]  eta: 0:07:43  lr: 0.000022  loss: 2.8790 (3.0485)  time: 0.6228  data: 0.0001  max mem: 8683
Epoch: [27]  [1280/2001]  eta: 0:07:36  lr: 0.000022  loss: 3.0306 (3.0480)  time: 0.6261  data: 0.0001  max mem: 8683
Epoch: [27]  [1290/2001]  eta: 0:07:30  lr: 0.000022  loss: 3.0306 (3.0486)  time: 0.6312  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9860, ratio_loss=0.0489, cls_kl=0.0667, token_kl=0.0967
Epoch: [27]  [1300/2001]  eta: 0:07:24  lr: 0.000022  loss: 3.2511 (3.0491)  time: 0.6271  data: 0.0001  max mem: 8683
Epoch: [27]  [1310/2001]  eta: 0:07:17  lr: 0.000022  loss: 3.3497 (3.0496)  time: 0.6219  data: 0.0001  max mem: 8683
Epoch: [27]  [1320/2001]  eta: 0:07:11  lr: 0.000022  loss: 3.2845 (3.0504)  time: 0.6223  data: 0.0001  max mem: 8683
Epoch: [27]  [1330/2001]  eta: 0:07:04  lr: 0.000022  loss: 3.2366 (3.0490)  time: 0.6237  data: 0.0001  max mem: 8683
Epoch: [27]  [1340/2001]  eta: 0:06:58  lr: 0.000022  loss: 2.7620 (3.0471)  time: 0.6233  data: 0.0001  max mem: 8683
Epoch: [27]  [1350/2001]  eta: 0:06:52  lr: 0.000022  loss: 3.1018 (3.0473)  time: 0.6255  data: 0.0001  max mem: 8683
Epoch: [27]  [1360/2001]  eta: 0:06:45  lr: 0.000022  loss: 3.1875 (3.0470)  time: 0.6263  data: 0.0001  max mem: 8683
Epoch: [27]  [1370/2001]  eta: 0:06:39  lr: 0.000022  loss: 2.9380 (3.0462)  time: 0.6226  data: 0.0001  max mem: 8683
Epoch: [27]  [1380/2001]  eta: 0:06:33  lr: 0.000022  loss: 3.1991 (3.0463)  time: 0.6219  data: 0.0001  max mem: 8683
Epoch: [27]  [1390/2001]  eta: 0:06:26  lr: 0.000022  loss: 3.3228 (3.0486)  time: 0.6228  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9134, ratio_loss=0.0435, cls_kl=0.0647, token_kl=0.0930
Epoch: [27]  [1400/2001]  eta: 0:06:20  lr: 0.000022  loss: 3.1414 (3.0473)  time: 0.6266  data: 0.0001  max mem: 8683
Epoch: [27]  [1410/2001]  eta: 0:06:13  lr: 0.000022  loss: 3.0380 (3.0485)  time: 0.6290  data: 0.0001  max mem: 8683
Epoch: [27]  [1420/2001]  eta: 0:06:07  lr: 0.000022  loss: 3.4119 (3.0490)  time: 0.6246  data: 0.0001  max mem: 8683
Epoch: [27]  [1430/2001]  eta: 0:06:01  lr: 0.000022  loss: 2.9264 (3.0480)  time: 0.6242  data: 0.0001  max mem: 8683
Epoch: [27]  [1440/2001]  eta: 0:05:54  lr: 0.000022  loss: 2.8476 (3.0473)  time: 0.6301  data: 0.0001  max mem: 8683
Epoch: [27]  [1450/2001]  eta: 0:05:48  lr: 0.000022  loss: 3.0107 (3.0472)  time: 0.6280  data: 0.0001  max mem: 8683
Epoch: [27]  [1460/2001]  eta: 0:05:42  lr: 0.000022  loss: 3.2316 (3.0481)  time: 0.6287  data: 0.0001  max mem: 8683
Epoch: [27]  [1470/2001]  eta: 0:05:35  lr: 0.000022  loss: 3.0581 (3.0465)  time: 0.6315  data: 0.0001  max mem: 8683
Epoch: [27]  [1480/2001]  eta: 0:05:29  lr: 0.000022  loss: 3.0600 (3.0476)  time: 0.6240  data: 0.0001  max mem: 8683
Epoch: [27]  [1490/2001]  eta: 0:05:23  lr: 0.000022  loss: 3.0600 (3.0466)  time: 0.6200  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9139, ratio_loss=0.0416, cls_kl=0.0616, token_kl=0.0920
Epoch: [27]  [1500/2001]  eta: 0:05:16  lr: 0.000022  loss: 2.9393 (3.0459)  time: 0.6192  data: 0.0001  max mem: 8683
Epoch: [27]  [1510/2001]  eta: 0:05:10  lr: 0.000022  loss: 2.9393 (3.0457)  time: 0.6221  data: 0.0001  max mem: 8683
Epoch: [27]  [1520/2001]  eta: 0:05:04  lr: 0.000022  loss: 2.8158 (3.0439)  time: 0.6244  data: 0.0001  max mem: 8683
Epoch: [27]  [1530/2001]  eta: 0:04:57  lr: 0.000022  loss: 3.0165 (3.0440)  time: 0.6245  data: 0.0001  max mem: 8683
Epoch: [27]  [1540/2001]  eta: 0:04:51  lr: 0.000022  loss: 3.0801 (3.0442)  time: 0.6245  data: 0.0001  max mem: 8683
Epoch: [27]  [1550/2001]  eta: 0:04:45  lr: 0.000022  loss: 2.9994 (3.0425)  time: 0.6248  data: 0.0001  max mem: 8683
Epoch: [27]  [1560/2001]  eta: 0:04:38  lr: 0.000022  loss: 3.1726 (3.0441)  time: 0.6268  data: 0.0001  max mem: 8683
Epoch: [27]  [1570/2001]  eta: 0:04:32  lr: 0.000022  loss: 3.2702 (3.0442)  time: 0.6274  data: 0.0001  max mem: 8683
Epoch: [27]  [1580/2001]  eta: 0:04:26  lr: 0.000022  loss: 3.2399 (3.0457)  time: 0.6277  data: 0.0001  max mem: 8683
Epoch: [27]  [1590/2001]  eta: 0:04:19  lr: 0.000022  loss: 3.2189 (3.0460)  time: 0.6272  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9404, ratio_loss=0.0460, cls_kl=0.0624, token_kl=0.0940
Epoch: [27]  [1600/2001]  eta: 0:04:13  lr: 0.000022  loss: 3.0133 (3.0452)  time: 0.6292  data: 0.0001  max mem: 8683
Epoch: [27]  [1610/2001]  eta: 0:04:07  lr: 0.000022  loss: 3.3188 (3.0461)  time: 0.6309  data: 0.0001  max mem: 8683
Epoch: [27]  [1620/2001]  eta: 0:04:00  lr: 0.000022  loss: 3.3864 (3.0473)  time: 0.6241  data: 0.0001  max mem: 8683
Epoch: [27]  [1630/2001]  eta: 0:03:54  lr: 0.000022  loss: 3.2997 (3.0484)  time: 0.6219  data: 0.0001  max mem: 8683
Epoch: [27]  [1640/2001]  eta: 0:03:48  lr: 0.000022  loss: 3.1012 (3.0481)  time: 0.6245  data: 0.0001  max mem: 8683
Epoch: [27]  [1650/2001]  eta: 0:03:41  lr: 0.000022  loss: 3.0578 (3.0491)  time: 0.6252  data: 0.0001  max mem: 8683
Epoch: [27]  [1660/2001]  eta: 0:03:35  lr: 0.000022  loss: 3.2023 (3.0491)  time: 0.6253  data: 0.0001  max mem: 8683
Epoch: [27]  [1670/2001]  eta: 0:03:29  lr: 0.000022  loss: 3.2307 (3.0503)  time: 0.6252  data: 0.0001  max mem: 8683
Epoch: [27]  [1680/2001]  eta: 0:03:22  lr: 0.000022  loss: 3.2307 (3.0507)  time: 0.6250  data: 0.0001  max mem: 8683
Epoch: [27]  [1690/2001]  eta: 0:03:16  lr: 0.000022  loss: 3.1280 (3.0508)  time: 0.6299  data: 0.0001  max mem: 8683
loss info: cls_loss=3.0107, ratio_loss=0.0439, cls_kl=0.0636, token_kl=0.0919
Epoch: [27]  [1700/2001]  eta: 0:03:10  lr: 0.000022  loss: 2.9839 (3.0501)  time: 0.6387  data: 0.0001  max mem: 8683
Epoch: [27]  [1710/2001]  eta: 0:03:03  lr: 0.000022  loss: 2.9007 (3.0495)  time: 0.6399  data: 0.0001  max mem: 8683
Epoch: [27]  [1720/2001]  eta: 0:02:57  lr: 0.000022  loss: 3.1697 (3.0504)  time: 0.6336  data: 0.0001  max mem: 8683
Epoch: [27]  [1730/2001]  eta: 0:02:51  lr: 0.000022  loss: 3.2848 (3.0512)  time: 0.6282  data: 0.0001  max mem: 8683
Epoch: [27]  [1740/2001]  eta: 0:02:44  lr: 0.000022  loss: 3.2848 (3.0519)  time: 0.6277  data: 0.0001  max mem: 8683
Epoch: [27]  [1750/2001]  eta: 0:02:38  lr: 0.000022  loss: 3.1317 (3.0511)  time: 0.6270  data: 0.0001  max mem: 8683
Epoch: [27]  [1760/2001]  eta: 0:02:32  lr: 0.000022  loss: 3.1317 (3.0517)  time: 0.6269  data: 0.0001  max mem: 8683
Epoch: [27]  [1770/2001]  eta: 0:02:25  lr: 0.000022  loss: 3.2024 (3.0518)  time: 0.6254  data: 0.0001  max mem: 8683
Epoch: [27]  [1780/2001]  eta: 0:02:19  lr: 0.000022  loss: 3.0868 (3.0514)  time: 0.6247  data: 0.0001  max mem: 8683
Epoch: [27]  [1790/2001]  eta: 0:02:13  lr: 0.000022  loss: 3.3062 (3.0526)  time: 0.6273  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9922, ratio_loss=0.0457, cls_kl=0.0640, token_kl=0.0935
Epoch: [27]  [1800/2001]  eta: 0:02:06  lr: 0.000022  loss: 3.1668 (3.0526)  time: 0.6295  data: 0.0001  max mem: 8683
Epoch: [27]  [1810/2001]  eta: 0:02:00  lr: 0.000022  loss: 3.0356 (3.0527)  time: 0.6295  data: 0.0001  max mem: 8683
Epoch: [27]  [1820/2001]  eta: 0:01:54  lr: 0.000022  loss: 3.0033 (3.0513)  time: 0.6278  data: 0.0001  max mem: 8683
Epoch: [27]  [1830/2001]  eta: 0:01:47  lr: 0.000022  loss: 3.1948 (3.0522)  time: 0.6280  data: 0.0001  max mem: 8683
Epoch: [27]  [1840/2001]  eta: 0:01:41  lr: 0.000022  loss: 3.2185 (3.0509)  time: 0.6274  data: 0.0001  max mem: 8683
Epoch: [27]  [1850/2001]  eta: 0:01:35  lr: 0.000022  loss: 3.1791 (3.0523)  time: 0.6278  data: 0.0001  max mem: 8683
Epoch: [27]  [1860/2001]  eta: 0:01:29  lr: 0.000022  loss: 3.1844 (3.0511)  time: 0.6322  data: 0.0001  max mem: 8683
Epoch: [27]  [1870/2001]  eta: 0:01:22  lr: 0.000022  loss: 3.1844 (3.0515)  time: 0.6363  data: 0.0001  max mem: 8683
Epoch: [27]  [1880/2001]  eta: 0:01:16  lr: 0.000022  loss: 3.1187 (3.0500)  time: 0.6338  data: 0.0001  max mem: 8683
Epoch: [27]  [1890/2001]  eta: 0:01:10  lr: 0.000022  loss: 2.8731 (3.0494)  time: 0.6284  data: 0.0001  max mem: 8683
loss info: cls_loss=2.8681, ratio_loss=0.0438, cls_kl=0.0611, token_kl=0.0915
Epoch: [27]  [1900/2001]  eta: 0:01:03  lr: 0.000022  loss: 3.1220 (3.0487)  time: 0.6270  data: 0.0001  max mem: 8683
Epoch: [27]  [1910/2001]  eta: 0:00:57  lr: 0.000022  loss: 3.1102 (3.0492)  time: 0.6300  data: 0.0001  max mem: 8683
Epoch: [27]  [1920/2001]  eta: 0:00:51  lr: 0.000022  loss: 3.1102 (3.0497)  time: 0.6306  data: 0.0001  max mem: 8683
Epoch: [27]  [1930/2001]  eta: 0:00:44  lr: 0.000022  loss: 3.2194 (3.0489)  time: 0.6294  data: 0.0001  max mem: 8683
Epoch: [27]  [1940/2001]  eta: 0:00:38  lr: 0.000022  loss: 2.8809 (3.0475)  time: 0.6305  data: 0.0001  max mem: 8683
Epoch: [27]  [1950/2001]  eta: 0:00:32  lr: 0.000022  loss: 2.8809 (3.0468)  time: 0.6305  data: 0.0001  max mem: 8683
Epoch: [27]  [1960/2001]  eta: 0:00:25  lr: 0.000022  loss: 3.1019 (3.0479)  time: 0.6292  data: 0.0001  max mem: 8683
Epoch: [27]  [1970/2001]  eta: 0:00:19  lr: 0.000022  loss: 3.2490 (3.0494)  time: 0.6276  data: 0.0001  max mem: 8683
Epoch: [27]  [1980/2001]  eta: 0:00:13  lr: 0.000022  loss: 3.2193 (3.0495)  time: 0.6303  data: 0.0001  max mem: 8683
Epoch: [27]  [1990/2001]  eta: 0:00:06  lr: 0.000022  loss: 3.1578 (3.0495)  time: 0.6295  data: 0.0003  max mem: 8683
loss info: cls_loss=2.9374, ratio_loss=0.0467, cls_kl=0.0641, token_kl=0.0951
Epoch: [27]  [2000/2001]  eta: 0:00:00  lr: 0.000022  loss: 3.1184 (3.0490)  time: 0.6243  data: 0.0003  max mem: 8683
Epoch: [27] Total time: 0:21:03 (0.6316 s / it)
Averaged stats: lr: 0.000022  loss: 3.1184 (3.0378)
Test:  [ 0/53]  eta: 0:04:59  loss: 0.3479 (0.3479)  acc1: 94.1667 (94.1667)  acc5: 100.0000 (100.0000)  time: 5.6564  data: 5.1581  max mem: 8683
Test:  [10/53]  eta: 0:00:38  loss: 0.6928 (0.7614)  acc1: 85.0000 (83.5606)  acc5: 96.6667 (96.6667)  time: 0.8973  data: 0.5327  max mem: 8683
Test:  [20/53]  eta: 0:00:20  loss: 0.7041 (0.7725)  acc1: 81.6667 (83.0556)  acc5: 96.6667 (96.4683)  time: 0.3810  data: 0.0352  max mem: 8683
Test:  [30/53]  eta: 0:00:12  loss: 0.9004 (0.8507)  acc1: 78.3333 (81.0753)  acc5: 94.1667 (95.4032)  time: 0.3342  data: 0.0003  max mem: 8683
Test:  [40/53]  eta: 0:00:06  loss: 1.1128 (0.9184)  acc1: 76.6667 (79.3902)  acc5: 92.5000 (94.6545)  time: 0.2938  data: 0.0002  max mem: 8683
Test:  [50/53]  eta: 0:00:01  loss: 1.1103 (0.9507)  acc1: 74.1667 (78.6111)  acc5: 92.5000 (94.4281)  time: 0.2560  data: 0.0001  max mem: 8683
Test:  [52/53]  eta: 0:00:00  loss: 1.0981 (0.9359)  acc1: 74.1667 (78.8160)  acc5: 92.5000 (94.4960)  time: 0.2449  data: 0.0001  max mem: 8683
Test: Total time: 0:00:22 (0.4164 s / it)
Sparsity0:0.2977430303030303,Sparsity1:0.5598472727272727,Sparsity2:0.7925406060606061,
* Acc@1 79.042 Acc@5 94.576 loss 0.937
Accuracy of the network on the 50000 test images: 79.0%
Max accuracy: 79.04%
## Using lr  0.0000050 for BACKBONE, cosine lr = 0.0000154 for PREDICTOR
Epoch: [28]  [   0/2001]  eta: 2:34:59  lr: 0.000015  loss: 1.9547 (1.9547)  time: 4.6474  data: 4.0342  max mem: 8683
Epoch: [28]  [  10/2001]  eta: 0:32:48  lr: 0.000015  loss: 2.9318 (2.8432)  time: 0.9888  data: 0.3668  max mem: 8683
Epoch: [28]  [  20/2001]  eta: 0:26:46  lr: 0.000015  loss: 3.0774 (2.9784)  time: 0.6192  data: 0.0001  max mem: 8683
Epoch: [28]  [  30/2001]  eta: 0:24:35  lr: 0.000015  loss: 3.0234 (2.9791)  time: 0.6164  data: 0.0001  max mem: 8683
Epoch: [28]  [  40/2001]  eta: 0:23:24  lr: 0.000015  loss: 3.1537 (3.0381)  time: 0.6168  data: 0.0001  max mem: 8683
Epoch: [28]  [  50/2001]  eta: 0:22:42  lr: 0.000015  loss: 3.1555 (3.0797)  time: 0.6206  data: 0.0001  max mem: 8683
Epoch: [28]  [  60/2001]  eta: 0:22:13  lr: 0.000015  loss: 3.1506 (3.0971)  time: 0.6267  data: 0.0001  max mem: 8683
Epoch: [28]  [  70/2001]  eta: 0:21:51  lr: 0.000015  loss: 2.7946 (3.0150)  time: 0.6301  data: 0.0001  max mem: 8683
Epoch: [28]  [  80/2001]  eta: 0:21:34  lr: 0.000015  loss: 2.5996 (2.9871)  time: 0.6339  data: 0.0001  max mem: 8683
Epoch: [28]  [  90/2001]  eta: 0:21:19  lr: 0.000015  loss: 2.9658 (2.9856)  time: 0.6349  data: 0.0001  max mem: 8683
loss info: cls_loss=2.8822, ratio_loss=0.0446, cls_kl=0.0636, token_kl=0.0925
Epoch: [28]  [ 100/2001]  eta: 0:21:06  lr: 0.000015  loss: 2.9658 (2.9666)  time: 0.6365  data: 0.0001  max mem: 8683
Epoch: [28]  [ 110/2001]  eta: 0:20:55  lr: 0.000015  loss: 3.1072 (2.9842)  time: 0.6386  data: 0.0001  max mem: 8683
Epoch: [28]  [ 120/2001]  eta: 0:20:44  lr: 0.000015  loss: 2.9496 (2.9722)  time: 0.6363  data: 0.0001  max mem: 8683
Epoch: [28]  [ 130/2001]  eta: 0:20:34  lr: 0.000015  loss: 2.9335 (2.9779)  time: 0.6361  data: 0.0001  max mem: 8683
Epoch: [28]  [ 140/2001]  eta: 0:20:24  lr: 0.000015  loss: 3.0306 (2.9807)  time: 0.6358  data: 0.0001  max mem: 8683
Epoch: [28]  [ 150/2001]  eta: 0:20:14  lr: 0.000015  loss: 3.0306 (2.9789)  time: 0.6341  data: 0.0001  max mem: 8683
Epoch: [28]  [ 160/2001]  eta: 0:20:06  lr: 0.000015  loss: 2.9612 (2.9699)  time: 0.6400  data: 0.0001  max mem: 8683
Epoch: [28]  [ 170/2001]  eta: 0:19:58  lr: 0.000015  loss: 3.0752 (2.9874)  time: 0.6397  data: 0.0001  max mem: 8683
Epoch: [28]  [ 180/2001]  eta: 0:19:49  lr: 0.000015  loss: 3.1710 (2.9983)  time: 0.6330  data: 0.0001  max mem: 8683
Epoch: [28]  [ 190/2001]  eta: 0:19:41  lr: 0.000015  loss: 2.9597 (2.9898)  time: 0.6354  data: 0.0001  max mem: 8683
loss info: cls_loss=2.8873, ratio_loss=0.0461, cls_kl=0.0609, token_kl=0.0939
Epoch: [28]  [ 200/2001]  eta: 0:19:33  lr: 0.000015  loss: 3.0263 (2.9956)  time: 0.6370  data: 0.0001  max mem: 8683
Epoch: [28]  [ 210/2001]  eta: 0:19:25  lr: 0.000015  loss: 3.2450 (3.0061)  time: 0.6355  data: 0.0001  max mem: 8683
Epoch: [28]  [ 220/2001]  eta: 0:19:17  lr: 0.000015  loss: 3.2566 (3.0143)  time: 0.6342  data: 0.0001  max mem: 8683
Epoch: [28]  [ 230/2001]  eta: 0:19:09  lr: 0.000015  loss: 3.1752 (3.0047)  time: 0.6326  data: 0.0001  max mem: 8683
Epoch: [28]  [ 240/2001]  eta: 0:19:02  lr: 0.000015  loss: 2.9881 (3.0080)  time: 0.6337  data: 0.0001  max mem: 8683
Epoch: [28]  [ 250/2001]  eta: 0:18:54  lr: 0.000015  loss: 3.0603 (3.0104)  time: 0.6357  data: 0.0001  max mem: 8683
Epoch: [28]  [ 260/2001]  eta: 0:18:47  lr: 0.000015  loss: 3.0603 (3.0103)  time: 0.6375  data: 0.0001  max mem: 8683
Epoch: [28]  [ 270/2001]  eta: 0:18:40  lr: 0.000015  loss: 2.9853 (3.0043)  time: 0.6357  data: 0.0001  max mem: 8683
Epoch: [28]  [ 280/2001]  eta: 0:18:32  lr: 0.000015  loss: 2.9202 (3.0036)  time: 0.6328  data: 0.0001  max mem: 8683
Epoch: [28]  [ 290/2001]  eta: 0:18:25  lr: 0.000015  loss: 3.0808 (3.0058)  time: 0.6337  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9462, ratio_loss=0.0413, cls_kl=0.0607, token_kl=0.0907
Epoch: [28]  [ 300/2001]  eta: 0:18:18  lr: 0.000015  loss: 3.1691 (3.0036)  time: 0.6357  data: 0.0001  max mem: 8683
Epoch: [28]  [ 310/2001]  eta: 0:18:11  lr: 0.000015  loss: 3.2002 (3.0127)  time: 0.6370  data: 0.0001  max mem: 8683
Epoch: [28]  [ 320/2001]  eta: 0:18:04  lr: 0.000015  loss: 3.3518 (3.0189)  time: 0.6363  data: 0.0001  max mem: 8683
Epoch: [28]  [ 330/2001]  eta: 0:17:57  lr: 0.000015  loss: 3.1731 (3.0153)  time: 0.6351  data: 0.0001  max mem: 8683
Epoch: [28]  [ 340/2001]  eta: 0:17:50  lr: 0.000015  loss: 2.9638 (3.0090)  time: 0.6346  data: 0.0001  max mem: 8683
Epoch: [28]  [ 350/2001]  eta: 0:17:44  lr: 0.000015  loss: 3.2912 (3.0103)  time: 0.6353  data: 0.0001  max mem: 8683
Epoch: [28]  [ 360/2001]  eta: 0:17:37  lr: 0.000015  loss: 3.1997 (3.0121)  time: 0.6349  data: 0.0001  max mem: 8683
Epoch: [28]  [ 370/2001]  eta: 0:17:30  lr: 0.000015  loss: 3.2149 (3.0182)  time: 0.6328  data: 0.0001  max mem: 8683
Epoch: [28]  [ 380/2001]  eta: 0:17:23  lr: 0.000015  loss: 3.2289 (3.0175)  time: 0.6338  data: 0.0001  max mem: 8683
Epoch: [28]  [ 390/2001]  eta: 0:17:16  lr: 0.000015  loss: 3.1192 (3.0196)  time: 0.6367  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9591, ratio_loss=0.0426, cls_kl=0.0609, token_kl=0.0897
Epoch: [28]  [ 400/2001]  eta: 0:17:10  lr: 0.000015  loss: 3.1712 (3.0248)  time: 0.6387  data: 0.0001  max mem: 8683
Epoch: [28]  [ 410/2001]  eta: 0:17:03  lr: 0.000015  loss: 3.2796 (3.0298)  time: 0.6367  data: 0.0001  max mem: 8683
Epoch: [28]  [ 420/2001]  eta: 0:16:56  lr: 0.000015  loss: 3.2796 (3.0298)  time: 0.6324  data: 0.0001  max mem: 8683
Epoch: [28]  [ 430/2001]  eta: 0:16:50  lr: 0.000015  loss: 3.1336 (3.0264)  time: 0.6403  data: 0.0001  max mem: 8683
Epoch: [28]  [ 440/2001]  eta: 0:16:43  lr: 0.000015  loss: 3.1330 (3.0269)  time: 0.6408  data: 0.0001  max mem: 8683
Epoch: [28]  [ 450/2001]  eta: 0:16:36  lr: 0.000015  loss: 3.2377 (3.0274)  time: 0.6330  data: 0.0001  max mem: 8683
Epoch: [28]  [ 460/2001]  eta: 0:16:29  lr: 0.000015  loss: 3.1490 (3.0248)  time: 0.6323  data: 0.0001  max mem: 8683
Epoch: [28]  [ 470/2001]  eta: 0:16:22  lr: 0.000015  loss: 3.1490 (3.0328)  time: 0.6304  data: 0.0001  max mem: 8683
Epoch: [28]  [ 480/2001]  eta: 0:16:16  lr: 0.000015  loss: 3.3694 (3.0364)  time: 0.6323  data: 0.0001  max mem: 8683
Epoch: [28]  [ 490/2001]  eta: 0:16:09  lr: 0.000015  loss: 3.2639 (3.0298)  time: 0.6343  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9536, ratio_loss=0.0446, cls_kl=0.0626, token_kl=0.0922
Epoch: [28]  [ 500/2001]  eta: 0:16:02  lr: 0.000015  loss: 2.9733 (3.0316)  time: 0.6322  data: 0.0001  max mem: 8683
Epoch: [28]  [ 510/2001]  eta: 0:15:56  lr: 0.000015  loss: 3.3063 (3.0336)  time: 0.6308  data: 0.0001  max mem: 8683
Epoch: [28]  [ 520/2001]  eta: 0:15:49  lr: 0.000015  loss: 3.2308 (3.0304)  time: 0.6294  data: 0.0001  max mem: 8683
Epoch: [28]  [ 530/2001]  eta: 0:15:42  lr: 0.000015  loss: 2.9917 (3.0317)  time: 0.6316  data: 0.0001  max mem: 8683
Epoch: [28]  [ 540/2001]  eta: 0:15:36  lr: 0.000015  loss: 3.0982 (3.0314)  time: 0.6319  data: 0.0001  max mem: 8683
Epoch: [28]  [ 550/2001]  eta: 0:15:29  lr: 0.000015  loss: 3.0920 (3.0349)  time: 0.6315  data: 0.0001  max mem: 8683
Epoch: [28]  [ 560/2001]  eta: 0:15:22  lr: 0.000015  loss: 3.1875 (3.0360)  time: 0.6323  data: 0.0001  max mem: 8683
Epoch: [28]  [ 570/2001]  eta: 0:15:16  lr: 0.000015  loss: 3.1875 (3.0359)  time: 0.6297  data: 0.0001  max mem: 8683
Epoch: [28]  [ 580/2001]  eta: 0:15:09  lr: 0.000015  loss: 3.1503 (3.0373)  time: 0.6287  data: 0.0001  max mem: 8683
Epoch: [28]  [ 590/2001]  eta: 0:15:03  lr: 0.000015  loss: 3.1503 (3.0392)  time: 0.6364  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9720, ratio_loss=0.0461, cls_kl=0.0628, token_kl=0.0922
Epoch: [28]  [ 600/2001]  eta: 0:14:56  lr: 0.000015  loss: 3.0939 (3.0397)  time: 0.6362  data: 0.0001  max mem: 8683
Epoch: [28]  [ 610/2001]  eta: 0:14:49  lr: 0.000015  loss: 3.0678 (3.0374)  time: 0.6263  data: 0.0001  max mem: 8683
Epoch: [28]  [ 620/2001]  eta: 0:14:43  lr: 0.000015  loss: 3.0678 (3.0384)  time: 0.6254  data: 0.0001  max mem: 8683
Epoch: [28]  [ 630/2001]  eta: 0:14:36  lr: 0.000015  loss: 3.2054 (3.0391)  time: 0.6260  data: 0.0001  max mem: 8683
Epoch: [28]  [ 640/2001]  eta: 0:14:29  lr: 0.000015  loss: 3.2550 (3.0426)  time: 0.6253  data: 0.0001  max mem: 8683
Epoch: [28]  [ 650/2001]  eta: 0:14:23  lr: 0.000015  loss: 3.2550 (3.0411)  time: 0.6261  data: 0.0001  max mem: 8683
Epoch: [28]  [ 660/2001]  eta: 0:14:16  lr: 0.000015  loss: 3.2035 (3.0455)  time: 0.6269  data: 0.0001  max mem: 8683
Epoch: [28]  [ 670/2001]  eta: 0:14:09  lr: 0.000015  loss: 3.3639 (3.0480)  time: 0.6250  data: 0.0001  max mem: 8683
Epoch: [28]  [ 680/2001]  eta: 0:14:03  lr: 0.000015  loss: 3.2846 (3.0462)  time: 0.6264  data: 0.0001  max mem: 8683
Epoch: [28]  [ 690/2001]  eta: 0:13:56  lr: 0.000015  loss: 3.3093 (3.0508)  time: 0.6293  data: 0.0001  max mem: 8683
loss info: cls_loss=3.0198, ratio_loss=0.0494, cls_kl=0.0647, token_kl=0.0966
Epoch: [28]  [ 700/2001]  eta: 0:13:49  lr: 0.000015  loss: 3.3093 (3.0532)  time: 0.6263  data: 0.0001  max mem: 8683
Epoch: [28]  [ 710/2001]  eta: 0:13:43  lr: 0.000015  loss: 2.9958 (3.0525)  time: 0.6268  data: 0.0001  max mem: 8683
Epoch: [28]  [ 720/2001]  eta: 0:13:36  lr: 0.000015  loss: 3.4213 (3.0574)  time: 0.6262  data: 0.0001  max mem: 8683
Epoch: [28]  [ 730/2001]  eta: 0:13:30  lr: 0.000015  loss: 3.3167 (3.0557)  time: 0.6254  data: 0.0001  max mem: 8683
Epoch: [28]  [ 740/2001]  eta: 0:13:23  lr: 0.000015  loss: 3.1902 (3.0571)  time: 0.6266  data: 0.0001  max mem: 8683
Epoch: [28]  [ 750/2001]  eta: 0:13:16  lr: 0.000015  loss: 3.1748 (3.0548)  time: 0.6228  data: 0.0001  max mem: 8683
Epoch: [28]  [ 760/2001]  eta: 0:13:10  lr: 0.000015  loss: 3.1748 (3.0561)  time: 0.6189  data: 0.0001  max mem: 8683
Epoch: [28]  [ 770/2001]  eta: 0:13:03  lr: 0.000015  loss: 3.1801 (3.0532)  time: 0.6196  data: 0.0001  max mem: 8683
Epoch: [28]  [ 780/2001]  eta: 0:12:57  lr: 0.000015  loss: 2.8734 (3.0511)  time: 0.6224  data: 0.0001  max mem: 8683
Epoch: [28]  [ 790/2001]  eta: 0:12:50  lr: 0.000015  loss: 3.0715 (3.0504)  time: 0.6225  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9312, ratio_loss=0.0428, cls_kl=0.0615, token_kl=0.0910
Epoch: [28]  [ 800/2001]  eta: 0:12:43  lr: 0.000015  loss: 3.1733 (3.0509)  time: 0.6232  data: 0.0001  max mem: 8683
Epoch: [28]  [ 810/2001]  eta: 0:12:37  lr: 0.000015  loss: 3.1733 (3.0511)  time: 0.6225  data: 0.0001  max mem: 8683
Epoch: [28]  [ 820/2001]  eta: 0:12:30  lr: 0.000015  loss: 2.9713 (3.0485)  time: 0.6249  data: 0.0001  max mem: 8683
Epoch: [28]  [ 830/2001]  eta: 0:12:24  lr: 0.000015  loss: 2.9926 (3.0490)  time: 0.6235  data: 0.0001  max mem: 8683
Epoch: [28]  [ 840/2001]  eta: 0:12:17  lr: 0.000015  loss: 3.2006 (3.0505)  time: 0.6218  data: 0.0001  max mem: 8683
Epoch: [28]  [ 850/2001]  eta: 0:12:11  lr: 0.000015  loss: 3.2179 (3.0483)  time: 0.6246  data: 0.0001  max mem: 8683
Epoch: [28]  [ 860/2001]  eta: 0:12:04  lr: 0.000015  loss: 2.9277 (3.0447)  time: 0.6308  data: 0.0001  max mem: 8683
Epoch: [28]  [ 870/2001]  eta: 0:11:58  lr: 0.000015  loss: 2.8889 (3.0421)  time: 0.6364  data: 0.0001  max mem: 8683
Epoch: [28]  [ 880/2001]  eta: 0:11:52  lr: 0.000015  loss: 3.0103 (3.0421)  time: 0.6301  data: 0.0001  max mem: 8683
Epoch: [28]  [ 890/2001]  eta: 0:11:45  lr: 0.000015  loss: 3.1026 (3.0423)  time: 0.6223  data: 0.0001  max mem: 8683
loss info: cls_loss=2.8578, ratio_loss=0.0417, cls_kl=0.0609, token_kl=0.0926
Epoch: [28]  [ 900/2001]  eta: 0:11:39  lr: 0.000015  loss: 2.9479 (3.0400)  time: 0.6217  data: 0.0001  max mem: 8683
Epoch: [28]  [ 910/2001]  eta: 0:11:32  lr: 0.000015  loss: 2.9185 (3.0387)  time: 0.6235  data: 0.0001  max mem: 8683
Epoch: [28]  [ 920/2001]  eta: 0:11:26  lr: 0.000015  loss: 3.0517 (3.0400)  time: 0.6226  data: 0.0001  max mem: 8683
Epoch: [28]  [ 930/2001]  eta: 0:11:19  lr: 0.000015  loss: 3.1597 (3.0399)  time: 0.6239  data: 0.0001  max mem: 8683
Epoch: [28]  [ 940/2001]  eta: 0:11:13  lr: 0.000015  loss: 3.1597 (3.0418)  time: 0.6261  data: 0.0001  max mem: 8683
Epoch: [28]  [ 950/2001]  eta: 0:11:06  lr: 0.000015  loss: 3.1985 (3.0418)  time: 0.6259  data: 0.0001  max mem: 8683
Epoch: [28]  [ 960/2001]  eta: 0:11:00  lr: 0.000015  loss: 3.1159 (3.0405)  time: 0.6231  data: 0.0001  max mem: 8683
Epoch: [28]  [ 970/2001]  eta: 0:10:53  lr: 0.000015  loss: 3.1159 (3.0405)  time: 0.6238  data: 0.0001  max mem: 8683
Epoch: [28]  [ 980/2001]  eta: 0:10:47  lr: 0.000015  loss: 3.2964 (3.0446)  time: 0.6297  data: 0.0001  max mem: 8683
Epoch: [28]  [ 990/2001]  eta: 0:10:41  lr: 0.000015  loss: 3.3144 (3.0446)  time: 0.6284  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9892, ratio_loss=0.0445, cls_kl=0.0629, token_kl=0.0933
Epoch: [28]  [1000/2001]  eta: 0:10:34  lr: 0.000015  loss: 3.1364 (3.0455)  time: 0.6233  data: 0.0001  max mem: 8683
Epoch: [28]  [1010/2001]  eta: 0:10:28  lr: 0.000015  loss: 3.1364 (3.0464)  time: 0.6247  data: 0.0001  max mem: 8683
Epoch: [28]  [1020/2001]  eta: 0:10:21  lr: 0.000015  loss: 3.0308 (3.0451)  time: 0.6294  data: 0.0001  max mem: 8683
Epoch: [28]  [1030/2001]  eta: 0:10:15  lr: 0.000015  loss: 2.9884 (3.0440)  time: 0.6275  data: 0.0001  max mem: 8683
Epoch: [28]  [1040/2001]  eta: 0:10:08  lr: 0.000015  loss: 2.9796 (3.0437)  time: 0.6225  data: 0.0001  max mem: 8683
Epoch: [28]  [1050/2001]  eta: 0:10:02  lr: 0.000015  loss: 3.0173 (3.0418)  time: 0.6217  data: 0.0001  max mem: 8683
Epoch: [28]  [1060/2001]  eta: 0:09:56  lr: 0.000015  loss: 3.1388 (3.0426)  time: 0.6257  data: 0.0001  max mem: 8683
Epoch: [28]  [1070/2001]  eta: 0:09:49  lr: 0.000015  loss: 3.1010 (3.0414)  time: 0.6269  data: 0.0001  max mem: 8683
Epoch: [28]  [1080/2001]  eta: 0:09:43  lr: 0.000015  loss: 3.1352 (3.0427)  time: 0.6241  data: 0.0001  max mem: 8683
Epoch: [28]  [1090/2001]  eta: 0:09:36  lr: 0.000015  loss: 3.1166 (3.0406)  time: 0.6251  data: 0.0001  max mem: 8683
loss info: cls_loss=2.8619, ratio_loss=0.0429, cls_kl=0.0594, token_kl=0.0915
Epoch: [28]  [1100/2001]  eta: 0:09:30  lr: 0.000015  loss: 2.8743 (3.0396)  time: 0.6255  data: 0.0001  max mem: 8683
Epoch: [28]  [1110/2001]  eta: 0:09:24  lr: 0.000015  loss: 2.9502 (3.0392)  time: 0.6266  data: 0.0001  max mem: 8683
Epoch: [28]  [1120/2001]  eta: 0:09:17  lr: 0.000015  loss: 2.9502 (3.0382)  time: 0.6243  data: 0.0001  max mem: 8683
Epoch: [28]  [1130/2001]  eta: 0:09:11  lr: 0.000015  loss: 3.1494 (3.0403)  time: 0.6233  data: 0.0001  max mem: 8683
Epoch: [28]  [1140/2001]  eta: 0:09:04  lr: 0.000015  loss: 3.2698 (3.0419)  time: 0.6262  data: 0.0001  max mem: 8683
Epoch: [28]  [1150/2001]  eta: 0:08:58  lr: 0.000015  loss: 3.1339 (3.0414)  time: 0.6290  data: 0.0001  max mem: 8683
Epoch: [28]  [1160/2001]  eta: 0:08:52  lr: 0.000015  loss: 3.2883 (3.0440)  time: 0.6305  data: 0.0001  max mem: 8683
Epoch: [28]  [1170/2001]  eta: 0:08:45  lr: 0.000015  loss: 3.2095 (3.0431)  time: 0.6267  data: 0.0001  max mem: 8683
Epoch: [28]  [1180/2001]  eta: 0:08:39  lr: 0.000015  loss: 3.1902 (3.0451)  time: 0.6261  data: 0.0001  max mem: 8683
Epoch: [28]  [1190/2001]  eta: 0:08:33  lr: 0.000015  loss: 2.9636 (3.0424)  time: 0.6267  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9841, ratio_loss=0.0440, cls_kl=0.0629, token_kl=0.0929
Epoch: [28]  [1200/2001]  eta: 0:08:26  lr: 0.000015  loss: 3.0258 (3.0444)  time: 0.6258  data: 0.0001  max mem: 8683
Epoch: [28]  [1210/2001]  eta: 0:08:20  lr: 0.000015  loss: 3.3429 (3.0442)  time: 0.6282  data: 0.0001  max mem: 8683
Epoch: [28]  [1220/2001]  eta: 0:08:14  lr: 0.000015  loss: 3.1107 (3.0456)  time: 0.6347  data: 0.0001  max mem: 8683
Epoch: [28]  [1230/2001]  eta: 0:08:07  lr: 0.000015  loss: 3.1159 (3.0452)  time: 0.6363  data: 0.0001  max mem: 8683
Epoch: [28]  [1240/2001]  eta: 0:08:01  lr: 0.000015  loss: 3.3085 (3.0473)  time: 0.6307  data: 0.0001  max mem: 8683
Epoch: [28]  [1250/2001]  eta: 0:07:55  lr: 0.000015  loss: 3.1782 (3.0474)  time: 0.6309  data: 0.0001  max mem: 8683
Epoch: [28]  [1260/2001]  eta: 0:07:48  lr: 0.000015  loss: 3.1782 (3.0480)  time: 0.6290  data: 0.0001  max mem: 8683
Epoch: [28]  [1270/2001]  eta: 0:07:42  lr: 0.000015  loss: 3.2647 (3.0482)  time: 0.6262  data: 0.0001  max mem: 8683
Epoch: [28]  [1280/2001]  eta: 0:07:36  lr: 0.000015  loss: 3.2684 (3.0483)  time: 0.6268  data: 0.0001  max mem: 8683
Epoch: [28]  [1290/2001]  eta: 0:07:29  lr: 0.000015  loss: 3.2684 (3.0484)  time: 0.6291  data: 0.0001  max mem: 8683
loss info: cls_loss=3.0131, ratio_loss=0.0481, cls_kl=0.0656, token_kl=0.0947
Epoch: [28]  [1300/2001]  eta: 0:07:23  lr: 0.000015  loss: 3.3080 (3.0501)  time: 0.6307  data: 0.0001  max mem: 8683
Epoch: [28]  [1310/2001]  eta: 0:07:17  lr: 0.000015  loss: 3.1075 (3.0493)  time: 0.6269  data: 0.0001  max mem: 8683
Epoch: [28]  [1320/2001]  eta: 0:07:10  lr: 0.000015  loss: 2.9312 (3.0477)  time: 0.6298  data: 0.0001  max mem: 8683
Epoch: [28]  [1330/2001]  eta: 0:07:04  lr: 0.000015  loss: 2.8394 (3.0471)  time: 0.6317  data: 0.0001  max mem: 8683
Epoch: [28]  [1340/2001]  eta: 0:06:58  lr: 0.000015  loss: 2.9629 (3.0460)  time: 0.6296  data: 0.0001  max mem: 8683
Epoch: [28]  [1350/2001]  eta: 0:06:51  lr: 0.000015  loss: 3.2887 (3.0479)  time: 0.6285  data: 0.0001  max mem: 8683
Epoch: [28]  [1360/2001]  eta: 0:06:45  lr: 0.000015  loss: 3.3074 (3.0471)  time: 0.6286  data: 0.0001  max mem: 8683
Epoch: [28]  [1370/2001]  eta: 0:06:38  lr: 0.000015  loss: 3.0532 (3.0462)  time: 0.6290  data: 0.0001  max mem: 8683
Epoch: [28]  [1380/2001]  eta: 0:06:32  lr: 0.000015  loss: 3.0367 (3.0441)  time: 0.6295  data: 0.0001  max mem: 8683
Epoch: [28]  [1390/2001]  eta: 0:06:26  lr: 0.000015  loss: 2.8664 (3.0428)  time: 0.6292  data: 0.0001  max mem: 8683
loss info: cls_loss=2.8752, ratio_loss=0.0424, cls_kl=0.0615, token_kl=0.0919
Epoch: [28]  [1400/2001]  eta: 0:06:19  lr: 0.000015  loss: 3.1296 (3.0445)  time: 0.6276  data: 0.0001  max mem: 8683
Epoch: [28]  [1410/2001]  eta: 0:06:13  lr: 0.000015  loss: 3.1852 (3.0453)  time: 0.6321  data: 0.0001  max mem: 8683
Epoch: [28]  [1420/2001]  eta: 0:06:07  lr: 0.000015  loss: 3.0892 (3.0436)  time: 0.6335  data: 0.0001  max mem: 8683
Epoch: [28]  [1430/2001]  eta: 0:06:00  lr: 0.000015  loss: 3.0171 (3.0438)  time: 0.6298  data: 0.0001  max mem: 8683
Epoch: [28]  [1440/2001]  eta: 0:05:54  lr: 0.000015  loss: 3.0810 (3.0443)  time: 0.6328  data: 0.0001  max mem: 8683
Epoch: [28]  [1450/2001]  eta: 0:05:48  lr: 0.000015  loss: 3.3412 (3.0458)  time: 0.6329  data: 0.0001  max mem: 8683
Epoch: [28]  [1460/2001]  eta: 0:05:42  lr: 0.000015  loss: 3.3141 (3.0450)  time: 0.6285  data: 0.0001  max mem: 8683
Epoch: [28]  [1470/2001]  eta: 0:05:35  lr: 0.000015  loss: 3.0940 (3.0453)  time: 0.6293  data: 0.0001  max mem: 8683
Epoch: [28]  [1480/2001]  eta: 0:05:29  lr: 0.000015  loss: 3.1305 (3.0460)  time: 0.6295  data: 0.0001  max mem: 8683
Epoch: [28]  [1490/2001]  eta: 0:05:23  lr: 0.000015  loss: 3.2006 (3.0461)  time: 0.6289  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9643, ratio_loss=0.0418, cls_kl=0.0623, token_kl=0.0914
Epoch: [28]  [1500/2001]  eta: 0:05:16  lr: 0.000015  loss: 3.1617 (3.0468)  time: 0.6294  data: 0.0001  max mem: 8683
Epoch: [28]  [1510/2001]  eta: 0:05:10  lr: 0.000015  loss: 3.0592 (3.0469)  time: 0.6313  data: 0.0001  max mem: 8683
Epoch: [28]  [1520/2001]  eta: 0:05:04  lr: 0.000015  loss: 3.1112 (3.0469)  time: 0.6326  data: 0.0001  max mem: 8683
Epoch: [28]  [1530/2001]  eta: 0:04:57  lr: 0.000015  loss: 3.1360 (3.0461)  time: 0.6307  data: 0.0001  max mem: 8683
Epoch: [28]  [1540/2001]  eta: 0:04:51  lr: 0.000015  loss: 3.0172 (3.0444)  time: 0.6309  data: 0.0001  max mem: 8683
Epoch: [28]  [1550/2001]  eta: 0:04:45  lr: 0.000015  loss: 3.0318 (3.0432)  time: 0.6328  data: 0.0001  max mem: 8683
Epoch: [28]  [1560/2001]  eta: 0:04:38  lr: 0.000015  loss: 3.1890 (3.0427)  time: 0.6342  data: 0.0001  max mem: 8683
Epoch: [28]  [1570/2001]  eta: 0:04:32  lr: 0.000015  loss: 3.2496 (3.0417)  time: 0.6338  data: 0.0001  max mem: 8683
Epoch: [28]  [1580/2001]  eta: 0:04:26  lr: 0.000015  loss: 3.0098 (3.0411)  time: 0.6331  data: 0.0001  max mem: 8683
Epoch: [28]  [1590/2001]  eta: 0:04:19  lr: 0.000015  loss: 3.0411 (3.0416)  time: 0.6353  data: 0.0001  max mem: 8683
loss info: cls_loss=2.8802, ratio_loss=0.0448, cls_kl=0.0634, token_kl=0.0952
Epoch: [28]  [1600/2001]  eta: 0:04:13  lr: 0.000015  loss: 3.2047 (3.0418)  time: 0.6354  data: 0.0001  max mem: 8683
Epoch: [28]  [1610/2001]  eta: 0:04:07  lr: 0.000015  loss: 3.1511 (3.0415)  time: 0.6348  data: 0.0001  max mem: 8683
Epoch: [28]  [1620/2001]  eta: 0:04:00  lr: 0.000015  loss: 3.1119 (3.0417)  time: 0.6354  data: 0.0001  max mem: 8683
Epoch: [28]  [1630/2001]  eta: 0:03:54  lr: 0.000015  loss: 3.2056 (3.0430)  time: 0.6347  data: 0.0001  max mem: 8683
Epoch: [28]  [1640/2001]  eta: 0:03:48  lr: 0.000015  loss: 3.3005 (3.0443)  time: 0.6327  data: 0.0001  max mem: 8683
Epoch: [28]  [1650/2001]  eta: 0:03:41  lr: 0.000015  loss: 3.1980 (3.0423)  time: 0.6315  data: 0.0001  max mem: 8683
Epoch: [28]  [1660/2001]  eta: 0:03:35  lr: 0.000015  loss: 2.9361 (3.0422)  time: 0.6318  data: 0.0001  max mem: 8683
Epoch: [28]  [1670/2001]  eta: 0:03:29  lr: 0.000015  loss: 2.9361 (3.0413)  time: 0.6310  data: 0.0001  max mem: 8683
Epoch: [28]  [1680/2001]  eta: 0:03:22  lr: 0.000015  loss: 2.9445 (3.0419)  time: 0.6353  data: 0.0001  max mem: 8683
Epoch: [28]  [1690/2001]  eta: 0:03:16  lr: 0.000015  loss: 3.1378 (3.0429)  time: 0.6356  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9388, ratio_loss=0.0445, cls_kl=0.0628, token_kl=0.0936
Epoch: [28]  [1700/2001]  eta: 0:03:10  lr: 0.000015  loss: 3.1905 (3.0436)  time: 0.6321  data: 0.0001  max mem: 8683
Epoch: [28]  [1710/2001]  eta: 0:03:04  lr: 0.000015  loss: 3.1447 (3.0428)  time: 0.6383  data: 0.0001  max mem: 8683
Epoch: [28]  [1720/2001]  eta: 0:02:57  lr: 0.000015  loss: 3.0730 (3.0431)  time: 0.6393  data: 0.0001  max mem: 8683
Epoch: [28]  [1730/2001]  eta: 0:02:51  lr: 0.000015  loss: 2.9613 (3.0413)  time: 0.6347  data: 0.0001  max mem: 8683
Epoch: [28]  [1740/2001]  eta: 0:02:45  lr: 0.000015  loss: 2.9613 (3.0417)  time: 0.6357  data: 0.0001  max mem: 8683
Epoch: [28]  [1750/2001]  eta: 0:02:38  lr: 0.000015  loss: 3.2122 (3.0427)  time: 0.6376  data: 0.0001  max mem: 8683
Epoch: [28]  [1760/2001]  eta: 0:02:32  lr: 0.000015  loss: 3.3559 (3.0442)  time: 0.6368  data: 0.0001  max mem: 8683
Epoch: [28]  [1770/2001]  eta: 0:02:26  lr: 0.000015  loss: 3.2107 (3.0436)  time: 0.6371  data: 0.0001  max mem: 8683
Epoch: [28]  [1780/2001]  eta: 0:02:19  lr: 0.000015  loss: 2.9929 (3.0428)  time: 0.6379  data: 0.0001  max mem: 8683
Epoch: [28]  [1790/2001]  eta: 0:02:13  lr: 0.000015  loss: 3.1215 (3.0420)  time: 0.6379  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9358, ratio_loss=0.0438, cls_kl=0.0621, token_kl=0.0923
Epoch: [28]  [1800/2001]  eta: 0:02:07  lr: 0.000015  loss: 3.1451 (3.0433)  time: 0.6374  data: 0.0001  max mem: 8683
Epoch: [28]  [1810/2001]  eta: 0:02:00  lr: 0.000015  loss: 3.3575 (3.0435)  time: 0.6355  data: 0.0001  max mem: 8683
Epoch: [28]  [1820/2001]  eta: 0:01:54  lr: 0.000015  loss: 3.1603 (3.0434)  time: 0.6349  data: 0.0001  max mem: 8683
Epoch: [28]  [1830/2001]  eta: 0:01:48  lr: 0.000015  loss: 3.1952 (3.0448)  time: 0.6381  data: 0.0001  max mem: 8683
Epoch: [28]  [1840/2001]  eta: 0:01:41  lr: 0.000015  loss: 3.1952 (3.0446)  time: 0.6368  data: 0.0001  max mem: 8683
Epoch: [28]  [1850/2001]  eta: 0:01:35  lr: 0.000015  loss: 3.0208 (3.0444)  time: 0.6335  data: 0.0001  max mem: 8683
Epoch: [28]  [1860/2001]  eta: 0:01:29  lr: 0.000015  loss: 3.1842 (3.0460)  time: 0.6359  data: 0.0001  max mem: 8683
Epoch: [28]  [1870/2001]  eta: 0:01:22  lr: 0.000015  loss: 3.3325 (3.0479)  time: 0.6397  data: 0.0001  max mem: 8683
Epoch: [28]  [1880/2001]  eta: 0:01:16  lr: 0.000015  loss: 3.3609 (3.0490)  time: 0.6382  data: 0.0001  max mem: 8683
Epoch: [28]  [1890/2001]  eta: 0:01:10  lr: 0.000015  loss: 3.3305 (3.0497)  time: 0.6340  data: 0.0001  max mem: 8683
loss info: cls_loss=3.0114, ratio_loss=0.0472, cls_kl=0.0649, token_kl=0.0943
Epoch: [28]  [1900/2001]  eta: 0:01:03  lr: 0.000015  loss: 3.1465 (3.0477)  time: 0.6343  data: 0.0001  max mem: 8683
Epoch: [28]  [1910/2001]  eta: 0:00:57  lr: 0.000015  loss: 3.1174 (3.0489)  time: 0.6326  data: 0.0001  max mem: 8683
Epoch: [28]  [1920/2001]  eta: 0:00:51  lr: 0.000015  loss: 3.1967 (3.0494)  time: 0.6319  data: 0.0001  max mem: 8683
Epoch: [28]  [1930/2001]  eta: 0:00:44  lr: 0.000015  loss: 3.3042 (3.0499)  time: 0.6340  data: 0.0001  max mem: 8683
Epoch: [28]  [1940/2001]  eta: 0:00:38  lr: 0.000015  loss: 3.3743 (3.0508)  time: 0.6342  data: 0.0001  max mem: 8683
Epoch: [28]  [1950/2001]  eta: 0:00:32  lr: 0.000015  loss: 3.2523 (3.0504)  time: 0.6321  data: 0.0001  max mem: 8683
Epoch: [28]  [1960/2001]  eta: 0:00:25  lr: 0.000015  loss: 3.0428 (3.0494)  time: 0.6304  data: 0.0001  max mem: 8683
Epoch: [28]  [1970/2001]  eta: 0:00:19  lr: 0.000015  loss: 3.0734 (3.0502)  time: 0.6309  data: 0.0001  max mem: 8683
Epoch: [28]  [1980/2001]  eta: 0:00:13  lr: 0.000015  loss: 3.3247 (3.0511)  time: 0.6308  data: 0.0001  max mem: 8683
Epoch: [28]  [1990/2001]  eta: 0:00:06  lr: 0.000015  loss: 3.1636 (3.0511)  time: 0.6277  data: 0.0003  max mem: 8683
loss info: cls_loss=3.0259, ratio_loss=0.0442, cls_kl=0.0647, token_kl=0.0940
Epoch: [28]  [2000/2001]  eta: 0:00:00  lr: 0.000015  loss: 3.1100 (3.0518)  time: 0.6244  data: 0.0003  max mem: 8683
Epoch: [28] Total time: 0:21:06 (0.6329 s / it)
Averaged stats: lr: 0.000015  loss: 3.1100 (3.0506)
Test:  [ 0/53]  eta: 0:04:32  loss: 0.3414 (0.3414)  acc1: 95.0000 (95.0000)  acc5: 99.1667 (99.1667)  time: 5.1366  data: 4.6332  max mem: 8683
Test:  [10/53]  eta: 0:00:33  loss: 0.7634 (0.7597)  acc1: 82.5000 (83.4091)  acc5: 96.6667 (96.6667)  time: 0.7693  data: 0.4214  max mem: 8683
Test:  [20/53]  eta: 0:00:18  loss: 0.7256 (0.7690)  acc1: 82.5000 (83.2143)  acc5: 96.6667 (96.5873)  time: 0.3299  data: 0.0002  max mem: 8683
Test:  [30/53]  eta: 0:00:11  loss: 0.8994 (0.8542)  acc1: 77.5000 (80.7527)  acc5: 94.1667 (95.3763)  time: 0.3266  data: 0.0002  max mem: 8683
Test:  [40/53]  eta: 0:00:05  loss: 1.1128 (0.9189)  acc1: 75.8333 (79.3496)  acc5: 92.5000 (94.6342)  time: 0.3042  data: 0.0002  max mem: 8683
Test:  [50/53]  eta: 0:00:01  loss: 1.1103 (0.9511)  acc1: 75.0000 (78.5131)  acc5: 92.5000 (94.4444)  time: 0.2690  data: 0.0001  max mem: 8683
Test:  [52/53]  eta: 0:00:00  loss: 1.0959 (0.9363)  acc1: 75.8333 (78.6720)  acc5: 93.3333 (94.4960)  time: 0.2531  data: 0.0001  max mem: 8683
Test: Total time: 0:00:20 (0.3922 s / it)
Sparsity0:0.29829656565656565,Sparsity1:0.5570383838383839,Sparsity2:0.7899741414141415,
* Acc@1 79.084 Acc@5 94.672 loss 0.937
Accuracy of the network on the 50000 test images: 79.1%
Max accuracy: 79.08%
## Using lr  0.0000050 for BACKBONE, cosine lr = 0.0000113 for PREDICTOR
Epoch: [29]  [   0/2001]  eta: 2:32:50  lr: 0.000011  loss: 2.9536 (2.9536)  time: 4.5827  data: 3.9642  max mem: 8683
Epoch: [29]  [  10/2001]  eta: 0:32:06  lr: 0.000011  loss: 3.3566 (3.2096)  time: 0.9678  data: 0.3605  max mem: 8683
Epoch: [29]  [  20/2001]  eta: 0:26:21  lr: 0.000011  loss: 3.2752 (3.1004)  time: 0.6089  data: 0.0001  max mem: 8683
Epoch: [29]  [  30/2001]  eta: 0:24:16  lr: 0.000011  loss: 3.0482 (3.0130)  time: 0.6127  data: 0.0001  max mem: 8683
Epoch: [29]  [  40/2001]  eta: 0:23:09  lr: 0.000011  loss: 2.9646 (3.0007)  time: 0.6147  data: 0.0001  max mem: 8683
Epoch: [29]  [  50/2001]  eta: 0:22:28  lr: 0.000011  loss: 3.1064 (3.0167)  time: 0.6181  data: 0.0001  max mem: 8683
Epoch: [29]  [  60/2001]  eta: 0:21:59  lr: 0.000011  loss: 3.2185 (3.0366)  time: 0.6203  data: 0.0001  max mem: 8683
Epoch: [29]  [  70/2001]  eta: 0:21:38  lr: 0.000011  loss: 3.2717 (3.0704)  time: 0.6237  data: 0.0001  max mem: 8683
Epoch: [29]  [  80/2001]  eta: 0:21:20  lr: 0.000011  loss: 3.2717 (3.0791)  time: 0.6268  data: 0.0001  max mem: 8683
Epoch: [29]  [  90/2001]  eta: 0:21:05  lr: 0.000011  loss: 3.1468 (3.0734)  time: 0.6257  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9596, ratio_loss=0.0451, cls_kl=0.0651, token_kl=0.0947
Epoch: [29]  [ 100/2001]  eta: 0:20:51  lr: 0.000011  loss: 3.1468 (3.0729)  time: 0.6248  data: 0.0001  max mem: 8683
Epoch: [29]  [ 110/2001]  eta: 0:20:39  lr: 0.000011  loss: 2.8057 (3.0331)  time: 0.6248  data: 0.0001  max mem: 8683
Epoch: [29]  [ 120/2001]  eta: 0:20:28  lr: 0.000011  loss: 2.8338 (3.0448)  time: 0.6258  data: 0.0001  max mem: 8683
Epoch: [29]  [ 130/2001]  eta: 0:20:19  lr: 0.000011  loss: 3.1833 (3.0530)  time: 0.6309  data: 0.0001  max mem: 8683
Epoch: [29]  [ 140/2001]  eta: 0:20:09  lr: 0.000011  loss: 3.0359 (3.0296)  time: 0.6313  data: 0.0001  max mem: 8683
Epoch: [29]  [ 150/2001]  eta: 0:20:01  lr: 0.000011  loss: 2.8989 (3.0282)  time: 0.6316  data: 0.0001  max mem: 8683
Epoch: [29]  [ 160/2001]  eta: 0:19:51  lr: 0.000011  loss: 3.0362 (3.0282)  time: 0.6300  data: 0.0001  max mem: 8683
Epoch: [29]  [ 170/2001]  eta: 0:19:43  lr: 0.000011  loss: 3.1635 (3.0421)  time: 0.6267  data: 0.0001  max mem: 8683
Epoch: [29]  [ 180/2001]  eta: 0:19:35  lr: 0.000011  loss: 3.1812 (3.0387)  time: 0.6280  data: 0.0001  max mem: 8683
Epoch: [29]  [ 190/2001]  eta: 0:19:26  lr: 0.000011  loss: 3.2245 (3.0481)  time: 0.6250  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9369, ratio_loss=0.0428, cls_kl=0.0621, token_kl=0.0921
Epoch: [29]  [ 200/2001]  eta: 0:19:18  lr: 0.000011  loss: 3.3536 (3.0593)  time: 0.6237  data: 0.0001  max mem: 8683
Epoch: [29]  [ 210/2001]  eta: 0:19:10  lr: 0.000011  loss: 2.9328 (3.0407)  time: 0.6239  data: 0.0001  max mem: 8683
Epoch: [29]  [ 220/2001]  eta: 0:19:02  lr: 0.000011  loss: 2.9131 (3.0412)  time: 0.6249  data: 0.0001  max mem: 8683
Epoch: [29]  [ 230/2001]  eta: 0:18:54  lr: 0.000011  loss: 3.0451 (3.0369)  time: 0.6250  data: 0.0001  max mem: 8683
Epoch: [29]  [ 240/2001]  eta: 0:18:47  lr: 0.000011  loss: 3.1330 (3.0474)  time: 0.6259  data: 0.0001  max mem: 8683
Epoch: [29]  [ 250/2001]  eta: 0:18:39  lr: 0.000011  loss: 3.2626 (3.0572)  time: 0.6260  data: 0.0001  max mem: 8683
Epoch: [29]  [ 260/2001]  eta: 0:18:32  lr: 0.000011  loss: 3.1871 (3.0614)  time: 0.6253  data: 0.0001  max mem: 8683
Epoch: [29]  [ 270/2001]  eta: 0:18:25  lr: 0.000011  loss: 3.1871 (3.0682)  time: 0.6245  data: 0.0001  max mem: 8683
Epoch: [29]  [ 280/2001]  eta: 0:18:17  lr: 0.000011  loss: 3.1994 (3.0635)  time: 0.6227  data: 0.0001  max mem: 8683
Epoch: [29]  [ 290/2001]  eta: 0:18:10  lr: 0.000011  loss: 3.3039 (3.0740)  time: 0.6215  data: 0.0001  max mem: 8683
loss info: cls_loss=3.0139, ratio_loss=0.0441, cls_kl=0.0638, token_kl=0.0938
Epoch: [29]  [ 300/2001]  eta: 0:18:03  lr: 0.000011  loss: 3.3251 (3.0787)  time: 0.6228  data: 0.0001  max mem: 8683
Epoch: [29]  [ 310/2001]  eta: 0:17:56  lr: 0.000011  loss: 3.3134 (3.0861)  time: 0.6239  data: 0.0001  max mem: 8683
Epoch: [29]  [ 320/2001]  eta: 0:17:49  lr: 0.000011  loss: 3.3183 (3.0865)  time: 0.6237  data: 0.0001  max mem: 8683
Epoch: [29]  [ 330/2001]  eta: 0:17:42  lr: 0.000011  loss: 3.0307 (3.0801)  time: 0.6233  data: 0.0001  max mem: 8683
Epoch: [29]  [ 340/2001]  eta: 0:17:35  lr: 0.000011  loss: 3.0307 (3.0817)  time: 0.6224  data: 0.0001  max mem: 8683
Epoch: [29]  [ 350/2001]  eta: 0:17:28  lr: 0.000011  loss: 3.2040 (3.0808)  time: 0.6227  data: 0.0001  max mem: 8683
Epoch: [29]  [ 360/2001]  eta: 0:17:21  lr: 0.000011  loss: 3.3612 (3.0824)  time: 0.6212  data: 0.0001  max mem: 8683
Epoch: [29]  [ 370/2001]  eta: 0:17:14  lr: 0.000011  loss: 3.3871 (3.0859)  time: 0.6227  data: 0.0001  max mem: 8683
Epoch: [29]  [ 380/2001]  eta: 0:17:07  lr: 0.000011  loss: 3.1522 (3.0853)  time: 0.6248  data: 0.0001  max mem: 8683
Epoch: [29]  [ 390/2001]  eta: 0:17:00  lr: 0.000011  loss: 3.1055 (3.0847)  time: 0.6225  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9946, ratio_loss=0.0473, cls_kl=0.0639, token_kl=0.0958
Epoch: [29]  [ 400/2001]  eta: 0:16:54  lr: 0.000011  loss: 3.1162 (3.0842)  time: 0.6251  data: 0.0001  max mem: 8683
Epoch: [29]  [ 410/2001]  eta: 0:16:47  lr: 0.000011  loss: 2.9550 (3.0807)  time: 0.6253  data: 0.0001  max mem: 8683
Epoch: [29]  [ 420/2001]  eta: 0:16:41  lr: 0.000011  loss: 3.1383 (3.0842)  time: 0.6289  data: 0.0001  max mem: 8683
Epoch: [29]  [ 430/2001]  eta: 0:16:34  lr: 0.000011  loss: 3.0429 (3.0795)  time: 0.6287  data: 0.0001  max mem: 8683
Epoch: [29]  [ 440/2001]  eta: 0:16:27  lr: 0.000011  loss: 3.0070 (3.0776)  time: 0.6218  data: 0.0001  max mem: 8683
Epoch: [29]  [ 450/2001]  eta: 0:16:21  lr: 0.000011  loss: 3.1415 (3.0786)  time: 0.6236  data: 0.0001  max mem: 8683
Epoch: [29]  [ 460/2001]  eta: 0:16:14  lr: 0.000011  loss: 3.1415 (3.0721)  time: 0.6247  data: 0.0001  max mem: 8683
Epoch: [29]  [ 470/2001]  eta: 0:16:08  lr: 0.000011  loss: 2.6120 (3.0631)  time: 0.6250  data: 0.0001  max mem: 8683
Epoch: [29]  [ 480/2001]  eta: 0:16:01  lr: 0.000011  loss: 2.8391 (3.0605)  time: 0.6250  data: 0.0001  max mem: 8683
Epoch: [29]  [ 490/2001]  eta: 0:15:54  lr: 0.000011  loss: 3.2326 (3.0609)  time: 0.6248  data: 0.0001  max mem: 8683
loss info: cls_loss=2.8408, ratio_loss=0.0425, cls_kl=0.0610, token_kl=0.0923
Epoch: [29]  [ 500/2001]  eta: 0:15:48  lr: 0.000011  loss: 3.2534 (3.0574)  time: 0.6239  data: 0.0001  max mem: 8683
Epoch: [29]  [ 510/2001]  eta: 0:15:41  lr: 0.000011  loss: 3.2209 (3.0586)  time: 0.6243  data: 0.0001  max mem: 8683
Epoch: [29]  [ 520/2001]  eta: 0:15:35  lr: 0.000011  loss: 3.1922 (3.0550)  time: 0.6257  data: 0.0001  max mem: 8683
Epoch: [29]  [ 530/2001]  eta: 0:15:28  lr: 0.000011  loss: 3.0542 (3.0547)  time: 0.6250  data: 0.0001  max mem: 8683
Epoch: [29]  [ 540/2001]  eta: 0:15:22  lr: 0.000011  loss: 3.0646 (3.0569)  time: 0.6255  data: 0.0001  max mem: 8683
Epoch: [29]  [ 550/2001]  eta: 0:15:15  lr: 0.000011  loss: 3.1786 (3.0593)  time: 0.6269  data: 0.0001  max mem: 8683
Epoch: [29]  [ 560/2001]  eta: 0:15:09  lr: 0.000011  loss: 2.8993 (3.0553)  time: 0.6300  data: 0.0001  max mem: 8683
Epoch: [29]  [ 570/2001]  eta: 0:15:03  lr: 0.000011  loss: 3.2613 (3.0612)  time: 0.6293  data: 0.0001  max mem: 8683
Epoch: [29]  [ 580/2001]  eta: 0:14:56  lr: 0.000011  loss: 3.3508 (3.0572)  time: 0.6290  data: 0.0001  max mem: 8683
Epoch: [29]  [ 590/2001]  eta: 0:14:50  lr: 0.000011  loss: 3.1145 (3.0584)  time: 0.6284  data: 0.0001  max mem: 8683
loss info: cls_loss=2.9635, ratio_loss=0.0478, cls_kl=0.0648, token_kl=0.0956
Epoch: [29]  [ 600/2001]  eta: 0:14:43  lr: 0.000011  loss: 3.1145 (3.0567)  time: 0.6241  data: 0.0001  max mem: 8683
Epoch: [29]  [ 610/2001]  eta: 0:14:37  lr: 0.000011  loss: 2.9474 (3.0546)  time: 0.6251  data: 0.0001  max mem: 8683
Epoch: [29]  [ 620/2001]  eta: 0:14:31  lr: 0.000011  loss: 3.1042 (3.0539)  time: 0.6252  data: 0.0001  max mem: 8683
Epoch: [29]  [ 630/2001]  eta: 0:14:24  lr: 0.000011  loss: 2.9784 (3.0512)  time: 0.6244  data: 0.0001  max mem: 8683
Epoch: [29]  [ 640/2001]  eta: 0:14:18  lr: 0.000011  loss: 3.0786 (3.0533)  time: 0.6275  data: 0.0001  max mem: 8683
Epoch: [29]  [ 650/2001]  eta: 0:14:11  lr: 0.000011  loss: 3.0945 (3.0512)  time: 0.6286  data: 0.0001  max mem: 8683
Epoch: [29]  [ 660/2001]  eta: 0:14:05  lr: 0.000011  loss: 3.0945 (3.0483)  time: 0.6256  data: 0.0001  max mem: 8683
Epoch: [29]  [ 670/2001]  eta: 0:13:59  lr: 0.000011  loss: 2.9226 (3.0459)  time: 0.6265  data: 0.0001  max mem: 8683
Loss is nan, stopping training
Traceback (most recent call last):
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 256, in main
    cmd=cmd)
subprocess.CalledProcessError: Command '['/home/zlkong/anaconda3/envs/DynamicVit/bin/python3', '-u', 'main_l2_vit.py', '--output_dir', 'logs/no-amp', '--arch', 'deit_small', '--input-size', '224', '--batch-size', '80', '--data-path', '/data/ImageNet_new/', '--epochs', '30', '--dist-eval', '--distill', '--base_rate', '0.7', '--resume', 'logs/no-amp/checkpoint.pth']' returned non-zero exit status 1.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 3): env://
| distributed init (rank 7): env://
| distributed init (rank 0): env://
| distributed init (rank 5): env://
| distributed init (rank 1): env://
| distributed init (rank 4): env://
| distributed init (rank 2): env://
| distributed init (rank 6): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp/checkpoint.pth', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000050 for BACKBONE, cosine lr = 0.0000113 for PREDICTOR
Failed to find state_dict_ema, starting from loaded model weights
Epoch: [29]  [   0/2001]  eta: 3:36:23  lr: 0.000011  loss: 3.3416 (3.3416)  time: 6.4884  data: 2.9067  max mem: 8604
Epoch: [29]  [  10/2001]  eta: 0:38:15  lr: 0.000011  loss: 3.3416 (3.2597)  time: 1.1531  data: 0.2644  max mem: 8681
Epoch: [29]  [  20/2001]  eta: 0:29:14  lr: 0.000011  loss: 3.2732 (3.2048)  time: 0.6057  data: 0.0001  max mem: 8681
Epoch: [29]  [  30/2001]  eta: 0:26:10  lr: 0.000011  loss: 3.3030 (3.2355)  time: 0.6009  data: 0.0001  max mem: 8681
Epoch: [29]  [  40/2001]  eta: 0:24:29  lr: 0.000011  loss: 3.2482 (3.1801)  time: 0.6062  data: 0.0002  max mem: 8681
Epoch: [29]  [  50/2001]  eta: 0:23:31  lr: 0.000011  loss: 3.1584 (3.1750)  time: 0.6094  data: 0.0001  max mem: 8681
Epoch: [29]  [  60/2001]  eta: 0:22:49  lr: 0.000011  loss: 3.1253 (3.1533)  time: 0.6156  data: 0.0002  max mem: 8681
Epoch: [29]  [  70/2001]  eta: 0:22:20  lr: 0.000011  loss: 3.0498 (3.1219)  time: 0.6193  data: 0.0002  max mem: 8681
Epoch: [29]  [  80/2001]  eta: 0:21:56  lr: 0.000011  loss: 3.0159 (3.1213)  time: 0.6243  data: 0.0002  max mem: 8681
Epoch: [29]  [  90/2001]  eta: 0:21:37  lr: 0.000011  loss: 3.0894 (3.1062)  time: 0.6260  data: 0.0002  max mem: 8681
loss info: cls_loss=3.0067, ratio_loss=0.0463, cls_kl=0.0657, token_kl=0.0945
Epoch: [29]  [ 100/2001]  eta: 0:21:23  lr: 0.000011  loss: 3.2454 (3.1190)  time: 0.6329  data: 0.0001  max mem: 8681
Epoch: [29]  [ 110/2001]  eta: 0:21:09  lr: 0.000011  loss: 3.2612 (3.1164)  time: 0.6370  data: 0.0001  max mem: 8681
Epoch: [29]  [ 120/2001]  eta: 0:20:56  lr: 0.000011  loss: 3.3212 (3.1205)  time: 0.6328  data: 0.0001  max mem: 8681
Epoch: [29]  [ 130/2001]  eta: 0:20:44  lr: 0.000011  loss: 3.1646 (3.1198)  time: 0.6313  data: 0.0001  max mem: 8681
Epoch: [29]  [ 140/2001]  eta: 0:20:34  lr: 0.000011  loss: 3.1392 (3.1120)  time: 0.6349  data: 0.0001  max mem: 8681
Epoch: [29]  [ 150/2001]  eta: 0:20:24  lr: 0.000011  loss: 3.0439 (3.1048)  time: 0.6352  data: 0.0002  max mem: 8681
Epoch: [29]  [ 160/2001]  eta: 0:20:15  lr: 0.000011  loss: 3.2120 (3.1109)  time: 0.6392  data: 0.0002  max mem: 8681
Epoch: [29]  [ 170/2001]  eta: 0:20:06  lr: 0.000011  loss: 3.1668 (3.1065)  time: 0.6418  data: 0.0002  max mem: 8681
Epoch: [29]  [ 180/2001]  eta: 0:19:58  lr: 0.000011  loss: 2.9235 (3.0920)  time: 0.6388  data: 0.0001  max mem: 8681
Epoch: [29]  [ 190/2001]  eta: 0:19:51  lr: 0.000011  loss: 2.8940 (3.0893)  time: 0.6463  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9316, ratio_loss=0.0420, cls_kl=0.0619, token_kl=0.0924
Epoch: [29]  [ 200/2001]  eta: 0:19:42  lr: 0.000011  loss: 2.9658 (3.0773)  time: 0.6450  data: 0.0001  max mem: 8681
Epoch: [29]  [ 210/2001]  eta: 0:19:34  lr: 0.000011  loss: 2.9658 (3.0714)  time: 0.6395  data: 0.0001  max mem: 8681
Epoch: [29]  [ 220/2001]  eta: 0:19:27  lr: 0.000011  loss: 3.0427 (3.0631)  time: 0.6414  data: 0.0001  max mem: 8681
Epoch: [29]  [ 230/2001]  eta: 0:19:19  lr: 0.000011  loss: 2.9867 (3.0581)  time: 0.6432  data: 0.0001  max mem: 8681
Epoch: [29]  [ 240/2001]  eta: 0:19:12  lr: 0.000011  loss: 3.0074 (3.0545)  time: 0.6435  data: 0.0001  max mem: 8681
Epoch: [29]  [ 250/2001]  eta: 0:19:04  lr: 0.000011  loss: 2.9766 (3.0458)  time: 0.6418  data: 0.0001  max mem: 8681
Epoch: [29]  [ 260/2001]  eta: 0:18:57  lr: 0.000011  loss: 2.8593 (3.0363)  time: 0.6423  data: 0.0001  max mem: 8681
Epoch: [29]  [ 270/2001]  eta: 0:18:50  lr: 0.000011  loss: 2.8593 (3.0344)  time: 0.6443  data: 0.0001  max mem: 8681
Epoch: [29]  [ 280/2001]  eta: 0:18:43  lr: 0.000011  loss: 3.2220 (3.0411)  time: 0.6470  data: 0.0001  max mem: 8681
Epoch: [29]  [ 290/2001]  eta: 0:18:36  lr: 0.000011  loss: 3.1663 (3.0361)  time: 0.6451  data: 0.0001  max mem: 8681
loss info: cls_loss=2.8309, ratio_loss=0.0416, cls_kl=0.0589, token_kl=0.0915
Epoch: [29]  [ 300/2001]  eta: 0:18:29  lr: 0.000011  loss: 2.8069 (3.0290)  time: 0.6433  data: 0.0001  max mem: 8681
Epoch: [29]  [ 310/2001]  eta: 0:18:22  lr: 0.000011  loss: 2.8791 (3.0307)  time: 0.6447  data: 0.0001  max mem: 8681
Epoch: [29]  [ 320/2001]  eta: 0:18:16  lr: 0.000011  loss: 3.2758 (3.0414)  time: 0.6478  data: 0.0001  max mem: 8681
Epoch: [29]  [ 330/2001]  eta: 0:18:09  lr: 0.000011  loss: 3.2445 (3.0382)  time: 0.6459  data: 0.0001  max mem: 8681
Epoch: [29]  [ 340/2001]  eta: 0:18:02  lr: 0.000011  loss: 3.2108 (3.0461)  time: 0.6429  data: 0.0001  max mem: 8681
Epoch: [29]  [ 350/2001]  eta: 0:17:55  lr: 0.000011  loss: 3.3340 (3.0502)  time: 0.6467  data: 0.0001  max mem: 8681
Epoch: [29]  [ 360/2001]  eta: 0:17:48  lr: 0.000011  loss: 3.1814 (3.0511)  time: 0.6471  data: 0.0001  max mem: 8681
Epoch: [29]  [ 370/2001]  eta: 0:17:41  lr: 0.000011  loss: 3.0047 (3.0492)  time: 0.6448  data: 0.0001  max mem: 8681
Epoch: [29]  [ 380/2001]  eta: 0:17:35  lr: 0.000011  loss: 3.0047 (3.0463)  time: 0.6454  data: 0.0001  max mem: 8681
Epoch: [29]  [ 390/2001]  eta: 0:17:28  lr: 0.000011  loss: 2.9086 (3.0398)  time: 0.6478  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9853, ratio_loss=0.0436, cls_kl=0.0625, token_kl=0.0940
Epoch: [29]  [ 400/2001]  eta: 0:17:21  lr: 0.000011  loss: 3.3089 (3.0459)  time: 0.6487  data: 0.0001  max mem: 8681
Epoch: [29]  [ 410/2001]  eta: 0:17:15  lr: 0.000011  loss: 3.3089 (3.0485)  time: 0.6477  data: 0.0001  max mem: 8681
Epoch: [29]  [ 420/2001]  eta: 0:17:08  lr: 0.000011  loss: 3.1392 (3.0449)  time: 0.6454  data: 0.0001  max mem: 8681
Epoch: [29]  [ 430/2001]  eta: 0:17:01  lr: 0.000011  loss: 3.2033 (3.0514)  time: 0.6457  data: 0.0001  max mem: 8681
Epoch: [29]  [ 440/2001]  eta: 0:16:55  lr: 0.000011  loss: 3.2745 (3.0535)  time: 0.6452  data: 0.0001  max mem: 8681
Epoch: [29]  [ 450/2001]  eta: 0:16:48  lr: 0.000011  loss: 3.1044 (3.0536)  time: 0.6430  data: 0.0001  max mem: 8681
Epoch: [29]  [ 460/2001]  eta: 0:16:42  lr: 0.000011  loss: 2.9653 (3.0477)  time: 0.6486  data: 0.0001  max mem: 8681
Epoch: [29]  [ 470/2001]  eta: 0:16:35  lr: 0.000011  loss: 2.6446 (3.0378)  time: 0.6484  data: 0.0001  max mem: 8681
Epoch: [29]  [ 480/2001]  eta: 0:16:28  lr: 0.000011  loss: 2.8071 (3.0382)  time: 0.6417  data: 0.0001  max mem: 8681
Epoch: [29]  [ 490/2001]  eta: 0:16:21  lr: 0.000011  loss: 3.1138 (3.0416)  time: 0.6442  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9098, ratio_loss=0.0446, cls_kl=0.0627, token_kl=0.0946
Epoch: [29]  [ 500/2001]  eta: 0:16:15  lr: 0.000011  loss: 3.0679 (3.0406)  time: 0.6476  data: 0.0001  max mem: 8681
Epoch: [29]  [ 510/2001]  eta: 0:16:08  lr: 0.000011  loss: 3.2013 (3.0438)  time: 0.6455  data: 0.0001  max mem: 8681
Epoch: [29]  [ 520/2001]  eta: 0:16:02  lr: 0.000011  loss: 3.2445 (3.0443)  time: 0.6456  data: 0.0001  max mem: 8681
Epoch: [29]  [ 530/2001]  eta: 0:15:55  lr: 0.000011  loss: 3.1756 (3.0404)  time: 0.6460  data: 0.0001  max mem: 8681
Epoch: [29]  [ 540/2001]  eta: 0:15:48  lr: 0.000011  loss: 3.1448 (3.0385)  time: 0.6458  data: 0.0001  max mem: 8681
Epoch: [29]  [ 550/2001]  eta: 0:15:42  lr: 0.000011  loss: 3.1448 (3.0385)  time: 0.6468  data: 0.0001  max mem: 8681
Epoch: [29]  [ 560/2001]  eta: 0:15:35  lr: 0.000011  loss: 3.2081 (3.0416)  time: 0.6438  data: 0.0001  max mem: 8681
Epoch: [29]  [ 570/2001]  eta: 0:15:28  lr: 0.000011  loss: 3.3618 (3.0460)  time: 0.6411  data: 0.0001  max mem: 8681
Epoch: [29]  [ 580/2001]  eta: 0:15:22  lr: 0.000011  loss: 3.3511 (3.0481)  time: 0.6422  data: 0.0001  max mem: 8681
Epoch: [29]  [ 590/2001]  eta: 0:15:15  lr: 0.000011  loss: 3.2457 (3.0503)  time: 0.6431  data: 0.0001  max mem: 8681
loss info: cls_loss=3.0068, ratio_loss=0.0453, cls_kl=0.0631, token_kl=0.0932
Epoch: [29]  [ 600/2001]  eta: 0:15:08  lr: 0.000011  loss: 3.2373 (3.0507)  time: 0.6414  data: 0.0001  max mem: 8681
Epoch: [29]  [ 610/2001]  eta: 0:15:02  lr: 0.000011  loss: 2.9975 (3.0503)  time: 0.6390  data: 0.0001  max mem: 8681
Epoch: [29]  [ 620/2001]  eta: 0:14:55  lr: 0.000011  loss: 3.0255 (3.0514)  time: 0.6466  data: 0.0001  max mem: 8681
Epoch: [29]  [ 630/2001]  eta: 0:14:49  lr: 0.000011  loss: 3.0621 (3.0519)  time: 0.6463  data: 0.0001  max mem: 8681
Epoch: [29]  [ 640/2001]  eta: 0:14:42  lr: 0.000011  loss: 2.9461 (3.0489)  time: 0.6370  data: 0.0001  max mem: 8681
Epoch: [29]  [ 650/2001]  eta: 0:14:35  lr: 0.000011  loss: 2.7905 (3.0475)  time: 0.6366  data: 0.0001  max mem: 8681
Epoch: [29]  [ 660/2001]  eta: 0:14:29  lr: 0.000011  loss: 2.8353 (3.0426)  time: 0.6383  data: 0.0001  max mem: 8681
Epoch: [29]  [ 670/2001]  eta: 0:14:22  lr: 0.000011  loss: 3.0914 (3.0465)  time: 0.6422  data: 0.0001  max mem: 8681
Epoch: [29]  [ 680/2001]  eta: 0:14:15  lr: 0.000011  loss: 3.2606 (3.0481)  time: 0.6420  data: 0.0001  max mem: 8681
Epoch: [29]  [ 690/2001]  eta: 0:14:09  lr: 0.000011  loss: 3.0327 (3.0454)  time: 0.6390  data: 0.0001  max mem: 8681
loss info: cls_loss=2.8770, ratio_loss=0.0453, cls_kl=0.0622, token_kl=0.0941
Epoch: [29]  [ 700/2001]  eta: 0:14:02  lr: 0.000011  loss: 2.8776 (3.0430)  time: 0.6379  data: 0.0001  max mem: 8681
Epoch: [29]  [ 710/2001]  eta: 0:13:55  lr: 0.000011  loss: 3.0849 (3.0415)  time: 0.6369  data: 0.0001  max mem: 8681
Epoch: [29]  [ 720/2001]  eta: 0:13:49  lr: 0.000011  loss: 3.0531 (3.0379)  time: 0.6369  data: 0.0001  max mem: 8681
Epoch: [29]  [ 730/2001]  eta: 0:13:42  lr: 0.000011  loss: 3.0531 (3.0383)  time: 0.6362  data: 0.0001  max mem: 8681
Epoch: [29]  [ 740/2001]  eta: 0:13:35  lr: 0.000011  loss: 3.1984 (3.0424)  time: 0.6348  data: 0.0001  max mem: 8681
Epoch: [29]  [ 750/2001]  eta: 0:13:29  lr: 0.000011  loss: 3.3301 (3.0421)  time: 0.6352  data: 0.0001  max mem: 8681
Epoch: [29]  [ 760/2001]  eta: 0:13:22  lr: 0.000011  loss: 3.1950 (3.0426)  time: 0.6352  data: 0.0001  max mem: 8681
Epoch: [29]  [ 770/2001]  eta: 0:13:15  lr: 0.000011  loss: 3.1603 (3.0450)  time: 0.6332  data: 0.0001  max mem: 8681
Epoch: [29]  [ 780/2001]  eta: 0:13:09  lr: 0.000011  loss: 3.1603 (3.0457)  time: 0.6329  data: 0.0001  max mem: 8681
Epoch: [29]  [ 790/2001]  eta: 0:13:02  lr: 0.000011  loss: 3.0608 (3.0439)  time: 0.6346  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9421, ratio_loss=0.0445, cls_kl=0.0637, token_kl=0.0928
Epoch: [29]  [ 800/2001]  eta: 0:12:55  lr: 0.000011  loss: 3.0615 (3.0444)  time: 0.6337  data: 0.0001  max mem: 8681
Epoch: [29]  [ 810/2001]  eta: 0:12:49  lr: 0.000011  loss: 2.8066 (3.0372)  time: 0.6331  data: 0.0001  max mem: 8681
Epoch: [29]  [ 820/2001]  eta: 0:12:42  lr: 0.000011  loss: 2.9209 (3.0395)  time: 0.6362  data: 0.0001  max mem: 8681
Epoch: [29]  [ 830/2001]  eta: 0:12:36  lr: 0.000011  loss: 3.1817 (3.0367)  time: 0.6367  data: 0.0001  max mem: 8681
Epoch: [29]  [ 840/2001]  eta: 0:12:29  lr: 0.000011  loss: 2.7921 (3.0364)  time: 0.6352  data: 0.0001  max mem: 8681
Epoch: [29]  [ 850/2001]  eta: 0:12:22  lr: 0.000011  loss: 2.9729 (3.0347)  time: 0.6357  data: 0.0001  max mem: 8681
Epoch: [29]  [ 860/2001]  eta: 0:12:16  lr: 0.000011  loss: 2.9321 (3.0340)  time: 0.6350  data: 0.0001  max mem: 8681
Epoch: [29]  [ 870/2001]  eta: 0:12:09  lr: 0.000011  loss: 2.9694 (3.0350)  time: 0.6315  data: 0.0001  max mem: 8681
Epoch: [29]  [ 880/2001]  eta: 0:12:02  lr: 0.000011  loss: 2.9921 (3.0331)  time: 0.6296  data: 0.0001  max mem: 8681
Epoch: [29]  [ 890/2001]  eta: 0:11:56  lr: 0.000011  loss: 2.9921 (3.0311)  time: 0.6347  data: 0.0001  max mem: 8681
loss info: cls_loss=2.8213, ratio_loss=0.0436, cls_kl=0.0624, token_kl=0.0942
Epoch: [29]  [ 900/2001]  eta: 0:11:49  lr: 0.000011  loss: 3.1156 (3.0315)  time: 0.6343  data: 0.0001  max mem: 8681
Epoch: [29]  [ 910/2001]  eta: 0:11:43  lr: 0.000011  loss: 3.1172 (3.0312)  time: 0.6280  data: 0.0001  max mem: 8681
Epoch: [29]  [ 920/2001]  eta: 0:11:36  lr: 0.000011  loss: 3.2980 (3.0325)  time: 0.6289  data: 0.0001  max mem: 8681
Epoch: [29]  [ 930/2001]  eta: 0:11:29  lr: 0.000011  loss: 3.2538 (3.0358)  time: 0.6290  data: 0.0001  max mem: 8681
Epoch: [29]  [ 940/2001]  eta: 0:11:23  lr: 0.000011  loss: 3.2207 (3.0354)  time: 0.6281  data: 0.0001  max mem: 8681
Epoch: [29]  [ 950/2001]  eta: 0:11:16  lr: 0.000011  loss: 2.6295 (3.0308)  time: 0.6277  data: 0.0001  max mem: 8681
Epoch: [29]  [ 960/2001]  eta: 0:11:10  lr: 0.000011  loss: 2.9850 (3.0320)  time: 0.6281  data: 0.0001  max mem: 8681
Epoch: [29]  [ 970/2001]  eta: 0:11:03  lr: 0.000011  loss: 3.1093 (3.0332)  time: 0.6274  data: 0.0001  max mem: 8681
Epoch: [29]  [ 980/2001]  eta: 0:10:56  lr: 0.000011  loss: 3.2646 (3.0340)  time: 0.6265  data: 0.0001  max mem: 8681
Epoch: [29]  [ 990/2001]  eta: 0:10:50  lr: 0.000011  loss: 3.3307 (3.0335)  time: 0.6266  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9478, ratio_loss=0.0424, cls_kl=0.0635, token_kl=0.0921
Epoch: [29]  [1000/2001]  eta: 0:10:43  lr: 0.000011  loss: 3.1823 (3.0330)  time: 0.6277  data: 0.0001  max mem: 8681
Epoch: [29]  [1010/2001]  eta: 0:10:37  lr: 0.000011  loss: 3.1823 (3.0351)  time: 0.6316  data: 0.0001  max mem: 8681
Epoch: [29]  [1020/2001]  eta: 0:10:30  lr: 0.000011  loss: 3.2307 (3.0350)  time: 0.6313  data: 0.0001  max mem: 8681
Epoch: [29]  [1030/2001]  eta: 0:10:23  lr: 0.000011  loss: 2.9751 (3.0322)  time: 0.6294  data: 0.0001  max mem: 8681
Epoch: [29]  [1040/2001]  eta: 0:10:17  lr: 0.000011  loss: 2.9977 (3.0340)  time: 0.6358  data: 0.0001  max mem: 8681
Epoch: [29]  [1050/2001]  eta: 0:10:10  lr: 0.000011  loss: 3.1812 (3.0334)  time: 0.6342  data: 0.0001  max mem: 8681
Epoch: [29]  [1060/2001]  eta: 0:10:04  lr: 0.000011  loss: 3.0774 (3.0341)  time: 0.6256  data: 0.0001  max mem: 8681
Epoch: [29]  [1070/2001]  eta: 0:09:57  lr: 0.000011  loss: 3.0774 (3.0342)  time: 0.6264  data: 0.0001  max mem: 8681
Epoch: [29]  [1080/2001]  eta: 0:09:51  lr: 0.000011  loss: 3.0428 (3.0336)  time: 0.6264  data: 0.0001  max mem: 8681
Epoch: [29]  [1090/2001]  eta: 0:09:44  lr: 0.000011  loss: 3.0228 (3.0336)  time: 0.6275  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9229, ratio_loss=0.0431, cls_kl=0.0622, token_kl=0.0932
Epoch: [29]  [1100/2001]  eta: 0:09:38  lr: 0.000011  loss: 2.9967 (3.0331)  time: 0.6277  data: 0.0001  max mem: 8681
Epoch: [29]  [1110/2001]  eta: 0:09:31  lr: 0.000011  loss: 3.0025 (3.0337)  time: 0.6252  data: 0.0001  max mem: 8681
Epoch: [29]  [1120/2001]  eta: 0:09:25  lr: 0.000011  loss: 3.1634 (3.0343)  time: 0.6266  data: 0.0001  max mem: 8681
Epoch: [29]  [1130/2001]  eta: 0:09:18  lr: 0.000011  loss: 3.2378 (3.0359)  time: 0.6277  data: 0.0001  max mem: 8681
Epoch: [29]  [1140/2001]  eta: 0:09:12  lr: 0.000011  loss: 3.1969 (3.0348)  time: 0.6303  data: 0.0001  max mem: 8681
Epoch: [29]  [1150/2001]  eta: 0:09:05  lr: 0.000011  loss: 3.0603 (3.0344)  time: 0.6314  data: 0.0001  max mem: 8681
Epoch: [29]  [1160/2001]  eta: 0:08:59  lr: 0.000011  loss: 3.0786 (3.0331)  time: 0.6281  data: 0.0001  max mem: 8681
Epoch: [29]  [1170/2001]  eta: 0:08:52  lr: 0.000011  loss: 3.0505 (3.0322)  time: 0.6283  data: 0.0001  max mem: 8681
Epoch: [29]  [1180/2001]  eta: 0:08:46  lr: 0.000011  loss: 3.2323 (3.0351)  time: 0.6289  data: 0.0001  max mem: 8681
Epoch: [29]  [1190/2001]  eta: 0:08:39  lr: 0.000011  loss: 3.4083 (3.0371)  time: 0.6306  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9730, ratio_loss=0.0456, cls_kl=0.0633, token_kl=0.0918
Epoch: [29]  [1200/2001]  eta: 0:08:33  lr: 0.000011  loss: 3.1984 (3.0370)  time: 0.6338  data: 0.0001  max mem: 8681
Epoch: [29]  [1210/2001]  eta: 0:08:26  lr: 0.000011  loss: 3.0307 (3.0362)  time: 0.6304  data: 0.0001  max mem: 8681
Epoch: [29]  [1220/2001]  eta: 0:08:20  lr: 0.000011  loss: 3.0746 (3.0353)  time: 0.6278  data: 0.0001  max mem: 8681
Epoch: [29]  [1230/2001]  eta: 0:08:13  lr: 0.000011  loss: 3.1214 (3.0350)  time: 0.6296  data: 0.0001  max mem: 8681
Epoch: [29]  [1240/2001]  eta: 0:08:07  lr: 0.000011  loss: 3.0585 (3.0346)  time: 0.6312  data: 0.0001  max mem: 8681
Epoch: [29]  [1250/2001]  eta: 0:08:00  lr: 0.000011  loss: 3.0207 (3.0334)  time: 0.6312  data: 0.0001  max mem: 8681
Epoch: [29]  [1260/2001]  eta: 0:07:54  lr: 0.000011  loss: 3.0506 (3.0343)  time: 0.6294  data: 0.0001  max mem: 8681
Epoch: [29]  [1270/2001]  eta: 0:07:47  lr: 0.000011  loss: 3.0747 (3.0355)  time: 0.6301  data: 0.0001  max mem: 8681
Epoch: [29]  [1280/2001]  eta: 0:07:41  lr: 0.000011  loss: 3.2618 (3.0372)  time: 0.6375  data: 0.0001  max mem: 8681
Epoch: [29]  [1290/2001]  eta: 0:07:35  lr: 0.000011  loss: 3.2157 (3.0377)  time: 0.6354  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9364, ratio_loss=0.0458, cls_kl=0.0629, token_kl=0.0927
Epoch: [29]  [1300/2001]  eta: 0:07:28  lr: 0.000011  loss: 3.1960 (3.0380)  time: 0.6296  data: 0.0001  max mem: 8681
Epoch: [29]  [1310/2001]  eta: 0:07:22  lr: 0.000011  loss: 2.9825 (3.0370)  time: 0.6353  data: 0.0001  max mem: 8681
Epoch: [29]  [1320/2001]  eta: 0:07:15  lr: 0.000011  loss: 2.8023 (3.0346)  time: 0.6353  data: 0.0001  max mem: 8681
Epoch: [29]  [1330/2001]  eta: 0:07:09  lr: 0.000011  loss: 2.9781 (3.0358)  time: 0.6319  data: 0.0001  max mem: 8681
Epoch: [29]  [1340/2001]  eta: 0:07:02  lr: 0.000011  loss: 3.2995 (3.0358)  time: 0.6336  data: 0.0001  max mem: 8681
Epoch: [29]  [1350/2001]  eta: 0:06:56  lr: 0.000011  loss: 3.0573 (3.0362)  time: 0.6339  data: 0.0001  max mem: 8681
Epoch: [29]  [1360/2001]  eta: 0:06:50  lr: 0.000011  loss: 3.2306 (3.0381)  time: 0.6318  data: 0.0001  max mem: 8681
Epoch: [29]  [1370/2001]  eta: 0:06:43  lr: 0.000011  loss: 3.3336 (3.0400)  time: 0.6310  data: 0.0001  max mem: 8681
Epoch: [29]  [1380/2001]  eta: 0:06:37  lr: 0.000011  loss: 3.2711 (3.0407)  time: 0.6320  data: 0.0001  max mem: 8681
Epoch: [29]  [1390/2001]  eta: 0:06:30  lr: 0.000011  loss: 3.2718 (3.0413)  time: 0.6330  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9706, ratio_loss=0.0438, cls_kl=0.0628, token_kl=0.0910
Epoch: [29]  [1400/2001]  eta: 0:06:24  lr: 0.000011  loss: 3.2718 (3.0405)  time: 0.6352  data: 0.0001  max mem: 8681
Epoch: [29]  [1410/2001]  eta: 0:06:17  lr: 0.000011  loss: 3.3219 (3.0426)  time: 0.6355  data: 0.0001  max mem: 8681
Epoch: [29]  [1420/2001]  eta: 0:06:11  lr: 0.000011  loss: 3.2070 (3.0425)  time: 0.6335  data: 0.0001  max mem: 8681
Epoch: [29]  [1430/2001]  eta: 0:06:05  lr: 0.000011  loss: 3.1573 (3.0424)  time: 0.6340  data: 0.0001  max mem: 8681
Epoch: [29]  [1440/2001]  eta: 0:05:58  lr: 0.000011  loss: 3.1482 (3.0424)  time: 0.6371  data: 0.0001  max mem: 8681
Epoch: [29]  [1450/2001]  eta: 0:05:52  lr: 0.000011  loss: 3.0862 (3.0423)  time: 0.6351  data: 0.0001  max mem: 8681
Epoch: [29]  [1460/2001]  eta: 0:05:45  lr: 0.000011  loss: 3.1064 (3.0433)  time: 0.6314  data: 0.0001  max mem: 8681
Epoch: [29]  [1470/2001]  eta: 0:05:39  lr: 0.000011  loss: 3.0924 (3.0423)  time: 0.6382  data: 0.0001  max mem: 8681
Epoch: [29]  [1480/2001]  eta: 0:05:33  lr: 0.000011  loss: 2.8189 (3.0408)  time: 0.6405  data: 0.0001  max mem: 8681
Epoch: [29]  [1490/2001]  eta: 0:05:26  lr: 0.000011  loss: 2.7215 (3.0379)  time: 0.6348  data: 0.0001  max mem: 8681
loss info: cls_loss=2.8962, ratio_loss=0.0432, cls_kl=0.0626, token_kl=0.0934
Epoch: [29]  [1500/2001]  eta: 0:05:20  lr: 0.000011  loss: 2.8575 (3.0378)  time: 0.6379  data: 0.0001  max mem: 8681
Epoch: [29]  [1510/2001]  eta: 0:05:13  lr: 0.000011  loss: 3.1832 (3.0389)  time: 0.6459  data: 0.0001  max mem: 8681
Epoch: [29]  [1520/2001]  eta: 0:05:07  lr: 0.000011  loss: 3.3028 (3.0402)  time: 0.6438  data: 0.0001  max mem: 8681
Epoch: [29]  [1530/2001]  eta: 0:05:01  lr: 0.000011  loss: 3.1549 (3.0394)  time: 0.6366  data: 0.0001  max mem: 8681
Epoch: [29]  [1540/2001]  eta: 0:04:54  lr: 0.000011  loss: 2.9883 (3.0396)  time: 0.6368  data: 0.0001  max mem: 8681
Epoch: [29]  [1550/2001]  eta: 0:04:48  lr: 0.000011  loss: 2.9996 (3.0389)  time: 0.6363  data: 0.0001  max mem: 8681
Epoch: [29]  [1560/2001]  eta: 0:04:41  lr: 0.000011  loss: 3.1013 (3.0385)  time: 0.6335  data: 0.0001  max mem: 8681
Epoch: [29]  [1570/2001]  eta: 0:04:35  lr: 0.000011  loss: 3.0641 (3.0370)  time: 0.6362  data: 0.0001  max mem: 8681
Epoch: [29]  [1580/2001]  eta: 0:04:29  lr: 0.000011  loss: 3.0641 (3.0366)  time: 0.6440  data: 0.0001  max mem: 8681
Epoch: [29]  [1590/2001]  eta: 0:04:22  lr: 0.000011  loss: 3.1714 (3.0383)  time: 0.6409  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9666, ratio_loss=0.0426, cls_kl=0.0623, token_kl=0.0921
Epoch: [29]  [1600/2001]  eta: 0:04:16  lr: 0.000011  loss: 3.3367 (3.0401)  time: 0.6337  data: 0.0001  max mem: 8681
Epoch: [29]  [1610/2001]  eta: 0:04:09  lr: 0.000011  loss: 3.2729 (3.0413)  time: 0.6330  data: 0.0001  max mem: 8681
Epoch: [29]  [1620/2001]  eta: 0:04:03  lr: 0.000011  loss: 3.1230 (3.0413)  time: 0.6364  data: 0.0001  max mem: 8681
Epoch: [29]  [1630/2001]  eta: 0:03:57  lr: 0.000011  loss: 3.1783 (3.0416)  time: 0.6396  data: 0.0001  max mem: 8681
Epoch: [29]  [1640/2001]  eta: 0:03:50  lr: 0.000011  loss: 3.2231 (3.0420)  time: 0.6412  data: 0.0001  max mem: 8681
Epoch: [29]  [1650/2001]  eta: 0:03:44  lr: 0.000011  loss: 2.8671 (3.0392)  time: 0.6393  data: 0.0001  max mem: 8681
Epoch: [29]  [1660/2001]  eta: 0:03:37  lr: 0.000011  loss: 2.5323 (3.0366)  time: 0.6337  data: 0.0001  max mem: 8681
Epoch: [29]  [1670/2001]  eta: 0:03:31  lr: 0.000011  loss: 2.7722 (3.0372)  time: 0.6350  data: 0.0001  max mem: 8681
Epoch: [29]  [1680/2001]  eta: 0:03:25  lr: 0.000011  loss: 3.2148 (3.0377)  time: 0.6384  data: 0.0001  max mem: 8681
Epoch: [29]  [1690/2001]  eta: 0:03:18  lr: 0.000011  loss: 3.1773 (3.0381)  time: 0.6396  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9329, ratio_loss=0.0428, cls_kl=0.0622, token_kl=0.0938
Epoch: [29]  [1700/2001]  eta: 0:03:12  lr: 0.000011  loss: 3.3697 (3.0403)  time: 0.6376  data: 0.0001  max mem: 8681
Epoch: [29]  [1710/2001]  eta: 0:03:05  lr: 0.000011  loss: 3.1699 (3.0400)  time: 0.6355  data: 0.0001  max mem: 8681
Epoch: [29]  [1720/2001]  eta: 0:02:59  lr: 0.000011  loss: 3.0474 (3.0398)  time: 0.6344  data: 0.0001  max mem: 8681
Epoch: [29]  [1730/2001]  eta: 0:02:53  lr: 0.000011  loss: 3.2127 (3.0413)  time: 0.6361  data: 0.0001  max mem: 8681
Epoch: [29]  [1740/2001]  eta: 0:02:46  lr: 0.000011  loss: 3.2176 (3.0410)  time: 0.6425  data: 0.0001  max mem: 8681
Epoch: [29]  [1750/2001]  eta: 0:02:40  lr: 0.000011  loss: 3.0217 (3.0403)  time: 0.6424  data: 0.0001  max mem: 8681
Epoch: [29]  [1760/2001]  eta: 0:02:34  lr: 0.000011  loss: 2.9490 (3.0404)  time: 0.6376  data: 0.0001  max mem: 8681
Epoch: [29]  [1770/2001]  eta: 0:02:27  lr: 0.000011  loss: 3.2046 (3.0409)  time: 0.6388  data: 0.0001  max mem: 8681
Epoch: [29]  [1780/2001]  eta: 0:02:21  lr: 0.000011  loss: 3.3373 (3.0416)  time: 0.6383  data: 0.0001  max mem: 8681
Epoch: [29]  [1790/2001]  eta: 0:02:14  lr: 0.000011  loss: 3.2288 (3.0410)  time: 0.6354  data: 0.0001  max mem: 8681
loss info: cls_loss=2.9756, ratio_loss=0.0447, cls_kl=0.0626, token_kl=0.0926
Epoch: [29]  [1800/2001]  eta: 0:02:08  lr: 0.000011  loss: 3.2288 (3.0421)  time: 0.6365  data: 0.0001  max mem: 8681
Epoch: [29]  [1810/2001]  eta: 0:02:02  lr: 0.000011  loss: 3.2651 (3.0420)  time: 0.6418  data: 0.0001  max mem: 8681
Epoch: [29]  [1820/2001]  eta: 0:01:55  lr: 0.000011  loss: 3.1212 (3.0427)  time: 0.6413  data: 0.0001  max mem: 8681
Epoch: [29]  [1830/2001]  eta: 0:01:49  lr: 0.000011  loss: 3.1441 (3.0436)  time: 0.6367  data: 0.0001  max mem: 8681
Epoch: [29]  [1840/2001]  eta: 0:01:42  lr: 0.000011  loss: 3.1265 (3.0431)  time: 0.6423  data: 0.0001  max mem: 8681
Epoch: [29]  [1850/2001]  eta: 0:01:36  lr: 0.000011  loss: 2.9719 (3.0416)  time: 0.6427  data: 0.0001  max mem: 8681
Epoch: [29]  [1860/2001]  eta: 0:01:30  lr: 0.000011  loss: 3.0216 (3.0410)  time: 0.6382  data: 0.0001  max mem: 8681
Epoch: [29]  [1870/2001]  eta: 0:01:23  lr: 0.000011  loss: 3.0073 (3.0399)  time: 0.6418  data: 0.0001  max mem: 8681
Epoch: [29]  [1880/2001]  eta: 0:01:17  lr: 0.000011  loss: 3.2784 (3.0413)  time: 0.6425  data: 0.0001  max mem: 8681
Epoch: [29]  [1890/2001]  eta: 0:01:10  lr: 0.000011  loss: 3.2784 (3.0401)  time: 0.6411  data: 0.0001  max mem: 8681
loss info: cls_loss=2.8816, ratio_loss=0.0432, cls_kl=0.0608, token_kl=0.0923
Epoch: [29]  [1900/2001]  eta: 0:01:04  lr: 0.000011  loss: 3.0661 (3.0396)  time: 0.6467  data: 0.0001  max mem: 8681
Epoch: [29]  [1910/2001]  eta: 0:00:58  lr: 0.000011  loss: 3.2368 (3.0403)  time: 0.6448  data: 0.0001  max mem: 8681
Epoch: [29]  [1920/2001]  eta: 0:00:51  lr: 0.000011  loss: 3.0628 (3.0382)  time: 0.6420  data: 0.0001  max mem: 8681
Epoch: [29]  [1930/2001]  eta: 0:00:45  lr: 0.000011  loss: 2.7555 (3.0377)  time: 0.6426  data: 0.0001  max mem: 8681
Epoch: [29]  [1940/2001]  eta: 0:00:38  lr: 0.000011  loss: 3.1790 (3.0376)  time: 0.6377  data: 0.0001  max mem: 8681
Epoch: [29]  [1950/2001]  eta: 0:00:32  lr: 0.000011  loss: 3.1790 (3.0370)  time: 0.6404  data: 0.0001  max mem: 8681
Epoch: [29]  [1960/2001]  eta: 0:00:26  lr: 0.000011  loss: 3.0865 (3.0364)  time: 0.6424  data: 0.0001  max mem: 8681
Epoch: [29]  [1970/2001]  eta: 0:00:19  lr: 0.000011  loss: 3.0723 (3.0345)  time: 0.6396  data: 0.0001  max mem: 8681
Epoch: [29]  [1980/2001]  eta: 0:00:13  lr: 0.000011  loss: 2.8672 (3.0343)  time: 0.6397  data: 0.0001  max mem: 8681
Epoch: [29]  [1990/2001]  eta: 0:00:07  lr: 0.000011  loss: 3.2300 (3.0339)  time: 0.6361  data: 0.0004  max mem: 8681
loss info: cls_loss=2.8065, ratio_loss=0.0387, cls_kl=0.0586, token_kl=0.0902
Epoch: [29]  [2000/2001]  eta: 0:00:00  lr: 0.000011  loss: 3.0658 (3.0328)  time: 0.6299  data: 0.0004  max mem: 8681
Epoch: [29] Total time: 0:21:19 (0.6395 s / it)
Averaged stats: lr: 0.000011  loss: 3.0658 (3.0406)
Test:  [ 0/53]  eta: 0:04:41  loss: 0.3633 (0.3633)  acc1: 93.3333 (93.3333)  acc5: 100.0000 (100.0000)  time: 5.3147  data: 4.0936  max mem: 8681
Test:  [10/53]  eta: 0:00:36  loss: 0.7479 (0.7686)  acc1: 84.1667 (83.1818)  acc5: 96.6667 (96.6667)  time: 0.8410  data: 0.3745  max mem: 8681
Test:  [20/53]  eta: 0:00:20  loss: 0.7479 (0.7709)  acc1: 83.3333 (83.2143)  acc5: 96.6667 (96.5873)  time: 0.3748  data: 0.0014  max mem: 8681
Test:  [30/53]  eta: 0:00:12  loss: 0.8845 (0.8509)  acc1: 79.1667 (80.9409)  acc5: 94.1667 (95.5645)  time: 0.3507  data: 0.0003  max mem: 8681
Test:  [40/53]  eta: 0:00:06  loss: 1.0605 (0.9125)  acc1: 75.8333 (79.5935)  acc5: 93.3333 (94.7358)  time: 0.3134  data: 0.0002  max mem: 8681
Test:  [50/53]  eta: 0:00:01  loss: 1.0809 (0.9420)  acc1: 76.6667 (78.7909)  acc5: 92.5000 (94.5588)  time: 0.2704  data: 0.0001  max mem: 8681
Test:  [52/53]  eta: 0:00:00  loss: 1.0636 (0.9285)  acc1: 76.6667 (78.9600)  acc5: 93.3333 (94.6240)  time: 0.2542  data: 0.0001  max mem: 8681
Test: Total time: 0:00:22 (0.4163 s / it)
Sparsity0:0.29591676767676767,Sparsity1:0.5573591919191919,Sparsity2:0.7902917171717172,
* Acc@1 79.074 Acc@5 94.522 loss 0.936
Accuracy of the network on the 50000 test images: 79.1%
Max accuracy: 79.07%
Training time 0:21:43
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
