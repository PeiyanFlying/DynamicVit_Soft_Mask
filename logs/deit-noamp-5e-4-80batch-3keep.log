| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 5): env://
| distributed init (rank 7): env://
| distributed init (rank 4): env://
| distributed init (rank 6): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Start training for 30 epochs
## Using lr  0.0000000 for BACKBONE, cosine lr = 0.0006250 for PREDICTOR
Epoch: [0]  [   0/2001]  eta: 3:44:12  lr: 0.000625  loss: 5.4271 (5.4271)  time: 6.7227  data: 3.6302  max mem: 8478
Epoch: [0]  [  10/2001]  eta: 0:38:34  lr: 0.000625  loss: 5.2220 (5.0457)  time: 1.1623  data: 0.3302  max mem: 8739
Epoch: [0]  [  20/2001]  eta: 0:29:16  lr: 0.000625  loss: 4.9336 (4.8444)  time: 0.5947  data: 0.0002  max mem: 8739
Epoch: [0]  [  30/2001]  eta: 0:25:58  lr: 0.000625  loss: 4.8909 (4.8858)  time: 0.5862  data: 0.0001  max mem: 8739
Epoch: [0]  [  40/2001]  eta: 0:24:24  lr: 0.000625  loss: 4.6662 (4.7276)  time: 0.6001  data: 0.0001  max mem: 8739
Epoch: [0]  [  50/2001]  eta: 0:23:16  lr: 0.000625  loss: 4.3021 (4.6426)  time: 0.6004  data: 0.0001  max mem: 8739
Epoch: [0]  [  60/2001]  eta: 0:22:27  lr: 0.000625  loss: 4.1503 (4.4999)  time: 0.5860  data: 0.0002  max mem: 8739
Epoch: [0]  [  70/2001]  eta: 0:21:52  lr: 0.000625  loss: 3.6613 (4.3314)  time: 0.5878  data: 0.0002  max mem: 8739
Epoch: [0]  [  80/2001]  eta: 0:21:24  lr: 0.000625  loss: 3.3562 (4.2199)  time: 0.5915  data: 0.0002  max mem: 8739
Epoch: [0]  [  90/2001]  eta: 0:21:00  lr: 0.000625  loss: 3.3229 (4.1253)  time: 0.5872  data: 0.0002  max mem: 8739
loss info: cls_loss=3.5500, ratio_loss=0.1103, cls_kl=0.5519, token_kl=0.3489
Epoch: [0]  [ 100/2001]  eta: 0:20:41  lr: 0.000625  loss: 3.4922 (4.0682)  time: 0.5887  data: 0.0001  max mem: 8739
Epoch: [0]  [ 110/2001]  eta: 0:20:22  lr: 0.000625  loss: 3.5343 (4.0101)  time: 0.5884  data: 0.0002  max mem: 8739
Epoch: [0]  [ 120/2001]  eta: 0:20:08  lr: 0.000625  loss: 3.4082 (3.9626)  time: 0.5902  data: 0.0001  max mem: 8739
Traceback (most recent call last):
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 253, in main
    process.wait()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/subprocess.py", line 1477, in wait
    (pid, sts) = self._try_wait(0)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/subprocess.py", line 1424, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Traceback (most recent call last):
  File "main_l2_vit_3keep.py", line 566, in <module>
    main(args)
  File "main_l2_vit_3keep.py", line 513, in main
    set_training_mode=args.finetune == '' # keep in eval mode during finetuning
  File "/home/zlkong/DynamicVit_Soft_Mask/engine_l2.py", line 57, in train_one_epoch
    parameters=model.parameters(), create_graph=is_second_order)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/timm/utils/cuda.py", line 48, in __call__
    self._scaler.step(optimizer)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/cuda/amp/grad_scaler.py", line 320, in step
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/cuda/amp/grad_scaler.py", line 320, in <genexpr>
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
KeyboardInterrupt
Traceback (most recent call last):
  File "main_l2_vit_3keep.py", line 566, in <module>
    main(args)
  File "main_l2_vit_3keep.py", line 513, in main
    set_training_mode=args.finetune == '' # keep in eval mode during finetuning
  File "/home/zlkong/DynamicVit_Soft_Mask/engine_l2.py", line 57, in train_one_epoch
    parameters=model.parameters(), create_graph=is_second_order)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/timm/utils/cuda.py", line 48, in __call__
    self._scaler.step(optimizer)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/cuda/amp/grad_scaler.py", line 320, in step
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/cuda/amp/grad_scaler.py", line 320, in <genexpr>
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
KeyboardInterrupt
Traceback (most recent call last):
  File "main_l2_vit_3keep.py", line 566, in <module>
Traceback (most recent call last):
  File "main_l2_vit_3keep.py", line 566, in <module>
    main(args)
  File "main_l2_vit_3keep.py", line 513, in main
    set_training_mode=args.finetune == '' # keep in eval mode during finetuning
  File "/home/zlkong/DynamicVit_Soft_Mask/engine_l2.py", line 57, in train_one_epoch
    parameters=model.parameters(), create_graph=is_second_order)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/timm/utils/cuda.py", line 48, in __call__
    self._scaler.step(optimizer)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/cuda/amp/grad_scaler.py", line 320, in step
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/cuda/amp/grad_scaler.py", line 320, in <genexpr>
    main(args)
  File "main_l2_vit_3keep.py", line 513, in main
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
KeyboardInterrupt
    set_training_mode=args.finetune == '' # keep in eval mode during finetuning
  File "/home/zlkong/DynamicVit_Soft_Mask/engine_l2.py", line 57, in train_one_epoch
Traceback (most recent call last):
  File "main_l2_vit_3keep.py", line 566, in <module>
    parameters=model.parameters(), create_graph=is_second_order)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/timm/utils/cuda.py", line 48, in __call__
    self._scaler.step(optimizer)
Traceback (most recent call last):
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/cuda/amp/grad_scaler.py", line 320, in step
  File "main_l2_vit_3keep.py", line 566, in <module>
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/cuda/amp/grad_scaler.py", line 320, in <genexpr>
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
    main(args)
  File "main_l2_vit_3keep.py", line 513, in main
KeyboardInterrupt
    main(args)
    set_training_mode=args.finetune == '' # keep in eval mode during finetuning
  File "/home/zlkong/DynamicVit_Soft_Mask/engine_l2.py", line 57, in train_one_epoch
  File "main_l2_vit_3keep.py", line 513, in main
    parameters=model.parameters(), create_graph=is_second_order)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/timm/utils/cuda.py", line 48, in __call__
    self._scaler.step(optimizer)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/cuda/amp/grad_scaler.py", line 320, in step
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/cuda/amp/grad_scaler.py", line 320, in <genexpr>
    set_training_mode=args.finetune == '' # keep in eval mode during finetuning
  File "/home/zlkong/DynamicVit_Soft_Mask/engine_l2.py", line 57, in train_one_epoch
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
    parameters=model.parameters(), create_graph=is_second_order)
KeyboardInterrupt
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/timm/utils/cuda.py", line 48, in __call__
    self._scaler.step(optimizer)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/cuda/amp/grad_scaler.py", line 320, in step
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/cuda/amp/grad_scaler.py", line 320, in <genexpr>
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
KeyboardInterrupt
Traceback (most recent call last):
  File "main_l2_vit_3keep.py", line 566, in <module>
    main(args)
  File "main_l2_vit_3keep.py", line 513, in main
    set_training_mode=args.finetune == '' # keep in eval mode during finetuning
  File "/home/zlkong/DynamicVit_Soft_Mask/engine_l2.py", line 57, in train_one_epoch
    parameters=model.parameters(), create_graph=is_second_order)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/timm/utils/cuda.py", line 48, in __call__
    self._scaler.step(optimizer)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/cuda/amp/grad_scaler.py", line 320, in step
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/cuda/amp/grad_scaler.py", line 320, in <genexpr>
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
KeyboardInterrupt
Traceback (most recent call last):
  File "main_l2_vit_3keep.py", line 566, in <module>
    main(args)
  File "main_l2_vit_3keep.py", line 513, in main
    set_training_mode=args.finetune == '' # keep in eval mode during finetuning
  File "/home/zlkong/DynamicVit_Soft_Mask/engine_l2.py", line 57, in train_one_epoch
    parameters=model.parameters(), create_graph=is_second_order)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/timm/utils/cuda.py", line 48, in __call__
    self._scaler.step(optimizer)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/cuda/amp/grad_scaler.py", line 320, in step
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/cuda/amp/grad_scaler.py", line 320, in <genexpr>
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
KeyboardInterrupt
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 4): env://
| distributed init (rank 0): env://
| distributed init (rank 7): env://
| distributed init (rank 5): env://
| distributed init (rank 6): env://
| distributed init (rank 2): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Start training for 30 epochs
## Using lr  0.0000000 for BACKBONE, cosine lr = 0.0006250 for PREDICTOR
Epoch: [0]  [   0/2001]  eta: 3:40:46  lr: 0.000625  loss: 5.4271 (5.4271)  time: 6.6197  data: 3.0226  max mem: 8478
Epoch: [0]  [  10/2001]  eta: 0:38:17  lr: 0.000625  loss: 5.2220 (5.0457)  time: 1.1537  data: 0.2749  max mem: 8739
Epoch: [0]  [  20/2001]  eta: 0:29:14  lr: 0.000625  loss: 4.9336 (4.8444)  time: 0.5988  data: 0.0001  max mem: 8739
Epoch: [0]  [  30/2001]  eta: 0:25:50  lr: 0.000625  loss: 4.8909 (4.8858)  time: 0.5848  data: 0.0001  max mem: 8739
Epoch: [0]  [  40/2001]  eta: 0:24:10  lr: 0.000625  loss: 4.6662 (4.7276)  time: 0.5867  data: 0.0001  max mem: 8739
Epoch: [0]  [  50/2001]  eta: 0:23:06  lr: 0.000625  loss: 4.3021 (4.6426)  time: 0.5934  data: 0.0001  max mem: 8739
Epoch: [0]  [  60/2001]  eta: 0:22:19  lr: 0.000625  loss: 4.1503 (4.4999)  time: 0.5887  data: 0.0001  max mem: 8739
Epoch: [0]  [  70/2001]  eta: 0:21:47  lr: 0.000625  loss: 3.6613 (4.3314)  time: 0.5917  data: 0.0001  max mem: 8739
Epoch: [0]  [  80/2001]  eta: 0:21:22  lr: 0.000625  loss: 3.3562 (4.2199)  time: 0.5995  data: 0.0001  max mem: 8739
Epoch: [0]  [  90/2001]  eta: 0:21:00  lr: 0.000625  loss: 3.3229 (4.1253)  time: 0.5971  data: 0.0001  max mem: 8739
loss info: cls_loss=3.5500, ratio_loss=0.1103, cls_kl=0.5519, token_kl=0.3489
Epoch: [0]  [ 100/2001]  eta: 0:20:42  lr: 0.000625  loss: 3.4922 (4.0682)  time: 0.5965  data: 0.0001  max mem: 8739
Epoch: [0]  [ 110/2001]  eta: 0:20:27  lr: 0.000625  loss: 3.5343 (4.0101)  time: 0.6024  data: 0.0001  max mem: 8739
Epoch: [0]  [ 120/2001]  eta: 0:20:14  lr: 0.000625  loss: 3.4082 (3.9626)  time: 0.6058  data: 0.0001  max mem: 8739
Epoch: [0]  [ 130/2001]  eta: 0:20:02  lr: 0.000625  loss: 3.3191 (3.9097)  time: 0.6056  data: 0.0001  max mem: 8739
Epoch: [0]  [ 140/2001]  eta: 0:19:51  lr: 0.000625  loss: 3.2516 (3.8666)  time: 0.6077  data: 0.0001  max mem: 8739
Epoch: [0]  [ 150/2001]  eta: 0:19:41  lr: 0.000625  loss: 3.3963 (3.8262)  time: 0.6087  data: 0.0001  max mem: 8739
Epoch: [0]  [ 160/2001]  eta: 0:19:31  lr: 0.000625  loss: 3.4284 (3.8023)  time: 0.6086  data: 0.0001  max mem: 8739
Epoch: [0]  [ 170/2001]  eta: 0:19:22  lr: 0.000625  loss: 3.4554 (3.7775)  time: 0.6106  data: 0.0001  max mem: 8739
Epoch: [0]  [ 180/2001]  eta: 0:19:13  lr: 0.000625  loss: 3.3557 (3.7396)  time: 0.6118  data: 0.0001  max mem: 8739
Epoch: [0]  [ 190/2001]  eta: 0:19:05  lr: 0.000625  loss: 3.0986 (3.7175)  time: 0.6135  data: 0.0001  max mem: 8739
loss info: cls_loss=3.0129, ratio_loss=0.2136, cls_kl=0.1479, token_kl=0.1354
Epoch: [0]  [ 200/2001]  eta: 0:18:58  lr: 0.000625  loss: 3.1636 (3.6833)  time: 0.6159  data: 0.0001  max mem: 8739
Epoch: [0]  [ 210/2001]  eta: 0:18:50  lr: 0.000625  loss: 3.3853 (3.6616)  time: 0.6180  data: 0.0001  max mem: 8739
Epoch: [0]  [ 220/2001]  eta: 0:18:43  lr: 0.000625  loss: 3.3919 (3.6486)  time: 0.6194  data: 0.0001  max mem: 8739
Epoch: [0]  [ 230/2001]  eta: 0:18:36  lr: 0.000625  loss: 3.3813 (3.6318)  time: 0.6223  data: 0.0001  max mem: 8739
Epoch: [0]  [ 240/2001]  eta: 0:18:29  lr: 0.000625  loss: 3.3813 (3.6155)  time: 0.6247  data: 0.0001  max mem: 8739
Epoch: [0]  [ 250/2001]  eta: 0:18:23  lr: 0.000625  loss: 3.3352 (3.5978)  time: 0.6237  data: 0.0001  max mem: 8739
Epoch: [0]  [ 260/2001]  eta: 0:18:16  lr: 0.000625  loss: 3.2672 (3.5749)  time: 0.6215  data: 0.0001  max mem: 8739
Epoch: [0]  [ 270/2001]  eta: 0:18:09  lr: 0.000625  loss: 2.8621 (3.5549)  time: 0.6235  data: 0.0001  max mem: 8739
Epoch: [0]  [ 280/2001]  eta: 0:18:03  lr: 0.000625  loss: 3.2392 (3.5450)  time: 0.6262  data: 0.0001  max mem: 8739
Epoch: [0]  [ 290/2001]  eta: 0:17:56  lr: 0.000625  loss: 3.2392 (3.5270)  time: 0.6277  data: 0.0001  max mem: 8739
loss info: cls_loss=2.9115, ratio_loss=0.1703, cls_kl=0.1289, token_kl=0.1307
Epoch: [0]  [ 300/2001]  eta: 0:17:51  lr: 0.000625  loss: 2.9714 (3.5069)  time: 0.6351  data: 0.0001  max mem: 8739
Epoch: [0]  [ 310/2001]  eta: 0:17:44  lr: 0.000625  loss: 3.0731 (3.4969)  time: 0.6342  data: 0.0001  max mem: 8739
Epoch: [0]  [ 320/2001]  eta: 0:17:38  lr: 0.000625  loss: 3.5191 (3.4983)  time: 0.6283  data: 0.0001  max mem: 8739
Epoch: [0]  [ 330/2001]  eta: 0:17:32  lr: 0.000625  loss: 3.5630 (3.4894)  time: 0.6284  data: 0.0001  max mem: 8739
Epoch: [0]  [ 340/2001]  eta: 0:17:25  lr: 0.000625  loss: 3.4964 (3.4862)  time: 0.6278  data: 0.0001  max mem: 8739
Epoch: [0]  [ 350/2001]  eta: 0:17:19  lr: 0.000625  loss: 3.3809 (3.4815)  time: 0.6312  data: 0.0001  max mem: 8739
Epoch: [0]  [ 360/2001]  eta: 0:17:13  lr: 0.000625  loss: 3.3809 (3.4755)  time: 0.6334  data: 0.0001  max mem: 8739
Epoch: [0]  [ 370/2001]  eta: 0:17:07  lr: 0.000625  loss: 3.2079 (3.4669)  time: 0.6325  data: 0.0001  max mem: 8739
Epoch: [0]  [ 380/2001]  eta: 0:17:01  lr: 0.000625  loss: 3.2867 (3.4586)  time: 0.6330  data: 0.0001  max mem: 8739
Epoch: [0]  [ 390/2001]  eta: 0:16:55  lr: 0.000625  loss: 3.2971 (3.4466)  time: 0.6346  data: 0.0001  max mem: 8739
loss info: cls_loss=3.0336, ratio_loss=0.1462, cls_kl=0.1179, token_kl=0.1257
Epoch: [0]  [ 400/2001]  eta: 0:16:48  lr: 0.000625  loss: 3.3311 (3.4447)  time: 0.6344  data: 0.0001  max mem: 8739
Epoch: [0]  [ 410/2001]  eta: 0:16:42  lr: 0.000625  loss: 3.3572 (3.4451)  time: 0.6341  data: 0.0001  max mem: 8739
Epoch: [0]  [ 420/2001]  eta: 0:16:36  lr: 0.000625  loss: 3.3572 (3.4399)  time: 0.6353  data: 0.0001  max mem: 8739
Epoch: [0]  [ 430/2001]  eta: 0:16:30  lr: 0.000625  loss: 3.3660 (3.4381)  time: 0.6360  data: 0.0001  max mem: 8739
Epoch: [0]  [ 440/2001]  eta: 0:16:24  lr: 0.000625  loss: 3.2523 (3.4340)  time: 0.6369  data: 0.0001  max mem: 8739
Epoch: [0]  [ 450/2001]  eta: 0:16:18  lr: 0.000625  loss: 3.2246 (3.4303)  time: 0.6424  data: 0.0001  max mem: 8739
Epoch: [0]  [ 460/2001]  eta: 0:16:12  lr: 0.000625  loss: 3.2084 (3.4218)  time: 0.6440  data: 0.0001  max mem: 8739
Epoch: [0]  [ 470/2001]  eta: 0:16:06  lr: 0.000625  loss: 2.8018 (3.4082)  time: 0.6394  data: 0.0001  max mem: 8739
Epoch: [0]  [ 480/2001]  eta: 0:16:00  lr: 0.000625  loss: 3.0806 (3.4032)  time: 0.6386  data: 0.0001  max mem: 8739
Epoch: [0]  [ 490/2001]  eta: 0:15:54  lr: 0.000625  loss: 3.1948 (3.4054)  time: 0.6407  data: 0.0001  max mem: 8739
loss info: cls_loss=3.0245, ratio_loss=0.1387, cls_kl=0.1141, token_kl=0.1219
Epoch: [0]  [ 500/2001]  eta: 0:15:48  lr: 0.000625  loss: 3.4524 (3.4037)  time: 0.6418  data: 0.0001  max mem: 8739
Epoch: [0]  [ 510/2001]  eta: 0:15:42  lr: 0.000625  loss: 3.4009 (3.4024)  time: 0.6397  data: 0.0001  max mem: 8739
Epoch: [0]  [ 520/2001]  eta: 0:15:36  lr: 0.000625  loss: 3.3085 (3.3997)  time: 0.6400  data: 0.0001  max mem: 8739
Epoch: [0]  [ 530/2001]  eta: 0:15:30  lr: 0.000625  loss: 3.1243 (3.3896)  time: 0.6383  data: 0.0001  max mem: 8739
Epoch: [0]  [ 540/2001]  eta: 0:15:23  lr: 0.000625  loss: 3.1976 (3.3842)  time: 0.6357  data: 0.0001  max mem: 8739
Epoch: [0]  [ 550/2001]  eta: 0:15:17  lr: 0.000625  loss: 3.2741 (3.3794)  time: 0.6360  data: 0.0001  max mem: 8739
Epoch: [0]  [ 560/2001]  eta: 0:15:11  lr: 0.000625  loss: 3.3599 (3.3792)  time: 0.6353  data: 0.0001  max mem: 8739
Epoch: [0]  [ 570/2001]  eta: 0:15:05  lr: 0.000625  loss: 3.3853 (3.3786)  time: 0.6343  data: 0.0001  max mem: 8739
Epoch: [0]  [ 580/2001]  eta: 0:14:58  lr: 0.000625  loss: 3.3853 (3.3780)  time: 0.6351  data: 0.0001  max mem: 8739
Epoch: [0]  [ 590/2001]  eta: 0:14:52  lr: 0.000625  loss: 3.3768 (3.3769)  time: 0.6350  data: 0.0001  max mem: 8739
loss info: cls_loss=3.0437, ratio_loss=0.1331, cls_kl=0.1100, token_kl=0.1183
Epoch: [0]  [ 600/2001]  eta: 0:14:46  lr: 0.000625  loss: 3.3490 (3.3748)  time: 0.6342  data: 0.0001  max mem: 8739
Epoch: [0]  [ 610/2001]  eta: 0:14:40  lr: 0.000625  loss: 3.0783 (3.3732)  time: 0.6348  data: 0.0001  max mem: 8739
Epoch: [0]  [ 620/2001]  eta: 0:14:33  lr: 0.000625  loss: 3.4621 (3.3739)  time: 0.6352  data: 0.0001  max mem: 8739
Epoch: [0]  [ 630/2001]  eta: 0:14:27  lr: 0.000625  loss: 3.4976 (3.3723)  time: 0.6350  data: 0.0001  max mem: 8739
Epoch: [0]  [ 640/2001]  eta: 0:14:21  lr: 0.000625  loss: 3.1617 (3.3671)  time: 0.6347  data: 0.0001  max mem: 8739
Epoch: [0]  [ 650/2001]  eta: 0:14:14  lr: 0.000625  loss: 3.2126 (3.3658)  time: 0.6339  data: 0.0001  max mem: 8739
Epoch: [0]  [ 660/2001]  eta: 0:14:08  lr: 0.000625  loss: 3.1237 (3.3584)  time: 0.6331  data: 0.0001  max mem: 8739
Epoch: [0]  [ 670/2001]  eta: 0:14:02  lr: 0.000625  loss: 3.1237 (3.3596)  time: 0.6332  data: 0.0001  max mem: 8739
Epoch: [0]  [ 680/2001]  eta: 0:13:55  lr: 0.000625  loss: 3.3620 (3.3581)  time: 0.6331  data: 0.0001  max mem: 8739
Epoch: [0]  [ 690/2001]  eta: 0:13:49  lr: 0.000625  loss: 3.2151 (3.3532)  time: 0.6331  data: 0.0001  max mem: 8739
loss info: cls_loss=2.9875, ratio_loss=0.1274, cls_kl=0.1047, token_kl=0.1159
Epoch: [0]  [ 700/2001]  eta: 0:13:43  lr: 0.000625  loss: 3.0816 (3.3494)  time: 0.6337  data: 0.0001  max mem: 8739
Epoch: [0]  [ 710/2001]  eta: 0:13:37  lr: 0.000625  loss: 3.3394 (3.3455)  time: 0.6383  data: 0.0001  max mem: 8739
Epoch: [0]  [ 720/2001]  eta: 0:13:31  lr: 0.000625  loss: 3.3142 (3.3400)  time: 0.6427  data: 0.0001  max mem: 8739
Epoch: [0]  [ 730/2001]  eta: 0:13:24  lr: 0.000625  loss: 3.1958 (3.3392)  time: 0.6379  data: 0.0001  max mem: 8739
Epoch: [0]  [ 740/2001]  eta: 0:13:18  lr: 0.000625  loss: 3.4366 (3.3416)  time: 0.6318  data: 0.0001  max mem: 8739
Epoch: [0]  [ 750/2001]  eta: 0:13:11  lr: 0.000625  loss: 3.5235 (3.3392)  time: 0.6308  data: 0.0001  max mem: 8739
Epoch: [0]  [ 760/2001]  eta: 0:13:05  lr: 0.000625  loss: 3.3669 (3.3361)  time: 0.6304  data: 0.0001  max mem: 8739
Epoch: [0]  [ 770/2001]  eta: 0:12:59  lr: 0.000625  loss: 3.3669 (3.3363)  time: 0.6308  data: 0.0001  max mem: 8739
Epoch: [0]  [ 780/2001]  eta: 0:12:52  lr: 0.000625  loss: 3.5180 (3.3357)  time: 0.6315  data: 0.0001  max mem: 8739
Epoch: [0]  [ 790/2001]  eta: 0:12:46  lr: 0.000625  loss: 3.2439 (3.3333)  time: 0.6297  data: 0.0001  max mem: 8739
loss info: cls_loss=3.0170, ratio_loss=0.1252, cls_kl=0.1015, token_kl=0.1110
Epoch: [0]  [ 800/2001]  eta: 0:12:40  lr: 0.000625  loss: 3.3558 (3.3318)  time: 0.6286  data: 0.0001  max mem: 8739
Epoch: [0]  [ 810/2001]  eta: 0:12:33  lr: 0.000625  loss: 2.8935 (3.3235)  time: 0.6293  data: 0.0001  max mem: 8739
Epoch: [0]  [ 820/2001]  eta: 0:12:27  lr: 0.000625  loss: 3.3046 (3.3246)  time: 0.6292  data: 0.0001  max mem: 8739
Epoch: [0]  [ 830/2001]  eta: 0:12:20  lr: 0.000625  loss: 3.4609 (3.3187)  time: 0.6288  data: 0.0001  max mem: 8739
Epoch: [0]  [ 840/2001]  eta: 0:12:14  lr: 0.000625  loss: 2.9306 (3.3175)  time: 0.6281  data: 0.0001  max mem: 8739
Epoch: [0]  [ 850/2001]  eta: 0:12:08  lr: 0.000625  loss: 3.4834 (3.3146)  time: 0.6277  data: 0.0001  max mem: 8739
Epoch: [0]  [ 860/2001]  eta: 0:12:01  lr: 0.000625  loss: 3.2995 (3.3135)  time: 0.6318  data: 0.0001  max mem: 8739
Epoch: [0]  [ 870/2001]  eta: 0:11:55  lr: 0.000625  loss: 3.1480 (3.3121)  time: 0.6361  data: 0.0001  max mem: 8739
Epoch: [0]  [ 880/2001]  eta: 0:11:49  lr: 0.000625  loss: 3.1141 (3.3079)  time: 0.6313  data: 0.0001  max mem: 8739
Epoch: [0]  [ 890/2001]  eta: 0:11:42  lr: 0.000625  loss: 3.0433 (3.3040)  time: 0.6288  data: 0.0001  max mem: 8739
loss info: cls_loss=2.8859, ratio_loss=0.1180, cls_kl=0.0983, token_kl=0.1104
Epoch: [0]  [ 900/2001]  eta: 0:11:36  lr: 0.000625  loss: 3.2443 (3.3023)  time: 0.6320  data: 0.0001  max mem: 8739
Epoch: [0]  [ 910/2001]  eta: 0:11:30  lr: 0.000625  loss: 3.3052 (3.3015)  time: 0.6286  data: 0.0001  max mem: 8739
Epoch: [0]  [ 920/2001]  eta: 0:11:23  lr: 0.000625  loss: 3.3983 (3.3004)  time: 0.6250  data: 0.0001  max mem: 8739
Epoch: [0]  [ 930/2001]  eta: 0:11:17  lr: 0.000625  loss: 3.4270 (3.3020)  time: 0.6256  data: 0.0001  max mem: 8739
Epoch: [0]  [ 940/2001]  eta: 0:11:10  lr: 0.000625  loss: 3.3606 (3.2996)  time: 0.6251  data: 0.0001  max mem: 8739
Epoch: [0]  [ 950/2001]  eta: 0:11:04  lr: 0.000625  loss: 2.8408 (3.2943)  time: 0.6246  data: 0.0001  max mem: 8739
Epoch: [0]  [ 960/2001]  eta: 0:10:58  lr: 0.000625  loss: 2.9308 (3.2934)  time: 0.6261  data: 0.0001  max mem: 8739
Epoch: [0]  [ 970/2001]  eta: 0:10:51  lr: 0.000625  loss: 3.3756 (3.2929)  time: 0.6256  data: 0.0001  max mem: 8739
Epoch: [0]  [ 980/2001]  eta: 0:10:45  lr: 0.000625  loss: 3.2738 (3.2924)  time: 0.6232  data: 0.0001  max mem: 8739
Epoch: [0]  [ 990/2001]  eta: 0:10:38  lr: 0.000625  loss: 3.4187 (3.2928)  time: 0.6231  data: 0.0001  max mem: 8739
loss info: cls_loss=3.0138, ratio_loss=0.1170, cls_kl=0.0973, token_kl=0.1077
Epoch: [0]  [1000/2001]  eta: 0:10:32  lr: 0.000625  loss: 3.3140 (3.2909)  time: 0.6258  data: 0.0001  max mem: 8739
Epoch: [0]  [1010/2001]  eta: 0:10:26  lr: 0.000625  loss: 3.2999 (3.2919)  time: 0.6280  data: 0.0001  max mem: 8739
Epoch: [0]  [1020/2001]  eta: 0:10:19  lr: 0.000625  loss: 3.3809 (3.2901)  time: 0.6280  data: 0.0001  max mem: 8739
Epoch: [0]  [1030/2001]  eta: 0:10:13  lr: 0.000625  loss: 3.0072 (3.2858)  time: 0.6284  data: 0.0001  max mem: 8739
Epoch: [0]  [1040/2001]  eta: 0:10:07  lr: 0.000625  loss: 3.2540 (3.2865)  time: 0.6293  data: 0.0001  max mem: 8739
Epoch: [0]  [1050/2001]  eta: 0:10:00  lr: 0.000625  loss: 3.2540 (3.2850)  time: 0.6279  data: 0.0001  max mem: 8739
Epoch: [0]  [1060/2001]  eta: 0:09:54  lr: 0.000625  loss: 3.2504 (3.2851)  time: 0.6266  data: 0.0001  max mem: 8739
Epoch: [0]  [1070/2001]  eta: 0:09:48  lr: 0.000625  loss: 3.3484 (3.2842)  time: 0.6280  data: 0.0001  max mem: 8739
Epoch: [0]  [1080/2001]  eta: 0:09:41  lr: 0.000625  loss: 3.3694 (3.2828)  time: 0.6265  data: 0.0001  max mem: 8739
Epoch: [0]  [1090/2001]  eta: 0:09:35  lr: 0.000625  loss: 3.2267 (3.2810)  time: 0.6242  data: 0.0001  max mem: 8739
loss info: cls_loss=2.9775, ratio_loss=0.1184, cls_kl=0.0943, token_kl=0.1061
Epoch: [0]  [1100/2001]  eta: 0:09:28  lr: 0.000625  loss: 3.2267 (3.2793)  time: 0.6245  data: 0.0001  max mem: 8739
Epoch: [0]  [1110/2001]  eta: 0:09:22  lr: 0.000625  loss: 3.3446 (3.2795)  time: 0.6249  data: 0.0001  max mem: 8739
Epoch: [0]  [1120/2001]  eta: 0:09:16  lr: 0.000625  loss: 3.4843 (3.2802)  time: 0.6281  data: 0.0001  max mem: 8739
Epoch: [0]  [1130/2001]  eta: 0:09:10  lr: 0.000625  loss: 3.4574 (3.2810)  time: 0.6397  data: 0.0001  max mem: 8739
Epoch: [0]  [1140/2001]  eta: 0:09:03  lr: 0.000625  loss: 3.3105 (3.2793)  time: 0.6356  data: 0.0001  max mem: 8739
Epoch: [0]  [1150/2001]  eta: 0:08:57  lr: 0.000625  loss: 3.1889 (3.2784)  time: 0.6226  data: 0.0001  max mem: 8739
Epoch: [0]  [1160/2001]  eta: 0:08:50  lr: 0.000625  loss: 3.3007 (3.2769)  time: 0.6233  data: 0.0001  max mem: 8739
Epoch: [0]  [1170/2001]  eta: 0:08:44  lr: 0.000625  loss: 3.2823 (3.2764)  time: 0.6237  data: 0.0001  max mem: 8739
Epoch: [0]  [1180/2001]  eta: 0:08:38  lr: 0.000625  loss: 3.4553 (3.2786)  time: 0.6237  data: 0.0001  max mem: 8739
Epoch: [0]  [1190/2001]  eta: 0:08:31  lr: 0.000625  loss: 3.4997 (3.2792)  time: 0.6238  data: 0.0001  max mem: 8739
loss info: cls_loss=3.1049, ratio_loss=0.1182, cls_kl=0.0986, token_kl=0.1051
Epoch: [0]  [1200/2001]  eta: 0:08:25  lr: 0.000625  loss: 3.4207 (3.2795)  time: 0.6231  data: 0.0001  max mem: 8739
Epoch: [0]  [1210/2001]  eta: 0:08:19  lr: 0.000625  loss: 3.2207 (3.2775)  time: 0.6221  data: 0.0001  max mem: 8739
Epoch: [0]  [1220/2001]  eta: 0:08:12  lr: 0.000625  loss: 3.1745 (3.2761)  time: 0.6223  data: 0.0001  max mem: 8739
Epoch: [0]  [1230/2001]  eta: 0:08:06  lr: 0.000625  loss: 3.2660 (3.2753)  time: 0.6231  data: 0.0001  max mem: 8739
Epoch: [0]  [1240/2001]  eta: 0:07:59  lr: 0.000625  loss: 3.2696 (3.2738)  time: 0.6230  data: 0.0001  max mem: 8739
Epoch: [0]  [1250/2001]  eta: 0:07:53  lr: 0.000625  loss: 3.0579 (3.2708)  time: 0.6235  data: 0.0001  max mem: 8739
Epoch: [0]  [1260/2001]  eta: 0:07:47  lr: 0.000625  loss: 3.0618 (3.2709)  time: 0.6242  data: 0.0001  max mem: 8739
Epoch: [0]  [1270/2001]  eta: 0:07:41  lr: 0.000625  loss: 3.3646 (3.2708)  time: 0.6289  data: 0.0001  max mem: 8739
Epoch: [0]  [1280/2001]  eta: 0:07:34  lr: 0.000625  loss: 3.3703 (3.2718)  time: 0.6384  data: 0.0001  max mem: 8739
Epoch: [0]  [1290/2001]  eta: 0:07:28  lr: 0.000625  loss: 3.4056 (3.2723)  time: 0.6338  data: 0.0001  max mem: 8739
loss info: cls_loss=3.0001, ratio_loss=0.1190, cls_kl=0.0940, token_kl=0.1045
Epoch: [0]  [1300/2001]  eta: 0:07:22  lr: 0.000625  loss: 3.3196 (3.2721)  time: 0.6251  data: 0.0001  max mem: 8739
Epoch: [0]  [1310/2001]  eta: 0:07:15  lr: 0.000625  loss: 3.2393 (3.2702)  time: 0.6264  data: 0.0001  max mem: 8739
Epoch: [0]  [1320/2001]  eta: 0:07:09  lr: 0.000625  loss: 2.9160 (3.2674)  time: 0.6286  data: 0.0001  max mem: 8739
Epoch: [0]  [1330/2001]  eta: 0:07:03  lr: 0.000625  loss: 3.0359 (3.2677)  time: 0.6301  data: 0.0001  max mem: 8739
Epoch: [0]  [1340/2001]  eta: 0:06:56  lr: 0.000625  loss: 3.3442 (3.2674)  time: 0.6279  data: 0.0001  max mem: 8739
Epoch: [0]  [1350/2001]  eta: 0:06:50  lr: 0.000625  loss: 3.3057 (3.2664)  time: 0.6263  data: 0.0001  max mem: 8739
Epoch: [0]  [1360/2001]  eta: 0:06:44  lr: 0.000625  loss: 3.3792 (3.2674)  time: 0.6277  data: 0.0001  max mem: 8739
Epoch: [0]  [1370/2001]  eta: 0:06:37  lr: 0.000625  loss: 3.5164 (3.2693)  time: 0.6279  data: 0.0001  max mem: 8739
Epoch: [0]  [1380/2001]  eta: 0:06:31  lr: 0.000625  loss: 3.5117 (3.2699)  time: 0.6277  data: 0.0001  max mem: 8739
Epoch: [0]  [1390/2001]  eta: 0:06:25  lr: 0.000625  loss: 3.4756 (3.2695)  time: 0.6271  data: 0.0001  max mem: 8739
loss info: cls_loss=3.0428, ratio_loss=0.1138, cls_kl=0.0946, token_kl=0.1033
Epoch: [0]  [1400/2001]  eta: 0:06:18  lr: 0.000625  loss: 3.2655 (3.2681)  time: 0.6261  data: 0.0001  max mem: 8739
Epoch: [0]  [1410/2001]  eta: 0:06:12  lr: 0.000625  loss: 3.3414 (3.2699)  time: 0.6286  data: 0.0001  max mem: 8739
Epoch: [0]  [1420/2001]  eta: 0:06:06  lr: 0.000625  loss: 3.3414 (3.2688)  time: 0.6284  data: 0.0001  max mem: 8739
Epoch: [0]  [1430/2001]  eta: 0:05:59  lr: 0.000625  loss: 3.2099 (3.2680)  time: 0.6269  data: 0.0001  max mem: 8739
Epoch: [0]  [1440/2001]  eta: 0:05:53  lr: 0.000625  loss: 3.1544 (3.2670)  time: 0.6274  data: 0.0001  max mem: 8739
Epoch: [0]  [1450/2001]  eta: 0:05:47  lr: 0.000625  loss: 3.1544 (3.2667)  time: 0.6275  data: 0.0001  max mem: 8739
Epoch: [0]  [1460/2001]  eta: 0:05:41  lr: 0.000625  loss: 3.3758 (3.2674)  time: 0.6291  data: 0.0001  max mem: 8739
Epoch: [0]  [1470/2001]  eta: 0:05:34  lr: 0.000625  loss: 3.3758 (3.2670)  time: 0.6310  data: 0.0001  max mem: 8739
Epoch: [0]  [1480/2001]  eta: 0:05:28  lr: 0.000625  loss: 3.1917 (3.2650)  time: 0.6306  data: 0.0001  max mem: 8739
Epoch: [0]  [1490/2001]  eta: 0:05:22  lr: 0.000625  loss: 2.8700 (3.2616)  time: 0.6311  data: 0.0001  max mem: 8739
loss info: cls_loss=2.9831, ratio_loss=0.1101, cls_kl=0.0940, token_kl=0.1061
Epoch: [0]  [1500/2001]  eta: 0:05:15  lr: 0.000625  loss: 2.8700 (3.2605)  time: 0.6317  data: 0.0001  max mem: 8739
Epoch: [0]  [1510/2001]  eta: 0:05:09  lr: 0.000625  loss: 3.2053 (3.2610)  time: 0.6318  data: 0.0001  max mem: 8739
Epoch: [0]  [1520/2001]  eta: 0:05:03  lr: 0.000625  loss: 3.2841 (3.2612)  time: 0.6323  data: 0.0001  max mem: 8739
Epoch: [0]  [1530/2001]  eta: 0:04:56  lr: 0.000625  loss: 3.2352 (3.2596)  time: 0.6329  data: 0.0001  max mem: 8739
Epoch: [0]  [1540/2001]  eta: 0:04:50  lr: 0.000625  loss: 3.2352 (3.2594)  time: 0.6392  data: 0.0001  max mem: 8739
Epoch: [0]  [1550/2001]  eta: 0:04:44  lr: 0.000625  loss: 3.0795 (3.2577)  time: 0.6407  data: 0.0001  max mem: 8739
Epoch: [0]  [1560/2001]  eta: 0:04:38  lr: 0.000625  loss: 3.0267 (3.2566)  time: 0.6339  data: 0.0001  max mem: 8739
Epoch: [0]  [1570/2001]  eta: 0:04:31  lr: 0.000625  loss: 2.9746 (3.2542)  time: 0.6301  data: 0.0001  max mem: 8739
Epoch: [0]  [1580/2001]  eta: 0:04:25  lr: 0.000625  loss: 2.9746 (3.2535)  time: 0.6293  data: 0.0001  max mem: 8739
Epoch: [0]  [1590/2001]  eta: 0:04:19  lr: 0.000625  loss: 3.1589 (3.2542)  time: 0.6307  data: 0.0003  max mem: 8739
loss info: cls_loss=2.9970, ratio_loss=0.1107, cls_kl=0.0891, token_kl=0.1021
Epoch: [0]  [1600/2001]  eta: 0:04:12  lr: 0.000625  loss: 3.3507 (3.2549)  time: 0.6320  data: 0.0003  max mem: 8739
Epoch: [0]  [1610/2001]  eta: 0:04:06  lr: 0.000625  loss: 3.3507 (3.2553)  time: 0.6323  data: 0.0001  max mem: 8739
Epoch: [0]  [1620/2001]  eta: 0:04:00  lr: 0.000625  loss: 3.3378 (3.2548)  time: 0.6332  data: 0.0001  max mem: 8739
Epoch: [0]  [1630/2001]  eta: 0:03:53  lr: 0.000625  loss: 3.2948 (3.2546)  time: 0.6312  data: 0.0001  max mem: 8739
Epoch: [0]  [1640/2001]  eta: 0:03:47  lr: 0.000625  loss: 3.2948 (3.2540)  time: 0.6283  data: 0.0001  max mem: 8739
Epoch: [0]  [1650/2001]  eta: 0:03:41  lr: 0.000625  loss: 3.0684 (3.2508)  time: 0.6294  data: 0.0001  max mem: 8739
Epoch: [0]  [1660/2001]  eta: 0:03:35  lr: 0.000625  loss: 2.6994 (3.2480)  time: 0.6305  data: 0.0001  max mem: 8739
Epoch: [0]  [1670/2001]  eta: 0:03:28  lr: 0.000625  loss: 3.0621 (3.2475)  time: 0.6301  data: 0.0001  max mem: 8739
Epoch: [0]  [1680/2001]  eta: 0:03:22  lr: 0.000625  loss: 3.2389 (3.2473)  time: 0.6334  data: 0.0001  max mem: 8739
Epoch: [0]  [1690/2001]  eta: 0:03:16  lr: 0.000625  loss: 3.3309 (3.2466)  time: 0.6426  data: 0.0001  max mem: 8739
loss info: cls_loss=2.9642, ratio_loss=0.1113, cls_kl=0.0891, token_kl=0.1031
Epoch: [0]  [1700/2001]  eta: 0:03:09  lr: 0.000625  loss: 3.3715 (3.2478)  time: 0.6430  data: 0.0001  max mem: 8739
Epoch: [0]  [1710/2001]  eta: 0:03:03  lr: 0.000625  loss: 3.2151 (3.2471)  time: 0.6363  data: 0.0001  max mem: 8739
Epoch: [0]  [1720/2001]  eta: 0:02:57  lr: 0.000625  loss: 3.0589 (3.2460)  time: 0.6348  data: 0.0001  max mem: 8739
Epoch: [0]  [1730/2001]  eta: 0:02:50  lr: 0.000625  loss: 3.3996 (3.2468)  time: 0.6347  data: 0.0001  max mem: 8739
Epoch: [0]  [1740/2001]  eta: 0:02:44  lr: 0.000625  loss: 3.3996 (3.2465)  time: 0.6344  data: 0.0001  max mem: 8739
Epoch: [0]  [1750/2001]  eta: 0:02:38  lr: 0.000625  loss: 3.1815 (3.2458)  time: 0.6357  data: 0.0001  max mem: 8739
Epoch: [0]  [1760/2001]  eta: 0:02:32  lr: 0.000625  loss: 3.1815 (3.2451)  time: 0.6363  data: 0.0001  max mem: 8739
Epoch: [0]  [1770/2001]  eta: 0:02:25  lr: 0.000625  loss: 3.4048 (3.2452)  time: 0.6334  data: 0.0001  max mem: 8739
Epoch: [0]  [1780/2001]  eta: 0:02:19  lr: 0.000625  loss: 3.4029 (3.2453)  time: 0.6324  data: 0.0001  max mem: 8739
Epoch: [0]  [1790/2001]  eta: 0:02:13  lr: 0.000625  loss: 3.2187 (3.2439)  time: 0.6325  data: 0.0001  max mem: 8739
loss info: cls_loss=3.0324, ratio_loss=0.1088, cls_kl=0.0933, token_kl=0.1032
Epoch: [0]  [1800/2001]  eta: 0:02:06  lr: 0.000625  loss: 3.3538 (3.2449)  time: 0.6333  data: 0.0001  max mem: 8739
Epoch: [0]  [1810/2001]  eta: 0:02:00  lr: 0.000625  loss: 3.3469 (3.2440)  time: 0.6346  data: 0.0001  max mem: 8739
Epoch: [0]  [1820/2001]  eta: 0:01:54  lr: 0.000625  loss: 3.1649 (3.2446)  time: 0.6345  data: 0.0001  max mem: 8739
Epoch: [0]  [1830/2001]  eta: 0:01:47  lr: 0.000625  loss: 3.3058 (3.2448)  time: 0.6351  data: 0.0001  max mem: 8739
Epoch: [0]  [1840/2001]  eta: 0:01:41  lr: 0.000625  loss: 3.3449 (3.2447)  time: 0.6371  data: 0.0001  max mem: 8739
Epoch: [0]  [1850/2001]  eta: 0:01:35  lr: 0.000625  loss: 3.0158 (3.2427)  time: 0.6370  data: 0.0001  max mem: 8739
Epoch: [0]  [1860/2001]  eta: 0:01:28  lr: 0.000625  loss: 3.0158 (3.2419)  time: 0.6353  data: 0.0001  max mem: 8739
Epoch: [0]  [1870/2001]  eta: 0:01:22  lr: 0.000625  loss: 3.2388 (3.2404)  time: 0.6335  data: 0.0001  max mem: 8739
Epoch: [0]  [1880/2001]  eta: 0:01:16  lr: 0.000625  loss: 3.3755 (3.2416)  time: 0.6320  data: 0.0001  max mem: 8739
Epoch: [0]  [1890/2001]  eta: 0:01:10  lr: 0.000625  loss: 3.4094 (3.2407)  time: 0.6343  data: 0.0001  max mem: 8739
loss info: cls_loss=2.9760, ratio_loss=0.1105, cls_kl=0.0886, token_kl=0.1012
Epoch: [0]  [1900/2001]  eta: 0:01:03  lr: 0.000625  loss: 3.1419 (3.2401)  time: 0.6362  data: 0.0001  max mem: 8739
Epoch: [0]  [1910/2001]  eta: 0:00:57  lr: 0.000625  loss: 3.2593 (3.2407)  time: 0.6336  data: 0.0001  max mem: 8739
Epoch: [0]  [1920/2001]  eta: 0:00:51  lr: 0.000625  loss: 2.9698 (3.2377)  time: 0.6324  data: 0.0001  max mem: 8739
Epoch: [0]  [1930/2001]  eta: 0:00:44  lr: 0.000625  loss: 2.8257 (3.2370)  time: 0.6332  data: 0.0001  max mem: 8739
Epoch: [0]  [1940/2001]  eta: 0:00:38  lr: 0.000625  loss: 3.0964 (3.2358)  time: 0.6376  data: 0.0001  max mem: 8739
Epoch: [0]  [1950/2001]  eta: 0:00:32  lr: 0.000625  loss: 3.2170 (3.2353)  time: 0.6447  data: 0.0001  max mem: 8739
Epoch: [0]  [1960/2001]  eta: 0:00:25  lr: 0.000625  loss: 3.2369 (3.2344)  time: 0.6506  data: 0.0001  max mem: 8739
Epoch: [0]  [1970/2001]  eta: 0:00:19  lr: 0.000625  loss: 3.1997 (3.2323)  time: 0.6437  data: 0.0001  max mem: 8739
Epoch: [0]  [1980/2001]  eta: 0:00:13  lr: 0.000625  loss: 2.9873 (3.2313)  time: 0.6338  data: 0.0001  max mem: 8739
Epoch: [0]  [1990/2001]  eta: 0:00:06  lr: 0.000625  loss: 3.1569 (3.2302)  time: 0.6308  data: 0.0002  max mem: 8739
loss info: cls_loss=2.8665, ratio_loss=0.1029, cls_kl=0.0881, token_kl=0.1001
Epoch: [0]  [2000/2001]  eta: 0:00:00  lr: 0.000625  loss: 3.3788 (3.2293)  time: 0.6278  data: 0.0002  max mem: 8739
Epoch: [0] Total time: 0:21:03 (0.6317 s / it)
Averaged stats: lr: 0.000625  loss: 3.3788 (3.2313)
Test:  [ 0/53]  eta: 0:04:33  loss: 0.3809 (0.3809)  acc1: 93.3333 (93.3333)  acc5: 100.0000 (100.0000)  time: 5.1580  data: 3.9545  max mem: 8739
Test:  [10/53]  eta: 0:00:36  loss: 0.8120 (0.8094)  acc1: 83.3333 (82.8788)  acc5: 96.6667 (96.0606)  time: 0.8418  data: 0.4054  max mem: 8739
Test:  [20/53]  eta: 0:00:19  loss: 0.7451 (0.8026)  acc1: 83.3333 (82.7381)  acc5: 96.6667 (96.3889)  time: 0.3747  data: 0.0253  max mem: 8739
Test:  [30/53]  eta: 0:00:11  loss: 0.9955 (0.8906)  acc1: 78.3333 (80.6183)  acc5: 95.0000 (95.2957)  time: 0.3291  data: 0.0002  max mem: 8739
Test:  [40/53]  eta: 0:00:05  loss: 1.1445 (0.9545)  acc1: 73.3333 (78.8008)  acc5: 92.5000 (94.4309)  time: 0.3036  data: 0.0082  max mem: 8739
Test:  [50/53]  eta: 0:00:01  loss: 1.1069 (0.9819)  acc1: 75.0000 (78.0065)  acc5: 92.5000 (94.2484)  time: 0.2729  data: 0.0081  max mem: 8739
Test:  [52/53]  eta: 0:00:00  loss: 1.1069 (0.9659)  acc1: 75.8333 (78.2080)  acc5: 92.5000 (94.3360)  time: 0.2514  data: 0.0000  max mem: 8739
Test: Total time: 0:00:21 (0.4093 s / it)
Sparsity0:0.23222141414141415,Sparsity1:0.4696852261306533,Sparsity2:0.6970472,
* Acc@1 78.614 Acc@5 94.364 loss 0.966
Accuracy of the network on the 50000 test images: 78.6%
Max accuracy: 78.61%
## Using lr  0.0000000 for BACKBONE, cosine lr = 0.0006233 for PREDICTOR
Epoch: [1]  [   0/2001]  eta: 2:12:08  lr: 0.000623  loss: 2.7110 (2.7110)  time: 3.9622  data: 3.1866  max mem: 8739
Epoch: [1]  [  10/2001]  eta: 0:30:38  lr: 0.000623  loss: 3.5303 (3.4315)  time: 0.9232  data: 0.2898  max mem: 8740
Epoch: [1]  [  20/2001]  eta: 0:25:38  lr: 0.000623  loss: 3.2021 (3.2714)  time: 0.6172  data: 0.0001  max mem: 8740
Epoch: [1]  [  30/2001]  eta: 0:23:52  lr: 0.000623  loss: 3.1941 (3.2891)  time: 0.6191  data: 0.0001  max mem: 8740
Epoch: [1]  [  40/2001]  eta: 0:22:57  lr: 0.000623  loss: 3.3363 (3.2725)  time: 0.6245  data: 0.0001  max mem: 8740
Epoch: [1]  [  50/2001]  eta: 0:22:23  lr: 0.000623  loss: 3.2189 (3.2392)  time: 0.6290  data: 0.0001  max mem: 8740
Epoch: [1]  [  60/2001]  eta: 0:21:58  lr: 0.000623  loss: 3.0412 (3.1896)  time: 0.6314  data: 0.0001  max mem: 8740
Epoch: [1]  [  70/2001]  eta: 0:21:38  lr: 0.000623  loss: 3.1827 (3.2229)  time: 0.6317  data: 0.0001  max mem: 8740
Epoch: [1]  [  80/2001]  eta: 0:21:22  lr: 0.000623  loss: 3.2685 (3.1936)  time: 0.6327  data: 0.0001  max mem: 8740
Epoch: [1]  [  90/2001]  eta: 0:21:08  lr: 0.000623  loss: 3.2407 (3.2044)  time: 0.6328  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0248, ratio_loss=0.1107, cls_kl=0.0924, token_kl=0.1023
Epoch: [1]  [ 100/2001]  eta: 0:20:56  lr: 0.000623  loss: 3.2407 (3.1903)  time: 0.6333  data: 0.0001  max mem: 8740
Epoch: [1]  [ 110/2001]  eta: 0:20:45  lr: 0.000623  loss: 3.1526 (3.1967)  time: 0.6351  data: 0.0001  max mem: 8740
Epoch: [1]  [ 120/2001]  eta: 0:20:35  lr: 0.000623  loss: 3.2478 (3.1880)  time: 0.6356  data: 0.0001  max mem: 8740
Epoch: [1]  [ 130/2001]  eta: 0:20:25  lr: 0.000623  loss: 3.2478 (3.1976)  time: 0.6341  data: 0.0001  max mem: 8740
Epoch: [1]  [ 140/2001]  eta: 0:20:15  lr: 0.000623  loss: 3.4434 (3.2117)  time: 0.6337  data: 0.0001  max mem: 8740
Epoch: [1]  [ 150/2001]  eta: 0:20:07  lr: 0.000623  loss: 3.4099 (3.2066)  time: 0.6358  data: 0.0001  max mem: 8740
Epoch: [1]  [ 160/2001]  eta: 0:19:58  lr: 0.000623  loss: 3.3417 (3.2032)  time: 0.6342  data: 0.0001  max mem: 8740
Epoch: [1]  [ 170/2001]  eta: 0:19:49  lr: 0.000623  loss: 3.2691 (3.2031)  time: 0.6309  data: 0.0001  max mem: 8740
Epoch: [1]  [ 180/2001]  eta: 0:19:41  lr: 0.000623  loss: 3.3375 (3.2013)  time: 0.6319  data: 0.0001  max mem: 8740
Epoch: [1]  [ 190/2001]  eta: 0:19:33  lr: 0.000623  loss: 3.4162 (3.2061)  time: 0.6331  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0171, ratio_loss=0.1097, cls_kl=0.0902, token_kl=0.1013
Epoch: [1]  [ 200/2001]  eta: 0:19:25  lr: 0.000623  loss: 3.2108 (3.1912)  time: 0.6331  data: 0.0002  max mem: 8740
Epoch: [1]  [ 210/2001]  eta: 0:19:18  lr: 0.000623  loss: 3.1551 (3.1930)  time: 0.6351  data: 0.0001  max mem: 8740
Epoch: [1]  [ 220/2001]  eta: 0:19:10  lr: 0.000623  loss: 3.1253 (3.1828)  time: 0.6337  data: 0.0001  max mem: 8740
Epoch: [1]  [ 230/2001]  eta: 0:19:03  lr: 0.000623  loss: 3.1253 (3.1727)  time: 0.6348  data: 0.0001  max mem: 8740
Epoch: [1]  [ 240/2001]  eta: 0:18:56  lr: 0.000623  loss: 3.1869 (3.1727)  time: 0.6347  data: 0.0001  max mem: 8740
Epoch: [1]  [ 250/2001]  eta: 0:18:49  lr: 0.000623  loss: 3.1436 (3.1657)  time: 0.6327  data: 0.0001  max mem: 8740
Epoch: [1]  [ 260/2001]  eta: 0:18:41  lr: 0.000623  loss: 2.9196 (3.1622)  time: 0.6332  data: 0.0001  max mem: 8740
Epoch: [1]  [ 270/2001]  eta: 0:18:34  lr: 0.000623  loss: 3.3002 (3.1664)  time: 0.6326  data: 0.0001  max mem: 8740
Epoch: [1]  [ 280/2001]  eta: 0:18:27  lr: 0.000623  loss: 3.3459 (3.1742)  time: 0.6318  data: 0.0001  max mem: 8740
Epoch: [1]  [ 290/2001]  eta: 0:18:19  lr: 0.000623  loss: 3.3459 (3.1687)  time: 0.6289  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9444, ratio_loss=0.1040, cls_kl=0.0879, token_kl=0.1000
Epoch: [1]  [ 300/2001]  eta: 0:18:12  lr: 0.000623  loss: 3.0304 (3.1591)  time: 0.6296  data: 0.0001  max mem: 8740
Epoch: [1]  [ 310/2001]  eta: 0:18:05  lr: 0.000623  loss: 3.0304 (3.1578)  time: 0.6308  data: 0.0001  max mem: 8740
Epoch: [1]  [ 320/2001]  eta: 0:17:58  lr: 0.000623  loss: 3.3142 (3.1612)  time: 0.6312  data: 0.0002  max mem: 8740
Epoch: [1]  [ 330/2001]  eta: 0:17:51  lr: 0.000623  loss: 3.3142 (3.1681)  time: 0.6294  data: 0.0001  max mem: 8740
Epoch: [1]  [ 340/2001]  eta: 0:17:44  lr: 0.000623  loss: 3.2330 (3.1646)  time: 0.6268  data: 0.0001  max mem: 8740
Epoch: [1]  [ 350/2001]  eta: 0:17:37  lr: 0.000623  loss: 3.0902 (3.1630)  time: 0.6307  data: 0.0001  max mem: 8740
Epoch: [1]  [ 360/2001]  eta: 0:17:31  lr: 0.000623  loss: 3.0361 (3.1578)  time: 0.6344  data: 0.0001  max mem: 8740
Epoch: [1]  [ 370/2001]  eta: 0:17:24  lr: 0.000623  loss: 3.1019 (3.1577)  time: 0.6326  data: 0.0001  max mem: 8740
Epoch: [1]  [ 380/2001]  eta: 0:17:17  lr: 0.000623  loss: 3.2292 (3.1607)  time: 0.6278  data: 0.0001  max mem: 8740
Epoch: [1]  [ 390/2001]  eta: 0:17:10  lr: 0.000623  loss: 3.2292 (3.1552)  time: 0.6284  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9637, ratio_loss=0.1063, cls_kl=0.0894, token_kl=0.1008
Epoch: [1]  [ 400/2001]  eta: 0:17:04  lr: 0.000623  loss: 3.1915 (3.1555)  time: 0.6355  data: 0.0001  max mem: 8740
Epoch: [1]  [ 410/2001]  eta: 0:16:57  lr: 0.000623  loss: 3.3043 (3.1593)  time: 0.6363  data: 0.0001  max mem: 8740
Epoch: [1]  [ 420/2001]  eta: 0:16:50  lr: 0.000623  loss: 3.1733 (3.1550)  time: 0.6299  data: 0.0002  max mem: 8740
Epoch: [1]  [ 430/2001]  eta: 0:16:43  lr: 0.000623  loss: 3.2372 (3.1602)  time: 0.6252  data: 0.0002  max mem: 8740
Epoch: [1]  [ 440/2001]  eta: 0:16:36  lr: 0.000623  loss: 3.2924 (3.1627)  time: 0.6251  data: 0.0001  max mem: 8740
Epoch: [1]  [ 450/2001]  eta: 0:16:29  lr: 0.000623  loss: 3.3378 (3.1690)  time: 0.6254  data: 0.0001  max mem: 8740
Epoch: [1]  [ 460/2001]  eta: 0:16:23  lr: 0.000623  loss: 3.4740 (3.1682)  time: 0.6248  data: 0.0001  max mem: 8740
Epoch: [1]  [ 470/2001]  eta: 0:16:16  lr: 0.000623  loss: 3.3091 (3.1660)  time: 0.6270  data: 0.0001  max mem: 8740
Epoch: [1]  [ 480/2001]  eta: 0:16:09  lr: 0.000623  loss: 2.9725 (3.1643)  time: 0.6280  data: 0.0001  max mem: 8740
Epoch: [1]  [ 490/2001]  eta: 0:16:02  lr: 0.000623  loss: 3.2346 (3.1697)  time: 0.6259  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0432, ratio_loss=0.1085, cls_kl=0.0886, token_kl=0.1000
Epoch: [1]  [ 500/2001]  eta: 0:15:56  lr: 0.000623  loss: 3.1104 (3.1637)  time: 0.6342  data: 0.0001  max mem: 8740
Epoch: [1]  [ 510/2001]  eta: 0:15:50  lr: 0.000623  loss: 2.8774 (3.1630)  time: 0.6361  data: 0.0001  max mem: 8740
Epoch: [1]  [ 520/2001]  eta: 0:15:43  lr: 0.000623  loss: 3.0504 (3.1625)  time: 0.6289  data: 0.0001  max mem: 8740
Epoch: [1]  [ 530/2001]  eta: 0:15:36  lr: 0.000623  loss: 3.2155 (3.1643)  time: 0.6265  data: 0.0001  max mem: 8740
Epoch: [1]  [ 540/2001]  eta: 0:15:30  lr: 0.000623  loss: 3.2036 (3.1618)  time: 0.6284  data: 0.0001  max mem: 8740
Epoch: [1]  [ 550/2001]  eta: 0:15:23  lr: 0.000623  loss: 3.0558 (3.1650)  time: 0.6266  data: 0.0001  max mem: 8740
Epoch: [1]  [ 560/2001]  eta: 0:15:16  lr: 0.000623  loss: 3.3808 (3.1712)  time: 0.6261  data: 0.0001  max mem: 8740
Epoch: [1]  [ 570/2001]  eta: 0:15:10  lr: 0.000623  loss: 3.3644 (3.1752)  time: 0.6288  data: 0.0002  max mem: 8740
Epoch: [1]  [ 580/2001]  eta: 0:15:03  lr: 0.000623  loss: 3.2388 (3.1752)  time: 0.6253  data: 0.0001  max mem: 8740
Epoch: [1]  [ 590/2001]  eta: 0:14:57  lr: 0.000623  loss: 3.1918 (3.1735)  time: 0.6238  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0386, ratio_loss=0.1087, cls_kl=0.0932, token_kl=0.1006
Epoch: [1]  [ 600/2001]  eta: 0:14:50  lr: 0.000623  loss: 3.2538 (3.1730)  time: 0.6242  data: 0.0001  max mem: 8740
Epoch: [1]  [ 610/2001]  eta: 0:14:43  lr: 0.000623  loss: 3.2013 (3.1680)  time: 0.6241  data: 0.0001  max mem: 8740
Epoch: [1]  [ 620/2001]  eta: 0:14:37  lr: 0.000623  loss: 3.0523 (3.1696)  time: 0.6248  data: 0.0001  max mem: 8740
Epoch: [1]  [ 630/2001]  eta: 0:14:30  lr: 0.000623  loss: 3.2749 (3.1693)  time: 0.6241  data: 0.0001  max mem: 8740
Epoch: [1]  [ 640/2001]  eta: 0:14:24  lr: 0.000623  loss: 3.4429 (3.1736)  time: 0.6229  data: 0.0001  max mem: 8740
Epoch: [1]  [ 650/2001]  eta: 0:14:17  lr: 0.000623  loss: 3.5036 (3.1720)  time: 0.6282  data: 0.0001  max mem: 8740
Epoch: [1]  [ 660/2001]  eta: 0:14:11  lr: 0.000623  loss: 3.2343 (3.1740)  time: 0.6290  data: 0.0001  max mem: 8740
Epoch: [1]  [ 670/2001]  eta: 0:14:04  lr: 0.000623  loss: 3.3869 (3.1755)  time: 0.6292  data: 0.0001  max mem: 8740
Epoch: [1]  [ 680/2001]  eta: 0:13:58  lr: 0.000623  loss: 3.4462 (3.1774)  time: 0.6303  data: 0.0001  max mem: 8740
Epoch: [1]  [ 690/2001]  eta: 0:13:51  lr: 0.000623  loss: 3.4589 (3.1803)  time: 0.6252  data: 0.0002  max mem: 8740
loss info: cls_loss=3.0708, ratio_loss=0.1089, cls_kl=0.0899, token_kl=0.1001
Epoch: [1]  [ 700/2001]  eta: 0:13:45  lr: 0.000623  loss: 3.4652 (3.1826)  time: 0.6260  data: 0.0002  max mem: 8740
Epoch: [1]  [ 710/2001]  eta: 0:13:38  lr: 0.000623  loss: 3.3567 (3.1859)  time: 0.6328  data: 0.0001  max mem: 8740
Epoch: [1]  [ 720/2001]  eta: 0:13:32  lr: 0.000623  loss: 3.2221 (3.1841)  time: 0.6335  data: 0.0001  max mem: 8740
Epoch: [1]  [ 730/2001]  eta: 0:13:26  lr: 0.000623  loss: 3.3169 (3.1880)  time: 0.6281  data: 0.0001  max mem: 8740
Epoch: [1]  [ 740/2001]  eta: 0:13:19  lr: 0.000623  loss: 3.0213 (3.1835)  time: 0.6270  data: 0.0001  max mem: 8740
Epoch: [1]  [ 750/2001]  eta: 0:13:13  lr: 0.000623  loss: 3.0213 (3.1849)  time: 0.6296  data: 0.0001  max mem: 8740
Epoch: [1]  [ 760/2001]  eta: 0:13:06  lr: 0.000623  loss: 3.2707 (3.1819)  time: 0.6338  data: 0.0001  max mem: 8740
Epoch: [1]  [ 770/2001]  eta: 0:13:00  lr: 0.000623  loss: 3.4423 (3.1844)  time: 0.6325  data: 0.0001  max mem: 8740
Epoch: [1]  [ 780/2001]  eta: 0:12:54  lr: 0.000623  loss: 3.4630 (3.1842)  time: 0.6278  data: 0.0001  max mem: 8740
Epoch: [1]  [ 790/2001]  eta: 0:12:47  lr: 0.000623  loss: 3.0790 (3.1827)  time: 0.6275  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0086, ratio_loss=0.1074, cls_kl=0.0868, token_kl=0.0985
Epoch: [1]  [ 800/2001]  eta: 0:12:41  lr: 0.000623  loss: 2.9747 (3.1796)  time: 0.6301  data: 0.0001  max mem: 8740
Epoch: [1]  [ 810/2001]  eta: 0:12:34  lr: 0.000623  loss: 3.1825 (3.1786)  time: 0.6307  data: 0.0002  max mem: 8740
Epoch: [1]  [ 820/2001]  eta: 0:12:28  lr: 0.000623  loss: 3.1825 (3.1782)  time: 0.6343  data: 0.0002  max mem: 8740
Epoch: [1]  [ 830/2001]  eta: 0:12:22  lr: 0.000623  loss: 3.2004 (3.1775)  time: 0.6373  data: 0.0001  max mem: 8740
Epoch: [1]  [ 840/2001]  eta: 0:12:15  lr: 0.000623  loss: 3.2004 (3.1772)  time: 0.6298  data: 0.0001  max mem: 8740
Epoch: [1]  [ 850/2001]  eta: 0:12:09  lr: 0.000623  loss: 3.1000 (3.1758)  time: 0.6260  data: 0.0001  max mem: 8740
Epoch: [1]  [ 860/2001]  eta: 0:12:02  lr: 0.000623  loss: 2.8515 (3.1694)  time: 0.6271  data: 0.0001  max mem: 8740
Epoch: [1]  [ 870/2001]  eta: 0:11:56  lr: 0.000623  loss: 2.7704 (3.1670)  time: 0.6305  data: 0.0001  max mem: 8740
Epoch: [1]  [ 880/2001]  eta: 0:11:50  lr: 0.000623  loss: 3.2572 (3.1669)  time: 0.6325  data: 0.0001  max mem: 8740
Epoch: [1]  [ 890/2001]  eta: 0:11:43  lr: 0.000623  loss: 3.2732 (3.1649)  time: 0.6300  data: 0.0001  max mem: 8740
loss info: cls_loss=2.8903, ratio_loss=0.1018, cls_kl=0.0859, token_kl=0.0987
Epoch: [1]  [ 900/2001]  eta: 0:11:37  lr: 0.000623  loss: 3.2439 (3.1660)  time: 0.6288  data: 0.0001  max mem: 8740
Epoch: [1]  [ 910/2001]  eta: 0:11:31  lr: 0.000623  loss: 3.2511 (3.1635)  time: 0.6365  data: 0.0001  max mem: 8740
Epoch: [1]  [ 920/2001]  eta: 0:11:25  lr: 0.000623  loss: 3.2925 (3.1661)  time: 0.6469  data: 0.0001  max mem: 8740
Epoch: [1]  [ 930/2001]  eta: 0:11:18  lr: 0.000623  loss: 3.2925 (3.1690)  time: 0.6388  data: 0.0001  max mem: 8740
Epoch: [1]  [ 940/2001]  eta: 0:11:12  lr: 0.000623  loss: 3.5684 (3.1725)  time: 0.6281  data: 0.0001  max mem: 8740
Epoch: [1]  [ 950/2001]  eta: 0:11:05  lr: 0.000623  loss: 3.1046 (3.1678)  time: 0.6331  data: 0.0001  max mem: 8740
Epoch: [1]  [ 960/2001]  eta: 0:10:59  lr: 0.000623  loss: 2.9799 (3.1668)  time: 0.6338  data: 0.0001  max mem: 8740
Epoch: [1]  [ 970/2001]  eta: 0:10:53  lr: 0.000623  loss: 3.2204 (3.1678)  time: 0.6298  data: 0.0001  max mem: 8740
Epoch: [1]  [ 980/2001]  eta: 0:10:46  lr: 0.000623  loss: 3.2875 (3.1679)  time: 0.6322  data: 0.0001  max mem: 8740
Epoch: [1]  [ 990/2001]  eta: 0:10:40  lr: 0.000623  loss: 3.4218 (3.1692)  time: 0.6341  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0172, ratio_loss=0.1079, cls_kl=0.0904, token_kl=0.0997
Epoch: [1]  [1000/2001]  eta: 0:10:34  lr: 0.000623  loss: 3.3818 (3.1682)  time: 0.6329  data: 0.0001  max mem: 8740
Epoch: [1]  [1010/2001]  eta: 0:10:27  lr: 0.000623  loss: 3.0962 (3.1674)  time: 0.6339  data: 0.0001  max mem: 8740
Epoch: [1]  [1020/2001]  eta: 0:10:21  lr: 0.000623  loss: 3.1456 (3.1673)  time: 0.6330  data: 0.0001  max mem: 8740
Epoch: [1]  [1030/2001]  eta: 0:10:15  lr: 0.000623  loss: 3.1456 (3.1657)  time: 0.6318  data: 0.0001  max mem: 8740
Epoch: [1]  [1040/2001]  eta: 0:10:08  lr: 0.000623  loss: 3.3473 (3.1662)  time: 0.6318  data: 0.0001  max mem: 8740
Epoch: [1]  [1050/2001]  eta: 0:10:02  lr: 0.000623  loss: 3.3653 (3.1679)  time: 0.6311  data: 0.0001  max mem: 8740
Epoch: [1]  [1060/2001]  eta: 0:09:56  lr: 0.000623  loss: 3.2847 (3.1679)  time: 0.6351  data: 0.0001  max mem: 8740
Epoch: [1]  [1070/2001]  eta: 0:09:49  lr: 0.000623  loss: 3.1420 (3.1671)  time: 0.6352  data: 0.0001  max mem: 8740
Epoch: [1]  [1080/2001]  eta: 0:09:43  lr: 0.000623  loss: 3.0350 (3.1664)  time: 0.6381  data: 0.0001  max mem: 8740
Epoch: [1]  [1090/2001]  eta: 0:09:37  lr: 0.000623  loss: 3.1799 (3.1657)  time: 0.6380  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9844, ratio_loss=0.1022, cls_kl=0.0867, token_kl=0.0974
Epoch: [1]  [1100/2001]  eta: 0:09:30  lr: 0.000623  loss: 3.2772 (3.1650)  time: 0.6327  data: 0.0001  max mem: 8740
Epoch: [1]  [1110/2001]  eta: 0:09:24  lr: 0.000623  loss: 3.2166 (3.1647)  time: 0.6333  data: 0.0001  max mem: 8740
Epoch: [1]  [1120/2001]  eta: 0:09:18  lr: 0.000623  loss: 3.1561 (3.1649)  time: 0.6340  data: 0.0001  max mem: 8740
Epoch: [1]  [1130/2001]  eta: 0:09:11  lr: 0.000623  loss: 3.2437 (3.1647)  time: 0.6342  data: 0.0001  max mem: 8740
Epoch: [1]  [1140/2001]  eta: 0:09:05  lr: 0.000623  loss: 3.1160 (3.1611)  time: 0.6323  data: 0.0002  max mem: 8740
Epoch: [1]  [1150/2001]  eta: 0:08:59  lr: 0.000623  loss: 3.1379 (3.1611)  time: 0.6322  data: 0.0001  max mem: 8740
Epoch: [1]  [1160/2001]  eta: 0:08:52  lr: 0.000623  loss: 3.2399 (3.1598)  time: 0.6327  data: 0.0001  max mem: 8740
Epoch: [1]  [1170/2001]  eta: 0:08:46  lr: 0.000623  loss: 3.4208 (3.1611)  time: 0.6369  data: 0.0001  max mem: 8740
Epoch: [1]  [1180/2001]  eta: 0:08:40  lr: 0.000623  loss: 3.3704 (3.1615)  time: 0.6411  data: 0.0001  max mem: 8740
Epoch: [1]  [1190/2001]  eta: 0:08:33  lr: 0.000623  loss: 3.1954 (3.1586)  time: 0.6382  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9396, ratio_loss=0.1035, cls_kl=0.0859, token_kl=0.0993
Epoch: [1]  [1200/2001]  eta: 0:08:27  lr: 0.000623  loss: 3.1954 (3.1603)  time: 0.6370  data: 0.0001  max mem: 8740
Epoch: [1]  [1210/2001]  eta: 0:08:21  lr: 0.000623  loss: 3.4794 (3.1618)  time: 0.6362  data: 0.0001  max mem: 8740
Epoch: [1]  [1220/2001]  eta: 0:08:15  lr: 0.000623  loss: 3.4436 (3.1620)  time: 0.6372  data: 0.0001  max mem: 8740
Epoch: [1]  [1230/2001]  eta: 0:08:08  lr: 0.000623  loss: 3.3195 (3.1637)  time: 0.6407  data: 0.0001  max mem: 8740
Epoch: [1]  [1240/2001]  eta: 0:08:02  lr: 0.000623  loss: 3.3613 (3.1670)  time: 0.6379  data: 0.0001  max mem: 8740
Epoch: [1]  [1250/2001]  eta: 0:07:56  lr: 0.000623  loss: 3.4858 (3.1677)  time: 0.6371  data: 0.0001  max mem: 8740
Epoch: [1]  [1260/2001]  eta: 0:07:49  lr: 0.000623  loss: 3.1736 (3.1662)  time: 0.6389  data: 0.0001  max mem: 8740
Epoch: [1]  [1270/2001]  eta: 0:07:43  lr: 0.000623  loss: 3.0135 (3.1658)  time: 0.6377  data: 0.0001  max mem: 8740
Epoch: [1]  [1280/2001]  eta: 0:07:37  lr: 0.000623  loss: 2.8418 (3.1651)  time: 0.6362  data: 0.0002  max mem: 8740
Epoch: [1]  [1290/2001]  eta: 0:07:30  lr: 0.000623  loss: 3.0843 (3.1660)  time: 0.6358  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0779, ratio_loss=0.1113, cls_kl=0.0922, token_kl=0.1026
Epoch: [1]  [1300/2001]  eta: 0:07:24  lr: 0.000623  loss: 3.4503 (3.1670)  time: 0.6355  data: 0.0001  max mem: 8740
Epoch: [1]  [1310/2001]  eta: 0:07:18  lr: 0.000623  loss: 3.4995 (3.1678)  time: 0.6366  data: 0.0001  max mem: 8740
Epoch: [1]  [1320/2001]  eta: 0:07:11  lr: 0.000623  loss: 3.5115 (3.1692)  time: 0.6395  data: 0.0002  max mem: 8740
Epoch: [1]  [1330/2001]  eta: 0:07:05  lr: 0.000623  loss: 3.2342 (3.1668)  time: 0.6442  data: 0.0001  max mem: 8740
Epoch: [1]  [1340/2001]  eta: 0:06:59  lr: 0.000623  loss: 3.0074 (3.1652)  time: 0.6418  data: 0.0001  max mem: 8740
Epoch: [1]  [1350/2001]  eta: 0:06:52  lr: 0.000623  loss: 3.1391 (3.1654)  time: 0.6356  data: 0.0001  max mem: 8740
Epoch: [1]  [1360/2001]  eta: 0:06:46  lr: 0.000623  loss: 3.2664 (3.1646)  time: 0.6357  data: 0.0001  max mem: 8740
Epoch: [1]  [1370/2001]  eta: 0:06:40  lr: 0.000623  loss: 3.0796 (3.1640)  time: 0.6366  data: 0.0001  max mem: 8740
Epoch: [1]  [1380/2001]  eta: 0:06:33  lr: 0.000623  loss: 3.1154 (3.1635)  time: 0.6390  data: 0.0001  max mem: 8740
Epoch: [1]  [1390/2001]  eta: 0:06:27  lr: 0.000623  loss: 3.2959 (3.1647)  time: 0.6391  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9487, ratio_loss=0.1059, cls_kl=0.0866, token_kl=0.0999
Epoch: [1]  [1400/2001]  eta: 0:06:21  lr: 0.000623  loss: 3.1809 (3.1630)  time: 0.6369  data: 0.0001  max mem: 8740
Epoch: [1]  [1410/2001]  eta: 0:06:14  lr: 0.000623  loss: 3.1643 (3.1634)  time: 0.6399  data: 0.0001  max mem: 8740
Epoch: [1]  [1420/2001]  eta: 0:06:08  lr: 0.000623  loss: 3.3929 (3.1639)  time: 0.6413  data: 0.0001  max mem: 8740
Epoch: [1]  [1430/2001]  eta: 0:06:02  lr: 0.000623  loss: 3.0307 (3.1625)  time: 0.6412  data: 0.0001  max mem: 8740
Epoch: [1]  [1440/2001]  eta: 0:05:55  lr: 0.000623  loss: 3.0212 (3.1616)  time: 0.6400  data: 0.0001  max mem: 8740
Epoch: [1]  [1450/2001]  eta: 0:05:49  lr: 0.000623  loss: 3.1033 (3.1616)  time: 0.6365  data: 0.0001  max mem: 8740
Epoch: [1]  [1460/2001]  eta: 0:05:43  lr: 0.000623  loss: 3.2254 (3.1616)  time: 0.6355  data: 0.0001  max mem: 8740
Epoch: [1]  [1470/2001]  eta: 0:05:36  lr: 0.000623  loss: 2.9741 (3.1595)  time: 0.6387  data: 0.0001  max mem: 8740
Epoch: [1]  [1480/2001]  eta: 0:05:30  lr: 0.000623  loss: 3.1496 (3.1602)  time: 0.6385  data: 0.0002  max mem: 8740
Epoch: [1]  [1490/2001]  eta: 0:05:24  lr: 0.000623  loss: 3.2052 (3.1601)  time: 0.6388  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9343, ratio_loss=0.1021, cls_kl=0.0863, token_kl=0.0990
Epoch: [1]  [1500/2001]  eta: 0:05:17  lr: 0.000623  loss: 3.1205 (3.1591)  time: 0.6402  data: 0.0001  max mem: 8740
Epoch: [1]  [1510/2001]  eta: 0:05:11  lr: 0.000623  loss: 3.1825 (3.1587)  time: 0.6355  data: 0.0001  max mem: 8740
Epoch: [1]  [1520/2001]  eta: 0:05:05  lr: 0.000623  loss: 3.1698 (3.1579)  time: 0.6352  data: 0.0001  max mem: 8740
Epoch: [1]  [1530/2001]  eta: 0:04:58  lr: 0.000623  loss: 3.1222 (3.1575)  time: 0.6363  data: 0.0001  max mem: 8740
Epoch: [1]  [1540/2001]  eta: 0:04:52  lr: 0.000623  loss: 3.1189 (3.1561)  time: 0.6347  data: 0.0001  max mem: 8740
Epoch: [1]  [1550/2001]  eta: 0:04:46  lr: 0.000623  loss: 3.0487 (3.1551)  time: 0.6337  data: 0.0001  max mem: 8740
Epoch: [1]  [1560/2001]  eta: 0:04:39  lr: 0.000623  loss: 3.3463 (3.1566)  time: 0.6350  data: 0.0001  max mem: 8740
Epoch: [1]  [1570/2001]  eta: 0:04:33  lr: 0.000623  loss: 3.4684 (3.1572)  time: 0.6350  data: 0.0001  max mem: 8740
Epoch: [1]  [1580/2001]  eta: 0:04:27  lr: 0.000623  loss: 3.3752 (3.1584)  time: 0.6363  data: 0.0001  max mem: 8740
Epoch: [1]  [1590/2001]  eta: 0:04:20  lr: 0.000623  loss: 3.3074 (3.1593)  time: 0.6372  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9944, ratio_loss=0.1081, cls_kl=0.0909, token_kl=0.1009
Epoch: [1]  [1600/2001]  eta: 0:04:14  lr: 0.000623  loss: 3.2550 (3.1587)  time: 0.6380  data: 0.0001  max mem: 8740
Epoch: [1]  [1610/2001]  eta: 0:04:08  lr: 0.000623  loss: 3.3416 (3.1589)  time: 0.6360  data: 0.0001  max mem: 8740
Epoch: [1]  [1620/2001]  eta: 0:04:01  lr: 0.000623  loss: 3.3597 (3.1599)  time: 0.6318  data: 0.0001  max mem: 8740
Epoch: [1]  [1630/2001]  eta: 0:03:55  lr: 0.000623  loss: 3.3193 (3.1611)  time: 0.6325  data: 0.0001  max mem: 8740
Epoch: [1]  [1640/2001]  eta: 0:03:49  lr: 0.000623  loss: 3.2848 (3.1612)  time: 0.6352  data: 0.0001  max mem: 8740
Epoch: [1]  [1650/2001]  eta: 0:03:42  lr: 0.000623  loss: 3.3894 (3.1625)  time: 0.6337  data: 0.0001  max mem: 8740
Epoch: [1]  [1660/2001]  eta: 0:03:36  lr: 0.000623  loss: 3.4133 (3.1626)  time: 0.6299  data: 0.0001  max mem: 8740
Epoch: [1]  [1670/2001]  eta: 0:03:30  lr: 0.000623  loss: 3.3752 (3.1632)  time: 0.6322  data: 0.0001  max mem: 8740
Epoch: [1]  [1680/2001]  eta: 0:03:23  lr: 0.000623  loss: 3.3434 (3.1633)  time: 0.6316  data: 0.0001  max mem: 8740
Epoch: [1]  [1690/2001]  eta: 0:03:17  lr: 0.000623  loss: 3.2935 (3.1639)  time: 0.6310  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0598, ratio_loss=0.1048, cls_kl=0.0895, token_kl=0.0972
Epoch: [1]  [1700/2001]  eta: 0:03:11  lr: 0.000623  loss: 3.2458 (3.1630)  time: 0.6332  data: 0.0001  max mem: 8740
Epoch: [1]  [1710/2001]  eta: 0:03:04  lr: 0.000623  loss: 3.1054 (3.1620)  time: 0.6313  data: 0.0001  max mem: 8740
Epoch: [1]  [1720/2001]  eta: 0:02:58  lr: 0.000623  loss: 3.1707 (3.1635)  time: 0.6296  data: 0.0002  max mem: 8740
Epoch: [1]  [1730/2001]  eta: 0:02:51  lr: 0.000623  loss: 3.4102 (3.1649)  time: 0.6319  data: 0.0002  max mem: 8740
Epoch: [1]  [1740/2001]  eta: 0:02:45  lr: 0.000623  loss: 3.4527 (3.1655)  time: 0.6344  data: 0.0002  max mem: 8740
Epoch: [1]  [1750/2001]  eta: 0:02:39  lr: 0.000623  loss: 3.1272 (3.1643)  time: 0.6349  data: 0.0001  max mem: 8740
Epoch: [1]  [1760/2001]  eta: 0:02:32  lr: 0.000623  loss: 3.1507 (3.1652)  time: 0.6306  data: 0.0001  max mem: 8740
Epoch: [1]  [1770/2001]  eta: 0:02:26  lr: 0.000623  loss: 3.4310 (3.1659)  time: 0.6272  data: 0.0001  max mem: 8740
Epoch: [1]  [1780/2001]  eta: 0:02:20  lr: 0.000623  loss: 3.3636 (3.1652)  time: 0.6315  data: 0.0001  max mem: 8740
Epoch: [1]  [1790/2001]  eta: 0:02:13  lr: 0.000623  loss: 3.2351 (3.1662)  time: 0.6316  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0631, ratio_loss=0.1092, cls_kl=0.0883, token_kl=0.0991
Epoch: [1]  [1800/2001]  eta: 0:02:07  lr: 0.000623  loss: 3.2865 (3.1667)  time: 0.6273  data: 0.0001  max mem: 8740
Epoch: [1]  [1810/2001]  eta: 0:02:01  lr: 0.000623  loss: 3.2599 (3.1665)  time: 0.6272  data: 0.0001  max mem: 8740
Epoch: [1]  [1820/2001]  eta: 0:01:54  lr: 0.000623  loss: 3.1966 (3.1659)  time: 0.6312  data: 0.0001  max mem: 8740
Epoch: [1]  [1830/2001]  eta: 0:01:48  lr: 0.000623  loss: 3.4747 (3.1672)  time: 0.6288  data: 0.0001  max mem: 8740
Epoch: [1]  [1840/2001]  eta: 0:01:42  lr: 0.000623  loss: 3.4627 (3.1658)  time: 0.6267  data: 0.0001  max mem: 8740
Epoch: [1]  [1850/2001]  eta: 0:01:35  lr: 0.000623  loss: 3.2796 (3.1674)  time: 0.6282  data: 0.0001  max mem: 8740
Epoch: [1]  [1860/2001]  eta: 0:01:29  lr: 0.000623  loss: 3.3802 (3.1664)  time: 0.6254  data: 0.0001  max mem: 8740
Epoch: [1]  [1870/2001]  eta: 0:01:23  lr: 0.000623  loss: 3.3200 (3.1665)  time: 0.6250  data: 0.0001  max mem: 8740
Epoch: [1]  [1880/2001]  eta: 0:01:16  lr: 0.000623  loss: 3.2766 (3.1654)  time: 0.6249  data: 0.0001  max mem: 8740
Epoch: [1]  [1890/2001]  eta: 0:01:10  lr: 0.000623  loss: 3.0727 (3.1648)  time: 0.6269  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9610, ratio_loss=0.1037, cls_kl=0.0846, token_kl=0.0974
Epoch: [1]  [1900/2001]  eta: 0:01:04  lr: 0.000623  loss: 3.0727 (3.1639)  time: 0.6317  data: 0.0001  max mem: 8740
Epoch: [1]  [1910/2001]  eta: 0:00:57  lr: 0.000623  loss: 3.1375 (3.1645)  time: 0.6323  data: 0.0001  max mem: 8740
Epoch: [1]  [1920/2001]  eta: 0:00:51  lr: 0.000623  loss: 3.2983 (3.1647)  time: 0.6280  data: 0.0001  max mem: 8740
Epoch: [1]  [1930/2001]  eta: 0:00:45  lr: 0.000623  loss: 3.3406 (3.1638)  time: 0.6239  data: 0.0002  max mem: 8740
Epoch: [1]  [1940/2001]  eta: 0:00:38  lr: 0.000623  loss: 2.9694 (3.1627)  time: 0.6228  data: 0.0001  max mem: 8740
Epoch: [1]  [1950/2001]  eta: 0:00:32  lr: 0.000623  loss: 3.0266 (3.1618)  time: 0.6237  data: 0.0001  max mem: 8740
Epoch: [1]  [1960/2001]  eta: 0:00:25  lr: 0.000623  loss: 3.2306 (3.1623)  time: 0.6249  data: 0.0001  max mem: 8740
Epoch: [1]  [1970/2001]  eta: 0:00:19  lr: 0.000623  loss: 3.3457 (3.1631)  time: 0.6250  data: 0.0001  max mem: 8740
Epoch: [1]  [1980/2001]  eta: 0:00:13  lr: 0.000623  loss: 3.2752 (3.1631)  time: 0.6248  data: 0.0001  max mem: 8740
Epoch: [1]  [1990/2001]  eta: 0:00:06  lr: 0.000623  loss: 3.2722 (3.1632)  time: 0.6199  data: 0.0004  max mem: 8740
loss info: cls_loss=2.9590, ratio_loss=0.1063, cls_kl=0.0867, token_kl=0.1007
Epoch: [1]  [2000/2001]  eta: 0:00:00  lr: 0.000623  loss: 3.3073 (3.1626)  time: 0.6184  data: 0.0003  max mem: 8740
Epoch: [1] Total time: 0:21:08 (0.6338 s / it)
Averaged stats: lr: 0.000623  loss: 3.3073 (3.1522)
Test:  [ 0/53]  eta: 0:04:39  loss: 0.3956 (0.3956)  acc1: 92.5000 (92.5000)  acc5: 99.1667 (99.1667)  time: 5.2643  data: 4.3993  max mem: 8740
Test:  [10/53]  eta: 0:00:33  loss: 0.7679 (0.8038)  acc1: 81.6667 (82.3485)  acc5: 96.6667 (96.2121)  time: 0.7724  data: 0.4001  max mem: 8740
Test:  [20/53]  eta: 0:00:18  loss: 0.7679 (0.8029)  acc1: 81.6667 (82.3413)  acc5: 95.8333 (96.1905)  time: 0.3382  data: 0.0005  max mem: 8740
Test:  [30/53]  eta: 0:00:11  loss: 0.8935 (0.8828)  acc1: 78.3333 (80.5914)  acc5: 94.1667 (95.1075)  time: 0.3578  data: 0.0005  max mem: 8740
Test:  [40/53]  eta: 0:00:05  loss: 1.1362 (0.9547)  acc1: 74.1667 (78.6789)  acc5: 92.5000 (94.3902)  time: 0.3210  data: 0.0002  max mem: 8740
Test:  [50/53]  eta: 0:00:01  loss: 1.1362 (0.9829)  acc1: 74.1667 (77.8431)  acc5: 92.5000 (94.2811)  time: 0.2689  data: 0.0001  max mem: 8740
Test:  [52/53]  eta: 0:00:00  loss: 1.1114 (0.9668)  acc1: 74.1667 (78.0160)  acc5: 93.3333 (94.3680)  time: 0.2534  data: 0.0001  max mem: 8740
Test: Total time: 0:00:21 (0.4051 s / it)
Sparsity0:0.24086868686868687,Sparsity1:0.49415396984924626,Sparsity2:0.7087576,
* Acc@1 78.634 Acc@5 94.376 loss 0.971
Accuracy of the network on the 50000 test images: 78.6%
Max accuracy: 78.63%
## Using lr  0.0000000 for BACKBONE, cosine lr = 0.0006183 for PREDICTOR
Epoch: [2]  [   0/2001]  eta: 2:33:31  lr: 0.000618  loss: 2.2602 (2.2602)  time: 4.6035  data: 3.9851  max mem: 8740
Epoch: [2]  [  10/2001]  eta: 0:32:09  lr: 0.000618  loss: 3.0426 (3.0080)  time: 0.9692  data: 0.3624  max mem: 8740
Epoch: [2]  [  20/2001]  eta: 0:26:19  lr: 0.000618  loss: 3.1839 (3.1376)  time: 0.6070  data: 0.0001  max mem: 8740
Epoch: [2]  [  30/2001]  eta: 0:24:11  lr: 0.000618  loss: 3.1791 (3.1118)  time: 0.6085  data: 0.0001  max mem: 8740
Epoch: [2]  [  40/2001]  eta: 0:23:08  lr: 0.000618  loss: 3.3716 (3.1670)  time: 0.6145  data: 0.0001  max mem: 8740
Epoch: [2]  [  50/2001]  eta: 0:22:27  lr: 0.000618  loss: 3.4099 (3.2170)  time: 0.6193  data: 0.0001  max mem: 8740
Epoch: [2]  [  60/2001]  eta: 0:21:56  lr: 0.000618  loss: 3.4266 (3.2390)  time: 0.6171  data: 0.0001  max mem: 8740
Epoch: [2]  [  70/2001]  eta: 0:21:34  lr: 0.000618  loss: 3.1300 (3.1798)  time: 0.6185  data: 0.0001  max mem: 8740
Epoch: [2]  [  80/2001]  eta: 0:21:16  lr: 0.000618  loss: 2.7741 (3.1464)  time: 0.6226  data: 0.0001  max mem: 8740
Epoch: [2]  [  90/2001]  eta: 0:21:01  lr: 0.000618  loss: 3.0326 (3.1395)  time: 0.6246  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9722, ratio_loss=0.1039, cls_kl=0.0909, token_kl=0.0994
Epoch: [2]  [ 100/2001]  eta: 0:20:48  lr: 0.000618  loss: 3.0339 (3.1098)  time: 0.6258  data: 0.0001  max mem: 8740
Epoch: [2]  [ 110/2001]  eta: 0:20:36  lr: 0.000618  loss: 3.1101 (3.1127)  time: 0.6251  data: 0.0001  max mem: 8740
Epoch: [2]  [ 120/2001]  eta: 0:20:25  lr: 0.000618  loss: 3.0728 (3.1050)  time: 0.6252  data: 0.0001  max mem: 8740
Epoch: [2]  [ 130/2001]  eta: 0:20:15  lr: 0.000618  loss: 3.1972 (3.1137)  time: 0.6268  data: 0.0001  max mem: 8740
Epoch: [2]  [ 140/2001]  eta: 0:20:06  lr: 0.000618  loss: 3.2142 (3.1144)  time: 0.6267  data: 0.0001  max mem: 8740
Epoch: [2]  [ 150/2001]  eta: 0:19:57  lr: 0.000618  loss: 3.1623 (3.1130)  time: 0.6277  data: 0.0001  max mem: 8740
Epoch: [2]  [ 160/2001]  eta: 0:19:49  lr: 0.000618  loss: 3.1267 (3.1082)  time: 0.6312  data: 0.0001  max mem: 8740
Epoch: [2]  [ 170/2001]  eta: 0:19:41  lr: 0.000618  loss: 3.2654 (3.1197)  time: 0.6324  data: 0.0001  max mem: 8740
Epoch: [2]  [ 180/2001]  eta: 0:19:33  lr: 0.000618  loss: 3.2574 (3.1252)  time: 0.6298  data: 0.0001  max mem: 8740
Epoch: [2]  [ 190/2001]  eta: 0:19:25  lr: 0.000618  loss: 3.2347 (3.1228)  time: 0.6276  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9483, ratio_loss=0.1063, cls_kl=0.0863, token_kl=0.0993
Epoch: [2]  [ 200/2001]  eta: 0:19:17  lr: 0.000618  loss: 3.3220 (3.1250)  time: 0.6293  data: 0.0001  max mem: 8740
Epoch: [2]  [ 210/2001]  eta: 0:19:10  lr: 0.000618  loss: 3.2052 (3.1257)  time: 0.6344  data: 0.0001  max mem: 8740
Epoch: [2]  [ 220/2001]  eta: 0:19:03  lr: 0.000618  loss: 3.2994 (3.1351)  time: 0.6334  data: 0.0001  max mem: 8740
Epoch: [2]  [ 230/2001]  eta: 0:18:56  lr: 0.000618  loss: 3.2994 (3.1195)  time: 0.6323  data: 0.0001  max mem: 8740
Epoch: [2]  [ 240/2001]  eta: 0:18:48  lr: 0.000618  loss: 3.1174 (3.1237)  time: 0.6326  data: 0.0001  max mem: 8740
Epoch: [2]  [ 250/2001]  eta: 0:18:42  lr: 0.000618  loss: 3.2182 (3.1262)  time: 0.6333  data: 0.0001  max mem: 8740
Epoch: [2]  [ 260/2001]  eta: 0:18:34  lr: 0.000618  loss: 3.2143 (3.1254)  time: 0.6313  data: 0.0001  max mem: 8740
Epoch: [2]  [ 270/2001]  eta: 0:18:27  lr: 0.000618  loss: 3.0315 (3.1184)  time: 0.6271  data: 0.0001  max mem: 8740
Epoch: [2]  [ 280/2001]  eta: 0:18:20  lr: 0.000618  loss: 3.0933 (3.1180)  time: 0.6272  data: 0.0001  max mem: 8740
Epoch: [2]  [ 290/2001]  eta: 0:18:13  lr: 0.000618  loss: 3.1076 (3.1204)  time: 0.6268  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9659, ratio_loss=0.1016, cls_kl=0.0868, token_kl=0.0972
Epoch: [2]  [ 300/2001]  eta: 0:18:06  lr: 0.000618  loss: 2.9708 (3.1160)  time: 0.6277  data: 0.0001  max mem: 8740
Epoch: [2]  [ 310/2001]  eta: 0:17:59  lr: 0.000618  loss: 3.3374 (3.1280)  time: 0.6292  data: 0.0001  max mem: 8740
Epoch: [2]  [ 320/2001]  eta: 0:17:52  lr: 0.000618  loss: 3.3758 (3.1308)  time: 0.6285  data: 0.0001  max mem: 8740
Epoch: [2]  [ 330/2001]  eta: 0:17:45  lr: 0.000618  loss: 3.3221 (3.1313)  time: 0.6266  data: 0.0001  max mem: 8740
Epoch: [2]  [ 340/2001]  eta: 0:17:38  lr: 0.000618  loss: 3.1982 (3.1276)  time: 0.6290  data: 0.0001  max mem: 8740
Epoch: [2]  [ 350/2001]  eta: 0:17:32  lr: 0.000618  loss: 3.2861 (3.1269)  time: 0.6322  data: 0.0001  max mem: 8740
Epoch: [2]  [ 360/2001]  eta: 0:17:25  lr: 0.000618  loss: 3.2861 (3.1277)  time: 0.6360  data: 0.0001  max mem: 8740
Epoch: [2]  [ 370/2001]  eta: 0:17:19  lr: 0.000618  loss: 3.4250 (3.1355)  time: 0.6392  data: 0.0001  max mem: 8740
Epoch: [2]  [ 380/2001]  eta: 0:17:13  lr: 0.000618  loss: 3.4111 (3.1323)  time: 0.6364  data: 0.0001  max mem: 8740
Epoch: [2]  [ 390/2001]  eta: 0:17:06  lr: 0.000618  loss: 3.2263 (3.1355)  time: 0.6339  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0205, ratio_loss=0.1036, cls_kl=0.0872, token_kl=0.0972
Epoch: [2]  [ 400/2001]  eta: 0:16:59  lr: 0.000618  loss: 3.3378 (3.1395)  time: 0.6317  data: 0.0001  max mem: 8740
Epoch: [2]  [ 410/2001]  eta: 0:16:53  lr: 0.000618  loss: 3.3658 (3.1434)  time: 0.6353  data: 0.0001  max mem: 8740
Epoch: [2]  [ 420/2001]  eta: 0:16:47  lr: 0.000618  loss: 3.3234 (3.1466)  time: 0.6415  data: 0.0001  max mem: 8740
Epoch: [2]  [ 430/2001]  eta: 0:16:40  lr: 0.000618  loss: 3.1990 (3.1414)  time: 0.6356  data: 0.0001  max mem: 8740
Epoch: [2]  [ 440/2001]  eta: 0:16:34  lr: 0.000618  loss: 3.2109 (3.1442)  time: 0.6311  data: 0.0001  max mem: 8740
Epoch: [2]  [ 450/2001]  eta: 0:16:27  lr: 0.000618  loss: 3.4352 (3.1449)  time: 0.6314  data: 0.0001  max mem: 8740
Epoch: [2]  [ 460/2001]  eta: 0:16:21  lr: 0.000618  loss: 3.2057 (3.1421)  time: 0.6346  data: 0.0001  max mem: 8740
Epoch: [2]  [ 470/2001]  eta: 0:16:14  lr: 0.000618  loss: 3.5116 (3.1517)  time: 0.6338  data: 0.0001  max mem: 8740
Epoch: [2]  [ 480/2001]  eta: 0:16:08  lr: 0.000618  loss: 3.5776 (3.1518)  time: 0.6282  data: 0.0001  max mem: 8740
Epoch: [2]  [ 490/2001]  eta: 0:16:01  lr: 0.000618  loss: 3.1600 (3.1438)  time: 0.6332  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0090, ratio_loss=0.1038, cls_kl=0.0890, token_kl=0.0974
Epoch: [2]  [ 500/2001]  eta: 0:15:55  lr: 0.000618  loss: 3.1236 (3.1453)  time: 0.6365  data: 0.0001  max mem: 8740
Epoch: [2]  [ 510/2001]  eta: 0:15:48  lr: 0.000618  loss: 3.4410 (3.1506)  time: 0.6335  data: 0.0001  max mem: 8740
Epoch: [2]  [ 520/2001]  eta: 0:15:42  lr: 0.000618  loss: 3.4391 (3.1477)  time: 0.6316  data: 0.0001  max mem: 8740
Epoch: [2]  [ 530/2001]  eta: 0:15:35  lr: 0.000618  loss: 3.2036 (3.1501)  time: 0.6300  data: 0.0001  max mem: 8740
Epoch: [2]  [ 540/2001]  eta: 0:15:29  lr: 0.000618  loss: 3.3525 (3.1480)  time: 0.6300  data: 0.0001  max mem: 8740
Epoch: [2]  [ 550/2001]  eta: 0:15:22  lr: 0.000618  loss: 3.2670 (3.1488)  time: 0.6294  data: 0.0001  max mem: 8740
Epoch: [2]  [ 560/2001]  eta: 0:15:16  lr: 0.000618  loss: 3.2492 (3.1508)  time: 0.6317  data: 0.0001  max mem: 8740
Epoch: [2]  [ 570/2001]  eta: 0:15:10  lr: 0.000618  loss: 3.2492 (3.1508)  time: 0.6379  data: 0.0001  max mem: 8740
Epoch: [2]  [ 580/2001]  eta: 0:15:03  lr: 0.000618  loss: 3.3856 (3.1545)  time: 0.6360  data: 0.0001  max mem: 8740
Epoch: [2]  [ 590/2001]  eta: 0:14:57  lr: 0.000618  loss: 3.4380 (3.1546)  time: 0.6312  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0493, ratio_loss=0.1038, cls_kl=0.0891, token_kl=0.0977
Epoch: [2]  [ 600/2001]  eta: 0:14:50  lr: 0.000618  loss: 3.2492 (3.1557)  time: 0.6317  data: 0.0001  max mem: 8740
Epoch: [2]  [ 610/2001]  eta: 0:14:44  lr: 0.000618  loss: 3.1560 (3.1512)  time: 0.6328  data: 0.0001  max mem: 8740
Epoch: [2]  [ 620/2001]  eta: 0:14:38  lr: 0.000618  loss: 3.0663 (3.1511)  time: 0.6351  data: 0.0001  max mem: 8740
Epoch: [2]  [ 630/2001]  eta: 0:14:31  lr: 0.000618  loss: 3.1861 (3.1504)  time: 0.6375  data: 0.0001  max mem: 8740
Epoch: [2]  [ 640/2001]  eta: 0:14:25  lr: 0.000618  loss: 3.3882 (3.1544)  time: 0.6409  data: 0.0001  max mem: 8740
Epoch: [2]  [ 650/2001]  eta: 0:14:19  lr: 0.000618  loss: 3.3882 (3.1539)  time: 0.6395  data: 0.0001  max mem: 8740
Epoch: [2]  [ 660/2001]  eta: 0:14:12  lr: 0.000618  loss: 3.4103 (3.1585)  time: 0.6356  data: 0.0001  max mem: 8740
Epoch: [2]  [ 670/2001]  eta: 0:14:06  lr: 0.000618  loss: 3.2570 (3.1587)  time: 0.6401  data: 0.0001  max mem: 8740
Epoch: [2]  [ 680/2001]  eta: 0:14:00  lr: 0.000618  loss: 3.2349 (3.1587)  time: 0.6402  data: 0.0001  max mem: 8740
Epoch: [2]  [ 690/2001]  eta: 0:13:53  lr: 0.000618  loss: 3.3970 (3.1615)  time: 0.6351  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0533, ratio_loss=0.1100, cls_kl=0.0907, token_kl=0.1011
Epoch: [2]  [ 700/2001]  eta: 0:13:47  lr: 0.000618  loss: 3.4006 (3.1659)  time: 0.6363  data: 0.0001  max mem: 8740
Epoch: [2]  [ 710/2001]  eta: 0:13:41  lr: 0.000618  loss: 3.1527 (3.1646)  time: 0.6375  data: 0.0001  max mem: 8740
Epoch: [2]  [ 720/2001]  eta: 0:13:34  lr: 0.000618  loss: 3.1657 (3.1671)  time: 0.6370  data: 0.0001  max mem: 8740
Epoch: [2]  [ 730/2001]  eta: 0:13:28  lr: 0.000618  loss: 3.3908 (3.1636)  time: 0.6378  data: 0.0001  max mem: 8740
Epoch: [2]  [ 740/2001]  eta: 0:13:22  lr: 0.000618  loss: 3.3849 (3.1670)  time: 0.6351  data: 0.0001  max mem: 8740
Epoch: [2]  [ 750/2001]  eta: 0:13:15  lr: 0.000618  loss: 3.2083 (3.1646)  time: 0.6322  data: 0.0001  max mem: 8740
Epoch: [2]  [ 760/2001]  eta: 0:13:09  lr: 0.000618  loss: 3.1570 (3.1645)  time: 0.6370  data: 0.0001  max mem: 8740
Epoch: [2]  [ 770/2001]  eta: 0:13:03  lr: 0.000618  loss: 3.2992 (3.1622)  time: 0.6406  data: 0.0001  max mem: 8740
Epoch: [2]  [ 780/2001]  eta: 0:12:56  lr: 0.000618  loss: 3.2023 (3.1624)  time: 0.6389  data: 0.0001  max mem: 8740
Epoch: [2]  [ 790/2001]  eta: 0:12:50  lr: 0.000618  loss: 3.3264 (3.1640)  time: 0.6393  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9974, ratio_loss=0.1020, cls_kl=0.0863, token_kl=0.0956
Epoch: [2]  [ 800/2001]  eta: 0:12:44  lr: 0.000618  loss: 3.3274 (3.1646)  time: 0.6377  data: 0.0001  max mem: 8740
Epoch: [2]  [ 810/2001]  eta: 0:12:37  lr: 0.000618  loss: 3.2505 (3.1652)  time: 0.6346  data: 0.0001  max mem: 8740
Epoch: [2]  [ 820/2001]  eta: 0:12:31  lr: 0.000618  loss: 3.1453 (3.1632)  time: 0.6347  data: 0.0001  max mem: 8740
Epoch: [2]  [ 830/2001]  eta: 0:12:25  lr: 0.000618  loss: 3.2092 (3.1630)  time: 0.6427  data: 0.0001  max mem: 8740
Epoch: [2]  [ 840/2001]  eta: 0:12:18  lr: 0.000618  loss: 3.2172 (3.1643)  time: 0.6428  data: 0.0001  max mem: 8740
Epoch: [2]  [ 850/2001]  eta: 0:12:12  lr: 0.000618  loss: 3.3474 (3.1615)  time: 0.6349  data: 0.0001  max mem: 8740
Epoch: [2]  [ 860/2001]  eta: 0:12:06  lr: 0.000618  loss: 3.0027 (3.1587)  time: 0.6352  data: 0.0001  max mem: 8740
Epoch: [2]  [ 870/2001]  eta: 0:11:59  lr: 0.000618  loss: 2.9569 (3.1556)  time: 0.6363  data: 0.0001  max mem: 8740
Epoch: [2]  [ 880/2001]  eta: 0:11:53  lr: 0.000618  loss: 3.0313 (3.1566)  time: 0.6383  data: 0.0001  max mem: 8740
Epoch: [2]  [ 890/2001]  eta: 0:11:47  lr: 0.000618  loss: 3.2403 (3.1567)  time: 0.6411  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9211, ratio_loss=0.1000, cls_kl=0.0843, token_kl=0.0979
Epoch: [2]  [ 900/2001]  eta: 0:11:40  lr: 0.000618  loss: 2.9635 (3.1538)  time: 0.6400  data: 0.0001  max mem: 8740
Epoch: [2]  [ 910/2001]  eta: 0:11:34  lr: 0.000618  loss: 3.0373 (3.1539)  time: 0.6395  data: 0.0001  max mem: 8740
Epoch: [2]  [ 920/2001]  eta: 0:11:28  lr: 0.000618  loss: 3.1408 (3.1555)  time: 0.6409  data: 0.0001  max mem: 8740
Epoch: [2]  [ 930/2001]  eta: 0:11:21  lr: 0.000618  loss: 3.2004 (3.1562)  time: 0.6405  data: 0.0001  max mem: 8740
Epoch: [2]  [ 940/2001]  eta: 0:11:15  lr: 0.000618  loss: 3.3518 (3.1570)  time: 0.6386  data: 0.0001  max mem: 8740
Epoch: [2]  [ 950/2001]  eta: 0:11:09  lr: 0.000618  loss: 3.3518 (3.1567)  time: 0.6369  data: 0.0001  max mem: 8740
Epoch: [2]  [ 960/2001]  eta: 0:11:02  lr: 0.000618  loss: 3.1102 (3.1543)  time: 0.6361  data: 0.0001  max mem: 8740
Epoch: [2]  [ 970/2001]  eta: 0:10:56  lr: 0.000618  loss: 3.3239 (3.1552)  time: 0.6353  data: 0.0001  max mem: 8740
Epoch: [2]  [ 980/2001]  eta: 0:10:49  lr: 0.000618  loss: 3.4076 (3.1574)  time: 0.6343  data: 0.0001  max mem: 8740
Epoch: [2]  [ 990/2001]  eta: 0:10:43  lr: 0.000618  loss: 3.3544 (3.1591)  time: 0.6380  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0555, ratio_loss=0.1058, cls_kl=0.0894, token_kl=0.0992
Epoch: [2]  [1000/2001]  eta: 0:10:37  lr: 0.000618  loss: 3.3487 (3.1605)  time: 0.6385  data: 0.0001  max mem: 8740
Epoch: [2]  [1010/2001]  eta: 0:10:30  lr: 0.000618  loss: 3.4109 (3.1620)  time: 0.6341  data: 0.0001  max mem: 8740
Epoch: [2]  [1020/2001]  eta: 0:10:24  lr: 0.000618  loss: 3.3489 (3.1596)  time: 0.6324  data: 0.0001  max mem: 8740
Epoch: [2]  [1030/2001]  eta: 0:10:17  lr: 0.000618  loss: 2.9034 (3.1580)  time: 0.6308  data: 0.0001  max mem: 8740
Epoch: [2]  [1040/2001]  eta: 0:10:11  lr: 0.000618  loss: 3.1399 (3.1565)  time: 0.6335  data: 0.0001  max mem: 8740
Epoch: [2]  [1050/2001]  eta: 0:10:05  lr: 0.000618  loss: 3.1399 (3.1550)  time: 0.6384  data: 0.0001  max mem: 8740
Epoch: [2]  [1060/2001]  eta: 0:09:58  lr: 0.000618  loss: 3.3455 (3.1560)  time: 0.6393  data: 0.0001  max mem: 8740
Epoch: [2]  [1070/2001]  eta: 0:09:52  lr: 0.000618  loss: 3.3455 (3.1539)  time: 0.6341  data: 0.0001  max mem: 8740
Epoch: [2]  [1080/2001]  eta: 0:09:46  lr: 0.000618  loss: 3.3576 (3.1545)  time: 0.6304  data: 0.0001  max mem: 8740
Epoch: [2]  [1090/2001]  eta: 0:09:39  lr: 0.000618  loss: 3.0845 (3.1514)  time: 0.6345  data: 0.0001  max mem: 8740
loss info: cls_loss=2.8948, ratio_loss=0.1003, cls_kl=0.0841, token_kl=0.0964
Epoch: [2]  [1100/2001]  eta: 0:09:33  lr: 0.000618  loss: 3.0698 (3.1516)  time: 0.6338  data: 0.0001  max mem: 8740
Epoch: [2]  [1110/2001]  eta: 0:09:26  lr: 0.000618  loss: 3.1447 (3.1511)  time: 0.6304  data: 0.0001  max mem: 8740
Epoch: [2]  [1120/2001]  eta: 0:09:20  lr: 0.000618  loss: 2.9961 (3.1501)  time: 0.6316  data: 0.0001  max mem: 8740
Epoch: [2]  [1130/2001]  eta: 0:09:14  lr: 0.000618  loss: 3.2984 (3.1524)  time: 0.6308  data: 0.0001  max mem: 8740
Epoch: [2]  [1140/2001]  eta: 0:09:07  lr: 0.000618  loss: 3.4004 (3.1547)  time: 0.6327  data: 0.0001  max mem: 8740
Epoch: [2]  [1150/2001]  eta: 0:09:01  lr: 0.000618  loss: 3.3239 (3.1536)  time: 0.6337  data: 0.0001  max mem: 8740
Epoch: [2]  [1160/2001]  eta: 0:08:54  lr: 0.000618  loss: 3.2051 (3.1547)  time: 0.6301  data: 0.0001  max mem: 8740
Epoch: [2]  [1170/2001]  eta: 0:08:48  lr: 0.000618  loss: 3.2137 (3.1549)  time: 0.6288  data: 0.0001  max mem: 8740
Epoch: [2]  [1180/2001]  eta: 0:08:42  lr: 0.000618  loss: 3.4089 (3.1566)  time: 0.6305  data: 0.0001  max mem: 8740
Epoch: [2]  [1190/2001]  eta: 0:08:35  lr: 0.000618  loss: 3.3054 (3.1548)  time: 0.6331  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0480, ratio_loss=0.1028, cls_kl=0.0863, token_kl=0.0981
Epoch: [2]  [1200/2001]  eta: 0:08:29  lr: 0.000618  loss: 3.3175 (3.1569)  time: 0.6308  data: 0.0001  max mem: 8740
Epoch: [2]  [1210/2001]  eta: 0:08:22  lr: 0.000618  loss: 3.5235 (3.1576)  time: 0.6302  data: 0.0001  max mem: 8740
Epoch: [2]  [1220/2001]  eta: 0:08:16  lr: 0.000618  loss: 3.3820 (3.1595)  time: 0.6312  data: 0.0001  max mem: 8740
Epoch: [2]  [1230/2001]  eta: 0:08:10  lr: 0.000618  loss: 3.2526 (3.1587)  time: 0.6293  data: 0.0001  max mem: 8740
Epoch: [2]  [1240/2001]  eta: 0:08:03  lr: 0.000618  loss: 3.2526 (3.1606)  time: 0.6292  data: 0.0001  max mem: 8740
Epoch: [2]  [1250/2001]  eta: 0:07:57  lr: 0.000618  loss: 3.4869 (3.1607)  time: 0.6295  data: 0.0001  max mem: 8740
Epoch: [2]  [1260/2001]  eta: 0:07:50  lr: 0.000618  loss: 3.3560 (3.1615)  time: 0.6297  data: 0.0001  max mem: 8740
Epoch: [2]  [1270/2001]  eta: 0:07:44  lr: 0.000618  loss: 3.3563 (3.1617)  time: 0.6287  data: 0.0001  max mem: 8740
Epoch: [2]  [1280/2001]  eta: 0:07:38  lr: 0.000618  loss: 3.2344 (3.1616)  time: 0.6257  data: 0.0001  max mem: 8740
Epoch: [2]  [1290/2001]  eta: 0:07:31  lr: 0.000618  loss: 3.2535 (3.1620)  time: 0.6245  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0811, ratio_loss=0.1066, cls_kl=0.0927, token_kl=0.1007
Epoch: [2]  [1300/2001]  eta: 0:07:25  lr: 0.000618  loss: 3.2643 (3.1632)  time: 0.6267  data: 0.0001  max mem: 8740
Epoch: [2]  [1310/2001]  eta: 0:07:18  lr: 0.000618  loss: 3.2120 (3.1621)  time: 0.6263  data: 0.0001  max mem: 8740
Epoch: [2]  [1320/2001]  eta: 0:07:12  lr: 0.000618  loss: 3.1267 (3.1610)  time: 0.6275  data: 0.0001  max mem: 8740
Epoch: [2]  [1330/2001]  eta: 0:07:06  lr: 0.000618  loss: 3.1267 (3.1606)  time: 0.6337  data: 0.0002  max mem: 8740
Epoch: [2]  [1340/2001]  eta: 0:06:59  lr: 0.000618  loss: 3.1436 (3.1591)  time: 0.6321  data: 0.0002  max mem: 8740
Epoch: [2]  [1350/2001]  eta: 0:06:53  lr: 0.000618  loss: 3.3511 (3.1604)  time: 0.6266  data: 0.0001  max mem: 8740
Epoch: [2]  [1360/2001]  eta: 0:06:47  lr: 0.000618  loss: 3.2910 (3.1597)  time: 0.6255  data: 0.0001  max mem: 8740
Epoch: [2]  [1370/2001]  eta: 0:06:40  lr: 0.000618  loss: 2.9247 (3.1582)  time: 0.6235  data: 0.0001  max mem: 8740
Epoch: [2]  [1380/2001]  eta: 0:06:34  lr: 0.000618  loss: 2.9232 (3.1567)  time: 0.6215  data: 0.0001  max mem: 8740
Epoch: [2]  [1390/2001]  eta: 0:06:27  lr: 0.000618  loss: 3.0846 (3.1563)  time: 0.6235  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9428, ratio_loss=0.0991, cls_kl=0.0866, token_kl=0.0967
Epoch: [2]  [1400/2001]  eta: 0:06:21  lr: 0.000618  loss: 3.4020 (3.1584)  time: 0.6241  data: 0.0001  max mem: 8740
Epoch: [2]  [1410/2001]  eta: 0:06:15  lr: 0.000618  loss: 3.3719 (3.1593)  time: 0.6270  data: 0.0001  max mem: 8740
Epoch: [2]  [1420/2001]  eta: 0:06:08  lr: 0.000618  loss: 3.2894 (3.1573)  time: 0.6278  data: 0.0001  max mem: 8740
Epoch: [2]  [1430/2001]  eta: 0:06:02  lr: 0.000618  loss: 3.2433 (3.1576)  time: 0.6240  data: 0.0001  max mem: 8740
Epoch: [2]  [1440/2001]  eta: 0:05:55  lr: 0.000618  loss: 3.3092 (3.1573)  time: 0.6234  data: 0.0001  max mem: 8740
Epoch: [2]  [1450/2001]  eta: 0:05:49  lr: 0.000618  loss: 3.3501 (3.1581)  time: 0.6277  data: 0.0001  max mem: 8740
Epoch: [2]  [1460/2001]  eta: 0:05:43  lr: 0.000618  loss: 3.3290 (3.1578)  time: 0.6322  data: 0.0001  max mem: 8740
Epoch: [2]  [1470/2001]  eta: 0:05:36  lr: 0.000618  loss: 3.2439 (3.1582)  time: 0.6319  data: 0.0001  max mem: 8740
Epoch: [2]  [1480/2001]  eta: 0:05:30  lr: 0.000618  loss: 3.2331 (3.1590)  time: 0.6312  data: 0.0001  max mem: 8740
Epoch: [2]  [1490/2001]  eta: 0:05:24  lr: 0.000618  loss: 3.2854 (3.1587)  time: 0.6294  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9968, ratio_loss=0.0987, cls_kl=0.0858, token_kl=0.0953
Epoch: [2]  [1500/2001]  eta: 0:05:17  lr: 0.000618  loss: 3.2473 (3.1587)  time: 0.6273  data: 0.0001  max mem: 8740
Epoch: [2]  [1510/2001]  eta: 0:05:11  lr: 0.000618  loss: 3.2389 (3.1586)  time: 0.6291  data: 0.0001  max mem: 8740
Epoch: [2]  [1520/2001]  eta: 0:05:05  lr: 0.000618  loss: 3.3240 (3.1582)  time: 0.6283  data: 0.0001  max mem: 8740
Epoch: [2]  [1530/2001]  eta: 0:04:58  lr: 0.000618  loss: 3.1253 (3.1572)  time: 0.6268  data: 0.0001  max mem: 8740
Epoch: [2]  [1540/2001]  eta: 0:04:52  lr: 0.000618  loss: 2.9898 (3.1553)  time: 0.6282  data: 0.0001  max mem: 8740
Epoch: [2]  [1550/2001]  eta: 0:04:45  lr: 0.000618  loss: 3.1217 (3.1544)  time: 0.6252  data: 0.0001  max mem: 8740
Epoch: [2]  [1560/2001]  eta: 0:04:39  lr: 0.000618  loss: 3.2158 (3.1534)  time: 0.6250  data: 0.0001  max mem: 8740
Epoch: [2]  [1570/2001]  eta: 0:04:33  lr: 0.000618  loss: 3.2158 (3.1523)  time: 0.6250  data: 0.0001  max mem: 8740
Epoch: [2]  [1580/2001]  eta: 0:04:26  lr: 0.000618  loss: 3.2415 (3.1517)  time: 0.6246  data: 0.0001  max mem: 8740
Epoch: [2]  [1590/2001]  eta: 0:04:20  lr: 0.000618  loss: 3.2886 (3.1521)  time: 0.6269  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9113, ratio_loss=0.1049, cls_kl=0.0865, token_kl=0.1004
Epoch: [2]  [1600/2001]  eta: 0:04:14  lr: 0.000618  loss: 3.3740 (3.1523)  time: 0.6283  data: 0.0001  max mem: 8740
Epoch: [2]  [1610/2001]  eta: 0:04:07  lr: 0.000618  loss: 3.3026 (3.1517)  time: 0.6293  data: 0.0001  max mem: 8740
Epoch: [2]  [1620/2001]  eta: 0:04:01  lr: 0.000618  loss: 3.0844 (3.1513)  time: 0.6310  data: 0.0001  max mem: 8740
Epoch: [2]  [1630/2001]  eta: 0:03:55  lr: 0.000618  loss: 3.3664 (3.1530)  time: 0.6283  data: 0.0001  max mem: 8740
Epoch: [2]  [1640/2001]  eta: 0:03:48  lr: 0.000618  loss: 3.4710 (3.1542)  time: 0.6274  data: 0.0001  max mem: 8740
Epoch: [2]  [1650/2001]  eta: 0:03:42  lr: 0.000618  loss: 3.3876 (3.1527)  time: 0.6290  data: 0.0001  max mem: 8740
Epoch: [2]  [1660/2001]  eta: 0:03:36  lr: 0.000618  loss: 3.1242 (3.1533)  time: 0.6339  data: 0.0001  max mem: 8740
Epoch: [2]  [1670/2001]  eta: 0:03:29  lr: 0.000618  loss: 3.1242 (3.1523)  time: 0.6371  data: 0.0001  max mem: 8740
Epoch: [2]  [1680/2001]  eta: 0:03:23  lr: 0.000618  loss: 3.2194 (3.1535)  time: 0.6284  data: 0.0001  max mem: 8740
Epoch: [2]  [1690/2001]  eta: 0:03:17  lr: 0.000618  loss: 3.2889 (3.1543)  time: 0.6244  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0096, ratio_loss=0.1014, cls_kl=0.0872, token_kl=0.0973
Epoch: [2]  [1700/2001]  eta: 0:03:10  lr: 0.000618  loss: 3.3209 (3.1550)  time: 0.6253  data: 0.0001  max mem: 8740
Epoch: [2]  [1710/2001]  eta: 0:03:04  lr: 0.000618  loss: 3.3209 (3.1542)  time: 0.6268  data: 0.0001  max mem: 8740
Epoch: [2]  [1720/2001]  eta: 0:02:57  lr: 0.000618  loss: 2.9698 (3.1531)  time: 0.6271  data: 0.0001  max mem: 8740
Epoch: [2]  [1730/2001]  eta: 0:02:51  lr: 0.000618  loss: 2.8574 (3.1508)  time: 0.6253  data: 0.0001  max mem: 8740
Epoch: [2]  [1740/2001]  eta: 0:02:45  lr: 0.000618  loss: 3.0543 (3.1514)  time: 0.6316  data: 0.0001  max mem: 8740
Epoch: [2]  [1750/2001]  eta: 0:02:38  lr: 0.000618  loss: 3.3133 (3.1519)  time: 0.6341  data: 0.0001  max mem: 8740
Epoch: [2]  [1760/2001]  eta: 0:02:32  lr: 0.000618  loss: 3.3905 (3.1532)  time: 0.6302  data: 0.0001  max mem: 8740
Epoch: [2]  [1770/2001]  eta: 0:02:26  lr: 0.000618  loss: 3.3905 (3.1529)  time: 0.6297  data: 0.0001  max mem: 8740
Epoch: [2]  [1780/2001]  eta: 0:02:19  lr: 0.000618  loss: 3.0415 (3.1527)  time: 0.6272  data: 0.0001  max mem: 8740
Epoch: [2]  [1790/2001]  eta: 0:02:13  lr: 0.000618  loss: 3.2252 (3.1515)  time: 0.6261  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9512, ratio_loss=0.0998, cls_kl=0.0839, token_kl=0.0959
Epoch: [2]  [1800/2001]  eta: 0:02:07  lr: 0.000618  loss: 3.1944 (3.1514)  time: 0.6273  data: 0.0001  max mem: 8740
Epoch: [2]  [1810/2001]  eta: 0:02:00  lr: 0.000618  loss: 3.1944 (3.1513)  time: 0.6269  data: 0.0001  max mem: 8740
Epoch: [2]  [1820/2001]  eta: 0:01:54  lr: 0.000618  loss: 3.2047 (3.1515)  time: 0.6288  data: 0.0001  max mem: 8740
Epoch: [2]  [1830/2001]  eta: 0:01:48  lr: 0.000618  loss: 3.3526 (3.1523)  time: 0.6338  data: 0.0001  max mem: 8740
Epoch: [2]  [1840/2001]  eta: 0:01:41  lr: 0.000618  loss: 3.1896 (3.1521)  time: 0.6327  data: 0.0001  max mem: 8740
Epoch: [2]  [1850/2001]  eta: 0:01:35  lr: 0.000618  loss: 3.1204 (3.1518)  time: 0.6291  data: 0.0001  max mem: 8740
Epoch: [2]  [1860/2001]  eta: 0:01:29  lr: 0.000618  loss: 3.3910 (3.1531)  time: 0.6314  data: 0.0001  max mem: 8740
Epoch: [2]  [1870/2001]  eta: 0:01:22  lr: 0.000618  loss: 3.5483 (3.1555)  time: 0.6347  data: 0.0001  max mem: 8740
Epoch: [2]  [1880/2001]  eta: 0:01:16  lr: 0.000618  loss: 3.5144 (3.1562)  time: 0.6341  data: 0.0001  max mem: 8740
Epoch: [2]  [1890/2001]  eta: 0:01:10  lr: 0.000618  loss: 3.4023 (3.1567)  time: 0.6344  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0429, ratio_loss=0.1067, cls_kl=0.0902, token_kl=0.0975
Epoch: [2]  [1900/2001]  eta: 0:01:03  lr: 0.000618  loss: 3.0961 (3.1549)  time: 0.6348  data: 0.0001  max mem: 8740
Epoch: [2]  [1910/2001]  eta: 0:00:57  lr: 0.000618  loss: 3.0961 (3.1556)  time: 0.6328  data: 0.0001  max mem: 8740
Epoch: [2]  [1920/2001]  eta: 0:00:51  lr: 0.000618  loss: 3.3152 (3.1561)  time: 0.6359  data: 0.0001  max mem: 8740
Epoch: [2]  [1930/2001]  eta: 0:00:44  lr: 0.000618  loss: 3.4667 (3.1565)  time: 0.6396  data: 0.0001  max mem: 8740
Epoch: [2]  [1940/2001]  eta: 0:00:38  lr: 0.000618  loss: 3.4658 (3.1580)  time: 0.6344  data: 0.0001  max mem: 8740
Epoch: [2]  [1950/2001]  eta: 0:00:32  lr: 0.000618  loss: 3.3994 (3.1579)  time: 0.6321  data: 0.0001  max mem: 8740
Epoch: [2]  [1960/2001]  eta: 0:00:25  lr: 0.000618  loss: 3.1415 (3.1573)  time: 0.6332  data: 0.0001  max mem: 8740
Epoch: [2]  [1970/2001]  eta: 0:00:19  lr: 0.000618  loss: 3.2990 (3.1584)  time: 0.6329  data: 0.0001  max mem: 8740
Epoch: [2]  [1980/2001]  eta: 0:00:13  lr: 0.000618  loss: 3.3214 (3.1589)  time: 0.6339  data: 0.0001  max mem: 8740
Epoch: [2]  [1990/2001]  eta: 0:00:06  lr: 0.000618  loss: 3.2381 (3.1589)  time: 0.6302  data: 0.0002  max mem: 8740
loss info: cls_loss=3.0833, ratio_loss=0.1043, cls_kl=0.0893, token_kl=0.0979
Epoch: [2]  [2000/2001]  eta: 0:00:00  lr: 0.000618  loss: 3.2212 (3.1592)  time: 0.6255  data: 0.0002  max mem: 8740
Epoch: [2] Total time: 0:21:07 (0.6334 s / it)
Averaged stats: lr: 0.000618  loss: 3.2212 (3.1573)
Test:  [ 0/53]  eta: 0:05:29  loss: 0.3704 (0.3704)  acc1: 94.1667 (94.1667)  acc5: 100.0000 (100.0000)  time: 6.2201  data: 5.7025  max mem: 8740
Test:  [10/53]  eta: 0:00:38  loss: 0.7984 (0.8040)  acc1: 82.5000 (82.2727)  acc5: 96.6667 (96.7424)  time: 0.8901  data: 0.5186  max mem: 8740
Test:  [20/53]  eta: 0:00:20  loss: 0.7858 (0.8008)  acc1: 83.3333 (82.6191)  acc5: 95.8333 (96.5476)  time: 0.3533  data: 0.0027  max mem: 8740
Test:  [30/53]  eta: 0:00:12  loss: 0.9436 (0.8896)  acc1: 78.3333 (80.5645)  acc5: 94.1667 (95.1344)  time: 0.3391  data: 0.0027  max mem: 8740
Test:  [40/53]  eta: 0:00:06  loss: 1.1343 (0.9554)  acc1: 75.0000 (78.7398)  acc5: 91.6667 (94.3089)  time: 0.2968  data: 0.0002  max mem: 8740
Test:  [50/53]  eta: 0:00:01  loss: 1.1610 (0.9861)  acc1: 75.0000 (78.0065)  acc5: 91.6667 (94.0850)  time: 0.2601  data: 0.0001  max mem: 8740
Test:  [52/53]  eta: 0:00:00  loss: 1.1277 (0.9697)  acc1: 75.0000 (78.1920)  acc5: 92.5000 (94.1760)  time: 0.2494  data: 0.0000  max mem: 8740
Test: Total time: 0:00:22 (0.4189 s / it)
Sparsity0:0.23437252525252525,Sparsity1:0.4782793969849246,Sparsity2:0.7098872,
* Acc@1 78.698 Acc@5 94.464 loss 0.964
Accuracy of the network on the 50000 test images: 78.7%
Max accuracy: 78.70%
## Using lr  0.0000000 for BACKBONE, cosine lr = 0.0006099 for PREDICTOR
Epoch: [3]  [   0/2001]  eta: 2:34:08  lr: 0.000610  loss: 2.9701 (2.9701)  time: 4.6217  data: 3.9661  max mem: 8740
Epoch: [3]  [  10/2001]  eta: 0:32:18  lr: 0.000610  loss: 3.4291 (3.3595)  time: 0.9734  data: 0.3607  max mem: 8740
Epoch: [3]  [  20/2001]  eta: 0:26:32  lr: 0.000610  loss: 3.3705 (3.2506)  time: 0.6132  data: 0.0001  max mem: 8740
Epoch: [3]  [  30/2001]  eta: 0:24:28  lr: 0.000610  loss: 3.0344 (3.1184)  time: 0.6197  data: 0.0001  max mem: 8740
Epoch: [3]  [  40/2001]  eta: 0:23:23  lr: 0.000610  loss: 2.8920 (3.0994)  time: 0.6232  data: 0.0001  max mem: 8740
Epoch: [3]  [  50/2001]  eta: 0:22:41  lr: 0.000610  loss: 3.1742 (3.1093)  time: 0.6251  data: 0.0001  max mem: 8740
Epoch: [3]  [  60/2001]  eta: 0:22:12  lr: 0.000610  loss: 3.2407 (3.1187)  time: 0.6269  data: 0.0001  max mem: 8740
Epoch: [3]  [  70/2001]  eta: 0:21:50  lr: 0.000610  loss: 3.1972 (3.1525)  time: 0.6295  data: 0.0001  max mem: 8740
Epoch: [3]  [  80/2001]  eta: 0:21:32  lr: 0.000610  loss: 3.3828 (3.1681)  time: 0.6298  data: 0.0001  max mem: 8740
Epoch: [3]  [  90/2001]  eta: 0:21:17  lr: 0.000610  loss: 3.3828 (3.1667)  time: 0.6320  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0040, ratio_loss=0.1056, cls_kl=0.0858, token_kl=0.0985
Epoch: [3]  [ 100/2001]  eta: 0:21:04  lr: 0.000610  loss: 3.2462 (3.1693)  time: 0.6343  data: 0.0001  max mem: 8740
Epoch: [3]  [ 110/2001]  eta: 0:20:52  lr: 0.000610  loss: 2.7458 (3.1378)  time: 0.6347  data: 0.0001  max mem: 8740
Epoch: [3]  [ 120/2001]  eta: 0:20:42  lr: 0.000610  loss: 3.0122 (3.1489)  time: 0.6392  data: 0.0001  max mem: 8740
Epoch: [3]  [ 130/2001]  eta: 0:20:32  lr: 0.000610  loss: 3.3543 (3.1540)  time: 0.6397  data: 0.0001  max mem: 8740
Epoch: [3]  [ 140/2001]  eta: 0:20:22  lr: 0.000610  loss: 2.9848 (3.1300)  time: 0.6351  data: 0.0001  max mem: 8740
Epoch: [3]  [ 150/2001]  eta: 0:20:14  lr: 0.000610  loss: 2.8916 (3.1259)  time: 0.6362  data: 0.0001  max mem: 8740
Epoch: [3]  [ 160/2001]  eta: 0:20:06  lr: 0.000610  loss: 3.1099 (3.1283)  time: 0.6412  data: 0.0001  max mem: 8740
Epoch: [3]  [ 170/2001]  eta: 0:19:57  lr: 0.000610  loss: 3.3640 (3.1448)  time: 0.6401  data: 0.0001  max mem: 8740
Epoch: [3]  [ 180/2001]  eta: 0:19:49  lr: 0.000610  loss: 3.2391 (3.1393)  time: 0.6361  data: 0.0001  max mem: 8740
Epoch: [3]  [ 190/2001]  eta: 0:19:41  lr: 0.000610  loss: 3.2341 (3.1446)  time: 0.6357  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9814, ratio_loss=0.1019, cls_kl=0.0851, token_kl=0.0960
Epoch: [3]  [ 200/2001]  eta: 0:19:33  lr: 0.000610  loss: 3.3724 (3.1560)  time: 0.6356  data: 0.0001  max mem: 8740
Epoch: [3]  [ 210/2001]  eta: 0:19:25  lr: 0.000610  loss: 2.9590 (3.1392)  time: 0.6395  data: 0.0001  max mem: 8740
Epoch: [3]  [ 220/2001]  eta: 0:19:18  lr: 0.000610  loss: 2.9441 (3.1395)  time: 0.6414  data: 0.0001  max mem: 8740
Epoch: [3]  [ 230/2001]  eta: 0:19:11  lr: 0.000610  loss: 3.1245 (3.1304)  time: 0.6406  data: 0.0001  max mem: 8740
Epoch: [3]  [ 240/2001]  eta: 0:19:03  lr: 0.000610  loss: 3.2664 (3.1395)  time: 0.6390  data: 0.0001  max mem: 8740
Epoch: [3]  [ 250/2001]  eta: 0:18:56  lr: 0.000610  loss: 3.4661 (3.1499)  time: 0.6368  data: 0.0001  max mem: 8740
Epoch: [3]  [ 260/2001]  eta: 0:18:49  lr: 0.000610  loss: 3.4180 (3.1540)  time: 0.6369  data: 0.0001  max mem: 8740
Epoch: [3]  [ 270/2001]  eta: 0:18:41  lr: 0.000610  loss: 3.3073 (3.1603)  time: 0.6361  data: 0.0001  max mem: 8740
Epoch: [3]  [ 280/2001]  eta: 0:18:34  lr: 0.000610  loss: 3.4377 (3.1595)  time: 0.6366  data: 0.0001  max mem: 8740
Epoch: [3]  [ 290/2001]  eta: 0:18:27  lr: 0.000610  loss: 3.3158 (3.1643)  time: 0.6360  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0368, ratio_loss=0.1022, cls_kl=0.0878, token_kl=0.0983
Epoch: [3]  [ 300/2001]  eta: 0:18:20  lr: 0.000610  loss: 3.2747 (3.1694)  time: 0.6354  data: 0.0001  max mem: 8740
Epoch: [3]  [ 310/2001]  eta: 0:18:13  lr: 0.000610  loss: 3.4871 (3.1794)  time: 0.6360  data: 0.0001  max mem: 8740
Epoch: [3]  [ 320/2001]  eta: 0:18:06  lr: 0.000610  loss: 3.5459 (3.1826)  time: 0.6375  data: 0.0001  max mem: 8740
Epoch: [3]  [ 330/2001]  eta: 0:17:59  lr: 0.000610  loss: 3.2372 (3.1793)  time: 0.6380  data: 0.0001  max mem: 8740
Epoch: [3]  [ 340/2001]  eta: 0:17:52  lr: 0.000610  loss: 3.3221 (3.1830)  time: 0.6364  data: 0.0001  max mem: 8740
Epoch: [3]  [ 350/2001]  eta: 0:17:45  lr: 0.000610  loss: 3.4339 (3.1796)  time: 0.6396  data: 0.0001  max mem: 8740
Epoch: [3]  [ 360/2001]  eta: 0:17:39  lr: 0.000610  loss: 3.4009 (3.1822)  time: 0.6454  data: 0.0001  max mem: 8740
Epoch: [3]  [ 370/2001]  eta: 0:17:32  lr: 0.000610  loss: 3.4068 (3.1858)  time: 0.6411  data: 0.0001  max mem: 8740
Epoch: [3]  [ 380/2001]  eta: 0:17:26  lr: 0.000610  loss: 3.3418 (3.1889)  time: 0.6393  data: 0.0001  max mem: 8740
Epoch: [3]  [ 390/2001]  eta: 0:17:19  lr: 0.000610  loss: 3.3191 (3.1909)  time: 0.6427  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0957, ratio_loss=0.1068, cls_kl=0.0897, token_kl=0.1009
Epoch: [3]  [ 400/2001]  eta: 0:17:13  lr: 0.000610  loss: 3.2348 (3.1896)  time: 0.6433  data: 0.0001  max mem: 8740
Epoch: [3]  [ 410/2001]  eta: 0:17:06  lr: 0.000610  loss: 3.1954 (3.1861)  time: 0.6457  data: 0.0001  max mem: 8740
Epoch: [3]  [ 420/2001]  eta: 0:16:59  lr: 0.000610  loss: 3.2288 (3.1898)  time: 0.6392  data: 0.0001  max mem: 8740
Epoch: [3]  [ 430/2001]  eta: 0:16:52  lr: 0.000610  loss: 3.1412 (3.1839)  time: 0.6339  data: 0.0001  max mem: 8740
Epoch: [3]  [ 440/2001]  eta: 0:16:45  lr: 0.000610  loss: 3.1813 (3.1840)  time: 0.6343  data: 0.0001  max mem: 8740
Epoch: [3]  [ 450/2001]  eta: 0:16:39  lr: 0.000610  loss: 3.3950 (3.1832)  time: 0.6337  data: 0.0001  max mem: 8740
Epoch: [3]  [ 460/2001]  eta: 0:16:32  lr: 0.000610  loss: 3.2161 (3.1768)  time: 0.6335  data: 0.0001  max mem: 8740
Epoch: [3]  [ 470/2001]  eta: 0:16:25  lr: 0.000610  loss: 2.7953 (3.1697)  time: 0.6317  data: 0.0001  max mem: 8740
Epoch: [3]  [ 480/2001]  eta: 0:16:18  lr: 0.000610  loss: 3.0103 (3.1675)  time: 0.6320  data: 0.0001  max mem: 8740
Epoch: [3]  [ 490/2001]  eta: 0:16:12  lr: 0.000610  loss: 3.2637 (3.1676)  time: 0.6340  data: 0.0001  max mem: 8740
loss info: cls_loss=2.8920, ratio_loss=0.0983, cls_kl=0.0819, token_kl=0.0962
Epoch: [3]  [ 500/2001]  eta: 0:16:05  lr: 0.000610  loss: 3.2637 (3.1635)  time: 0.6334  data: 0.0001  max mem: 8740
Epoch: [3]  [ 510/2001]  eta: 0:15:58  lr: 0.000610  loss: 3.2650 (3.1655)  time: 0.6313  data: 0.0001  max mem: 8740
Epoch: [3]  [ 520/2001]  eta: 0:15:51  lr: 0.000610  loss: 3.2910 (3.1618)  time: 0.6330  data: 0.0001  max mem: 8740
Epoch: [3]  [ 530/2001]  eta: 0:15:44  lr: 0.000610  loss: 3.0198 (3.1603)  time: 0.6314  data: 0.0001  max mem: 8740
Epoch: [3]  [ 540/2001]  eta: 0:15:38  lr: 0.000610  loss: 3.2514 (3.1643)  time: 0.6387  data: 0.0001  max mem: 8740
Epoch: [3]  [ 550/2001]  eta: 0:15:32  lr: 0.000610  loss: 3.3617 (3.1657)  time: 0.6416  data: 0.0001  max mem: 8740
Epoch: [3]  [ 560/2001]  eta: 0:15:25  lr: 0.000610  loss: 3.0717 (3.1626)  time: 0.6394  data: 0.0001  max mem: 8740
Epoch: [3]  [ 570/2001]  eta: 0:15:18  lr: 0.000610  loss: 3.1110 (3.1662)  time: 0.6364  data: 0.0001  max mem: 8740
Epoch: [3]  [ 580/2001]  eta: 0:15:12  lr: 0.000610  loss: 3.2830 (3.1614)  time: 0.6284  data: 0.0001  max mem: 8740
Epoch: [3]  [ 590/2001]  eta: 0:15:05  lr: 0.000610  loss: 3.2543 (3.1643)  time: 0.6277  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0216, ratio_loss=0.1054, cls_kl=0.0877, token_kl=0.0994
Epoch: [3]  [ 600/2001]  eta: 0:14:58  lr: 0.000610  loss: 3.2386 (3.1624)  time: 0.6279  data: 0.0001  max mem: 8740
Epoch: [3]  [ 610/2001]  eta: 0:14:52  lr: 0.000610  loss: 3.1901 (3.1604)  time: 0.6288  data: 0.0001  max mem: 8740
Epoch: [3]  [ 620/2001]  eta: 0:14:45  lr: 0.000610  loss: 3.1922 (3.1616)  time: 0.6304  data: 0.0001  max mem: 8740
Epoch: [3]  [ 630/2001]  eta: 0:14:38  lr: 0.000610  loss: 3.3150 (3.1604)  time: 0.6289  data: 0.0001  max mem: 8740
Epoch: [3]  [ 640/2001]  eta: 0:14:32  lr: 0.000610  loss: 3.3150 (3.1639)  time: 0.6287  data: 0.0001  max mem: 8740
Epoch: [3]  [ 650/2001]  eta: 0:14:25  lr: 0.000610  loss: 3.1889 (3.1631)  time: 0.6312  data: 0.0001  max mem: 8740
Epoch: [3]  [ 660/2001]  eta: 0:14:18  lr: 0.000610  loss: 3.0622 (3.1602)  time: 0.6278  data: 0.0001  max mem: 8740
Epoch: [3]  [ 670/2001]  eta: 0:14:12  lr: 0.000610  loss: 3.0699 (3.1592)  time: 0.6270  data: 0.0001  max mem: 8740
Epoch: [3]  [ 680/2001]  eta: 0:14:05  lr: 0.000610  loss: 3.0418 (3.1569)  time: 0.6288  data: 0.0001  max mem: 8740
Epoch: [3]  [ 690/2001]  eta: 0:13:58  lr: 0.000610  loss: 2.9368 (3.1539)  time: 0.6290  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9461, ratio_loss=0.0999, cls_kl=0.0850, token_kl=0.0963
Epoch: [3]  [ 700/2001]  eta: 0:13:52  lr: 0.000610  loss: 3.1559 (3.1566)  time: 0.6260  data: 0.0001  max mem: 8740
Epoch: [3]  [ 710/2001]  eta: 0:13:45  lr: 0.000610  loss: 3.4078 (3.1594)  time: 0.6236  data: 0.0001  max mem: 8740
Epoch: [3]  [ 720/2001]  eta: 0:13:38  lr: 0.000610  loss: 3.4361 (3.1648)  time: 0.6243  data: 0.0001  max mem: 8740
Epoch: [3]  [ 730/2001]  eta: 0:13:32  lr: 0.000610  loss: 3.4741 (3.1668)  time: 0.6232  data: 0.0001  max mem: 8740
Epoch: [3]  [ 740/2001]  eta: 0:13:25  lr: 0.000610  loss: 3.1997 (3.1631)  time: 0.6228  data: 0.0001  max mem: 8740
Epoch: [3]  [ 750/2001]  eta: 0:13:18  lr: 0.000610  loss: 2.8328 (3.1607)  time: 0.6232  data: 0.0001  max mem: 8740
Epoch: [3]  [ 760/2001]  eta: 0:13:12  lr: 0.000610  loss: 3.0085 (3.1605)  time: 0.6246  data: 0.0001  max mem: 8740
Epoch: [3]  [ 770/2001]  eta: 0:13:05  lr: 0.000610  loss: 3.1558 (3.1596)  time: 0.6268  data: 0.0001  max mem: 8740
Epoch: [3]  [ 780/2001]  eta: 0:12:59  lr: 0.000610  loss: 3.3099 (3.1596)  time: 0.6267  data: 0.0001  max mem: 8740
Epoch: [3]  [ 790/2001]  eta: 0:12:52  lr: 0.000610  loss: 3.3756 (3.1627)  time: 0.6269  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0360, ratio_loss=0.0982, cls_kl=0.0881, token_kl=0.0966
Epoch: [3]  [ 800/2001]  eta: 0:12:46  lr: 0.000610  loss: 3.2881 (3.1602)  time: 0.6343  data: 0.0001  max mem: 8740
Epoch: [3]  [ 810/2001]  eta: 0:12:39  lr: 0.000610  loss: 3.2447 (3.1597)  time: 0.6356  data: 0.0001  max mem: 8740
Epoch: [3]  [ 820/2001]  eta: 0:12:33  lr: 0.000610  loss: 3.2633 (3.1604)  time: 0.6323  data: 0.0001  max mem: 8740
Epoch: [3]  [ 830/2001]  eta: 0:12:26  lr: 0.000610  loss: 3.0961 (3.1595)  time: 0.6278  data: 0.0001  max mem: 8740
Epoch: [3]  [ 840/2001]  eta: 0:12:20  lr: 0.000610  loss: 3.2048 (3.1596)  time: 0.6228  data: 0.0001  max mem: 8740
Epoch: [3]  [ 850/2001]  eta: 0:12:13  lr: 0.000610  loss: 3.0193 (3.1553)  time: 0.6251  data: 0.0001  max mem: 8740
Epoch: [3]  [ 860/2001]  eta: 0:12:07  lr: 0.000610  loss: 2.9877 (3.1537)  time: 0.6259  data: 0.0001  max mem: 8740
Epoch: [3]  [ 870/2001]  eta: 0:12:00  lr: 0.000610  loss: 3.1315 (3.1538)  time: 0.6244  data: 0.0001  max mem: 8740
Epoch: [3]  [ 880/2001]  eta: 0:11:53  lr: 0.000610  loss: 3.2483 (3.1530)  time: 0.6232  data: 0.0001  max mem: 8740
Epoch: [3]  [ 890/2001]  eta: 0:11:47  lr: 0.000610  loss: 3.1769 (3.1520)  time: 0.6247  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9297, ratio_loss=0.1028, cls_kl=0.0838, token_kl=0.0974
Epoch: [3]  [ 900/2001]  eta: 0:11:40  lr: 0.000610  loss: 3.2761 (3.1520)  time: 0.6272  data: 0.0001  max mem: 8740
Epoch: [3]  [ 910/2001]  eta: 0:11:34  lr: 0.000610  loss: 3.2936 (3.1502)  time: 0.6245  data: 0.0001  max mem: 8740
Epoch: [3]  [ 920/2001]  eta: 0:11:27  lr: 0.000610  loss: 3.0059 (3.1508)  time: 0.6213  data: 0.0001  max mem: 8740
Epoch: [3]  [ 930/2001]  eta: 0:11:21  lr: 0.000610  loss: 3.0059 (3.1499)  time: 0.6229  data: 0.0001  max mem: 8740
Epoch: [3]  [ 940/2001]  eta: 0:11:14  lr: 0.000610  loss: 3.2122 (3.1494)  time: 0.6245  data: 0.0001  max mem: 8740
Epoch: [3]  [ 950/2001]  eta: 0:11:08  lr: 0.000610  loss: 3.2547 (3.1476)  time: 0.6316  data: 0.0001  max mem: 8740
Epoch: [3]  [ 960/2001]  eta: 0:11:02  lr: 0.000610  loss: 3.1355 (3.1471)  time: 0.6427  data: 0.0001  max mem: 8740
Epoch: [3]  [ 970/2001]  eta: 0:10:55  lr: 0.000610  loss: 3.1355 (3.1469)  time: 0.6425  data: 0.0001  max mem: 8740
Epoch: [3]  [ 980/2001]  eta: 0:10:49  lr: 0.000610  loss: 3.0750 (3.1468)  time: 0.6302  data: 0.0001  max mem: 8740
Epoch: [3]  [ 990/2001]  eta: 0:10:42  lr: 0.000610  loss: 3.1489 (3.1467)  time: 0.6236  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9179, ratio_loss=0.0981, cls_kl=0.0861, token_kl=0.0976
Epoch: [3]  [1000/2001]  eta: 0:10:36  lr: 0.000610  loss: 3.0744 (3.1436)  time: 0.6246  data: 0.0001  max mem: 8740
Epoch: [3]  [1010/2001]  eta: 0:10:30  lr: 0.000610  loss: 2.7650 (3.1436)  time: 0.6247  data: 0.0001  max mem: 8740
Epoch: [3]  [1020/2001]  eta: 0:10:23  lr: 0.000610  loss: 3.3257 (3.1460)  time: 0.6262  data: 0.0001  max mem: 8740
Epoch: [3]  [1030/2001]  eta: 0:10:17  lr: 0.000610  loss: 3.3259 (3.1462)  time: 0.6288  data: 0.0001  max mem: 8740
Epoch: [3]  [1040/2001]  eta: 0:10:10  lr: 0.000610  loss: 3.2171 (3.1432)  time: 0.6277  data: 0.0001  max mem: 8740
Epoch: [3]  [1050/2001]  eta: 0:10:04  lr: 0.000610  loss: 3.2441 (3.1435)  time: 0.6284  data: 0.0001  max mem: 8740
Epoch: [3]  [1060/2001]  eta: 0:09:57  lr: 0.000610  loss: 3.3837 (3.1452)  time: 0.6285  data: 0.0001  max mem: 8740
Epoch: [3]  [1070/2001]  eta: 0:09:51  lr: 0.000610  loss: 3.2126 (3.1447)  time: 0.6263  data: 0.0001  max mem: 8740
Epoch: [3]  [1080/2001]  eta: 0:09:45  lr: 0.000610  loss: 3.0563 (3.1431)  time: 0.6269  data: 0.0001  max mem: 8740
Epoch: [3]  [1090/2001]  eta: 0:09:38  lr: 0.000610  loss: 3.1638 (3.1449)  time: 0.6265  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9927, ratio_loss=0.0964, cls_kl=0.0831, token_kl=0.0934
Epoch: [3]  [1100/2001]  eta: 0:09:32  lr: 0.000610  loss: 3.2126 (3.1447)  time: 0.6279  data: 0.0001  max mem: 8740
Epoch: [3]  [1110/2001]  eta: 0:09:25  lr: 0.000610  loss: 2.9992 (3.1434)  time: 0.6309  data: 0.0001  max mem: 8740
Epoch: [3]  [1120/2001]  eta: 0:09:19  lr: 0.000610  loss: 3.0760 (3.1427)  time: 0.6300  data: 0.0001  max mem: 8740
Epoch: [3]  [1130/2001]  eta: 0:09:13  lr: 0.000610  loss: 3.2885 (3.1437)  time: 0.6257  data: 0.0001  max mem: 8740
Epoch: [3]  [1140/2001]  eta: 0:09:06  lr: 0.000610  loss: 3.2711 (3.1418)  time: 0.6249  data: 0.0001  max mem: 8740
Epoch: [3]  [1150/2001]  eta: 0:09:00  lr: 0.000610  loss: 3.3075 (3.1451)  time: 0.6263  data: 0.0001  max mem: 8740
Epoch: [3]  [1160/2001]  eta: 0:08:53  lr: 0.000610  loss: 3.4281 (3.1472)  time: 0.6266  data: 0.0001  max mem: 8740
Epoch: [3]  [1170/2001]  eta: 0:08:47  lr: 0.000610  loss: 3.3680 (3.1478)  time: 0.6260  data: 0.0001  max mem: 8740
Epoch: [3]  [1180/2001]  eta: 0:08:41  lr: 0.000610  loss: 3.3331 (3.1472)  time: 0.6297  data: 0.0001  max mem: 8740
Epoch: [3]  [1190/2001]  eta: 0:08:34  lr: 0.000610  loss: 3.1632 (3.1449)  time: 0.6366  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9915, ratio_loss=0.1022, cls_kl=0.0878, token_kl=0.0979
Epoch: [3]  [1200/2001]  eta: 0:08:28  lr: 0.000610  loss: 3.1715 (3.1460)  time: 0.6393  data: 0.0001  max mem: 8740
Epoch: [3]  [1210/2001]  eta: 0:08:22  lr: 0.000610  loss: 3.2483 (3.1451)  time: 0.6432  data: 0.0001  max mem: 8740
Epoch: [3]  [1220/2001]  eta: 0:08:15  lr: 0.000610  loss: 3.2470 (3.1467)  time: 0.6453  data: 0.0001  max mem: 8740
Epoch: [3]  [1230/2001]  eta: 0:08:09  lr: 0.000610  loss: 3.2025 (3.1459)  time: 0.6453  data: 0.0001  max mem: 8740
Epoch: [3]  [1240/2001]  eta: 0:08:03  lr: 0.000610  loss: 3.3580 (3.1483)  time: 0.6422  data: 0.0001  max mem: 8740
Epoch: [3]  [1250/2001]  eta: 0:07:56  lr: 0.000610  loss: 3.4183 (3.1482)  time: 0.6325  data: 0.0001  max mem: 8740
Epoch: [3]  [1260/2001]  eta: 0:07:50  lr: 0.000610  loss: 3.3190 (3.1498)  time: 0.6295  data: 0.0001  max mem: 8740
Epoch: [3]  [1270/2001]  eta: 0:07:44  lr: 0.000610  loss: 3.3190 (3.1506)  time: 0.6297  data: 0.0001  max mem: 8740
Epoch: [3]  [1280/2001]  eta: 0:07:37  lr: 0.000610  loss: 2.8940 (3.1477)  time: 0.6283  data: 0.0001  max mem: 8740
Epoch: [3]  [1290/2001]  eta: 0:07:31  lr: 0.000610  loss: 3.2569 (3.1497)  time: 0.6308  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0155, ratio_loss=0.1022, cls_kl=0.0855, token_kl=0.0972
Epoch: [3]  [1300/2001]  eta: 0:07:25  lr: 0.000610  loss: 3.3020 (3.1492)  time: 0.6368  data: 0.0001  max mem: 8740
Epoch: [3]  [1310/2001]  eta: 0:07:18  lr: 0.000610  loss: 3.2047 (3.1497)  time: 0.6338  data: 0.0001  max mem: 8740
Epoch: [3]  [1320/2001]  eta: 0:07:12  lr: 0.000610  loss: 3.2177 (3.1495)  time: 0.6289  data: 0.0001  max mem: 8740
Epoch: [3]  [1330/2001]  eta: 0:07:05  lr: 0.000610  loss: 3.1012 (3.1479)  time: 0.6310  data: 0.0001  max mem: 8740
Epoch: [3]  [1340/2001]  eta: 0:06:59  lr: 0.000610  loss: 3.1222 (3.1490)  time: 0.6296  data: 0.0001  max mem: 8740
Epoch: [3]  [1350/2001]  eta: 0:06:53  lr: 0.000610  loss: 3.2335 (3.1494)  time: 0.6294  data: 0.0001  max mem: 8740
Epoch: [3]  [1360/2001]  eta: 0:06:46  lr: 0.000610  loss: 3.2421 (3.1492)  time: 0.6339  data: 0.0001  max mem: 8740
Epoch: [3]  [1370/2001]  eta: 0:06:40  lr: 0.000610  loss: 3.2565 (3.1495)  time: 0.6376  data: 0.0001  max mem: 8740
Epoch: [3]  [1380/2001]  eta: 0:06:34  lr: 0.000610  loss: 3.2565 (3.1491)  time: 0.6455  data: 0.0001  max mem: 8740
Epoch: [3]  [1390/2001]  eta: 0:06:27  lr: 0.000610  loss: 3.4020 (3.1513)  time: 0.6421  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9999, ratio_loss=0.1021, cls_kl=0.0860, token_kl=0.0981
Epoch: [3]  [1400/2001]  eta: 0:06:21  lr: 0.000610  loss: 3.3247 (3.1489)  time: 0.6299  data: 0.0001  max mem: 8740
Epoch: [3]  [1410/2001]  eta: 0:06:15  lr: 0.000610  loss: 3.2027 (3.1492)  time: 0.6308  data: 0.0001  max mem: 8740
Epoch: [3]  [1420/2001]  eta: 0:06:08  lr: 0.000610  loss: 3.2795 (3.1501)  time: 0.6337  data: 0.0001  max mem: 8740
Epoch: [3]  [1430/2001]  eta: 0:06:02  lr: 0.000610  loss: 3.2850 (3.1502)  time: 0.6345  data: 0.0001  max mem: 8740
Epoch: [3]  [1440/2001]  eta: 0:05:56  lr: 0.000610  loss: 3.1624 (3.1485)  time: 0.6336  data: 0.0001  max mem: 8740
Epoch: [3]  [1450/2001]  eta: 0:05:49  lr: 0.000610  loss: 3.0186 (3.1479)  time: 0.6354  data: 0.0001  max mem: 8740
Epoch: [3]  [1460/2001]  eta: 0:05:43  lr: 0.000610  loss: 3.2995 (3.1483)  time: 0.6350  data: 0.0001  max mem: 8740
Epoch: [3]  [1470/2001]  eta: 0:05:37  lr: 0.000610  loss: 3.3883 (3.1497)  time: 0.6348  data: 0.0001  max mem: 8740
Epoch: [3]  [1480/2001]  eta: 0:05:30  lr: 0.000610  loss: 3.2780 (3.1499)  time: 0.6366  data: 0.0001  max mem: 8740
Epoch: [3]  [1490/2001]  eta: 0:05:24  lr: 0.000610  loss: 3.1544 (3.1492)  time: 0.6348  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9927, ratio_loss=0.1003, cls_kl=0.0845, token_kl=0.0953
Epoch: [3]  [1500/2001]  eta: 0:05:17  lr: 0.000610  loss: 3.1704 (3.1490)  time: 0.6330  data: 0.0001  max mem: 8740
Epoch: [3]  [1510/2001]  eta: 0:05:11  lr: 0.000610  loss: 3.1757 (3.1492)  time: 0.6329  data: 0.0001  max mem: 8740
Epoch: [3]  [1520/2001]  eta: 0:05:05  lr: 0.000610  loss: 3.1070 (3.1481)  time: 0.6360  data: 0.0001  max mem: 8740
Epoch: [3]  [1530/2001]  eta: 0:04:58  lr: 0.000610  loss: 3.1070 (3.1485)  time: 0.6345  data: 0.0001  max mem: 8740
Epoch: [3]  [1540/2001]  eta: 0:04:52  lr: 0.000610  loss: 3.4020 (3.1496)  time: 0.6317  data: 0.0001  max mem: 8740
Epoch: [3]  [1550/2001]  eta: 0:04:46  lr: 0.000610  loss: 3.3698 (3.1497)  time: 0.6329  data: 0.0001  max mem: 8740
Epoch: [3]  [1560/2001]  eta: 0:04:39  lr: 0.000610  loss: 2.8909 (3.1458)  time: 0.6316  data: 0.0001  max mem: 8740
Epoch: [3]  [1570/2001]  eta: 0:04:33  lr: 0.000610  loss: 2.8909 (3.1456)  time: 0.6304  data: 0.0001  max mem: 8740
Epoch: [3]  [1580/2001]  eta: 0:04:27  lr: 0.000610  loss: 3.3081 (3.1462)  time: 0.6316  data: 0.0001  max mem: 8740
Epoch: [3]  [1590/2001]  eta: 0:04:20  lr: 0.000610  loss: 3.1512 (3.1464)  time: 0.6325  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9493, ratio_loss=0.0993, cls_kl=0.0832, token_kl=0.0969
Epoch: [3]  [1600/2001]  eta: 0:04:14  lr: 0.000610  loss: 3.1711 (3.1462)  time: 0.6364  data: 0.0001  max mem: 8740
Epoch: [3]  [1610/2001]  eta: 0:04:08  lr: 0.000610  loss: 3.3456 (3.1468)  time: 0.6372  data: 0.0001  max mem: 8740
Epoch: [3]  [1620/2001]  eta: 0:04:01  lr: 0.000610  loss: 3.2262 (3.1462)  time: 0.6384  data: 0.0001  max mem: 8740
Epoch: [3]  [1630/2001]  eta: 0:03:55  lr: 0.000610  loss: 3.4136 (3.1480)  time: 0.6415  data: 0.0001  max mem: 8740
Epoch: [3]  [1640/2001]  eta: 0:03:49  lr: 0.000610  loss: 3.1584 (3.1466)  time: 0.6410  data: 0.0001  max mem: 8740
Epoch: [3]  [1650/2001]  eta: 0:03:42  lr: 0.000610  loss: 2.9456 (3.1463)  time: 0.6431  data: 0.0001  max mem: 8740
Epoch: [3]  [1660/2001]  eta: 0:03:36  lr: 0.000610  loss: 3.3598 (3.1485)  time: 0.6409  data: 0.0001  max mem: 8740
Epoch: [3]  [1670/2001]  eta: 0:03:30  lr: 0.000610  loss: 3.3209 (3.1489)  time: 0.6353  data: 0.0001  max mem: 8740
Epoch: [3]  [1680/2001]  eta: 0:03:23  lr: 0.000610  loss: 3.1768 (3.1483)  time: 0.6387  data: 0.0001  max mem: 8740
Epoch: [3]  [1690/2001]  eta: 0:03:17  lr: 0.000610  loss: 3.0900 (3.1490)  time: 0.6404  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0399, ratio_loss=0.1042, cls_kl=0.0881, token_kl=0.0975
Epoch: [3]  [1700/2001]  eta: 0:03:11  lr: 0.000610  loss: 3.3568 (3.1502)  time: 0.6370  data: 0.0001  max mem: 8740
Epoch: [3]  [1710/2001]  eta: 0:03:04  lr: 0.000610  loss: 3.2343 (3.1497)  time: 0.6363  data: 0.0001  max mem: 8740
Epoch: [3]  [1720/2001]  eta: 0:02:58  lr: 0.000610  loss: 2.8676 (3.1462)  time: 0.6353  data: 0.0001  max mem: 8740
Epoch: [3]  [1730/2001]  eta: 0:02:52  lr: 0.000610  loss: 2.9455 (3.1472)  time: 0.6401  data: 0.0001  max mem: 8740
Epoch: [3]  [1740/2001]  eta: 0:02:45  lr: 0.000610  loss: 3.1439 (3.1466)  time: 0.6405  data: 0.0001  max mem: 8740
Epoch: [3]  [1750/2001]  eta: 0:02:39  lr: 0.000610  loss: 3.1439 (3.1475)  time: 0.6352  data: 0.0001  max mem: 8740
Epoch: [3]  [1760/2001]  eta: 0:02:33  lr: 0.000610  loss: 3.1517 (3.1469)  time: 0.6376  data: 0.0001  max mem: 8740
Epoch: [3]  [1770/2001]  eta: 0:02:26  lr: 0.000610  loss: 2.8975 (3.1458)  time: 0.6409  data: 0.0001  max mem: 8740
Epoch: [3]  [1780/2001]  eta: 0:02:20  lr: 0.000610  loss: 3.1336 (3.1465)  time: 0.6372  data: 0.0001  max mem: 8740
Epoch: [3]  [1790/2001]  eta: 0:02:14  lr: 0.000610  loss: 3.1803 (3.1475)  time: 0.6388  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9326, ratio_loss=0.0979, cls_kl=0.0843, token_kl=0.0956
Epoch: [3]  [1800/2001]  eta: 0:02:07  lr: 0.000610  loss: 3.1803 (3.1467)  time: 0.6494  data: 0.0001  max mem: 8740
Epoch: [3]  [1810/2001]  eta: 0:02:01  lr: 0.000610  loss: 3.1704 (3.1465)  time: 0.6433  data: 0.0001  max mem: 8740
Epoch: [3]  [1820/2001]  eta: 0:01:54  lr: 0.000610  loss: 3.2488 (3.1468)  time: 0.6335  data: 0.0001  max mem: 8740
Epoch: [3]  [1830/2001]  eta: 0:01:48  lr: 0.000610  loss: 3.3132 (3.1464)  time: 0.6344  data: 0.0001  max mem: 8740
Epoch: [3]  [1840/2001]  eta: 0:01:42  lr: 0.000610  loss: 3.4451 (3.1473)  time: 0.6345  data: 0.0001  max mem: 8740
Epoch: [3]  [1850/2001]  eta: 0:01:35  lr: 0.000610  loss: 3.5603 (3.1474)  time: 0.6348  data: 0.0001  max mem: 8740
Epoch: [3]  [1860/2001]  eta: 0:01:29  lr: 0.000610  loss: 3.1962 (3.1468)  time: 0.6373  data: 0.0001  max mem: 8740
Epoch: [3]  [1870/2001]  eta: 0:01:23  lr: 0.000610  loss: 3.3289 (3.1482)  time: 0.6367  data: 0.0001  max mem: 8740
Epoch: [3]  [1880/2001]  eta: 0:01:16  lr: 0.000610  loss: 3.3646 (3.1481)  time: 0.6333  data: 0.0001  max mem: 8740
Epoch: [3]  [1890/2001]  eta: 0:01:10  lr: 0.000610  loss: 3.1586 (3.1471)  time: 0.6366  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0094, ratio_loss=0.1022, cls_kl=0.0867, token_kl=0.0985
Epoch: [3]  [1900/2001]  eta: 0:01:04  lr: 0.000610  loss: 3.2707 (3.1480)  time: 0.6360  data: 0.0001  max mem: 8740
Epoch: [3]  [1910/2001]  eta: 0:00:57  lr: 0.000610  loss: 3.2707 (3.1480)  time: 0.6322  data: 0.0001  max mem: 8740
Epoch: [3]  [1920/2001]  eta: 0:00:51  lr: 0.000610  loss: 3.1214 (3.1473)  time: 0.6328  data: 0.0001  max mem: 8740
Epoch: [3]  [1930/2001]  eta: 0:00:45  lr: 0.000610  loss: 3.1214 (3.1480)  time: 0.6353  data: 0.0001  max mem: 8740
Epoch: [3]  [1940/2001]  eta: 0:00:38  lr: 0.000610  loss: 3.4417 (3.1479)  time: 0.6354  data: 0.0001  max mem: 8740
Epoch: [3]  [1950/2001]  eta: 0:00:32  lr: 0.000610  loss: 3.0696 (3.1472)  time: 0.6318  data: 0.0001  max mem: 8740
Epoch: [3]  [1960/2001]  eta: 0:00:26  lr: 0.000610  loss: 3.1696 (3.1475)  time: 0.6301  data: 0.0001  max mem: 8740
Epoch: [3]  [1970/2001]  eta: 0:00:19  lr: 0.000610  loss: 3.0846 (3.1460)  time: 0.6294  data: 0.0001  max mem: 8740
Epoch: [3]  [1980/2001]  eta: 0:00:13  lr: 0.000610  loss: 3.0846 (3.1466)  time: 0.6293  data: 0.0001  max mem: 8740
Epoch: [3]  [1990/2001]  eta: 0:00:06  lr: 0.000610  loss: 3.1882 (3.1464)  time: 0.6258  data: 0.0004  max mem: 8740
loss info: cls_loss=2.9598, ratio_loss=0.0993, cls_kl=0.0842, token_kl=0.0951
Epoch: [3]  [2000/2001]  eta: 0:00:00  lr: 0.000610  loss: 3.1882 (3.1460)  time: 0.6226  data: 0.0003  max mem: 8740
Epoch: [3] Total time: 0:21:10 (0.6352 s / it)
Averaged stats: lr: 0.000610  loss: 3.1882 (3.1503)
Test:  [ 0/53]  eta: 0:04:54  loss: 0.4269 (0.4269)  acc1: 92.5000 (92.5000)  acc5: 99.1667 (99.1667)  time: 5.5641  data: 5.0569  max mem: 8740
Test:  [10/53]  eta: 0:00:38  loss: 0.7715 (0.8103)  acc1: 81.6667 (82.1970)  acc5: 96.6667 (96.5909)  time: 0.8935  data: 0.5295  max mem: 8740
Test:  [20/53]  eta: 0:00:20  loss: 0.7715 (0.7987)  acc1: 83.3333 (82.5794)  acc5: 96.6667 (96.5873)  time: 0.3821  data: 0.0385  max mem: 8740
Test:  [30/53]  eta: 0:00:12  loss: 0.8901 (0.8831)  acc1: 78.3333 (80.5108)  acc5: 95.0000 (95.2688)  time: 0.3386  data: 0.0002  max mem: 8740
Test:  [40/53]  eta: 0:00:06  loss: 1.1458 (0.9473)  acc1: 74.1667 (78.9228)  acc5: 91.6667 (94.5122)  time: 0.3022  data: 0.0002  max mem: 8740
Test:  [50/53]  eta: 0:00:01  loss: 1.1224 (0.9754)  acc1: 74.1667 (78.0392)  acc5: 92.5000 (94.3137)  time: 0.2607  data: 0.0001  max mem: 8740
Test:  [52/53]  eta: 0:00:00  loss: 1.1145 (0.9589)  acc1: 75.0000 (78.2560)  acc5: 92.5000 (94.3840)  time: 0.2476  data: 0.0001  max mem: 8740
Test: Total time: 0:00:22 (0.4198 s / it)
Sparsity0:0.23860363636363635,Sparsity1:0.4976900502512563,Sparsity2:0.717312,
* Acc@1 78.630 Acc@5 94.434 loss 0.969
Accuracy of the network on the 50000 test images: 78.6%
Max accuracy: 78.70%
## Using lr  0.0000000 for BACKBONE, cosine lr = 0.0005984 for PREDICTOR
Epoch: [4]  [   0/2001]  eta: 2:35:11  lr: 0.000598  loss: 3.4023 (3.4023)  time: 4.6537  data: 2.6271  max mem: 8740
Epoch: [4]  [  10/2001]  eta: 0:32:37  lr: 0.000598  loss: 3.1256 (3.0410)  time: 0.9832  data: 0.2390  max mem: 8740
Epoch: [4]  [  20/2001]  eta: 0:26:37  lr: 0.000598  loss: 3.0238 (3.0240)  time: 0.6138  data: 0.0001  max mem: 8740
Epoch: [4]  [  30/2001]  eta: 0:24:26  lr: 0.000598  loss: 3.2212 (3.0826)  time: 0.6128  data: 0.0001  max mem: 8740
Epoch: [4]  [  40/2001]  eta: 0:23:18  lr: 0.000598  loss: 3.3543 (3.0881)  time: 0.6154  data: 0.0002  max mem: 8740
Epoch: [4]  [  50/2001]  eta: 0:22:35  lr: 0.000598  loss: 3.0884 (3.0268)  time: 0.6184  data: 0.0002  max mem: 8740
Epoch: [4]  [  60/2001]  eta: 0:22:06  lr: 0.000598  loss: 3.1611 (3.0680)  time: 0.6226  data: 0.0001  max mem: 8740
Epoch: [4]  [  70/2001]  eta: 0:21:43  lr: 0.000598  loss: 3.3737 (3.0784)  time: 0.6249  data: 0.0001  max mem: 8740
Epoch: [4]  [  80/2001]  eta: 0:21:26  lr: 0.000598  loss: 3.4283 (3.1048)  time: 0.6273  data: 0.0001  max mem: 8740
Epoch: [4]  [  90/2001]  eta: 0:21:11  lr: 0.000598  loss: 3.4909 (3.1352)  time: 0.6298  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9735, ratio_loss=0.1022, cls_kl=0.0880, token_kl=0.0966
Epoch: [4]  [ 100/2001]  eta: 0:20:57  lr: 0.000598  loss: 3.3638 (3.1273)  time: 0.6291  data: 0.0001  max mem: 8740
Epoch: [4]  [ 110/2001]  eta: 0:20:45  lr: 0.000598  loss: 3.1747 (3.1228)  time: 0.6275  data: 0.0001  max mem: 8740
Epoch: [4]  [ 120/2001]  eta: 0:20:34  lr: 0.000598  loss: 3.2104 (3.1235)  time: 0.6282  data: 0.0002  max mem: 8740
Epoch: [4]  [ 130/2001]  eta: 0:20:23  lr: 0.000598  loss: 3.1630 (3.1186)  time: 0.6285  data: 0.0002  max mem: 8740
Epoch: [4]  [ 140/2001]  eta: 0:20:13  lr: 0.000598  loss: 3.1630 (3.1203)  time: 0.6275  data: 0.0002  max mem: 8740
Epoch: [4]  [ 150/2001]  eta: 0:20:04  lr: 0.000598  loss: 3.0026 (3.1101)  time: 0.6303  data: 0.0001  max mem: 8740
Epoch: [4]  [ 160/2001]  eta: 0:19:56  lr: 0.000598  loss: 2.9572 (3.1021)  time: 0.6352  data: 0.0002  max mem: 8740
Epoch: [4]  [ 170/2001]  eta: 0:19:47  lr: 0.000598  loss: 3.2158 (3.1127)  time: 0.6301  data: 0.0002  max mem: 8740
Epoch: [4]  [ 180/2001]  eta: 0:19:38  lr: 0.000598  loss: 3.3546 (3.1223)  time: 0.6256  data: 0.0001  max mem: 8740
Epoch: [4]  [ 190/2001]  eta: 0:19:30  lr: 0.000598  loss: 3.3259 (3.1223)  time: 0.6269  data: 0.0002  max mem: 8740
loss info: cls_loss=2.9518, ratio_loss=0.1011, cls_kl=0.0832, token_kl=0.0949
Epoch: [4]  [ 200/2001]  eta: 0:19:21  lr: 0.000598  loss: 3.3400 (3.1294)  time: 0.6256  data: 0.0001  max mem: 8740
Epoch: [4]  [ 210/2001]  eta: 0:19:14  lr: 0.000598  loss: 3.2927 (3.1257)  time: 0.6307  data: 0.0001  max mem: 8740
Epoch: [4]  [ 220/2001]  eta: 0:19:06  lr: 0.000598  loss: 3.2641 (3.1240)  time: 0.6300  data: 0.0002  max mem: 8740
Epoch: [4]  [ 230/2001]  eta: 0:18:59  lr: 0.000598  loss: 3.0936 (3.1146)  time: 0.6276  data: 0.0002  max mem: 8740
Epoch: [4]  [ 240/2001]  eta: 0:18:51  lr: 0.000598  loss: 3.0580 (3.1153)  time: 0.6289  data: 0.0002  max mem: 8740
Epoch: [4]  [ 250/2001]  eta: 0:18:43  lr: 0.000598  loss: 3.2261 (3.1144)  time: 0.6267  data: 0.0002  max mem: 8740
Epoch: [4]  [ 260/2001]  eta: 0:18:37  lr: 0.000598  loss: 3.3057 (3.1253)  time: 0.6347  data: 0.0002  max mem: 8740
Epoch: [4]  [ 270/2001]  eta: 0:18:30  lr: 0.000598  loss: 3.3218 (3.1301)  time: 0.6386  data: 0.0002  max mem: 8740
Epoch: [4]  [ 280/2001]  eta: 0:18:23  lr: 0.000598  loss: 3.3260 (3.1357)  time: 0.6321  data: 0.0002  max mem: 8740
Epoch: [4]  [ 290/2001]  eta: 0:18:15  lr: 0.000598  loss: 3.3607 (3.1385)  time: 0.6265  data: 0.0002  max mem: 8740
loss info: cls_loss=3.0074, ratio_loss=0.1000, cls_kl=0.0862, token_kl=0.0980
Epoch: [4]  [ 300/2001]  eta: 0:18:08  lr: 0.000598  loss: 3.0667 (3.1350)  time: 0.6241  data: 0.0002  max mem: 8740
Epoch: [4]  [ 310/2001]  eta: 0:18:01  lr: 0.000598  loss: 2.9443 (3.1267)  time: 0.6291  data: 0.0002  max mem: 8740
Epoch: [4]  [ 320/2001]  eta: 0:17:54  lr: 0.000598  loss: 3.1026 (3.1313)  time: 0.6278  data: 0.0002  max mem: 8740
Epoch: [4]  [ 330/2001]  eta: 0:17:47  lr: 0.000598  loss: 3.3328 (3.1311)  time: 0.6244  data: 0.0002  max mem: 8740
Epoch: [4]  [ 340/2001]  eta: 0:17:40  lr: 0.000598  loss: 3.1475 (3.1249)  time: 0.6261  data: 0.0002  max mem: 8740
Epoch: [4]  [ 350/2001]  eta: 0:17:33  lr: 0.000598  loss: 3.1756 (3.1268)  time: 0.6257  data: 0.0002  max mem: 8740
Epoch: [4]  [ 360/2001]  eta: 0:17:26  lr: 0.000598  loss: 3.3583 (3.1269)  time: 0.6298  data: 0.0002  max mem: 8740
Epoch: [4]  [ 370/2001]  eta: 0:17:20  lr: 0.000598  loss: 3.2849 (3.1274)  time: 0.6300  data: 0.0001  max mem: 8740
Epoch: [4]  [ 380/2001]  eta: 0:17:13  lr: 0.000598  loss: 3.2654 (3.1308)  time: 0.6282  data: 0.0001  max mem: 8740
Epoch: [4]  [ 390/2001]  eta: 0:17:06  lr: 0.000598  loss: 3.2654 (3.1371)  time: 0.6282  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9780, ratio_loss=0.1019, cls_kl=0.0847, token_kl=0.0979
Epoch: [4]  [ 400/2001]  eta: 0:16:59  lr: 0.000598  loss: 3.3205 (3.1360)  time: 0.6282  data: 0.0001  max mem: 8740
Epoch: [4]  [ 410/2001]  eta: 0:16:54  lr: 0.000598  loss: 3.2237 (3.1346)  time: 0.6399  data: 0.0001  max mem: 8740
Epoch: [4]  [ 420/2001]  eta: 0:16:47  lr: 0.000598  loss: 3.2358 (3.1329)  time: 0.6446  data: 0.0001  max mem: 8740
Epoch: [4]  [ 430/2001]  eta: 0:16:40  lr: 0.000598  loss: 3.1331 (3.1297)  time: 0.6330  data: 0.0001  max mem: 8740
Epoch: [4]  [ 440/2001]  eta: 0:16:34  lr: 0.000598  loss: 3.2798 (3.1356)  time: 0.6281  data: 0.0001  max mem: 8740
Epoch: [4]  [ 450/2001]  eta: 0:16:27  lr: 0.000598  loss: 3.3490 (3.1397)  time: 0.6300  data: 0.0001  max mem: 8740
Epoch: [4]  [ 460/2001]  eta: 0:16:20  lr: 0.000598  loss: 3.3192 (3.1402)  time: 0.6280  data: 0.0001  max mem: 8740
Epoch: [4]  [ 470/2001]  eta: 0:16:14  lr: 0.000598  loss: 3.3102 (3.1372)  time: 0.6262  data: 0.0001  max mem: 8740
Epoch: [4]  [ 480/2001]  eta: 0:16:07  lr: 0.000598  loss: 2.9758 (3.1338)  time: 0.6297  data: 0.0001  max mem: 8740
Epoch: [4]  [ 490/2001]  eta: 0:16:01  lr: 0.000598  loss: 3.2508 (3.1399)  time: 0.6318  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0002, ratio_loss=0.1021, cls_kl=0.0859, token_kl=0.0976
Epoch: [4]  [ 500/2001]  eta: 0:15:54  lr: 0.000598  loss: 3.3746 (3.1421)  time: 0.6297  data: 0.0001  max mem: 8740
Epoch: [4]  [ 510/2001]  eta: 0:15:48  lr: 0.000598  loss: 3.3009 (3.1429)  time: 0.6295  data: 0.0001  max mem: 8740
Epoch: [4]  [ 520/2001]  eta: 0:15:41  lr: 0.000598  loss: 3.3009 (3.1443)  time: 0.6299  data: 0.0001  max mem: 8740
Epoch: [4]  [ 530/2001]  eta: 0:15:35  lr: 0.000598  loss: 3.3232 (3.1446)  time: 0.6301  data: 0.0001  max mem: 8740
Epoch: [4]  [ 540/2001]  eta: 0:15:28  lr: 0.000598  loss: 3.3416 (3.1471)  time: 0.6281  data: 0.0001  max mem: 8740
Epoch: [4]  [ 550/2001]  eta: 0:15:22  lr: 0.000598  loss: 3.4021 (3.1523)  time: 0.6284  data: 0.0001  max mem: 8740
Epoch: [4]  [ 560/2001]  eta: 0:15:15  lr: 0.000598  loss: 3.4021 (3.1537)  time: 0.6285  data: 0.0001  max mem: 8740
Epoch: [4]  [ 570/2001]  eta: 0:15:09  lr: 0.000598  loss: 3.4140 (3.1562)  time: 0.6363  data: 0.0001  max mem: 8740
Epoch: [4]  [ 580/2001]  eta: 0:15:02  lr: 0.000598  loss: 3.1800 (3.1517)  time: 0.6367  data: 0.0001  max mem: 8740
Epoch: [4]  [ 590/2001]  eta: 0:14:56  lr: 0.000598  loss: 3.2965 (3.1564)  time: 0.6262  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0742, ratio_loss=0.1011, cls_kl=0.0877, token_kl=0.0980
Epoch: [4]  [ 600/2001]  eta: 0:14:49  lr: 0.000598  loss: 3.4283 (3.1582)  time: 0.6285  data: 0.0001  max mem: 8740
Epoch: [4]  [ 610/2001]  eta: 0:14:43  lr: 0.000598  loss: 3.3039 (3.1572)  time: 0.6270  data: 0.0001  max mem: 8740
Epoch: [4]  [ 620/2001]  eta: 0:14:36  lr: 0.000598  loss: 3.2001 (3.1581)  time: 0.6319  data: 0.0002  max mem: 8740
Epoch: [4]  [ 630/2001]  eta: 0:14:30  lr: 0.000598  loss: 3.1742 (3.1563)  time: 0.6355  data: 0.0002  max mem: 8740
Epoch: [4]  [ 640/2001]  eta: 0:14:23  lr: 0.000598  loss: 3.2744 (3.1588)  time: 0.6287  data: 0.0001  max mem: 8740
Epoch: [4]  [ 650/2001]  eta: 0:14:17  lr: 0.000598  loss: 3.2781 (3.1579)  time: 0.6321  data: 0.0001  max mem: 8740
Epoch: [4]  [ 660/2001]  eta: 0:14:11  lr: 0.000598  loss: 3.1210 (3.1533)  time: 0.6328  data: 0.0001  max mem: 8740
Epoch: [4]  [ 670/2001]  eta: 0:14:04  lr: 0.000598  loss: 3.2615 (3.1548)  time: 0.6329  data: 0.0001  max mem: 8740
Epoch: [4]  [ 680/2001]  eta: 0:13:58  lr: 0.000598  loss: 3.2672 (3.1494)  time: 0.6340  data: 0.0001  max mem: 8740
Epoch: [4]  [ 690/2001]  eta: 0:13:51  lr: 0.000598  loss: 3.0592 (3.1490)  time: 0.6287  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9489, ratio_loss=0.0974, cls_kl=0.0839, token_kl=0.0974
Epoch: [4]  [ 700/2001]  eta: 0:13:45  lr: 0.000598  loss: 3.2589 (3.1511)  time: 0.6267  data: 0.0001  max mem: 8740
Epoch: [4]  [ 710/2001]  eta: 0:13:39  lr: 0.000598  loss: 3.1874 (3.1487)  time: 0.6284  data: 0.0001  max mem: 8740
Epoch: [4]  [ 720/2001]  eta: 0:13:32  lr: 0.000598  loss: 3.1131 (3.1507)  time: 0.6290  data: 0.0001  max mem: 8740
Epoch: [4]  [ 730/2001]  eta: 0:13:26  lr: 0.000598  loss: 3.2935 (3.1505)  time: 0.6331  data: 0.0001  max mem: 8740
Epoch: [4]  [ 740/2001]  eta: 0:13:19  lr: 0.000598  loss: 3.3323 (3.1533)  time: 0.6340  data: 0.0001  max mem: 8740
Epoch: [4]  [ 750/2001]  eta: 0:13:13  lr: 0.000598  loss: 3.3117 (3.1548)  time: 0.6298  data: 0.0001  max mem: 8740
Epoch: [4]  [ 760/2001]  eta: 0:13:07  lr: 0.000598  loss: 3.2135 (3.1557)  time: 0.6294  data: 0.0001  max mem: 8740
Epoch: [4]  [ 770/2001]  eta: 0:13:00  lr: 0.000598  loss: 3.3518 (3.1587)  time: 0.6338  data: 0.0001  max mem: 8740
Epoch: [4]  [ 780/2001]  eta: 0:12:54  lr: 0.000598  loss: 3.3758 (3.1580)  time: 0.6338  data: 0.0001  max mem: 8740
Epoch: [4]  [ 790/2001]  eta: 0:12:47  lr: 0.000598  loss: 3.3758 (3.1615)  time: 0.6299  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0759, ratio_loss=0.1038, cls_kl=0.0891, token_kl=0.0968
Epoch: [4]  [ 800/2001]  eta: 0:12:41  lr: 0.000598  loss: 3.1974 (3.1587)  time: 0.6346  data: 0.0001  max mem: 8740
Epoch: [4]  [ 810/2001]  eta: 0:12:35  lr: 0.000598  loss: 2.9291 (3.1564)  time: 0.6390  data: 0.0001  max mem: 8740
Epoch: [4]  [ 820/2001]  eta: 0:12:29  lr: 0.000598  loss: 3.0116 (3.1577)  time: 0.6429  data: 0.0001  max mem: 8740
Epoch: [4]  [ 830/2001]  eta: 0:12:22  lr: 0.000598  loss: 3.2899 (3.1584)  time: 0.6439  data: 0.0001  max mem: 8740
Epoch: [4]  [ 840/2001]  eta: 0:12:16  lr: 0.000598  loss: 3.2030 (3.1587)  time: 0.6356  data: 0.0001  max mem: 8740
Epoch: [4]  [ 850/2001]  eta: 0:12:10  lr: 0.000598  loss: 3.2268 (3.1595)  time: 0.6305  data: 0.0001  max mem: 8740
Epoch: [4]  [ 860/2001]  eta: 0:12:03  lr: 0.000598  loss: 3.2077 (3.1590)  time: 0.6313  data: 0.0001  max mem: 8740
Epoch: [4]  [ 870/2001]  eta: 0:11:57  lr: 0.000598  loss: 3.2077 (3.1586)  time: 0.6321  data: 0.0001  max mem: 8740
Epoch: [4]  [ 880/2001]  eta: 0:11:51  lr: 0.000598  loss: 3.3842 (3.1587)  time: 0.6329  data: 0.0001  max mem: 8740
Epoch: [4]  [ 890/2001]  eta: 0:11:44  lr: 0.000598  loss: 3.2153 (3.1571)  time: 0.6322  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9676, ratio_loss=0.0994, cls_kl=0.0833, token_kl=0.0948
Epoch: [4]  [ 900/2001]  eta: 0:11:38  lr: 0.000598  loss: 3.0071 (3.1551)  time: 0.6321  data: 0.0001  max mem: 8740
Epoch: [4]  [ 910/2001]  eta: 0:11:32  lr: 0.000598  loss: 3.2827 (3.1572)  time: 0.6357  data: 0.0001  max mem: 8740
Epoch: [4]  [ 920/2001]  eta: 0:11:25  lr: 0.000598  loss: 3.2115 (3.1568)  time: 0.6389  data: 0.0001  max mem: 8740
Epoch: [4]  [ 930/2001]  eta: 0:11:19  lr: 0.000598  loss: 3.1778 (3.1590)  time: 0.6355  data: 0.0001  max mem: 8740
Epoch: [4]  [ 940/2001]  eta: 0:11:13  lr: 0.000598  loss: 3.2552 (3.1590)  time: 0.6325  data: 0.0001  max mem: 8740
Epoch: [4]  [ 950/2001]  eta: 0:11:06  lr: 0.000598  loss: 3.0692 (3.1575)  time: 0.6330  data: 0.0001  max mem: 8740
Epoch: [4]  [ 960/2001]  eta: 0:11:00  lr: 0.000598  loss: 3.5418 (3.1619)  time: 0.6320  data: 0.0001  max mem: 8740
Epoch: [4]  [ 970/2001]  eta: 0:10:54  lr: 0.000598  loss: 3.5452 (3.1628)  time: 0.6393  data: 0.0001  max mem: 8740
Epoch: [4]  [ 980/2001]  eta: 0:10:47  lr: 0.000598  loss: 3.2340 (3.1605)  time: 0.6392  data: 0.0002  max mem: 8740
Epoch: [4]  [ 990/2001]  eta: 0:10:41  lr: 0.000598  loss: 3.1248 (3.1611)  time: 0.6381  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0423, ratio_loss=0.1021, cls_kl=0.0880, token_kl=0.0976
Epoch: [4]  [1000/2001]  eta: 0:10:35  lr: 0.000598  loss: 3.0228 (3.1579)  time: 0.6386  data: 0.0001  max mem: 8740
Epoch: [4]  [1010/2001]  eta: 0:10:28  lr: 0.000598  loss: 2.9692 (3.1568)  time: 0.6322  data: 0.0001  max mem: 8740
Epoch: [4]  [1020/2001]  eta: 0:10:22  lr: 0.000598  loss: 3.2855 (3.1570)  time: 0.6335  data: 0.0001  max mem: 8740
Epoch: [4]  [1030/2001]  eta: 0:10:16  lr: 0.000598  loss: 3.3133 (3.1579)  time: 0.6394  data: 0.0002  max mem: 8740
Epoch: [4]  [1040/2001]  eta: 0:10:09  lr: 0.000598  loss: 3.1678 (3.1567)  time: 0.6394  data: 0.0002  max mem: 8740
Epoch: [4]  [1050/2001]  eta: 0:10:03  lr: 0.000598  loss: 3.0684 (3.1546)  time: 0.6342  data: 0.0001  max mem: 8740
Epoch: [4]  [1060/2001]  eta: 0:09:57  lr: 0.000598  loss: 3.1558 (3.1535)  time: 0.6352  data: 0.0001  max mem: 8740
Epoch: [4]  [1070/2001]  eta: 0:09:50  lr: 0.000598  loss: 3.1558 (3.1529)  time: 0.6353  data: 0.0001  max mem: 8740
Epoch: [4]  [1080/2001]  eta: 0:09:44  lr: 0.000598  loss: 3.2180 (3.1523)  time: 0.6391  data: 0.0001  max mem: 8740
Epoch: [4]  [1090/2001]  eta: 0:09:38  lr: 0.000598  loss: 3.2180 (3.1529)  time: 0.6412  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9011, ratio_loss=0.0989, cls_kl=0.0847, token_kl=0.0972
Epoch: [4]  [1100/2001]  eta: 0:09:31  lr: 0.000598  loss: 3.1368 (3.1520)  time: 0.6396  data: 0.0001  max mem: 8740
Epoch: [4]  [1110/2001]  eta: 0:09:25  lr: 0.000598  loss: 3.1566 (3.1519)  time: 0.6388  data: 0.0001  max mem: 8740
Epoch: [4]  [1120/2001]  eta: 0:09:19  lr: 0.000598  loss: 3.0841 (3.1503)  time: 0.6361  data: 0.0001  max mem: 8740
Epoch: [4]  [1130/2001]  eta: 0:09:12  lr: 0.000598  loss: 3.0680 (3.1515)  time: 0.6364  data: 0.0001  max mem: 8740
Epoch: [4]  [1140/2001]  eta: 0:09:06  lr: 0.000598  loss: 3.2219 (3.1506)  time: 0.6363  data: 0.0001  max mem: 8740
Epoch: [4]  [1150/2001]  eta: 0:09:00  lr: 0.000598  loss: 3.0445 (3.1495)  time: 0.6359  data: 0.0001  max mem: 8740
Epoch: [4]  [1160/2001]  eta: 0:08:53  lr: 0.000598  loss: 3.0208 (3.1492)  time: 0.6352  data: 0.0001  max mem: 8740
Epoch: [4]  [1170/2001]  eta: 0:08:47  lr: 0.000598  loss: 3.2321 (3.1491)  time: 0.6352  data: 0.0001  max mem: 8740
Epoch: [4]  [1180/2001]  eta: 0:08:41  lr: 0.000598  loss: 3.2110 (3.1474)  time: 0.6412  data: 0.0001  max mem: 8740
Epoch: [4]  [1190/2001]  eta: 0:08:34  lr: 0.000598  loss: 2.9837 (3.1470)  time: 0.6404  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9616, ratio_loss=0.0969, cls_kl=0.0851, token_kl=0.0932
Epoch: [4]  [1200/2001]  eta: 0:08:28  lr: 0.000598  loss: 3.3561 (3.1485)  time: 0.6348  data: 0.0001  max mem: 8740
Epoch: [4]  [1210/2001]  eta: 0:08:22  lr: 0.000598  loss: 3.3804 (3.1482)  time: 0.6347  data: 0.0001  max mem: 8740
Epoch: [4]  [1220/2001]  eta: 0:08:15  lr: 0.000598  loss: 3.4227 (3.1506)  time: 0.6346  data: 0.0001  max mem: 8740
Epoch: [4]  [1230/2001]  eta: 0:08:09  lr: 0.000598  loss: 3.2965 (3.1498)  time: 0.6487  data: 0.0001  max mem: 8740
Epoch: [4]  [1240/2001]  eta: 0:08:03  lr: 0.000598  loss: 2.8478 (3.1484)  time: 0.6481  data: 0.0001  max mem: 8740
Epoch: [4]  [1250/2001]  eta: 0:07:57  lr: 0.000598  loss: 3.1527 (3.1493)  time: 0.6415  data: 0.0001  max mem: 8740
Epoch: [4]  [1260/2001]  eta: 0:07:50  lr: 0.000598  loss: 3.2734 (3.1501)  time: 0.6421  data: 0.0001  max mem: 8740
Epoch: [4]  [1270/2001]  eta: 0:07:44  lr: 0.000598  loss: 3.2854 (3.1503)  time: 0.6354  data: 0.0001  max mem: 8740
Epoch: [4]  [1280/2001]  eta: 0:07:37  lr: 0.000598  loss: 3.2854 (3.1504)  time: 0.6345  data: 0.0001  max mem: 8740
Epoch: [4]  [1290/2001]  eta: 0:07:31  lr: 0.000598  loss: 3.3207 (3.1511)  time: 0.6341  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0034, ratio_loss=0.1003, cls_kl=0.0846, token_kl=0.0955
Epoch: [4]  [1300/2001]  eta: 0:07:25  lr: 0.000598  loss: 3.2077 (3.1494)  time: 0.6347  data: 0.0001  max mem: 8740
Epoch: [4]  [1310/2001]  eta: 0:07:18  lr: 0.000598  loss: 3.1228 (3.1490)  time: 0.6350  data: 0.0001  max mem: 8740
Epoch: [4]  [1320/2001]  eta: 0:07:12  lr: 0.000598  loss: 3.0708 (3.1489)  time: 0.6347  data: 0.0001  max mem: 8740
Epoch: [4]  [1330/2001]  eta: 0:07:06  lr: 0.000598  loss: 3.0560 (3.1469)  time: 0.6361  data: 0.0001  max mem: 8740
Epoch: [4]  [1340/2001]  eta: 0:06:59  lr: 0.000598  loss: 3.1239 (3.1465)  time: 0.6360  data: 0.0001  max mem: 8740
Epoch: [4]  [1350/2001]  eta: 0:06:53  lr: 0.000598  loss: 3.2006 (3.1458)  time: 0.6336  data: 0.0001  max mem: 8740
Epoch: [4]  [1360/2001]  eta: 0:06:47  lr: 0.000598  loss: 3.2425 (3.1467)  time: 0.6332  data: 0.0001  max mem: 8740
Epoch: [4]  [1370/2001]  eta: 0:06:40  lr: 0.000598  loss: 3.2496 (3.1468)  time: 0.6328  data: 0.0001  max mem: 8740
Epoch: [4]  [1380/2001]  eta: 0:06:34  lr: 0.000598  loss: 3.1436 (3.1462)  time: 0.6384  data: 0.0001  max mem: 8740
Epoch: [4]  [1390/2001]  eta: 0:06:28  lr: 0.000598  loss: 3.3202 (3.1476)  time: 0.6393  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9551, ratio_loss=0.1010, cls_kl=0.0833, token_kl=0.0950
Epoch: [4]  [1400/2001]  eta: 0:06:21  lr: 0.000598  loss: 3.3489 (3.1460)  time: 0.6422  data: 0.0001  max mem: 8740
Epoch: [4]  [1410/2001]  eta: 0:06:15  lr: 0.000598  loss: 3.4537 (3.1485)  time: 0.6404  data: 0.0001  max mem: 8740
Epoch: [4]  [1420/2001]  eta: 0:06:09  lr: 0.000598  loss: 3.4622 (3.1497)  time: 0.6327  data: 0.0001  max mem: 8740
Epoch: [4]  [1430/2001]  eta: 0:06:02  lr: 0.000598  loss: 3.3583 (3.1496)  time: 0.6351  data: 0.0002  max mem: 8740
Epoch: [4]  [1440/2001]  eta: 0:05:56  lr: 0.000598  loss: 3.1716 (3.1498)  time: 0.6388  data: 0.0001  max mem: 8740
Epoch: [4]  [1450/2001]  eta: 0:05:50  lr: 0.000598  loss: 3.1716 (3.1494)  time: 0.6387  data: 0.0001  max mem: 8740
Epoch: [4]  [1460/2001]  eta: 0:05:43  lr: 0.000598  loss: 3.2206 (3.1501)  time: 0.6324  data: 0.0001  max mem: 8740
Epoch: [4]  [1470/2001]  eta: 0:05:37  lr: 0.000598  loss: 3.2206 (3.1504)  time: 0.6285  data: 0.0001  max mem: 8740
Epoch: [4]  [1480/2001]  eta: 0:05:30  lr: 0.000598  loss: 3.4111 (3.1516)  time: 0.6321  data: 0.0001  max mem: 8740
Epoch: [4]  [1490/2001]  eta: 0:05:24  lr: 0.000598  loss: 3.4060 (3.1525)  time: 0.6384  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0599, ratio_loss=0.1068, cls_kl=0.0885, token_kl=0.0978
Epoch: [4]  [1500/2001]  eta: 0:05:18  lr: 0.000598  loss: 2.8870 (3.1492)  time: 0.6366  data: 0.0001  max mem: 8740
Epoch: [4]  [1510/2001]  eta: 0:05:11  lr: 0.000598  loss: 2.4781 (3.1464)  time: 0.6334  data: 0.0001  max mem: 8740
Epoch: [4]  [1520/2001]  eta: 0:05:05  lr: 0.000598  loss: 2.9431 (3.1466)  time: 0.6321  data: 0.0001  max mem: 8740
Epoch: [4]  [1530/2001]  eta: 0:04:59  lr: 0.000598  loss: 3.4192 (3.1490)  time: 0.6290  data: 0.0001  max mem: 8740
Epoch: [4]  [1540/2001]  eta: 0:04:52  lr: 0.000598  loss: 3.2690 (3.1486)  time: 0.6261  data: 0.0001  max mem: 8740
Epoch: [4]  [1550/2001]  eta: 0:04:46  lr: 0.000598  loss: 3.1644 (3.1482)  time: 0.6261  data: 0.0001  max mem: 8740
Epoch: [4]  [1560/2001]  eta: 0:04:40  lr: 0.000598  loss: 3.1053 (3.1476)  time: 0.6272  data: 0.0001  max mem: 8740
Epoch: [4]  [1570/2001]  eta: 0:04:33  lr: 0.000598  loss: 3.1053 (3.1473)  time: 0.6267  data: 0.0001  max mem: 8740
Epoch: [4]  [1580/2001]  eta: 0:04:27  lr: 0.000598  loss: 3.2475 (3.1464)  time: 0.6263  data: 0.0001  max mem: 8740
Epoch: [4]  [1590/2001]  eta: 0:04:20  lr: 0.000598  loss: 3.0163 (3.1450)  time: 0.6303  data: 0.0001  max mem: 8740
loss info: cls_loss=2.8885, ratio_loss=0.0978, cls_kl=0.0830, token_kl=0.0976
Epoch: [4]  [1600/2001]  eta: 0:04:14  lr: 0.000598  loss: 3.1169 (3.1452)  time: 0.6306  data: 0.0001  max mem: 8740
Epoch: [4]  [1610/2001]  eta: 0:04:08  lr: 0.000598  loss: 3.0276 (3.1448)  time: 0.6264  data: 0.0001  max mem: 8740
Epoch: [4]  [1620/2001]  eta: 0:04:01  lr: 0.000598  loss: 3.0276 (3.1446)  time: 0.6246  data: 0.0001  max mem: 8740
Epoch: [4]  [1630/2001]  eta: 0:03:55  lr: 0.000598  loss: 3.1552 (3.1441)  time: 0.6235  data: 0.0002  max mem: 8740
Epoch: [4]  [1640/2001]  eta: 0:03:49  lr: 0.000598  loss: 3.1477 (3.1425)  time: 0.6277  data: 0.0003  max mem: 8740
Epoch: [4]  [1650/2001]  eta: 0:03:42  lr: 0.000598  loss: 3.2909 (3.1441)  time: 0.6354  data: 0.0001  max mem: 8740
Epoch: [4]  [1660/2001]  eta: 0:03:36  lr: 0.000598  loss: 3.1874 (3.1438)  time: 0.6379  data: 0.0001  max mem: 8740
Epoch: [4]  [1670/2001]  eta: 0:03:30  lr: 0.000598  loss: 3.2481 (3.1457)  time: 0.6293  data: 0.0002  max mem: 8740
Epoch: [4]  [1680/2001]  eta: 0:03:23  lr: 0.000598  loss: 3.3495 (3.1463)  time: 0.6229  data: 0.0001  max mem: 8740
Epoch: [4]  [1690/2001]  eta: 0:03:17  lr: 0.000598  loss: 3.3101 (3.1470)  time: 0.6219  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0429, ratio_loss=0.1040, cls_kl=0.0846, token_kl=0.0964
Epoch: [4]  [1700/2001]  eta: 0:03:10  lr: 0.000598  loss: 3.4079 (3.1490)  time: 0.6229  data: 0.0001  max mem: 8740
Epoch: [4]  [1710/2001]  eta: 0:03:04  lr: 0.000598  loss: 3.4698 (3.1502)  time: 0.6251  data: 0.0001  max mem: 8740
Epoch: [4]  [1720/2001]  eta: 0:02:58  lr: 0.000598  loss: 3.3697 (3.1496)  time: 0.6248  data: 0.0001  max mem: 8740
Epoch: [4]  [1730/2001]  eta: 0:02:51  lr: 0.000598  loss: 3.1952 (3.1496)  time: 0.6264  data: 0.0001  max mem: 8740
Epoch: [4]  [1740/2001]  eta: 0:02:45  lr: 0.000598  loss: 3.2468 (3.1497)  time: 0.6284  data: 0.0001  max mem: 8740
Epoch: [4]  [1750/2001]  eta: 0:02:39  lr: 0.000598  loss: 3.2297 (3.1487)  time: 0.6254  data: 0.0001  max mem: 8740
Epoch: [4]  [1760/2001]  eta: 0:02:32  lr: 0.000598  loss: 3.2297 (3.1487)  time: 0.6249  data: 0.0001  max mem: 8740
Epoch: [4]  [1770/2001]  eta: 0:02:26  lr: 0.000598  loss: 3.2187 (3.1484)  time: 0.6261  data: 0.0001  max mem: 8740
Epoch: [4]  [1780/2001]  eta: 0:02:20  lr: 0.000598  loss: 3.1313 (3.1484)  time: 0.6241  data: 0.0001  max mem: 8740
Epoch: [4]  [1790/2001]  eta: 0:02:13  lr: 0.000598  loss: 3.2447 (3.1488)  time: 0.6266  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9981, ratio_loss=0.0982, cls_kl=0.0841, token_kl=0.0949
Epoch: [4]  [1800/2001]  eta: 0:02:07  lr: 0.000598  loss: 3.1353 (3.1481)  time: 0.6287  data: 0.0001  max mem: 8740
Epoch: [4]  [1810/2001]  eta: 0:02:01  lr: 0.000598  loss: 3.1353 (3.1474)  time: 0.6248  data: 0.0001  max mem: 8740
Epoch: [4]  [1820/2001]  eta: 0:01:54  lr: 0.000598  loss: 3.0764 (3.1465)  time: 0.6280  data: 0.0001  max mem: 8740
Epoch: [4]  [1830/2001]  eta: 0:01:48  lr: 0.000598  loss: 3.0764 (3.1460)  time: 0.6290  data: 0.0001  max mem: 8740
Epoch: [4]  [1840/2001]  eta: 0:01:42  lr: 0.000598  loss: 3.2975 (3.1464)  time: 0.6237  data: 0.0001  max mem: 8740
Epoch: [4]  [1850/2001]  eta: 0:01:35  lr: 0.000598  loss: 3.0252 (3.1443)  time: 0.6278  data: 0.0001  max mem: 8740
Epoch: [4]  [1860/2001]  eta: 0:01:29  lr: 0.000598  loss: 3.0753 (3.1445)  time: 0.6272  data: 0.0001  max mem: 8740
Epoch: [4]  [1870/2001]  eta: 0:01:23  lr: 0.000598  loss: 3.3236 (3.1448)  time: 0.6229  data: 0.0001  max mem: 8740
Epoch: [4]  [1880/2001]  eta: 0:01:16  lr: 0.000598  loss: 3.3677 (3.1452)  time: 0.6249  data: 0.0001  max mem: 8740
Epoch: [4]  [1890/2001]  eta: 0:01:10  lr: 0.000598  loss: 3.2254 (3.1450)  time: 0.6279  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9149, ratio_loss=0.0941, cls_kl=0.0813, token_kl=0.0935
Epoch: [4]  [1900/2001]  eta: 0:01:03  lr: 0.000598  loss: 3.2254 (3.1444)  time: 0.6264  data: 0.0001  max mem: 8740
Epoch: [4]  [1910/2001]  eta: 0:00:57  lr: 0.000598  loss: 3.1530 (3.1442)  time: 0.6270  data: 0.0001  max mem: 8740
Epoch: [4]  [1920/2001]  eta: 0:00:51  lr: 0.000598  loss: 3.2271 (3.1446)  time: 0.6275  data: 0.0001  max mem: 8740
Epoch: [4]  [1930/2001]  eta: 0:00:44  lr: 0.000598  loss: 3.2498 (3.1444)  time: 0.6245  data: 0.0001  max mem: 8740
Epoch: [4]  [1940/2001]  eta: 0:00:38  lr: 0.000598  loss: 3.2498 (3.1456)  time: 0.6242  data: 0.0001  max mem: 8740
Epoch: [4]  [1950/2001]  eta: 0:00:32  lr: 0.000598  loss: 3.1757 (3.1449)  time: 0.6252  data: 0.0001  max mem: 8740
Epoch: [4]  [1960/2001]  eta: 0:00:25  lr: 0.000598  loss: 3.0372 (3.1440)  time: 0.6293  data: 0.0001  max mem: 8740
Epoch: [4]  [1970/2001]  eta: 0:00:19  lr: 0.000598  loss: 3.1332 (3.1441)  time: 0.6288  data: 0.0001  max mem: 8740
Epoch: [4]  [1980/2001]  eta: 0:00:13  lr: 0.000598  loss: 3.2000 (3.1443)  time: 0.6261  data: 0.0001  max mem: 8740
Epoch: [4]  [1990/2001]  eta: 0:00:06  lr: 0.000598  loss: 3.2639 (3.1440)  time: 0.6230  data: 0.0004  max mem: 8740
loss info: cls_loss=2.9761, ratio_loss=0.0997, cls_kl=0.0849, token_kl=0.0955
Epoch: [4]  [2000/2001]  eta: 0:00:00  lr: 0.000598  loss: 3.2224 (3.1442)  time: 0.6184  data: 0.0003  max mem: 8740
Epoch: [4] Total time: 0:21:07 (0.6334 s / it)
Averaged stats: lr: 0.000598  loss: 3.2224 (3.1427)
Test:  [ 0/53]  eta: 0:04:35  loss: 0.3968 (0.3968)  acc1: 92.5000 (92.5000)  acc5: 100.0000 (100.0000)  time: 5.1970  data: 4.8851  max mem: 8740
Test:  [10/53]  eta: 0:00:36  loss: 0.7660 (0.8211)  acc1: 80.0000 (81.5152)  acc5: 96.6667 (96.5152)  time: 0.8434  data: 0.4586  max mem: 8740
Test:  [20/53]  eta: 0:00:20  loss: 0.7660 (0.8091)  acc1: 80.8333 (81.7460)  acc5: 95.8333 (96.4286)  time: 0.3934  data: 0.0081  max mem: 8740
Test:  [30/53]  eta: 0:00:12  loss: 0.9194 (0.8937)  acc1: 78.3333 (79.9462)  acc5: 94.1667 (95.0807)  time: 0.3594  data: 0.0008  max mem: 8740
Test:  [40/53]  eta: 0:00:06  loss: 1.1527 (0.9606)  acc1: 75.8333 (78.2724)  acc5: 91.6667 (94.4309)  time: 0.2980  data: 0.0007  max mem: 8740
Test:  [50/53]  eta: 0:00:01  loss: 1.1224 (0.9838)  acc1: 75.8333 (77.7288)  acc5: 93.3333 (94.3137)  time: 0.2552  data: 0.0001  max mem: 8740
Test:  [52/53]  eta: 0:00:00  loss: 1.1016 (0.9684)  acc1: 76.6667 (77.9680)  acc5: 93.3333 (94.4000)  time: 0.2436  data: 0.0000  max mem: 8740
Test: Total time: 0:00:21 (0.4148 s / it)
Sparsity0:0.2377971717171717,Sparsity1:0.4895123618090452,Sparsity2:0.7309976,
* Acc@1 78.642 Acc@5 94.362 loss 0.971
Accuracy of the network on the 50000 test images: 78.6%
Max accuracy: 78.70%
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0005838 for PREDICTOR
Epoch: [5]  [   0/2001]  eta: 2:20:35  lr: 0.000584  loss: 2.7816 (2.7816)  time: 4.2155  data: 3.4737  max mem: 8740
Epoch: [5]  [  10/2001]  eta: 0:31:26  lr: 0.000584  loss: 3.3227 (3.2182)  time: 0.9474  data: 0.3159  max mem: 8740
Epoch: [5]  [  20/2001]  eta: 0:25:59  lr: 0.000584  loss: 3.3364 (3.2047)  time: 0.6160  data: 0.0001  max mem: 8740
Epoch: [5]  [  30/2001]  eta: 0:24:03  lr: 0.000584  loss: 3.4991 (3.2396)  time: 0.6139  data: 0.0001  max mem: 8740
Epoch: [5]  [  40/2001]  eta: 0:23:01  lr: 0.000584  loss: 3.3355 (3.2131)  time: 0.6172  data: 0.0001  max mem: 8740
Epoch: [5]  [  50/2001]  eta: 0:22:26  lr: 0.000584  loss: 3.3355 (3.2139)  time: 0.6256  data: 0.0001  max mem: 8740
Epoch: [5]  [  60/2001]  eta: 0:21:58  lr: 0.000584  loss: 3.3396 (3.2359)  time: 0.6274  data: 0.0001  max mem: 8740
Epoch: [5]  [  70/2001]  eta: 0:21:37  lr: 0.000584  loss: 3.2762 (3.2218)  time: 0.6244  data: 0.0001  max mem: 8740
Epoch: [5]  [  80/2001]  eta: 0:21:20  lr: 0.000584  loss: 3.2792 (3.2342)  time: 0.6282  data: 0.0001  max mem: 8740
Epoch: [5]  [  90/2001]  eta: 0:21:05  lr: 0.000584  loss: 3.3275 (3.2249)  time: 0.6294  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0703, ratio_loss=0.0972, cls_kl=0.0858, token_kl=0.0991
Epoch: [5]  [ 100/2001]  eta: 0:20:52  lr: 0.000584  loss: 3.2575 (3.2055)  time: 0.6287  data: 0.0001  max mem: 8740
Epoch: [5]  [ 110/2001]  eta: 0:20:41  lr: 0.000584  loss: 3.1618 (3.2054)  time: 0.6287  data: 0.0001  max mem: 8740
Epoch: [5]  [ 120/2001]  eta: 0:20:31  lr: 0.000584  loss: 3.1817 (3.2006)  time: 0.6311  data: 0.0001  max mem: 8740
Epoch: [5]  [ 130/2001]  eta: 0:20:20  lr: 0.000584  loss: 3.1939 (3.1858)  time: 0.6313  data: 0.0001  max mem: 8740
Epoch: [5]  [ 140/2001]  eta: 0:20:11  lr: 0.000584  loss: 3.1706 (3.1716)  time: 0.6295  data: 0.0001  max mem: 8740
Epoch: [5]  [ 150/2001]  eta: 0:20:04  lr: 0.000584  loss: 2.9214 (3.1612)  time: 0.6368  data: 0.0001  max mem: 8740
Epoch: [5]  [ 160/2001]  eta: 0:19:56  lr: 0.000584  loss: 3.0212 (3.1569)  time: 0.6426  data: 0.0001  max mem: 8740
Epoch: [5]  [ 170/2001]  eta: 0:19:49  lr: 0.000584  loss: 3.0390 (3.1624)  time: 0.6415  data: 0.0001  max mem: 8740
Epoch: [5]  [ 180/2001]  eta: 0:19:40  lr: 0.000584  loss: 3.3221 (3.1527)  time: 0.6351  data: 0.0001  max mem: 8740
Epoch: [5]  [ 190/2001]  eta: 0:19:32  lr: 0.000584  loss: 3.3363 (3.1583)  time: 0.6315  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9660, ratio_loss=0.0817, cls_kl=0.0796, token_kl=0.0955
Epoch: [5]  [ 200/2001]  eta: 0:19:25  lr: 0.000584  loss: 3.3484 (3.1707)  time: 0.6382  data: 0.0001  max mem: 8740
Epoch: [5]  [ 210/2001]  eta: 0:19:17  lr: 0.000584  loss: 3.2783 (3.1679)  time: 0.6364  data: 0.0001  max mem: 8740
Epoch: [5]  [ 220/2001]  eta: 0:19:10  lr: 0.000584  loss: 3.1331 (3.1536)  time: 0.6322  data: 0.0001  max mem: 8740
Epoch: [5]  [ 230/2001]  eta: 0:19:02  lr: 0.000584  loss: 3.1165 (3.1462)  time: 0.6337  data: 0.0001  max mem: 8740
Epoch: [5]  [ 240/2001]  eta: 0:18:55  lr: 0.000584  loss: 3.1324 (3.1455)  time: 0.6355  data: 0.0001  max mem: 8740
Epoch: [5]  [ 250/2001]  eta: 0:18:48  lr: 0.000584  loss: 3.3784 (3.1541)  time: 0.6348  data: 0.0001  max mem: 8740
Epoch: [5]  [ 260/2001]  eta: 0:18:42  lr: 0.000584  loss: 3.4458 (3.1650)  time: 0.6378  data: 0.0001  max mem: 8740
Epoch: [5]  [ 270/2001]  eta: 0:18:35  lr: 0.000584  loss: 3.2810 (3.1551)  time: 0.6416  data: 0.0001  max mem: 8740
Epoch: [5]  [ 280/2001]  eta: 0:18:28  lr: 0.000584  loss: 3.1322 (3.1601)  time: 0.6373  data: 0.0001  max mem: 8740
Epoch: [5]  [ 290/2001]  eta: 0:18:21  lr: 0.000584  loss: 3.2249 (3.1601)  time: 0.6357  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0220, ratio_loss=0.0788, cls_kl=0.0808, token_kl=0.0966
Epoch: [5]  [ 300/2001]  eta: 0:18:14  lr: 0.000584  loss: 3.2249 (3.1657)  time: 0.6367  data: 0.0001  max mem: 8740
Epoch: [5]  [ 310/2001]  eta: 0:18:07  lr: 0.000584  loss: 3.0868 (3.1525)  time: 0.6377  data: 0.0001  max mem: 8740
Epoch: [5]  [ 320/2001]  eta: 0:18:00  lr: 0.000584  loss: 2.8250 (3.1486)  time: 0.6363  data: 0.0001  max mem: 8740
Epoch: [5]  [ 330/2001]  eta: 0:17:54  lr: 0.000584  loss: 3.1458 (3.1502)  time: 0.6337  data: 0.0001  max mem: 8740
Epoch: [5]  [ 340/2001]  eta: 0:17:47  lr: 0.000584  loss: 3.3302 (3.1558)  time: 0.6343  data: 0.0001  max mem: 8740
Epoch: [5]  [ 350/2001]  eta: 0:17:40  lr: 0.000584  loss: 3.3462 (3.1607)  time: 0.6392  data: 0.0001  max mem: 8740
Epoch: [5]  [ 360/2001]  eta: 0:17:34  lr: 0.000584  loss: 3.2506 (3.1602)  time: 0.6443  data: 0.0001  max mem: 8740
Epoch: [5]  [ 370/2001]  eta: 0:17:27  lr: 0.000584  loss: 3.1965 (3.1536)  time: 0.6405  data: 0.0001  max mem: 8740
Epoch: [5]  [ 380/2001]  eta: 0:17:21  lr: 0.000584  loss: 2.8816 (3.1454)  time: 0.6359  data: 0.0001  max mem: 8740
Epoch: [5]  [ 390/2001]  eta: 0:17:14  lr: 0.000584  loss: 2.8816 (3.1446)  time: 0.6345  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9486, ratio_loss=0.0745, cls_kl=0.0754, token_kl=0.0955
Epoch: [5]  [ 400/2001]  eta: 0:17:07  lr: 0.000584  loss: 2.8725 (3.1382)  time: 0.6361  data: 0.0001  max mem: 8740
Epoch: [5]  [ 410/2001]  eta: 0:17:01  lr: 0.000584  loss: 2.8628 (3.1376)  time: 0.6425  data: 0.0001  max mem: 8740
Epoch: [5]  [ 420/2001]  eta: 0:16:55  lr: 0.000584  loss: 2.9875 (3.1346)  time: 0.6469  data: 0.0001  max mem: 8740
Epoch: [5]  [ 430/2001]  eta: 0:16:48  lr: 0.000584  loss: 2.9445 (3.1319)  time: 0.6416  data: 0.0001  max mem: 8740
Epoch: [5]  [ 440/2001]  eta: 0:16:42  lr: 0.000584  loss: 2.9836 (3.1285)  time: 0.6357  data: 0.0001  max mem: 8740
Epoch: [5]  [ 450/2001]  eta: 0:16:35  lr: 0.000584  loss: 3.2629 (3.1306)  time: 0.6342  data: 0.0001  max mem: 8740
Epoch: [5]  [ 460/2001]  eta: 0:16:28  lr: 0.000584  loss: 3.0296 (3.1233)  time: 0.6371  data: 0.0001  max mem: 8740
Epoch: [5]  [ 470/2001]  eta: 0:16:22  lr: 0.000584  loss: 3.2690 (3.1289)  time: 0.6421  data: 0.0001  max mem: 8740
Epoch: [5]  [ 480/2001]  eta: 0:16:15  lr: 0.000584  loss: 3.2690 (3.1284)  time: 0.6410  data: 0.0001  max mem: 8740
Epoch: [5]  [ 490/2001]  eta: 0:16:09  lr: 0.000584  loss: 3.1432 (3.1258)  time: 0.6378  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9199, ratio_loss=0.0744, cls_kl=0.0749, token_kl=0.0948
Epoch: [5]  [ 500/2001]  eta: 0:16:02  lr: 0.000584  loss: 3.1634 (3.1250)  time: 0.6385  data: 0.0001  max mem: 8740
Epoch: [5]  [ 510/2001]  eta: 0:15:56  lr: 0.000584  loss: 3.2026 (3.1272)  time: 0.6446  data: 0.0001  max mem: 8740
Epoch: [5]  [ 520/2001]  eta: 0:15:50  lr: 0.000584  loss: 3.1057 (3.1280)  time: 0.6432  data: 0.0001  max mem: 8740
Epoch: [5]  [ 530/2001]  eta: 0:15:43  lr: 0.000584  loss: 2.8708 (3.1233)  time: 0.6366  data: 0.0001  max mem: 8740
Epoch: [5]  [ 540/2001]  eta: 0:15:37  lr: 0.000584  loss: 2.7482 (3.1228)  time: 0.6372  data: 0.0001  max mem: 8740
Epoch: [5]  [ 550/2001]  eta: 0:15:30  lr: 0.000584  loss: 3.3159 (3.1226)  time: 0.6397  data: 0.0001  max mem: 8740
Epoch: [5]  [ 560/2001]  eta: 0:15:24  lr: 0.000584  loss: 2.9165 (3.1182)  time: 0.6376  data: 0.0001  max mem: 8740
Epoch: [5]  [ 570/2001]  eta: 0:15:17  lr: 0.000584  loss: 2.9165 (3.1164)  time: 0.6404  data: 0.0001  max mem: 8740
Epoch: [5]  [ 580/2001]  eta: 0:15:11  lr: 0.000584  loss: 3.1168 (3.1178)  time: 0.6432  data: 0.0001  max mem: 8740
Epoch: [5]  [ 590/2001]  eta: 0:15:04  lr: 0.000584  loss: 3.0319 (3.1149)  time: 0.6392  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9308, ratio_loss=0.0690, cls_kl=0.0710, token_kl=0.0948
Epoch: [5]  [ 600/2001]  eta: 0:14:58  lr: 0.000584  loss: 2.9085 (3.1115)  time: 0.6370  data: 0.0001  max mem: 8740
Epoch: [5]  [ 610/2001]  eta: 0:14:51  lr: 0.000584  loss: 3.0653 (3.1110)  time: 0.6368  data: 0.0001  max mem: 8740
Epoch: [5]  [ 620/2001]  eta: 0:14:45  lr: 0.000584  loss: 3.0653 (3.1092)  time: 0.6411  data: 0.0001  max mem: 8740
Epoch: [5]  [ 630/2001]  eta: 0:14:39  lr: 0.000584  loss: 3.2390 (3.1136)  time: 0.6427  data: 0.0001  max mem: 8740
Epoch: [5]  [ 640/2001]  eta: 0:14:32  lr: 0.000584  loss: 3.1985 (3.1101)  time: 0.6405  data: 0.0001  max mem: 8740
Epoch: [5]  [ 650/2001]  eta: 0:14:26  lr: 0.000584  loss: 2.9356 (3.1092)  time: 0.6385  data: 0.0001  max mem: 8740
Epoch: [5]  [ 660/2001]  eta: 0:14:19  lr: 0.000584  loss: 2.9356 (3.1073)  time: 0.6381  data: 0.0001  max mem: 8740
Epoch: [5]  [ 670/2001]  eta: 0:14:13  lr: 0.000584  loss: 3.1281 (3.1072)  time: 0.6401  data: 0.0001  max mem: 8740
Epoch: [5]  [ 680/2001]  eta: 0:14:06  lr: 0.000584  loss: 3.2802 (3.1113)  time: 0.6420  data: 0.0001  max mem: 8740
Epoch: [5]  [ 690/2001]  eta: 0:14:00  lr: 0.000584  loss: 3.2700 (3.1114)  time: 0.6395  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9643, ratio_loss=0.0689, cls_kl=0.0726, token_kl=0.0938
Epoch: [5]  [ 700/2001]  eta: 0:13:53  lr: 0.000584  loss: 3.1360 (3.1135)  time: 0.6341  data: 0.0001  max mem: 8740
Epoch: [5]  [ 710/2001]  eta: 0:13:47  lr: 0.000584  loss: 3.2612 (3.1136)  time: 0.6340  data: 0.0001  max mem: 8740
Epoch: [5]  [ 720/2001]  eta: 0:13:40  lr: 0.000584  loss: 3.0993 (3.1094)  time: 0.6350  data: 0.0001  max mem: 8740
Epoch: [5]  [ 730/2001]  eta: 0:13:34  lr: 0.000584  loss: 3.2033 (3.1130)  time: 0.6397  data: 0.0001  max mem: 8740
Epoch: [5]  [ 740/2001]  eta: 0:13:28  lr: 0.000584  loss: 3.3518 (3.1113)  time: 0.6418  data: 0.0001  max mem: 8740
Epoch: [5]  [ 750/2001]  eta: 0:13:21  lr: 0.000584  loss: 2.9194 (3.1122)  time: 0.6387  data: 0.0001  max mem: 8740
Epoch: [5]  [ 760/2001]  eta: 0:13:15  lr: 0.000584  loss: 2.9952 (3.1103)  time: 0.6365  data: 0.0001  max mem: 8740
Epoch: [5]  [ 770/2001]  eta: 0:13:08  lr: 0.000584  loss: 3.0809 (3.1112)  time: 0.6352  data: 0.0001  max mem: 8740
Epoch: [5]  [ 780/2001]  eta: 0:13:02  lr: 0.000584  loss: 3.1419 (3.1104)  time: 0.6339  data: 0.0001  max mem: 8740
Epoch: [5]  [ 790/2001]  eta: 0:12:55  lr: 0.000584  loss: 3.1419 (3.1099)  time: 0.6345  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9653, ratio_loss=0.0676, cls_kl=0.0754, token_kl=0.0968
Epoch: [5]  [ 800/2001]  eta: 0:12:49  lr: 0.000584  loss: 3.1498 (3.1084)  time: 0.6382  data: 0.0001  max mem: 8740
Epoch: [5]  [ 810/2001]  eta: 0:12:42  lr: 0.000584  loss: 3.2097 (3.1084)  time: 0.6403  data: 0.0001  max mem: 8740
Epoch: [5]  [ 820/2001]  eta: 0:12:36  lr: 0.000584  loss: 3.1869 (3.1075)  time: 0.6469  data: 0.0001  max mem: 8740
Epoch: [5]  [ 830/2001]  eta: 0:12:30  lr: 0.000584  loss: 3.1270 (3.1078)  time: 0.6443  data: 0.0001  max mem: 8740
Epoch: [5]  [ 840/2001]  eta: 0:12:23  lr: 0.000584  loss: 3.3969 (3.1099)  time: 0.6364  data: 0.0001  max mem: 8740
Epoch: [5]  [ 850/2001]  eta: 0:12:17  lr: 0.000584  loss: 3.4945 (3.1129)  time: 0.6333  data: 0.0001  max mem: 8740
Epoch: [5]  [ 860/2001]  eta: 0:12:10  lr: 0.000584  loss: 3.4657 (3.1147)  time: 0.6320  data: 0.0001  max mem: 8740
Epoch: [5]  [ 870/2001]  eta: 0:12:04  lr: 0.000584  loss: 3.4271 (3.1162)  time: 0.6328  data: 0.0001  max mem: 8740
Epoch: [5]  [ 880/2001]  eta: 0:11:57  lr: 0.000584  loss: 3.3516 (3.1170)  time: 0.6345  data: 0.0001  max mem: 8740
Epoch: [5]  [ 890/2001]  eta: 0:11:51  lr: 0.000584  loss: 3.2459 (3.1155)  time: 0.6347  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0153, ratio_loss=0.0650, cls_kl=0.0723, token_kl=0.0935
Epoch: [5]  [ 900/2001]  eta: 0:11:44  lr: 0.000584  loss: 3.1934 (3.1152)  time: 0.6316  data: 0.0001  max mem: 8740
Epoch: [5]  [ 910/2001]  eta: 0:11:38  lr: 0.000584  loss: 3.1934 (3.1146)  time: 0.6303  data: 0.0001  max mem: 8740
Epoch: [5]  [ 920/2001]  eta: 0:11:31  lr: 0.000584  loss: 3.0600 (3.1113)  time: 0.6316  data: 0.0001  max mem: 8740
Epoch: [5]  [ 930/2001]  eta: 0:11:25  lr: 0.000584  loss: 2.7860 (3.1109)  time: 0.6308  data: 0.0001  max mem: 8740
Epoch: [5]  [ 940/2001]  eta: 0:11:18  lr: 0.000584  loss: 3.1430 (3.1111)  time: 0.6295  data: 0.0001  max mem: 8740
Epoch: [5]  [ 950/2001]  eta: 0:11:12  lr: 0.000584  loss: 3.1430 (3.1112)  time: 0.6307  data: 0.0001  max mem: 8740
Epoch: [5]  [ 960/2001]  eta: 0:11:05  lr: 0.000584  loss: 3.2593 (3.1122)  time: 0.6298  data: 0.0001  max mem: 8740
Epoch: [5]  [ 970/2001]  eta: 0:10:59  lr: 0.000584  loss: 3.4226 (3.1136)  time: 0.6332  data: 0.0001  max mem: 8740
Epoch: [5]  [ 980/2001]  eta: 0:10:52  lr: 0.000584  loss: 3.2167 (3.1132)  time: 0.6378  data: 0.0001  max mem: 8740
Epoch: [5]  [ 990/2001]  eta: 0:10:46  lr: 0.000584  loss: 3.1962 (3.1144)  time: 0.6365  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9973, ratio_loss=0.0643, cls_kl=0.0738, token_kl=0.0940
Epoch: [5]  [1000/2001]  eta: 0:10:39  lr: 0.000584  loss: 3.1962 (3.1148)  time: 0.6289  data: 0.0001  max mem: 8740
Epoch: [5]  [1010/2001]  eta: 0:10:33  lr: 0.000584  loss: 3.3032 (3.1156)  time: 0.6242  data: 0.0001  max mem: 8740
Epoch: [5]  [1020/2001]  eta: 0:10:26  lr: 0.000584  loss: 3.3475 (3.1175)  time: 0.6283  data: 0.0001  max mem: 8740
Epoch: [5]  [1030/2001]  eta: 0:10:20  lr: 0.000584  loss: 3.2764 (3.1168)  time: 0.6304  data: 0.0001  max mem: 8740
Epoch: [5]  [1040/2001]  eta: 0:10:13  lr: 0.000584  loss: 3.2581 (3.1180)  time: 0.6308  data: 0.0001  max mem: 8740
Epoch: [5]  [1050/2001]  eta: 0:10:07  lr: 0.000584  loss: 3.1223 (3.1163)  time: 0.6294  data: 0.0001  max mem: 8740
Epoch: [5]  [1060/2001]  eta: 0:10:00  lr: 0.000584  loss: 3.1223 (3.1166)  time: 0.6295  data: 0.0001  max mem: 8740
Epoch: [5]  [1070/2001]  eta: 0:09:54  lr: 0.000584  loss: 3.2543 (3.1157)  time: 0.6288  data: 0.0001  max mem: 8740
Epoch: [5]  [1080/2001]  eta: 0:09:47  lr: 0.000584  loss: 3.1185 (3.1150)  time: 0.6254  data: 0.0001  max mem: 8740
Epoch: [5]  [1090/2001]  eta: 0:09:41  lr: 0.000584  loss: 3.1364 (3.1159)  time: 0.6321  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0086, ratio_loss=0.0672, cls_kl=0.0732, token_kl=0.0939
Epoch: [5]  [1100/2001]  eta: 0:09:35  lr: 0.000584  loss: 3.0672 (3.1139)  time: 0.6363  data: 0.0001  max mem: 8740
Epoch: [5]  [1110/2001]  eta: 0:09:28  lr: 0.000584  loss: 2.8710 (3.1125)  time: 0.6314  data: 0.0001  max mem: 8740
Epoch: [5]  [1120/2001]  eta: 0:09:22  lr: 0.000584  loss: 3.1005 (3.1120)  time: 0.6267  data: 0.0001  max mem: 8740
Epoch: [5]  [1130/2001]  eta: 0:09:15  lr: 0.000584  loss: 3.2036 (3.1114)  time: 0.6251  data: 0.0001  max mem: 8740
Epoch: [5]  [1140/2001]  eta: 0:09:09  lr: 0.000584  loss: 3.1548 (3.1137)  time: 0.6299  data: 0.0001  max mem: 8740
Epoch: [5]  [1150/2001]  eta: 0:09:02  lr: 0.000584  loss: 3.1548 (3.1133)  time: 0.6278  data: 0.0001  max mem: 8740
Epoch: [5]  [1160/2001]  eta: 0:08:56  lr: 0.000584  loss: 3.2113 (3.1143)  time: 0.6250  data: 0.0001  max mem: 8740
Epoch: [5]  [1170/2001]  eta: 0:08:49  lr: 0.000584  loss: 3.1907 (3.1122)  time: 0.6250  data: 0.0001  max mem: 8740
Epoch: [5]  [1180/2001]  eta: 0:08:43  lr: 0.000584  loss: 2.9183 (3.1115)  time: 0.6249  data: 0.0001  max mem: 8740
Epoch: [5]  [1190/2001]  eta: 0:08:36  lr: 0.000584  loss: 3.1262 (3.1118)  time: 0.6271  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9431, ratio_loss=0.0640, cls_kl=0.0716, token_kl=0.0952
Epoch: [5]  [1200/2001]  eta: 0:08:30  lr: 0.000584  loss: 3.3893 (3.1121)  time: 0.6253  data: 0.0001  max mem: 8740
Epoch: [5]  [1210/2001]  eta: 0:08:24  lr: 0.000584  loss: 3.3547 (3.1123)  time: 0.6254  data: 0.0001  max mem: 8740
Epoch: [5]  [1220/2001]  eta: 0:08:17  lr: 0.000584  loss: 2.9170 (3.1106)  time: 0.6252  data: 0.0001  max mem: 8740
Epoch: [5]  [1230/2001]  eta: 0:08:11  lr: 0.000584  loss: 3.1905 (3.1118)  time: 0.6272  data: 0.0001  max mem: 8740
Epoch: [5]  [1240/2001]  eta: 0:08:04  lr: 0.000584  loss: 3.1905 (3.1106)  time: 0.6395  data: 0.0001  max mem: 8740
Epoch: [5]  [1250/2001]  eta: 0:07:58  lr: 0.000584  loss: 3.0181 (3.1088)  time: 0.6411  data: 0.0001  max mem: 8740
Epoch: [5]  [1260/2001]  eta: 0:07:52  lr: 0.000584  loss: 3.0924 (3.1098)  time: 0.6327  data: 0.0001  max mem: 8740
Epoch: [5]  [1270/2001]  eta: 0:07:45  lr: 0.000584  loss: 3.1292 (3.1095)  time: 0.6286  data: 0.0001  max mem: 8740
Epoch: [5]  [1280/2001]  eta: 0:07:39  lr: 0.000584  loss: 3.1422 (3.1086)  time: 0.6245  data: 0.0001  max mem: 8740
Epoch: [5]  [1290/2001]  eta: 0:07:32  lr: 0.000584  loss: 3.3409 (3.1103)  time: 0.6239  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9587, ratio_loss=0.0631, cls_kl=0.0720, token_kl=0.0958
Epoch: [5]  [1300/2001]  eta: 0:07:26  lr: 0.000584  loss: 3.3797 (3.1114)  time: 0.6285  data: 0.0001  max mem: 8740
Epoch: [5]  [1310/2001]  eta: 0:07:19  lr: 0.000584  loss: 3.2695 (3.1120)  time: 0.6279  data: 0.0001  max mem: 8740
Epoch: [5]  [1320/2001]  eta: 0:07:13  lr: 0.000584  loss: 3.2030 (3.1128)  time: 0.6289  data: 0.0001  max mem: 8740
Epoch: [5]  [1330/2001]  eta: 0:07:07  lr: 0.000584  loss: 3.0926 (3.1117)  time: 0.6328  data: 0.0001  max mem: 8740
Epoch: [5]  [1340/2001]  eta: 0:07:00  lr: 0.000584  loss: 3.1275 (3.1131)  time: 0.6299  data: 0.0001  max mem: 8740
Epoch: [5]  [1350/2001]  eta: 0:06:54  lr: 0.000584  loss: 3.2804 (3.1137)  time: 0.6267  data: 0.0001  max mem: 8740
Epoch: [5]  [1360/2001]  eta: 0:06:47  lr: 0.000584  loss: 3.2999 (3.1140)  time: 0.6279  data: 0.0001  max mem: 8740
Epoch: [5]  [1370/2001]  eta: 0:06:41  lr: 0.000584  loss: 3.3334 (3.1138)  time: 0.6280  data: 0.0001  max mem: 8740
Epoch: [5]  [1380/2001]  eta: 0:06:35  lr: 0.000584  loss: 3.0497 (3.1130)  time: 0.6258  data: 0.0001  max mem: 8740
Epoch: [5]  [1390/2001]  eta: 0:06:28  lr: 0.000584  loss: 3.0497 (3.1120)  time: 0.6317  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0233, ratio_loss=0.0646, cls_kl=0.0723, token_kl=0.0935
Epoch: [5]  [1400/2001]  eta: 0:06:22  lr: 0.000584  loss: 3.1130 (3.1111)  time: 0.6319  data: 0.0001  max mem: 8740
Epoch: [5]  [1410/2001]  eta: 0:06:15  lr: 0.000584  loss: 3.2340 (3.1122)  time: 0.6288  data: 0.0001  max mem: 8740
Epoch: [5]  [1420/2001]  eta: 0:06:09  lr: 0.000584  loss: 3.2885 (3.1134)  time: 0.6286  data: 0.0001  max mem: 8740
Epoch: [5]  [1430/2001]  eta: 0:06:03  lr: 0.000584  loss: 3.1495 (3.1132)  time: 0.6272  data: 0.0001  max mem: 8740
Epoch: [5]  [1440/2001]  eta: 0:05:56  lr: 0.000584  loss: 2.8929 (3.1123)  time: 0.6260  data: 0.0001  max mem: 8740
Epoch: [5]  [1450/2001]  eta: 0:05:50  lr: 0.000584  loss: 3.0793 (3.1124)  time: 0.6304  data: 0.0001  max mem: 8740
Epoch: [5]  [1460/2001]  eta: 0:05:44  lr: 0.000584  loss: 3.4110 (3.1144)  time: 0.6378  data: 0.0001  max mem: 8740
Epoch: [5]  [1470/2001]  eta: 0:05:37  lr: 0.000584  loss: 3.4147 (3.1143)  time: 0.6327  data: 0.0001  max mem: 8740
Epoch: [5]  [1480/2001]  eta: 0:05:31  lr: 0.000584  loss: 3.3744 (3.1160)  time: 0.6252  data: 0.0001  max mem: 8740
Epoch: [5]  [1490/2001]  eta: 0:05:24  lr: 0.000584  loss: 3.2451 (3.1167)  time: 0.6248  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0571, ratio_loss=0.0630, cls_kl=0.0740, token_kl=0.0954
Epoch: [5]  [1500/2001]  eta: 0:05:18  lr: 0.000584  loss: 3.2426 (3.1184)  time: 0.6289  data: 0.0001  max mem: 8740
Epoch: [5]  [1510/2001]  eta: 0:05:12  lr: 0.000584  loss: 3.3243 (3.1192)  time: 0.6392  data: 0.0001  max mem: 8740
Epoch: [5]  [1520/2001]  eta: 0:05:05  lr: 0.000584  loss: 3.2013 (3.1184)  time: 0.6401  data: 0.0001  max mem: 8740
Epoch: [5]  [1530/2001]  eta: 0:04:59  lr: 0.000584  loss: 2.9987 (3.1181)  time: 0.6310  data: 0.0001  max mem: 8740
Epoch: [5]  [1540/2001]  eta: 0:04:53  lr: 0.000584  loss: 3.0888 (3.1183)  time: 0.6281  data: 0.0001  max mem: 8740
Epoch: [5]  [1550/2001]  eta: 0:04:46  lr: 0.000584  loss: 3.1681 (3.1188)  time: 0.6276  data: 0.0001  max mem: 8740
Epoch: [5]  [1560/2001]  eta: 0:04:40  lr: 0.000584  loss: 3.1488 (3.1172)  time: 0.6312  data: 0.0001  max mem: 8740
Epoch: [5]  [1570/2001]  eta: 0:04:33  lr: 0.000584  loss: 2.9593 (3.1164)  time: 0.6309  data: 0.0001  max mem: 8740
Epoch: [5]  [1580/2001]  eta: 0:04:27  lr: 0.000584  loss: 2.9593 (3.1150)  time: 0.6263  data: 0.0001  max mem: 8740
Epoch: [5]  [1590/2001]  eta: 0:04:21  lr: 0.000584  loss: 3.0148 (3.1146)  time: 0.6252  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9547, ratio_loss=0.0610, cls_kl=0.0699, token_kl=0.0934
Epoch: [5]  [1600/2001]  eta: 0:04:14  lr: 0.000584  loss: 3.2208 (3.1154)  time: 0.6296  data: 0.0001  max mem: 8740
Epoch: [5]  [1610/2001]  eta: 0:04:08  lr: 0.000584  loss: 3.2208 (3.1149)  time: 0.6312  data: 0.0001  max mem: 8740
Epoch: [5]  [1620/2001]  eta: 0:04:02  lr: 0.000584  loss: 3.0900 (3.1138)  time: 0.6266  data: 0.0001  max mem: 8740
Epoch: [5]  [1630/2001]  eta: 0:03:55  lr: 0.000584  loss: 3.1918 (3.1139)  time: 0.6294  data: 0.0001  max mem: 8740
Epoch: [5]  [1640/2001]  eta: 0:03:49  lr: 0.000584  loss: 3.1918 (3.1140)  time: 0.6329  data: 0.0001  max mem: 8740
Epoch: [5]  [1650/2001]  eta: 0:03:43  lr: 0.000584  loss: 3.0137 (3.1133)  time: 0.6394  data: 0.0001  max mem: 8740
Epoch: [5]  [1660/2001]  eta: 0:03:36  lr: 0.000584  loss: 3.3772 (3.1141)  time: 0.6373  data: 0.0001  max mem: 8740
Epoch: [5]  [1670/2001]  eta: 0:03:30  lr: 0.000584  loss: 3.1450 (3.1130)  time: 0.6349  data: 0.0001  max mem: 8740
Epoch: [5]  [1680/2001]  eta: 0:03:23  lr: 0.000584  loss: 2.8995 (3.1123)  time: 0.6349  data: 0.0001  max mem: 8740
Epoch: [5]  [1690/2001]  eta: 0:03:17  lr: 0.000584  loss: 3.2966 (3.1135)  time: 0.6285  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9617, ratio_loss=0.0637, cls_kl=0.0707, token_kl=0.0952
Epoch: [5]  [1700/2001]  eta: 0:03:11  lr: 0.000584  loss: 3.3097 (3.1133)  time: 0.6281  data: 0.0001  max mem: 8740
Epoch: [5]  [1710/2001]  eta: 0:03:04  lr: 0.000584  loss: 3.2026 (3.1128)  time: 0.6282  data: 0.0001  max mem: 8740
Epoch: [5]  [1720/2001]  eta: 0:02:58  lr: 0.000584  loss: 2.9020 (3.1103)  time: 0.6334  data: 0.0001  max mem: 8740
Epoch: [5]  [1730/2001]  eta: 0:02:52  lr: 0.000584  loss: 3.1004 (3.1114)  time: 0.6342  data: 0.0001  max mem: 8740
Epoch: [5]  [1740/2001]  eta: 0:02:45  lr: 0.000584  loss: 3.1963 (3.1106)  time: 0.6307  data: 0.0001  max mem: 8740
Epoch: [5]  [1750/2001]  eta: 0:02:39  lr: 0.000584  loss: 2.9675 (3.1096)  time: 0.6344  data: 0.0001  max mem: 8740
Epoch: [5]  [1760/2001]  eta: 0:02:33  lr: 0.000584  loss: 3.1035 (3.1098)  time: 0.6367  data: 0.0001  max mem: 8740
Epoch: [5]  [1770/2001]  eta: 0:02:26  lr: 0.000584  loss: 3.3519 (3.1096)  time: 0.6397  data: 0.0001  max mem: 8740
Epoch: [5]  [1780/2001]  eta: 0:02:20  lr: 0.000584  loss: 3.1341 (3.1105)  time: 0.6375  data: 0.0001  max mem: 8740
Epoch: [5]  [1790/2001]  eta: 0:02:14  lr: 0.000584  loss: 3.0853 (3.1094)  time: 0.6355  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9244, ratio_loss=0.0548, cls_kl=0.0671, token_kl=0.0902
Epoch: [5]  [1800/2001]  eta: 0:02:07  lr: 0.000584  loss: 3.1019 (3.1099)  time: 0.6395  data: 0.0001  max mem: 8740
Epoch: [5]  [1810/2001]  eta: 0:02:01  lr: 0.000584  loss: 3.1934 (3.1106)  time: 0.6356  data: 0.0001  max mem: 8740
Epoch: [5]  [1820/2001]  eta: 0:01:54  lr: 0.000584  loss: 3.1934 (3.1089)  time: 0.6338  data: 0.0001  max mem: 8740
Epoch: [5]  [1830/2001]  eta: 0:01:48  lr: 0.000584  loss: 3.1134 (3.1088)  time: 0.6379  data: 0.0001  max mem: 8740
Epoch: [5]  [1840/2001]  eta: 0:01:42  lr: 0.000584  loss: 3.2674 (3.1091)  time: 0.6361  data: 0.0001  max mem: 8740
Epoch: [5]  [1850/2001]  eta: 0:01:35  lr: 0.000584  loss: 3.2432 (3.1092)  time: 0.6333  data: 0.0001  max mem: 8740
Epoch: [5]  [1860/2001]  eta: 0:01:29  lr: 0.000584  loss: 3.1534 (3.1080)  time: 0.6339  data: 0.0001  max mem: 8740
Epoch: [5]  [1870/2001]  eta: 0:01:23  lr: 0.000584  loss: 3.1846 (3.1081)  time: 0.6343  data: 0.0001  max mem: 8740
Epoch: [5]  [1880/2001]  eta: 0:01:16  lr: 0.000584  loss: 3.1975 (3.1070)  time: 0.6386  data: 0.0001  max mem: 8740
Epoch: [5]  [1890/2001]  eta: 0:01:10  lr: 0.000584  loss: 3.0600 (3.1069)  time: 0.6401  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9455, ratio_loss=0.0643, cls_kl=0.0725, token_kl=0.1001
Epoch: [5]  [1900/2001]  eta: 0:01:04  lr: 0.000584  loss: 3.1549 (3.1077)  time: 0.6351  data: 0.0001  max mem: 8740
Epoch: [5]  [1910/2001]  eta: 0:00:57  lr: 0.000584  loss: 3.1549 (3.1070)  time: 0.6332  data: 0.0001  max mem: 8740
Epoch: [5]  [1920/2001]  eta: 0:00:51  lr: 0.000584  loss: 3.2013 (3.1078)  time: 0.6388  data: 0.0001  max mem: 8740
Epoch: [5]  [1930/2001]  eta: 0:00:45  lr: 0.000584  loss: 3.0079 (3.1076)  time: 0.6392  data: 0.0001  max mem: 8740
Epoch: [5]  [1940/2001]  eta: 0:00:38  lr: 0.000584  loss: 3.1212 (3.1075)  time: 0.6383  data: 0.0001  max mem: 8740
Epoch: [5]  [1950/2001]  eta: 0:00:32  lr: 0.000584  loss: 3.2575 (3.1074)  time: 0.6377  data: 0.0001  max mem: 8740
Epoch: [5]  [1960/2001]  eta: 0:00:26  lr: 0.000584  loss: 3.2575 (3.1069)  time: 0.6325  data: 0.0001  max mem: 8740
Epoch: [5]  [1970/2001]  eta: 0:00:19  lr: 0.000584  loss: 3.2622 (3.1073)  time: 0.6329  data: 0.0001  max mem: 8740
Epoch: [5]  [1980/2001]  eta: 0:00:13  lr: 0.000584  loss: 3.0817 (3.1056)  time: 0.6338  data: 0.0001  max mem: 8740
Epoch: [5]  [1990/2001]  eta: 0:00:06  lr: 0.000584  loss: 2.8086 (3.1047)  time: 0.6329  data: 0.0003  max mem: 8740
loss info: cls_loss=2.9435, ratio_loss=0.0568, cls_kl=0.0678, token_kl=0.0912
Epoch: [5]  [2000/2001]  eta: 0:00:00  lr: 0.000584  loss: 3.3187 (3.1067)  time: 0.6287  data: 0.0003  max mem: 8740
Epoch: [5] Total time: 0:21:11 (0.6355 s / it)
Averaged stats: lr: 0.000584  loss: 3.3187 (3.1007)
Test:  [ 0/53]  eta: 0:04:27  loss: 0.3733 (0.3733)  acc1: 94.1667 (94.1667)  acc5: 99.1667 (99.1667)  time: 5.0458  data: 4.5553  max mem: 8740
Test:  [10/53]  eta: 0:00:35  loss: 0.7343 (0.7717)  acc1: 81.6667 (83.2576)  acc5: 96.6667 (96.5909)  time: 0.8239  data: 0.4481  max mem: 8740
Test:  [20/53]  eta: 0:00:20  loss: 0.7249 (0.7658)  acc1: 81.6667 (83.1349)  acc5: 96.6667 (96.7857)  time: 0.4057  data: 0.0188  max mem: 8740
Test:  [30/53]  eta: 0:00:12  loss: 0.8818 (0.8604)  acc1: 78.3333 (80.9677)  acc5: 95.0000 (95.5376)  time: 0.3725  data: 0.0002  max mem: 8740
Test:  [40/53]  eta: 0:00:06  loss: 1.1607 (0.9328)  acc1: 76.6667 (79.0650)  acc5: 92.5000 (94.7155)  time: 0.2994  data: 0.0002  max mem: 8740
Test:  [50/53]  eta: 0:00:01  loss: 1.1300 (0.9609)  acc1: 75.0000 (78.3170)  acc5: 92.5000 (94.6078)  time: 0.2552  data: 0.0001  max mem: 8740
Test:  [52/53]  eta: 0:00:00  loss: 1.1043 (0.9479)  acc1: 76.6667 (78.5120)  acc5: 93.3333 (94.6720)  time: 0.2401  data: 0.0000  max mem: 8740
Test: Total time: 0:00:22 (0.4157 s / it)
Sparsity0:0.28331232323232325,Sparsity1:0.5377021105527638,Sparsity2:0.757636,
* Acc@1 78.808 Acc@5 94.488 loss 0.948
Accuracy of the network on the 50000 test images: 78.8%
Max accuracy: 78.81%
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0005663 for PREDICTOR
Epoch: [6]  [   0/2001]  eta: 2:42:56  lr: 0.000566  loss: 2.3685 (2.3685)  time: 4.8856  data: 4.2478  max mem: 8740
Epoch: [6]  [  10/2001]  eta: 0:33:12  lr: 0.000566  loss: 2.9910 (3.0203)  time: 1.0007  data: 0.3863  max mem: 8740
Epoch: [6]  [  20/2001]  eta: 0:27:05  lr: 0.000566  loss: 2.9910 (2.9891)  time: 0.6174  data: 0.0001  max mem: 8740
Epoch: [6]  [  30/2001]  eta: 0:24:49  lr: 0.000566  loss: 2.9975 (3.0161)  time: 0.6212  data: 0.0001  max mem: 8740
Epoch: [6]  [  40/2001]  eta: 0:23:40  lr: 0.000566  loss: 3.0253 (3.0391)  time: 0.6235  data: 0.0001  max mem: 8740
Epoch: [6]  [  50/2001]  eta: 0:22:57  lr: 0.000566  loss: 3.2545 (3.0914)  time: 0.6283  data: 0.0001  max mem: 8740
Epoch: [6]  [  60/2001]  eta: 0:22:26  lr: 0.000566  loss: 3.2738 (3.0858)  time: 0.6311  data: 0.0001  max mem: 8740
Epoch: [6]  [  70/2001]  eta: 0:22:03  lr: 0.000566  loss: 3.2973 (3.1152)  time: 0.6332  data: 0.0001  max mem: 8740
Epoch: [6]  [  80/2001]  eta: 0:21:44  lr: 0.000566  loss: 3.2059 (3.1076)  time: 0.6344  data: 0.0001  max mem: 8740
Epoch: [6]  [  90/2001]  eta: 0:21:28  lr: 0.000566  loss: 2.8597 (3.0668)  time: 0.6351  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9717, ratio_loss=0.0597, cls_kl=0.0686, token_kl=0.0934
Epoch: [6]  [ 100/2001]  eta: 0:21:14  lr: 0.000566  loss: 2.7736 (3.0495)  time: 0.6362  data: 0.0001  max mem: 8740
Epoch: [6]  [ 110/2001]  eta: 0:21:02  lr: 0.000566  loss: 3.0504 (3.0492)  time: 0.6368  data: 0.0001  max mem: 8740
Epoch: [6]  [ 120/2001]  eta: 0:20:50  lr: 0.000566  loss: 3.0504 (3.0376)  time: 0.6361  data: 0.0001  max mem: 8740
Epoch: [6]  [ 130/2001]  eta: 0:20:40  lr: 0.000566  loss: 2.7116 (3.0168)  time: 0.6360  data: 0.0001  max mem: 8740
Epoch: [6]  [ 140/2001]  eta: 0:20:29  lr: 0.000566  loss: 2.8499 (3.0244)  time: 0.6355  data: 0.0001  max mem: 8740
Epoch: [6]  [ 150/2001]  eta: 0:20:20  lr: 0.000566  loss: 3.1062 (3.0266)  time: 0.6356  data: 0.0001  max mem: 8740
Epoch: [6]  [ 160/2001]  eta: 0:20:11  lr: 0.000566  loss: 3.2035 (3.0373)  time: 0.6388  data: 0.0001  max mem: 8740
Epoch: [6]  [ 170/2001]  eta: 0:20:03  lr: 0.000566  loss: 3.2035 (3.0294)  time: 0.6425  data: 0.0001  max mem: 8740
Epoch: [6]  [ 180/2001]  eta: 0:19:56  lr: 0.000566  loss: 2.9223 (3.0238)  time: 0.6472  data: 0.0001  max mem: 8740
Epoch: [6]  [ 190/2001]  eta: 0:19:47  lr: 0.000566  loss: 2.9223 (3.0147)  time: 0.6449  data: 0.0001  max mem: 8740
loss info: cls_loss=2.8336, ratio_loss=0.0586, cls_kl=0.0662, token_kl=0.0938
Epoch: [6]  [ 200/2001]  eta: 0:19:40  lr: 0.000566  loss: 2.8249 (3.0069)  time: 0.6404  data: 0.0001  max mem: 8740
Epoch: [6]  [ 210/2001]  eta: 0:19:32  lr: 0.000566  loss: 2.8929 (3.0040)  time: 0.6422  data: 0.0001  max mem: 8740
Epoch: [6]  [ 220/2001]  eta: 0:19:24  lr: 0.000566  loss: 3.0759 (3.0042)  time: 0.6379  data: 0.0001  max mem: 8740
Epoch: [6]  [ 230/2001]  eta: 0:19:15  lr: 0.000566  loss: 3.1917 (3.0176)  time: 0.6328  data: 0.0001  max mem: 8740
Epoch: [6]  [ 240/2001]  eta: 0:19:07  lr: 0.000566  loss: 3.2028 (3.0194)  time: 0.6324  data: 0.0001  max mem: 8740
Epoch: [6]  [ 250/2001]  eta: 0:19:00  lr: 0.000566  loss: 3.0030 (3.0258)  time: 0.6320  data: 0.0001  max mem: 8740
Epoch: [6]  [ 260/2001]  eta: 0:18:52  lr: 0.000566  loss: 3.1864 (3.0298)  time: 0.6370  data: 0.0001  max mem: 8740
Epoch: [6]  [ 270/2001]  eta: 0:18:45  lr: 0.000566  loss: 2.9767 (3.0212)  time: 0.6384  data: 0.0001  max mem: 8740
Epoch: [6]  [ 280/2001]  eta: 0:18:38  lr: 0.000566  loss: 3.0678 (3.0268)  time: 0.6365  data: 0.0001  max mem: 8740
Epoch: [6]  [ 290/2001]  eta: 0:18:30  lr: 0.000566  loss: 3.2106 (3.0312)  time: 0.6340  data: 0.0002  max mem: 8740
loss info: cls_loss=2.9780, ratio_loss=0.0620, cls_kl=0.0705, token_kl=0.0960
Epoch: [6]  [ 300/2001]  eta: 0:18:22  lr: 0.000566  loss: 3.2052 (3.0393)  time: 0.6304  data: 0.0002  max mem: 8740
Epoch: [6]  [ 310/2001]  eta: 0:18:15  lr: 0.000566  loss: 3.1487 (3.0422)  time: 0.6315  data: 0.0001  max mem: 8740
Epoch: [6]  [ 320/2001]  eta: 0:18:08  lr: 0.000566  loss: 3.2359 (3.0492)  time: 0.6315  data: 0.0002  max mem: 8740
Epoch: [6]  [ 330/2001]  eta: 0:18:00  lr: 0.000566  loss: 3.2537 (3.0452)  time: 0.6315  data: 0.0001  max mem: 8740
Epoch: [6]  [ 340/2001]  eta: 0:17:53  lr: 0.000566  loss: 3.2537 (3.0510)  time: 0.6312  data: 0.0001  max mem: 8740
Epoch: [6]  [ 350/2001]  eta: 0:17:46  lr: 0.000566  loss: 3.2691 (3.0501)  time: 0.6305  data: 0.0001  max mem: 8740
Epoch: [6]  [ 360/2001]  eta: 0:17:39  lr: 0.000566  loss: 2.8888 (3.0411)  time: 0.6318  data: 0.0001  max mem: 8740
Epoch: [6]  [ 370/2001]  eta: 0:17:32  lr: 0.000566  loss: 2.7410 (3.0376)  time: 0.6313  data: 0.0001  max mem: 8740
Epoch: [6]  [ 380/2001]  eta: 0:17:25  lr: 0.000566  loss: 3.2741 (3.0442)  time: 0.6306  data: 0.0001  max mem: 8740
Epoch: [6]  [ 390/2001]  eta: 0:17:18  lr: 0.000566  loss: 3.1535 (3.0382)  time: 0.6361  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9275, ratio_loss=0.0551, cls_kl=0.0675, token_kl=0.0912
Epoch: [6]  [ 400/2001]  eta: 0:17:11  lr: 0.000566  loss: 2.9151 (3.0386)  time: 0.6367  data: 0.0001  max mem: 8740
Epoch: [6]  [ 410/2001]  eta: 0:17:05  lr: 0.000566  loss: 2.9890 (3.0357)  time: 0.6351  data: 0.0001  max mem: 8740
Epoch: [6]  [ 420/2001]  eta: 0:16:58  lr: 0.000566  loss: 3.2727 (3.0380)  time: 0.6339  data: 0.0001  max mem: 8740
Epoch: [6]  [ 430/2001]  eta: 0:16:50  lr: 0.000566  loss: 3.2028 (3.0354)  time: 0.6259  data: 0.0001  max mem: 8740
Epoch: [6]  [ 440/2001]  eta: 0:16:43  lr: 0.000566  loss: 2.9611 (3.0350)  time: 0.6273  data: 0.0001  max mem: 8740
Epoch: [6]  [ 450/2001]  eta: 0:16:36  lr: 0.000566  loss: 2.9611 (3.0311)  time: 0.6288  data: 0.0001  max mem: 8740
Epoch: [6]  [ 460/2001]  eta: 0:16:30  lr: 0.000566  loss: 3.1398 (3.0356)  time: 0.6279  data: 0.0001  max mem: 8740
Epoch: [6]  [ 470/2001]  eta: 0:16:23  lr: 0.000566  loss: 3.2040 (3.0354)  time: 0.6288  data: 0.0001  max mem: 8740
Epoch: [6]  [ 480/2001]  eta: 0:16:16  lr: 0.000566  loss: 3.0416 (3.0349)  time: 0.6292  data: 0.0001  max mem: 8740
Epoch: [6]  [ 490/2001]  eta: 0:16:09  lr: 0.000566  loss: 3.0916 (3.0370)  time: 0.6281  data: 0.0001  max mem: 8740
loss info: cls_loss=2.8862, ratio_loss=0.0589, cls_kl=0.0658, token_kl=0.0934
Epoch: [6]  [ 500/2001]  eta: 0:16:02  lr: 0.000566  loss: 3.2193 (3.0365)  time: 0.6257  data: 0.0001  max mem: 8740
Epoch: [6]  [ 510/2001]  eta: 0:15:55  lr: 0.000566  loss: 3.1835 (3.0390)  time: 0.6251  data: 0.0001  max mem: 8740
Epoch: [6]  [ 520/2001]  eta: 0:15:48  lr: 0.000566  loss: 3.3134 (3.0461)  time: 0.6246  data: 0.0001  max mem: 8740
Epoch: [6]  [ 530/2001]  eta: 0:15:42  lr: 0.000566  loss: 3.2587 (3.0435)  time: 0.6285  data: 0.0002  max mem: 8740
Epoch: [6]  [ 540/2001]  eta: 0:15:35  lr: 0.000566  loss: 3.0025 (3.0455)  time: 0.6281  data: 0.0002  max mem: 8740
Epoch: [6]  [ 550/2001]  eta: 0:15:28  lr: 0.000566  loss: 3.0025 (3.0435)  time: 0.6318  data: 0.0001  max mem: 8740
Epoch: [6]  [ 560/2001]  eta: 0:15:22  lr: 0.000566  loss: 2.8929 (3.0421)  time: 0.6349  data: 0.0002  max mem: 8740
Epoch: [6]  [ 570/2001]  eta: 0:15:15  lr: 0.000566  loss: 3.2168 (3.0461)  time: 0.6286  data: 0.0002  max mem: 8740
Epoch: [6]  [ 580/2001]  eta: 0:15:08  lr: 0.000566  loss: 3.2619 (3.0498)  time: 0.6259  data: 0.0001  max mem: 8740
Epoch: [6]  [ 590/2001]  eta: 0:15:02  lr: 0.000566  loss: 3.2059 (3.0518)  time: 0.6309  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0235, ratio_loss=0.0591, cls_kl=0.0699, token_kl=0.0944
Epoch: [6]  [ 600/2001]  eta: 0:14:55  lr: 0.000566  loss: 3.2089 (3.0529)  time: 0.6285  data: 0.0001  max mem: 8740
Epoch: [6]  [ 610/2001]  eta: 0:14:48  lr: 0.000566  loss: 3.1220 (3.0527)  time: 0.6210  data: 0.0001  max mem: 8740
Epoch: [6]  [ 620/2001]  eta: 0:14:42  lr: 0.000566  loss: 3.0928 (3.0535)  time: 0.6268  data: 0.0001  max mem: 8740
Epoch: [6]  [ 630/2001]  eta: 0:14:35  lr: 0.000566  loss: 3.0212 (3.0521)  time: 0.6323  data: 0.0001  max mem: 8740
Epoch: [6]  [ 640/2001]  eta: 0:14:28  lr: 0.000566  loss: 3.1617 (3.0528)  time: 0.6272  data: 0.0001  max mem: 8740
Epoch: [6]  [ 650/2001]  eta: 0:14:22  lr: 0.000566  loss: 3.2452 (3.0548)  time: 0.6236  data: 0.0001  max mem: 8740
Epoch: [6]  [ 660/2001]  eta: 0:14:15  lr: 0.000566  loss: 3.1541 (3.0555)  time: 0.6231  data: 0.0001  max mem: 8740
Epoch: [6]  [ 670/2001]  eta: 0:14:08  lr: 0.000566  loss: 3.2392 (3.0608)  time: 0.6240  data: 0.0001  max mem: 8740
Epoch: [6]  [ 680/2001]  eta: 0:14:02  lr: 0.000566  loss: 3.2613 (3.0622)  time: 0.6283  data: 0.0001  max mem: 8740
Epoch: [6]  [ 690/2001]  eta: 0:13:55  lr: 0.000566  loss: 3.1931 (3.0635)  time: 0.6268  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0236, ratio_loss=0.0594, cls_kl=0.0712, token_kl=0.0944
Epoch: [6]  [ 700/2001]  eta: 0:13:49  lr: 0.000566  loss: 3.3104 (3.0649)  time: 0.6252  data: 0.0001  max mem: 8740
Epoch: [6]  [ 710/2001]  eta: 0:13:42  lr: 0.000566  loss: 3.3104 (3.0663)  time: 0.6250  data: 0.0001  max mem: 8740
Epoch: [6]  [ 720/2001]  eta: 0:13:35  lr: 0.000566  loss: 3.3151 (3.0680)  time: 0.6227  data: 0.0001  max mem: 8740
Epoch: [6]  [ 730/2001]  eta: 0:13:29  lr: 0.000566  loss: 3.3151 (3.0679)  time: 0.6247  data: 0.0001  max mem: 8740
Epoch: [6]  [ 740/2001]  eta: 0:13:22  lr: 0.000566  loss: 2.9656 (3.0661)  time: 0.6252  data: 0.0001  max mem: 8740
Epoch: [6]  [ 750/2001]  eta: 0:13:16  lr: 0.000566  loss: 3.2268 (3.0677)  time: 0.6253  data: 0.0001  max mem: 8740
Epoch: [6]  [ 760/2001]  eta: 0:13:09  lr: 0.000566  loss: 3.1713 (3.0696)  time: 0.6253  data: 0.0001  max mem: 8740
Epoch: [6]  [ 770/2001]  eta: 0:13:03  lr: 0.000566  loss: 3.1103 (3.0693)  time: 0.6264  data: 0.0002  max mem: 8740
Epoch: [6]  [ 780/2001]  eta: 0:12:56  lr: 0.000566  loss: 3.0893 (3.0671)  time: 0.6275  data: 0.0001  max mem: 8740
Epoch: [6]  [ 790/2001]  eta: 0:12:50  lr: 0.000566  loss: 2.7048 (3.0646)  time: 0.6270  data: 0.0002  max mem: 8740
loss info: cls_loss=2.9406, ratio_loss=0.0567, cls_kl=0.0687, token_kl=0.0939
Epoch: [6]  [ 800/2001]  eta: 0:12:43  lr: 0.000566  loss: 2.9588 (3.0622)  time: 0.6269  data: 0.0002  max mem: 8740
Epoch: [6]  [ 810/2001]  eta: 0:12:37  lr: 0.000566  loss: 3.2686 (3.0657)  time: 0.6351  data: 0.0001  max mem: 8740
Epoch: [6]  [ 820/2001]  eta: 0:12:30  lr: 0.000566  loss: 3.3096 (3.0667)  time: 0.6351  data: 0.0001  max mem: 8740
Epoch: [6]  [ 830/2001]  eta: 0:12:24  lr: 0.000566  loss: 3.1550 (3.0670)  time: 0.6293  data: 0.0001  max mem: 8740
Epoch: [6]  [ 840/2001]  eta: 0:12:18  lr: 0.000566  loss: 3.1379 (3.0668)  time: 0.6316  data: 0.0001  max mem: 8740
Epoch: [6]  [ 850/2001]  eta: 0:12:11  lr: 0.000566  loss: 3.1628 (3.0679)  time: 0.6270  data: 0.0001  max mem: 8740
Epoch: [6]  [ 860/2001]  eta: 0:12:05  lr: 0.000566  loss: 3.1340 (3.0675)  time: 0.6278  data: 0.0001  max mem: 8740
Epoch: [6]  [ 870/2001]  eta: 0:11:58  lr: 0.000566  loss: 3.0190 (3.0673)  time: 0.6306  data: 0.0001  max mem: 8740
Epoch: [6]  [ 880/2001]  eta: 0:11:52  lr: 0.000566  loss: 3.0190 (3.0682)  time: 0.6295  data: 0.0001  max mem: 8740
Epoch: [6]  [ 890/2001]  eta: 0:11:45  lr: 0.000566  loss: 3.1827 (3.0679)  time: 0.6310  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9723, ratio_loss=0.0592, cls_kl=0.0682, token_kl=0.0915
Epoch: [6]  [ 900/2001]  eta: 0:11:39  lr: 0.000566  loss: 3.1827 (3.0689)  time: 0.6289  data: 0.0001  max mem: 8740
Epoch: [6]  [ 910/2001]  eta: 0:11:32  lr: 0.000566  loss: 3.1718 (3.0702)  time: 0.6260  data: 0.0001  max mem: 8740
Epoch: [6]  [ 920/2001]  eta: 0:11:26  lr: 0.000566  loss: 3.1642 (3.0724)  time: 0.6263  data: 0.0001  max mem: 8740
Epoch: [6]  [ 930/2001]  eta: 0:11:20  lr: 0.000566  loss: 3.1406 (3.0714)  time: 0.6275  data: 0.0001  max mem: 8740
Epoch: [6]  [ 940/2001]  eta: 0:11:13  lr: 0.000566  loss: 2.9426 (3.0684)  time: 0.6268  data: 0.0001  max mem: 8740
Epoch: [6]  [ 950/2001]  eta: 0:11:07  lr: 0.000566  loss: 3.0546 (3.0685)  time: 0.6259  data: 0.0001  max mem: 8740
Epoch: [6]  [ 960/2001]  eta: 0:11:00  lr: 0.000566  loss: 3.1512 (3.0702)  time: 0.6319  data: 0.0001  max mem: 8740
Epoch: [6]  [ 970/2001]  eta: 0:10:54  lr: 0.000566  loss: 3.1257 (3.0705)  time: 0.6324  data: 0.0001  max mem: 8740
Epoch: [6]  [ 980/2001]  eta: 0:10:47  lr: 0.000566  loss: 3.0328 (3.0671)  time: 0.6265  data: 0.0001  max mem: 8740
Epoch: [6]  [ 990/2001]  eta: 0:10:41  lr: 0.000566  loss: 2.5993 (3.0628)  time: 0.6273  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9062, ratio_loss=0.0598, cls_kl=0.0684, token_kl=0.0956
Epoch: [6]  [1000/2001]  eta: 0:10:35  lr: 0.000566  loss: 3.0518 (3.0643)  time: 0.6311  data: 0.0001  max mem: 8740
Epoch: [6]  [1010/2001]  eta: 0:10:28  lr: 0.000566  loss: 3.3718 (3.0664)  time: 0.6339  data: 0.0001  max mem: 8740
Epoch: [6]  [1020/2001]  eta: 0:10:22  lr: 0.000566  loss: 3.3931 (3.0694)  time: 0.6325  data: 0.0001  max mem: 8740
Epoch: [6]  [1030/2001]  eta: 0:10:16  lr: 0.000566  loss: 3.2994 (3.0689)  time: 0.6316  data: 0.0001  max mem: 8740
Epoch: [6]  [1040/2001]  eta: 0:10:09  lr: 0.000566  loss: 3.2808 (3.0700)  time: 0.6356  data: 0.0001  max mem: 8740
Epoch: [6]  [1050/2001]  eta: 0:10:03  lr: 0.000566  loss: 3.3550 (3.0722)  time: 0.6371  data: 0.0001  max mem: 8740
Epoch: [6]  [1060/2001]  eta: 0:09:57  lr: 0.000566  loss: 3.2650 (3.0697)  time: 0.6349  data: 0.0001  max mem: 8740
Epoch: [6]  [1070/2001]  eta: 0:09:50  lr: 0.000566  loss: 2.9401 (3.0694)  time: 0.6320  data: 0.0001  max mem: 8740
Epoch: [6]  [1080/2001]  eta: 0:09:44  lr: 0.000566  loss: 3.2222 (3.0686)  time: 0.6305  data: 0.0001  max mem: 8740
Epoch: [6]  [1090/2001]  eta: 0:09:38  lr: 0.000566  loss: 3.1510 (3.0692)  time: 0.6331  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0182, ratio_loss=0.0613, cls_kl=0.0714, token_kl=0.0957
Epoch: [6]  [1100/2001]  eta: 0:09:31  lr: 0.000566  loss: 3.3274 (3.0727)  time: 0.6320  data: 0.0001  max mem: 8740
Epoch: [6]  [1110/2001]  eta: 0:09:25  lr: 0.000566  loss: 3.0579 (3.0692)  time: 0.6313  data: 0.0001  max mem: 8740
Epoch: [6]  [1120/2001]  eta: 0:09:18  lr: 0.000566  loss: 2.9365 (3.0711)  time: 0.6306  data: 0.0001  max mem: 8740
Epoch: [6]  [1130/2001]  eta: 0:09:12  lr: 0.000566  loss: 3.1845 (3.0716)  time: 0.6270  data: 0.0001  max mem: 8740
Epoch: [6]  [1140/2001]  eta: 0:09:06  lr: 0.000566  loss: 3.2827 (3.0725)  time: 0.6279  data: 0.0001  max mem: 8740
Epoch: [6]  [1150/2001]  eta: 0:08:59  lr: 0.000566  loss: 3.3388 (3.0745)  time: 0.6297  data: 0.0001  max mem: 8740
Epoch: [6]  [1160/2001]  eta: 0:08:53  lr: 0.000566  loss: 3.1883 (3.0728)  time: 0.6307  data: 0.0001  max mem: 8740
Epoch: [6]  [1170/2001]  eta: 0:08:46  lr: 0.000566  loss: 3.0191 (3.0725)  time: 0.6303  data: 0.0001  max mem: 8740
Epoch: [6]  [1180/2001]  eta: 0:08:40  lr: 0.000566  loss: 3.2433 (3.0746)  time: 0.6301  data: 0.0001  max mem: 8740
Epoch: [6]  [1190/2001]  eta: 0:08:34  lr: 0.000566  loss: 3.1739 (3.0734)  time: 0.6341  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9816, ratio_loss=0.0573, cls_kl=0.0707, token_kl=0.0959
Epoch: [6]  [1200/2001]  eta: 0:08:27  lr: 0.000566  loss: 3.0935 (3.0731)  time: 0.6332  data: 0.0001  max mem: 8740
Epoch: [6]  [1210/2001]  eta: 0:08:21  lr: 0.000566  loss: 3.2690 (3.0752)  time: 0.6286  data: 0.0001  max mem: 8740
Epoch: [6]  [1220/2001]  eta: 0:08:15  lr: 0.000566  loss: 3.2690 (3.0759)  time: 0.6346  data: 0.0001  max mem: 8740
Epoch: [6]  [1230/2001]  eta: 0:08:08  lr: 0.000566  loss: 3.0153 (3.0751)  time: 0.6371  data: 0.0001  max mem: 8740
Epoch: [6]  [1240/2001]  eta: 0:08:02  lr: 0.000566  loss: 2.8748 (3.0723)  time: 0.6349  data: 0.0001  max mem: 8740
Epoch: [6]  [1250/2001]  eta: 0:07:56  lr: 0.000566  loss: 3.0680 (3.0731)  time: 0.6335  data: 0.0001  max mem: 8740
Epoch: [6]  [1260/2001]  eta: 0:07:49  lr: 0.000566  loss: 3.1991 (3.0728)  time: 0.6341  data: 0.0001  max mem: 8740
Epoch: [6]  [1270/2001]  eta: 0:07:43  lr: 0.000566  loss: 2.8881 (3.0708)  time: 0.6386  data: 0.0001  max mem: 8740
Epoch: [6]  [1280/2001]  eta: 0:07:37  lr: 0.000566  loss: 2.8881 (3.0709)  time: 0.6362  data: 0.0001  max mem: 8740
Epoch: [6]  [1290/2001]  eta: 0:07:30  lr: 0.000566  loss: 3.3635 (3.0722)  time: 0.6321  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9294, ratio_loss=0.0596, cls_kl=0.0682, token_kl=0.0959
Epoch: [6]  [1300/2001]  eta: 0:07:24  lr: 0.000566  loss: 3.1254 (3.0696)  time: 0.6362  data: 0.0001  max mem: 8740
Epoch: [6]  [1310/2001]  eta: 0:07:18  lr: 0.000566  loss: 2.7335 (3.0670)  time: 0.6415  data: 0.0001  max mem: 8740
Epoch: [6]  [1320/2001]  eta: 0:07:11  lr: 0.000566  loss: 2.9693 (3.0677)  time: 0.6383  data: 0.0001  max mem: 8740
Epoch: [6]  [1330/2001]  eta: 0:07:05  lr: 0.000566  loss: 3.2454 (3.0673)  time: 0.6347  data: 0.0001  max mem: 8740
Epoch: [6]  [1340/2001]  eta: 0:06:59  lr: 0.000566  loss: 3.2700 (3.0696)  time: 0.6351  data: 0.0001  max mem: 8740
Epoch: [6]  [1350/2001]  eta: 0:06:52  lr: 0.000566  loss: 3.3075 (3.0695)  time: 0.6348  data: 0.0001  max mem: 8740
Epoch: [6]  [1360/2001]  eta: 0:06:46  lr: 0.000566  loss: 3.1871 (3.0701)  time: 0.6337  data: 0.0001  max mem: 8740
Epoch: [6]  [1370/2001]  eta: 0:06:40  lr: 0.000566  loss: 3.2525 (3.0721)  time: 0.6356  data: 0.0001  max mem: 8740
Epoch: [6]  [1380/2001]  eta: 0:06:33  lr: 0.000566  loss: 3.3174 (3.0730)  time: 0.6401  data: 0.0001  max mem: 8740
Epoch: [6]  [1390/2001]  eta: 0:06:27  lr: 0.000566  loss: 3.0368 (3.0710)  time: 0.6374  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9339, ratio_loss=0.0571, cls_kl=0.0679, token_kl=0.0934
Epoch: [6]  [1400/2001]  eta: 0:06:21  lr: 0.000566  loss: 2.6969 (3.0681)  time: 0.6340  data: 0.0001  max mem: 8740
Epoch: [6]  [1410/2001]  eta: 0:06:14  lr: 0.000566  loss: 2.7654 (3.0679)  time: 0.6357  data: 0.0001  max mem: 8740
Epoch: [6]  [1420/2001]  eta: 0:06:08  lr: 0.000566  loss: 3.1140 (3.0665)  time: 0.6400  data: 0.0001  max mem: 8740
Epoch: [6]  [1430/2001]  eta: 0:06:02  lr: 0.000566  loss: 3.2614 (3.0693)  time: 0.6399  data: 0.0001  max mem: 8740
Epoch: [6]  [1440/2001]  eta: 0:05:55  lr: 0.000566  loss: 3.4290 (3.0712)  time: 0.6350  data: 0.0001  max mem: 8740
Epoch: [6]  [1450/2001]  eta: 0:05:49  lr: 0.000566  loss: 3.2451 (3.0710)  time: 0.6351  data: 0.0001  max mem: 8740
Epoch: [6]  [1460/2001]  eta: 0:05:43  lr: 0.000566  loss: 3.1914 (3.0721)  time: 0.6417  data: 0.0001  max mem: 8740
Epoch: [6]  [1470/2001]  eta: 0:05:36  lr: 0.000566  loss: 3.1914 (3.0721)  time: 0.6454  data: 0.0001  max mem: 8740
Epoch: [6]  [1480/2001]  eta: 0:05:30  lr: 0.000566  loss: 2.9458 (3.0707)  time: 0.6381  data: 0.0001  max mem: 8740
Epoch: [6]  [1490/2001]  eta: 0:05:24  lr: 0.000566  loss: 3.1707 (3.0718)  time: 0.6367  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9698, ratio_loss=0.0568, cls_kl=0.0671, token_kl=0.0931
Epoch: [6]  [1500/2001]  eta: 0:05:17  lr: 0.000566  loss: 3.2537 (3.0717)  time: 0.6429  data: 0.0001  max mem: 8740
Epoch: [6]  [1510/2001]  eta: 0:05:11  lr: 0.000566  loss: 3.0416 (3.0707)  time: 0.6437  data: 0.0001  max mem: 8740
Epoch: [6]  [1520/2001]  eta: 0:05:05  lr: 0.000566  loss: 2.8946 (3.0679)  time: 0.6408  data: 0.0001  max mem: 8740
Epoch: [6]  [1530/2001]  eta: 0:04:59  lr: 0.000566  loss: 3.0284 (3.0689)  time: 0.6423  data: 0.0001  max mem: 8740
Epoch: [6]  [1540/2001]  eta: 0:04:52  lr: 0.000566  loss: 3.1723 (3.0681)  time: 0.6474  data: 0.0001  max mem: 8740
Epoch: [6]  [1550/2001]  eta: 0:04:46  lr: 0.000566  loss: 3.1291 (3.0689)  time: 0.6422  data: 0.0001  max mem: 8740
Epoch: [6]  [1560/2001]  eta: 0:04:40  lr: 0.000566  loss: 2.9482 (3.0674)  time: 0.6351  data: 0.0001  max mem: 8740
Epoch: [6]  [1570/2001]  eta: 0:04:33  lr: 0.000566  loss: 2.8783 (3.0674)  time: 0.6365  data: 0.0001  max mem: 8740
Epoch: [6]  [1580/2001]  eta: 0:04:27  lr: 0.000566  loss: 3.2295 (3.0678)  time: 0.6378  data: 0.0001  max mem: 8740
Epoch: [6]  [1590/2001]  eta: 0:04:20  lr: 0.000566  loss: 2.8082 (3.0665)  time: 0.6392  data: 0.0001  max mem: 8740
loss info: cls_loss=2.8822, ratio_loss=0.0539, cls_kl=0.0668, token_kl=0.0939
Epoch: [6]  [1600/2001]  eta: 0:04:14  lr: 0.000566  loss: 2.8082 (3.0664)  time: 0.6381  data: 0.0001  max mem: 8740
Epoch: [6]  [1610/2001]  eta: 0:04:08  lr: 0.000566  loss: 3.1785 (3.0667)  time: 0.6378  data: 0.0001  max mem: 8740
Epoch: [6]  [1620/2001]  eta: 0:04:01  lr: 0.000566  loss: 3.2477 (3.0672)  time: 0.6392  data: 0.0001  max mem: 8740
Epoch: [6]  [1630/2001]  eta: 0:03:55  lr: 0.000566  loss: 3.2360 (3.0671)  time: 0.6375  data: 0.0002  max mem: 8740
Epoch: [6]  [1640/2001]  eta: 0:03:49  lr: 0.000566  loss: 2.9099 (3.0656)  time: 0.6351  data: 0.0002  max mem: 8740
Epoch: [6]  [1650/2001]  eta: 0:03:42  lr: 0.000566  loss: 2.6497 (3.0628)  time: 0.6415  data: 0.0001  max mem: 8740
Epoch: [6]  [1660/2001]  eta: 0:03:36  lr: 0.000566  loss: 2.8742 (3.0642)  time: 0.6412  data: 0.0001  max mem: 8740
Epoch: [6]  [1670/2001]  eta: 0:03:30  lr: 0.000566  loss: 3.3706 (3.0653)  time: 0.6333  data: 0.0001  max mem: 8740
Epoch: [6]  [1680/2001]  eta: 0:03:23  lr: 0.000566  loss: 3.2794 (3.0657)  time: 0.6342  data: 0.0001  max mem: 8740
Epoch: [6]  [1690/2001]  eta: 0:03:17  lr: 0.000566  loss: 3.2281 (3.0652)  time: 0.6375  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9200, ratio_loss=0.0521, cls_kl=0.0655, token_kl=0.0907
Epoch: [6]  [1700/2001]  eta: 0:03:11  lr: 0.000566  loss: 3.0020 (3.0642)  time: 0.6375  data: 0.0001  max mem: 8740
Epoch: [6]  [1710/2001]  eta: 0:03:04  lr: 0.000566  loss: 3.0125 (3.0649)  time: 0.6324  data: 0.0001  max mem: 8740
Epoch: [6]  [1720/2001]  eta: 0:02:58  lr: 0.000566  loss: 3.2023 (3.0657)  time: 0.6328  data: 0.0001  max mem: 8740
Epoch: [6]  [1730/2001]  eta: 0:02:52  lr: 0.000566  loss: 3.1983 (3.0651)  time: 0.6352  data: 0.0001  max mem: 8740
Epoch: [6]  [1740/2001]  eta: 0:02:45  lr: 0.000566  loss: 3.2153 (3.0658)  time: 0.6324  data: 0.0001  max mem: 8740
Epoch: [6]  [1750/2001]  eta: 0:02:39  lr: 0.000566  loss: 3.2153 (3.0667)  time: 0.6318  data: 0.0001  max mem: 8740
Epoch: [6]  [1760/2001]  eta: 0:02:33  lr: 0.000566  loss: 3.2623 (3.0673)  time: 0.6370  data: 0.0001  max mem: 8740
Epoch: [6]  [1770/2001]  eta: 0:02:26  lr: 0.000566  loss: 3.2623 (3.0681)  time: 0.6379  data: 0.0001  max mem: 8740
Epoch: [6]  [1780/2001]  eta: 0:02:20  lr: 0.000566  loss: 3.2985 (3.0679)  time: 0.6348  data: 0.0001  max mem: 8740
Epoch: [6]  [1790/2001]  eta: 0:02:14  lr: 0.000566  loss: 3.2714 (3.0689)  time: 0.6360  data: 0.0002  max mem: 8740
loss info: cls_loss=3.0178, ratio_loss=0.0603, cls_kl=0.0696, token_kl=0.0956
Epoch: [6]  [1800/2001]  eta: 0:02:07  lr: 0.000566  loss: 3.1259 (3.0695)  time: 0.6378  data: 0.0002  max mem: 8740
Epoch: [6]  [1810/2001]  eta: 0:02:01  lr: 0.000566  loss: 3.0426 (3.0677)  time: 0.6347  data: 0.0001  max mem: 8740
Epoch: [6]  [1820/2001]  eta: 0:01:54  lr: 0.000566  loss: 2.8884 (3.0680)  time: 0.6284  data: 0.0003  max mem: 8740
Epoch: [6]  [1830/2001]  eta: 0:01:48  lr: 0.000566  loss: 3.0471 (3.0674)  time: 0.6262  data: 0.0003  max mem: 8740
Epoch: [6]  [1840/2001]  eta: 0:01:42  lr: 0.000566  loss: 3.2329 (3.0678)  time: 0.6335  data: 0.0001  max mem: 8740
Epoch: [6]  [1850/2001]  eta: 0:01:35  lr: 0.000566  loss: 3.2377 (3.0688)  time: 0.6340  data: 0.0001  max mem: 8740
Epoch: [6]  [1860/2001]  eta: 0:01:29  lr: 0.000566  loss: 3.1532 (3.0687)  time: 0.6279  data: 0.0001  max mem: 8740
Epoch: [6]  [1870/2001]  eta: 0:01:23  lr: 0.000566  loss: 3.1573 (3.0694)  time: 0.6265  data: 0.0001  max mem: 8740
Epoch: [6]  [1880/2001]  eta: 0:01:16  lr: 0.000566  loss: 3.1573 (3.0683)  time: 0.6319  data: 0.0001  max mem: 8740
Epoch: [6]  [1890/2001]  eta: 0:01:10  lr: 0.000566  loss: 3.1628 (3.0683)  time: 0.6319  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9343, ratio_loss=0.0556, cls_kl=0.0677, token_kl=0.0941
Epoch: [6]  [1900/2001]  eta: 0:01:04  lr: 0.000566  loss: 3.1628 (3.0677)  time: 0.6241  data: 0.0001  max mem: 8740
Epoch: [6]  [1910/2001]  eta: 0:00:57  lr: 0.000566  loss: 3.1244 (3.0679)  time: 0.6277  data: 0.0001  max mem: 8740
Epoch: [6]  [1920/2001]  eta: 0:00:51  lr: 0.000566  loss: 3.1198 (3.0669)  time: 0.6280  data: 0.0002  max mem: 8740
Epoch: [6]  [1930/2001]  eta: 0:00:45  lr: 0.000566  loss: 2.8775 (3.0670)  time: 0.6247  data: 0.0002  max mem: 8740
Epoch: [6]  [1940/2001]  eta: 0:00:38  lr: 0.000566  loss: 3.1359 (3.0670)  time: 0.6246  data: 0.0001  max mem: 8740
Epoch: [6]  [1950/2001]  eta: 0:00:32  lr: 0.000566  loss: 3.1359 (3.0663)  time: 0.6238  data: 0.0001  max mem: 8740
Epoch: [6]  [1960/2001]  eta: 0:00:26  lr: 0.000566  loss: 2.9595 (3.0658)  time: 0.6250  data: 0.0001  max mem: 8740
Epoch: [6]  [1970/2001]  eta: 0:00:19  lr: 0.000566  loss: 2.9856 (3.0650)  time: 0.6235  data: 0.0001  max mem: 8740
Epoch: [6]  [1980/2001]  eta: 0:00:13  lr: 0.000566  loss: 3.2792 (3.0666)  time: 0.6210  data: 0.0001  max mem: 8740
Epoch: [6]  [1990/2001]  eta: 0:00:06  lr: 0.000566  loss: 3.3802 (3.0678)  time: 0.6203  data: 0.0004  max mem: 8740
loss info: cls_loss=2.9482, ratio_loss=0.0547, cls_kl=0.0674, token_kl=0.0929
Epoch: [6]  [2000/2001]  eta: 0:00:00  lr: 0.000566  loss: 3.2846 (3.0688)  time: 0.6183  data: 0.0003  max mem: 8740
Epoch: [6] Total time: 0:21:09 (0.6345 s / it)
Averaged stats: lr: 0.000566  loss: 3.2846 (3.0797)
Test:  [ 0/53]  eta: 0:04:41  loss: 0.3459 (0.3459)  acc1: 94.1667 (94.1667)  acc5: 100.0000 (100.0000)  time: 5.3042  data: 4.6486  max mem: 8740
Test:  [10/53]  eta: 0:00:38  loss: 0.7424 (0.7801)  acc1: 81.6667 (82.9546)  acc5: 96.6667 (96.1364)  time: 0.9014  data: 0.5048  max mem: 8740
Test:  [20/53]  eta: 0:00:20  loss: 0.7394 (0.7743)  acc1: 81.6667 (82.9365)  acc5: 95.8333 (96.4683)  time: 0.4000  data: 0.0458  max mem: 8740
Test:  [30/53]  eta: 0:00:12  loss: 0.8704 (0.8593)  acc1: 77.5000 (80.6183)  acc5: 95.0000 (95.4839)  time: 0.3315  data: 0.0047  max mem: 8740
Test:  [40/53]  eta: 0:00:06  loss: 1.1166 (0.9287)  acc1: 74.1667 (79.1463)  acc5: 92.5000 (94.6748)  time: 0.2941  data: 0.0042  max mem: 8740
Test:  [50/53]  eta: 0:00:01  loss: 1.0980 (0.9592)  acc1: 75.0000 (78.3660)  acc5: 92.5000 (94.3301)  time: 0.2587  data: 0.0001  max mem: 8740
Test:  [52/53]  eta: 0:00:00  loss: 1.0808 (0.9436)  acc1: 75.8333 (78.5440)  acc5: 92.5000 (94.4000)  time: 0.2461  data: 0.0000  max mem: 8740
Test: Total time: 0:00:22 (0.4177 s / it)
Sparsity0:0.2764056565656566,Sparsity1:0.5341081407035176,Sparsity2:0.7741432,
* Acc@1 78.886 Acc@5 94.470 loss 0.945
Accuracy of the network on the 50000 test images: 78.9%
Max accuracy: 78.89%
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0005460 for PREDICTOR
Epoch: [7]  [   0/2001]  eta: 2:42:22  lr: 0.000546  loss: 2.2692 (2.2692)  time: 4.8690  data: 4.2614  max mem: 8740
Epoch: [7]  [  10/2001]  eta: 0:32:59  lr: 0.000546  loss: 3.1870 (3.0664)  time: 0.9944  data: 0.3875  max mem: 8740
Epoch: [7]  [  20/2001]  eta: 0:26:49  lr: 0.000546  loss: 3.1889 (3.2034)  time: 0.6094  data: 0.0001  max mem: 8740
Epoch: [7]  [  30/2001]  eta: 0:24:32  lr: 0.000546  loss: 3.1889 (3.1770)  time: 0.6108  data: 0.0001  max mem: 8740
Epoch: [7]  [  40/2001]  eta: 0:23:20  lr: 0.000546  loss: 3.0649 (3.1626)  time: 0.6111  data: 0.0001  max mem: 8740
Epoch: [7]  [  50/2001]  eta: 0:22:34  lr: 0.000546  loss: 3.0585 (3.1240)  time: 0.6127  data: 0.0001  max mem: 8740
Epoch: [7]  [  60/2001]  eta: 0:22:02  lr: 0.000546  loss: 3.1885 (3.1511)  time: 0.6137  data: 0.0001  max mem: 8740
Epoch: [7]  [  70/2001]  eta: 0:21:38  lr: 0.000546  loss: 3.3437 (3.1624)  time: 0.6176  data: 0.0001  max mem: 8740
Epoch: [7]  [  80/2001]  eta: 0:21:20  lr: 0.000546  loss: 3.3486 (3.1850)  time: 0.6217  data: 0.0001  max mem: 8740
Epoch: [7]  [  90/2001]  eta: 0:21:04  lr: 0.000546  loss: 3.2098 (3.1768)  time: 0.6231  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0597, ratio_loss=0.0599, cls_kl=0.0704, token_kl=0.0961
Epoch: [7]  [ 100/2001]  eta: 0:20:51  lr: 0.000546  loss: 3.0288 (3.1499)  time: 0.6248  data: 0.0001  max mem: 8740
Epoch: [7]  [ 110/2001]  eta: 0:20:40  lr: 0.000546  loss: 2.6858 (3.1258)  time: 0.6295  data: 0.0001  max mem: 8740
Epoch: [7]  [ 120/2001]  eta: 0:20:29  lr: 0.000546  loss: 3.0634 (3.1266)  time: 0.6295  data: 0.0001  max mem: 8740
Epoch: [7]  [ 130/2001]  eta: 0:20:18  lr: 0.000546  loss: 3.1661 (3.1266)  time: 0.6261  data: 0.0001  max mem: 8740
Epoch: [7]  [ 140/2001]  eta: 0:20:08  lr: 0.000546  loss: 3.4254 (3.1484)  time: 0.6251  data: 0.0001  max mem: 8740
Epoch: [7]  [ 150/2001]  eta: 0:19:59  lr: 0.000546  loss: 3.2799 (3.1416)  time: 0.6252  data: 0.0001  max mem: 8740
Epoch: [7]  [ 160/2001]  eta: 0:19:51  lr: 0.000546  loss: 3.1551 (3.1312)  time: 0.6292  data: 0.0001  max mem: 8740
Epoch: [7]  [ 170/2001]  eta: 0:19:42  lr: 0.000546  loss: 2.8224 (3.1148)  time: 0.6294  data: 0.0001  max mem: 8740
Epoch: [7]  [ 180/2001]  eta: 0:19:34  lr: 0.000546  loss: 3.0167 (3.1170)  time: 0.6279  data: 0.0001  max mem: 8740
Epoch: [7]  [ 190/2001]  eta: 0:19:26  lr: 0.000546  loss: 3.2861 (3.1235)  time: 0.6281  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9652, ratio_loss=0.0570, cls_kl=0.0675, token_kl=0.0957
Epoch: [7]  [ 200/2001]  eta: 0:19:18  lr: 0.000546  loss: 3.0550 (3.1101)  time: 0.6280  data: 0.0001  max mem: 8740
Epoch: [7]  [ 210/2001]  eta: 0:19:11  lr: 0.000546  loss: 2.8052 (3.0967)  time: 0.6357  data: 0.0001  max mem: 8740
Epoch: [7]  [ 220/2001]  eta: 0:19:03  lr: 0.000546  loss: 3.0714 (3.0884)  time: 0.6327  data: 0.0001  max mem: 8740
Epoch: [7]  [ 230/2001]  eta: 0:18:56  lr: 0.000546  loss: 3.1611 (3.0860)  time: 0.6255  data: 0.0001  max mem: 8740
Epoch: [7]  [ 240/2001]  eta: 0:18:49  lr: 0.000546  loss: 3.1611 (3.0861)  time: 0.6319  data: 0.0001  max mem: 8740
Epoch: [7]  [ 250/2001]  eta: 0:18:42  lr: 0.000546  loss: 3.1235 (3.0854)  time: 0.6351  data: 0.0001  max mem: 8740
Epoch: [7]  [ 260/2001]  eta: 0:18:35  lr: 0.000546  loss: 3.1343 (3.0820)  time: 0.6313  data: 0.0001  max mem: 8740
Epoch: [7]  [ 270/2001]  eta: 0:18:27  lr: 0.000546  loss: 3.1180 (3.0861)  time: 0.6271  data: 0.0001  max mem: 8740
Epoch: [7]  [ 280/2001]  eta: 0:18:20  lr: 0.000546  loss: 3.1744 (3.0888)  time: 0.6250  data: 0.0001  max mem: 8740
Epoch: [7]  [ 290/2001]  eta: 0:18:13  lr: 0.000546  loss: 3.1030 (3.0880)  time: 0.6250  data: 0.0001  max mem: 8740
loss info: cls_loss=2.8928, ratio_loss=0.0533, cls_kl=0.0669, token_kl=0.0930
Epoch: [7]  [ 300/2001]  eta: 0:18:06  lr: 0.000546  loss: 3.0306 (3.0837)  time: 0.6264  data: 0.0001  max mem: 8740
Epoch: [7]  [ 310/2001]  eta: 0:17:59  lr: 0.000546  loss: 3.0306 (3.0826)  time: 0.6274  data: 0.0001  max mem: 8740
Epoch: [7]  [ 320/2001]  eta: 0:17:52  lr: 0.000546  loss: 3.1997 (3.0845)  time: 0.6276  data: 0.0001  max mem: 8740
Epoch: [7]  [ 330/2001]  eta: 0:17:45  lr: 0.000546  loss: 3.1452 (3.0846)  time: 0.6278  data: 0.0001  max mem: 8740
Epoch: [7]  [ 340/2001]  eta: 0:17:38  lr: 0.000546  loss: 3.0949 (3.0860)  time: 0.6271  data: 0.0001  max mem: 8740
Epoch: [7]  [ 350/2001]  eta: 0:17:32  lr: 0.000546  loss: 3.2103 (3.0844)  time: 0.6319  data: 0.0001  max mem: 8740
Epoch: [7]  [ 360/2001]  eta: 0:17:25  lr: 0.000546  loss: 3.2331 (3.0896)  time: 0.6350  data: 0.0001  max mem: 8740
Epoch: [7]  [ 370/2001]  eta: 0:17:19  lr: 0.000546  loss: 3.3188 (3.0904)  time: 0.6340  data: 0.0001  max mem: 8740
Epoch: [7]  [ 380/2001]  eta: 0:17:12  lr: 0.000546  loss: 3.0756 (3.0881)  time: 0.6323  data: 0.0001  max mem: 8740
Epoch: [7]  [ 390/2001]  eta: 0:17:05  lr: 0.000546  loss: 3.2236 (3.0951)  time: 0.6317  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0077, ratio_loss=0.0569, cls_kl=0.0695, token_kl=0.0949
Epoch: [7]  [ 400/2001]  eta: 0:16:59  lr: 0.000546  loss: 3.3846 (3.0984)  time: 0.6303  data: 0.0001  max mem: 8740
Epoch: [7]  [ 410/2001]  eta: 0:16:53  lr: 0.000546  loss: 3.2588 (3.0968)  time: 0.6365  data: 0.0001  max mem: 8740
Epoch: [7]  [ 420/2001]  eta: 0:16:46  lr: 0.000546  loss: 3.3137 (3.1026)  time: 0.6377  data: 0.0001  max mem: 8740
Epoch: [7]  [ 430/2001]  eta: 0:16:39  lr: 0.000546  loss: 3.3538 (3.1050)  time: 0.6283  data: 0.0001  max mem: 8740
Epoch: [7]  [ 440/2001]  eta: 0:16:33  lr: 0.000546  loss: 3.1691 (3.1025)  time: 0.6269  data: 0.0001  max mem: 8740
Epoch: [7]  [ 450/2001]  eta: 0:16:26  lr: 0.000546  loss: 3.3570 (3.1058)  time: 0.6282  data: 0.0001  max mem: 8740
Epoch: [7]  [ 460/2001]  eta: 0:16:20  lr: 0.000546  loss: 3.3856 (3.1080)  time: 0.6324  data: 0.0001  max mem: 8740
Epoch: [7]  [ 470/2001]  eta: 0:16:13  lr: 0.000546  loss: 3.3143 (3.1115)  time: 0.6366  data: 0.0001  max mem: 8740
Epoch: [7]  [ 480/2001]  eta: 0:16:07  lr: 0.000546  loss: 3.2769 (3.1122)  time: 0.6365  data: 0.0001  max mem: 8740
Epoch: [7]  [ 490/2001]  eta: 0:16:00  lr: 0.000546  loss: 3.1980 (3.1137)  time: 0.6307  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0503, ratio_loss=0.0589, cls_kl=0.0705, token_kl=0.0965
Epoch: [7]  [ 500/2001]  eta: 0:15:54  lr: 0.000546  loss: 3.0979 (3.1121)  time: 0.6270  data: 0.0001  max mem: 8740
Epoch: [7]  [ 510/2001]  eta: 0:15:47  lr: 0.000546  loss: 3.2707 (3.1148)  time: 0.6279  data: 0.0001  max mem: 8740
Epoch: [7]  [ 520/2001]  eta: 0:15:41  lr: 0.000546  loss: 3.2707 (3.1154)  time: 0.6327  data: 0.0001  max mem: 8740
Epoch: [7]  [ 530/2001]  eta: 0:15:34  lr: 0.000546  loss: 3.2287 (3.1152)  time: 0.6350  data: 0.0001  max mem: 8740
Epoch: [7]  [ 540/2001]  eta: 0:15:28  lr: 0.000546  loss: 2.9271 (3.1099)  time: 0.6330  data: 0.0001  max mem: 8740
Epoch: [7]  [ 550/2001]  eta: 0:15:21  lr: 0.000546  loss: 3.2029 (3.1157)  time: 0.6318  data: 0.0001  max mem: 8740
Epoch: [7]  [ 560/2001]  eta: 0:15:15  lr: 0.000546  loss: 3.3101 (3.1131)  time: 0.6326  data: 0.0001  max mem: 8740
Epoch: [7]  [ 570/2001]  eta: 0:15:09  lr: 0.000546  loss: 3.1537 (3.1124)  time: 0.6353  data: 0.0001  max mem: 8740
Epoch: [7]  [ 580/2001]  eta: 0:15:02  lr: 0.000546  loss: 3.1537 (3.1122)  time: 0.6332  data: 0.0001  max mem: 8740
Epoch: [7]  [ 590/2001]  eta: 0:14:56  lr: 0.000546  loss: 3.1625 (3.1122)  time: 0.6295  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9919, ratio_loss=0.0603, cls_kl=0.0708, token_kl=0.0969
Epoch: [7]  [ 600/2001]  eta: 0:14:49  lr: 0.000546  loss: 3.3141 (3.1142)  time: 0.6293  data: 0.0001  max mem: 8740
Epoch: [7]  [ 610/2001]  eta: 0:14:43  lr: 0.000546  loss: 3.2569 (3.1169)  time: 0.6334  data: 0.0001  max mem: 8740
Epoch: [7]  [ 620/2001]  eta: 0:14:37  lr: 0.000546  loss: 3.2569 (3.1160)  time: 0.6417  data: 0.0001  max mem: 8740
Epoch: [7]  [ 630/2001]  eta: 0:14:30  lr: 0.000546  loss: 3.1337 (3.1141)  time: 0.6374  data: 0.0001  max mem: 8740
Epoch: [7]  [ 640/2001]  eta: 0:14:24  lr: 0.000546  loss: 3.0722 (3.1083)  time: 0.6289  data: 0.0001  max mem: 8740
Epoch: [7]  [ 650/2001]  eta: 0:14:17  lr: 0.000546  loss: 3.0780 (3.1115)  time: 0.6308  data: 0.0001  max mem: 8740
Epoch: [7]  [ 660/2001]  eta: 0:14:11  lr: 0.000546  loss: 3.2120 (3.1089)  time: 0.6352  data: 0.0001  max mem: 8740
Epoch: [7]  [ 670/2001]  eta: 0:14:05  lr: 0.000546  loss: 2.9996 (3.1040)  time: 0.6401  data: 0.0001  max mem: 8740
Epoch: [7]  [ 680/2001]  eta: 0:13:59  lr: 0.000546  loss: 3.0290 (3.1021)  time: 0.6360  data: 0.0001  max mem: 8740
Epoch: [7]  [ 690/2001]  eta: 0:13:52  lr: 0.000546  loss: 2.6649 (3.0935)  time: 0.6305  data: 0.0001  max mem: 8740
loss info: cls_loss=2.8561, ratio_loss=0.0549, cls_kl=0.0661, token_kl=0.0922
Epoch: [7]  [ 700/2001]  eta: 0:13:46  lr: 0.000546  loss: 2.6649 (3.0939)  time: 0.6318  data: 0.0001  max mem: 8740
Epoch: [7]  [ 710/2001]  eta: 0:13:39  lr: 0.000546  loss: 3.1160 (3.0933)  time: 0.6332  data: 0.0001  max mem: 8740
Epoch: [7]  [ 720/2001]  eta: 0:13:33  lr: 0.000546  loss: 3.0278 (3.0887)  time: 0.6344  data: 0.0001  max mem: 8740
Epoch: [7]  [ 730/2001]  eta: 0:13:27  lr: 0.000546  loss: 3.1255 (3.0894)  time: 0.6356  data: 0.0001  max mem: 8740
Epoch: [7]  [ 740/2001]  eta: 0:13:20  lr: 0.000546  loss: 3.3116 (3.0895)  time: 0.6364  data: 0.0001  max mem: 8740
Epoch: [7]  [ 750/2001]  eta: 0:13:14  lr: 0.000546  loss: 3.1374 (3.0894)  time: 0.6342  data: 0.0001  max mem: 8740
Epoch: [7]  [ 760/2001]  eta: 0:13:08  lr: 0.000546  loss: 3.0924 (3.0864)  time: 0.6342  data: 0.0001  max mem: 8740
Epoch: [7]  [ 770/2001]  eta: 0:13:01  lr: 0.000546  loss: 2.8441 (3.0832)  time: 0.6355  data: 0.0001  max mem: 8740
Epoch: [7]  [ 780/2001]  eta: 0:12:55  lr: 0.000546  loss: 3.0507 (3.0845)  time: 0.6396  data: 0.0001  max mem: 8740
Epoch: [7]  [ 790/2001]  eta: 0:12:49  lr: 0.000546  loss: 3.2363 (3.0865)  time: 0.6391  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9302, ratio_loss=0.0551, cls_kl=0.0642, token_kl=0.0925
Epoch: [7]  [ 800/2001]  eta: 0:12:42  lr: 0.000546  loss: 3.2975 (3.0874)  time: 0.6341  data: 0.0001  max mem: 8740
Epoch: [7]  [ 810/2001]  eta: 0:12:36  lr: 0.000546  loss: 3.1073 (3.0853)  time: 0.6399  data: 0.0001  max mem: 8740
Epoch: [7]  [ 820/2001]  eta: 0:12:30  lr: 0.000546  loss: 2.8275 (3.0832)  time: 0.6472  data: 0.0001  max mem: 8740
Epoch: [7]  [ 830/2001]  eta: 0:12:24  lr: 0.000546  loss: 3.2992 (3.0853)  time: 0.6415  data: 0.0001  max mem: 8740
Epoch: [7]  [ 840/2001]  eta: 0:12:17  lr: 0.000546  loss: 3.3014 (3.0865)  time: 0.6327  data: 0.0001  max mem: 8740
Epoch: [7]  [ 850/2001]  eta: 0:12:11  lr: 0.000546  loss: 3.0710 (3.0850)  time: 0.6320  data: 0.0001  max mem: 8740
Epoch: [7]  [ 860/2001]  eta: 0:12:04  lr: 0.000546  loss: 3.0710 (3.0876)  time: 0.6332  data: 0.0001  max mem: 8740
Epoch: [7]  [ 870/2001]  eta: 0:11:58  lr: 0.000546  loss: 3.1389 (3.0866)  time: 0.6383  data: 0.0001  max mem: 8740
Epoch: [7]  [ 880/2001]  eta: 0:11:52  lr: 0.000546  loss: 3.0718 (3.0850)  time: 0.6418  data: 0.0001  max mem: 8740
Epoch: [7]  [ 890/2001]  eta: 0:11:45  lr: 0.000546  loss: 2.9346 (3.0834)  time: 0.6374  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9474, ratio_loss=0.0540, cls_kl=0.0667, token_kl=0.0938
Epoch: [7]  [ 900/2001]  eta: 0:11:39  lr: 0.000546  loss: 3.3122 (3.0857)  time: 0.6338  data: 0.0001  max mem: 8740
Epoch: [7]  [ 910/2001]  eta: 0:11:33  lr: 0.000546  loss: 3.2327 (3.0851)  time: 0.6341  data: 0.0001  max mem: 8740
Epoch: [7]  [ 920/2001]  eta: 0:11:26  lr: 0.000546  loss: 3.2326 (3.0848)  time: 0.6340  data: 0.0001  max mem: 8740
Epoch: [7]  [ 930/2001]  eta: 0:11:20  lr: 0.000546  loss: 3.1625 (3.0830)  time: 0.6380  data: 0.0001  max mem: 8740
Epoch: [7]  [ 940/2001]  eta: 0:11:14  lr: 0.000546  loss: 3.2540 (3.0848)  time: 0.6391  data: 0.0001  max mem: 8740
Epoch: [7]  [ 950/2001]  eta: 0:11:07  lr: 0.000546  loss: 3.2540 (3.0849)  time: 0.6351  data: 0.0001  max mem: 8740
Epoch: [7]  [ 960/2001]  eta: 0:11:01  lr: 0.000546  loss: 3.0157 (3.0854)  time: 0.6342  data: 0.0001  max mem: 8740
Epoch: [7]  [ 970/2001]  eta: 0:10:55  lr: 0.000546  loss: 2.9226 (3.0840)  time: 0.6388  data: 0.0001  max mem: 8740
Epoch: [7]  [ 980/2001]  eta: 0:10:48  lr: 0.000546  loss: 3.1658 (3.0850)  time: 0.6394  data: 0.0001  max mem: 8740
Epoch: [7]  [ 990/2001]  eta: 0:10:42  lr: 0.000546  loss: 3.2049 (3.0845)  time: 0.6345  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9675, ratio_loss=0.0568, cls_kl=0.0689, token_kl=0.0951
Epoch: [7]  [1000/2001]  eta: 0:10:36  lr: 0.000546  loss: 3.2049 (3.0853)  time: 0.6344  data: 0.0001  max mem: 8740
Epoch: [7]  [1010/2001]  eta: 0:10:29  lr: 0.000546  loss: 3.2586 (3.0845)  time: 0.6341  data: 0.0001  max mem: 8740
Epoch: [7]  [1020/2001]  eta: 0:10:23  lr: 0.000546  loss: 2.9379 (3.0842)  time: 0.6350  data: 0.0001  max mem: 8740
Epoch: [7]  [1030/2001]  eta: 0:10:17  lr: 0.000546  loss: 3.0461 (3.0840)  time: 0.6419  data: 0.0001  max mem: 8740
Epoch: [7]  [1040/2001]  eta: 0:10:10  lr: 0.000546  loss: 3.2548 (3.0833)  time: 0.6414  data: 0.0001  max mem: 8740
Epoch: [7]  [1050/2001]  eta: 0:10:04  lr: 0.000546  loss: 2.9696 (3.0816)  time: 0.6357  data: 0.0001  max mem: 8740
Epoch: [7]  [1060/2001]  eta: 0:09:58  lr: 0.000546  loss: 2.9009 (3.0780)  time: 0.6353  data: 0.0001  max mem: 8740
Epoch: [7]  [1070/2001]  eta: 0:09:51  lr: 0.000546  loss: 2.9355 (3.0790)  time: 0.6354  data: 0.0001  max mem: 8740
Epoch: [7]  [1080/2001]  eta: 0:09:45  lr: 0.000546  loss: 3.1959 (3.0784)  time: 0.6417  data: 0.0001  max mem: 8740
Epoch: [7]  [1090/2001]  eta: 0:09:39  lr: 0.000546  loss: 3.2647 (3.0801)  time: 0.6439  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9109, ratio_loss=0.0567, cls_kl=0.0669, token_kl=0.0957
Epoch: [7]  [1100/2001]  eta: 0:09:32  lr: 0.000546  loss: 3.1733 (3.0792)  time: 0.6371  data: 0.0001  max mem: 8740
Epoch: [7]  [1110/2001]  eta: 0:09:26  lr: 0.000546  loss: 3.1120 (3.0807)  time: 0.6352  data: 0.0001  max mem: 8740
Epoch: [7]  [1120/2001]  eta: 0:09:20  lr: 0.000546  loss: 3.0690 (3.0801)  time: 0.6369  data: 0.0001  max mem: 8740
Epoch: [7]  [1130/2001]  eta: 0:09:13  lr: 0.000546  loss: 2.9906 (3.0796)  time: 0.6368  data: 0.0001  max mem: 8740
Epoch: [7]  [1140/2001]  eta: 0:09:07  lr: 0.000546  loss: 3.2732 (3.0804)  time: 0.6334  data: 0.0001  max mem: 8740
Epoch: [7]  [1150/2001]  eta: 0:09:00  lr: 0.000546  loss: 3.2732 (3.0823)  time: 0.6301  data: 0.0001  max mem: 8740
Epoch: [7]  [1160/2001]  eta: 0:08:54  lr: 0.000546  loss: 3.2369 (3.0825)  time: 0.6304  data: 0.0001  max mem: 8740
Epoch: [7]  [1170/2001]  eta: 0:08:48  lr: 0.000546  loss: 3.1710 (3.0823)  time: 0.6313  data: 0.0001  max mem: 8740
Epoch: [7]  [1180/2001]  eta: 0:08:41  lr: 0.000546  loss: 3.1112 (3.0829)  time: 0.6396  data: 0.0001  max mem: 8740
Epoch: [7]  [1190/2001]  eta: 0:08:35  lr: 0.000546  loss: 3.1919 (3.0820)  time: 0.6395  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9909, ratio_loss=0.0564, cls_kl=0.0685, token_kl=0.0943
Epoch: [7]  [1200/2001]  eta: 0:08:29  lr: 0.000546  loss: 3.0468 (3.0814)  time: 0.6309  data: 0.0001  max mem: 8740
Epoch: [7]  [1210/2001]  eta: 0:08:22  lr: 0.000546  loss: 3.1068 (3.0813)  time: 0.6302  data: 0.0001  max mem: 8740
Epoch: [7]  [1220/2001]  eta: 0:08:16  lr: 0.000546  loss: 3.2062 (3.0815)  time: 0.6290  data: 0.0001  max mem: 8740
Epoch: [7]  [1230/2001]  eta: 0:08:10  lr: 0.000546  loss: 3.2094 (3.0818)  time: 0.6353  data: 0.0001  max mem: 8740
Epoch: [7]  [1240/2001]  eta: 0:08:03  lr: 0.000546  loss: 3.1938 (3.0819)  time: 0.6391  data: 0.0001  max mem: 8740
Epoch: [7]  [1250/2001]  eta: 0:07:57  lr: 0.000546  loss: 3.1938 (3.0817)  time: 0.6322  data: 0.0001  max mem: 8740
Epoch: [7]  [1260/2001]  eta: 0:07:50  lr: 0.000546  loss: 3.0779 (3.0815)  time: 0.6290  data: 0.0001  max mem: 8740
Epoch: [7]  [1270/2001]  eta: 0:07:44  lr: 0.000546  loss: 3.1742 (3.0824)  time: 0.6290  data: 0.0001  max mem: 8740
Epoch: [7]  [1280/2001]  eta: 0:07:38  lr: 0.000546  loss: 3.2849 (3.0814)  time: 0.6332  data: 0.0001  max mem: 8740
Epoch: [7]  [1290/2001]  eta: 0:07:31  lr: 0.000546  loss: 3.2075 (3.0839)  time: 0.6352  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9821, ratio_loss=0.0547, cls_kl=0.0675, token_kl=0.0923
Epoch: [7]  [1300/2001]  eta: 0:07:25  lr: 0.000546  loss: 3.0157 (3.0813)  time: 0.6300  data: 0.0001  max mem: 8740
Epoch: [7]  [1310/2001]  eta: 0:07:18  lr: 0.000546  loss: 2.8176 (3.0810)  time: 0.6269  data: 0.0001  max mem: 8740
Epoch: [7]  [1320/2001]  eta: 0:07:12  lr: 0.000546  loss: 3.1300 (3.0790)  time: 0.6275  data: 0.0001  max mem: 8740
Epoch: [7]  [1330/2001]  eta: 0:07:06  lr: 0.000546  loss: 2.8739 (3.0786)  time: 0.6277  data: 0.0001  max mem: 8740
Epoch: [7]  [1340/2001]  eta: 0:06:59  lr: 0.000546  loss: 3.1117 (3.0786)  time: 0.6301  data: 0.0001  max mem: 8740
Epoch: [7]  [1350/2001]  eta: 0:06:53  lr: 0.000546  loss: 3.2154 (3.0798)  time: 0.6313  data: 0.0001  max mem: 8740
Epoch: [7]  [1360/2001]  eta: 0:06:47  lr: 0.000546  loss: 3.3121 (3.0801)  time: 0.6286  data: 0.0001  max mem: 8740
Epoch: [7]  [1370/2001]  eta: 0:06:40  lr: 0.000546  loss: 3.3053 (3.0822)  time: 0.6278  data: 0.0001  max mem: 8740
Epoch: [7]  [1380/2001]  eta: 0:06:34  lr: 0.000546  loss: 3.2066 (3.0818)  time: 0.6278  data: 0.0001  max mem: 8740
Epoch: [7]  [1390/2001]  eta: 0:06:27  lr: 0.000546  loss: 2.9041 (3.0789)  time: 0.6312  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9093, ratio_loss=0.0521, cls_kl=0.0679, token_kl=0.0937
Epoch: [7]  [1400/2001]  eta: 0:06:21  lr: 0.000546  loss: 2.7339 (3.0779)  time: 0.6319  data: 0.0001  max mem: 8740
Epoch: [7]  [1410/2001]  eta: 0:06:15  lr: 0.000546  loss: 3.1195 (3.0782)  time: 0.6280  data: 0.0001  max mem: 8740
Epoch: [7]  [1420/2001]  eta: 0:06:08  lr: 0.000546  loss: 3.0853 (3.0761)  time: 0.6263  data: 0.0001  max mem: 8740
Epoch: [7]  [1430/2001]  eta: 0:06:02  lr: 0.000546  loss: 2.8812 (3.0761)  time: 0.6319  data: 0.0001  max mem: 8740
Epoch: [7]  [1440/2001]  eta: 0:05:56  lr: 0.000546  loss: 3.1177 (3.0769)  time: 0.6334  data: 0.0001  max mem: 8740
Epoch: [7]  [1450/2001]  eta: 0:05:49  lr: 0.000546  loss: 3.1177 (3.0765)  time: 0.6306  data: 0.0001  max mem: 8740
Epoch: [7]  [1460/2001]  eta: 0:05:43  lr: 0.000546  loss: 3.0014 (3.0749)  time: 0.6275  data: 0.0001  max mem: 8740
Epoch: [7]  [1470/2001]  eta: 0:05:36  lr: 0.000546  loss: 2.7915 (3.0730)  time: 0.6250  data: 0.0001  max mem: 8740
Epoch: [7]  [1480/2001]  eta: 0:05:30  lr: 0.000546  loss: 2.9638 (3.0734)  time: 0.6245  data: 0.0001  max mem: 8740
Epoch: [7]  [1490/2001]  eta: 0:05:24  lr: 0.000546  loss: 3.3144 (3.0747)  time: 0.6236  data: 0.0001  max mem: 8740
loss info: cls_loss=2.8893, ratio_loss=0.0545, cls_kl=0.0660, token_kl=0.0946
Epoch: [7]  [1500/2001]  eta: 0:05:17  lr: 0.000546  loss: 3.3144 (3.0741)  time: 0.6334  data: 0.0001  max mem: 8740
Epoch: [7]  [1510/2001]  eta: 0:05:11  lr: 0.000546  loss: 3.3223 (3.0744)  time: 0.6305  data: 0.0001  max mem: 8740
Epoch: [7]  [1520/2001]  eta: 0:05:05  lr: 0.000546  loss: 3.3320 (3.0763)  time: 0.6223  data: 0.0001  max mem: 8740
Epoch: [7]  [1530/2001]  eta: 0:04:58  lr: 0.000546  loss: 3.1600 (3.0753)  time: 0.6230  data: 0.0001  max mem: 8740
Epoch: [7]  [1540/2001]  eta: 0:04:52  lr: 0.000546  loss: 3.1492 (3.0762)  time: 0.6245  data: 0.0001  max mem: 8740
Epoch: [7]  [1550/2001]  eta: 0:04:46  lr: 0.000546  loss: 3.2818 (3.0767)  time: 0.6297  data: 0.0001  max mem: 8740
Epoch: [7]  [1560/2001]  eta: 0:04:39  lr: 0.000546  loss: 3.3184 (3.0777)  time: 0.6282  data: 0.0001  max mem: 8740
Epoch: [7]  [1570/2001]  eta: 0:04:33  lr: 0.000546  loss: 3.4271 (3.0787)  time: 0.6262  data: 0.0001  max mem: 8740
Epoch: [7]  [1580/2001]  eta: 0:04:26  lr: 0.000546  loss: 3.1585 (3.0769)  time: 0.6255  data: 0.0001  max mem: 8740
Epoch: [7]  [1590/2001]  eta: 0:04:20  lr: 0.000546  loss: 2.8180 (3.0753)  time: 0.6299  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9775, ratio_loss=0.0546, cls_kl=0.0682, token_kl=0.0937
Epoch: [7]  [1600/2001]  eta: 0:04:14  lr: 0.000546  loss: 3.1389 (3.0760)  time: 0.6305  data: 0.0001  max mem: 8740
Epoch: [7]  [1610/2001]  eta: 0:04:07  lr: 0.000546  loss: 3.2372 (3.0762)  time: 0.6275  data: 0.0001  max mem: 8740
Epoch: [7]  [1620/2001]  eta: 0:04:01  lr: 0.000546  loss: 3.1604 (3.0775)  time: 0.6262  data: 0.0001  max mem: 8740
Epoch: [7]  [1630/2001]  eta: 0:03:55  lr: 0.000546  loss: 2.9735 (3.0770)  time: 0.6220  data: 0.0001  max mem: 8740
Epoch: [7]  [1640/2001]  eta: 0:03:48  lr: 0.000546  loss: 2.9643 (3.0755)  time: 0.6223  data: 0.0001  max mem: 8740
Epoch: [7]  [1650/2001]  eta: 0:03:42  lr: 0.000546  loss: 3.0451 (3.0757)  time: 0.6385  data: 0.0001  max mem: 8740
Epoch: [7]  [1660/2001]  eta: 0:03:36  lr: 0.000546  loss: 3.1589 (3.0755)  time: 0.6382  data: 0.0001  max mem: 8740
Epoch: [7]  [1670/2001]  eta: 0:03:29  lr: 0.000546  loss: 3.3949 (3.0767)  time: 0.6228  data: 0.0001  max mem: 8740
Epoch: [7]  [1680/2001]  eta: 0:03:23  lr: 0.000546  loss: 3.2992 (3.0761)  time: 0.6226  data: 0.0001  max mem: 8740
Epoch: [7]  [1690/2001]  eta: 0:03:17  lr: 0.000546  loss: 3.0722 (3.0761)  time: 0.6272  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9494, ratio_loss=0.0573, cls_kl=0.0673, token_kl=0.0952
Epoch: [7]  [1700/2001]  eta: 0:03:10  lr: 0.000546  loss: 3.1611 (3.0755)  time: 0.6281  data: 0.0001  max mem: 8740
Epoch: [7]  [1710/2001]  eta: 0:03:04  lr: 0.000546  loss: 3.2271 (3.0766)  time: 0.6268  data: 0.0001  max mem: 8740
Epoch: [7]  [1720/2001]  eta: 0:02:58  lr: 0.000546  loss: 3.2211 (3.0751)  time: 0.6277  data: 0.0001  max mem: 8740
Epoch: [7]  [1730/2001]  eta: 0:02:51  lr: 0.000546  loss: 3.1020 (3.0746)  time: 0.6257  data: 0.0001  max mem: 8740
Epoch: [7]  [1740/2001]  eta: 0:02:45  lr: 0.000546  loss: 3.1797 (3.0750)  time: 0.6312  data: 0.0001  max mem: 8740
Epoch: [7]  [1750/2001]  eta: 0:02:39  lr: 0.000546  loss: 3.3313 (3.0761)  time: 0.6323  data: 0.0001  max mem: 8740
Epoch: [7]  [1760/2001]  eta: 0:02:32  lr: 0.000546  loss: 3.2889 (3.0753)  time: 0.6275  data: 0.0001  max mem: 8740
Epoch: [7]  [1770/2001]  eta: 0:02:26  lr: 0.000546  loss: 3.2889 (3.0764)  time: 0.6254  data: 0.0001  max mem: 8740
Epoch: [7]  [1780/2001]  eta: 0:02:19  lr: 0.000546  loss: 3.3335 (3.0749)  time: 0.6245  data: 0.0001  max mem: 8740
Epoch: [7]  [1790/2001]  eta: 0:02:13  lr: 0.000546  loss: 3.0978 (3.0752)  time: 0.6247  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9518, ratio_loss=0.0557, cls_kl=0.0659, token_kl=0.0934
Epoch: [7]  [1800/2001]  eta: 0:02:07  lr: 0.000546  loss: 3.2620 (3.0752)  time: 0.6277  data: 0.0001  max mem: 8740
Epoch: [7]  [1810/2001]  eta: 0:02:00  lr: 0.000546  loss: 3.0540 (3.0758)  time: 0.6267  data: 0.0001  max mem: 8740
Epoch: [7]  [1820/2001]  eta: 0:01:54  lr: 0.000546  loss: 3.2000 (3.0762)  time: 0.6241  data: 0.0001  max mem: 8740
Epoch: [7]  [1830/2001]  eta: 0:01:48  lr: 0.000546  loss: 3.2402 (3.0768)  time: 0.6265  data: 0.0001  max mem: 8740
Epoch: [7]  [1840/2001]  eta: 0:01:41  lr: 0.000546  loss: 3.2729 (3.0774)  time: 0.6313  data: 0.0001  max mem: 8740
Epoch: [7]  [1850/2001]  eta: 0:01:35  lr: 0.000546  loss: 3.1126 (3.0766)  time: 0.6338  data: 0.0001  max mem: 8740
Epoch: [7]  [1860/2001]  eta: 0:01:29  lr: 0.000546  loss: 3.1015 (3.0768)  time: 0.6326  data: 0.0001  max mem: 8740
Epoch: [7]  [1870/2001]  eta: 0:01:22  lr: 0.000546  loss: 3.2528 (3.0784)  time: 0.6304  data: 0.0001  max mem: 8740
Epoch: [7]  [1880/2001]  eta: 0:01:16  lr: 0.000546  loss: 3.2985 (3.0788)  time: 0.6264  data: 0.0001  max mem: 8740
Epoch: [7]  [1890/2001]  eta: 0:01:10  lr: 0.000546  loss: 3.2533 (3.0788)  time: 0.6264  data: 0.0001  max mem: 8740
loss info: cls_loss=3.0352, ratio_loss=0.0597, cls_kl=0.0693, token_kl=0.0963
Epoch: [7]  [1900/2001]  eta: 0:01:03  lr: 0.000546  loss: 3.2533 (3.0792)  time: 0.6279  data: 0.0001  max mem: 8740
Epoch: [7]  [1910/2001]  eta: 0:00:57  lr: 0.000546  loss: 2.9199 (3.0780)  time: 0.6345  data: 0.0001  max mem: 8740
Epoch: [7]  [1920/2001]  eta: 0:00:51  lr: 0.000546  loss: 2.6077 (3.0748)  time: 0.6415  data: 0.0001  max mem: 8740
Epoch: [7]  [1930/2001]  eta: 0:00:44  lr: 0.000546  loss: 2.7103 (3.0742)  time: 0.6361  data: 0.0001  max mem: 8740
Epoch: [7]  [1940/2001]  eta: 0:00:38  lr: 0.000546  loss: 3.0469 (3.0741)  time: 0.6283  data: 0.0001  max mem: 8740
Epoch: [7]  [1950/2001]  eta: 0:00:32  lr: 0.000546  loss: 3.0376 (3.0738)  time: 0.6266  data: 0.0001  max mem: 8740
Epoch: [7]  [1960/2001]  eta: 0:00:25  lr: 0.000546  loss: 3.2232 (3.0740)  time: 0.6285  data: 0.0001  max mem: 8740
Epoch: [7]  [1970/2001]  eta: 0:00:19  lr: 0.000546  loss: 3.4006 (3.0742)  time: 0.6302  data: 0.0001  max mem: 8740
Epoch: [7]  [1980/2001]  eta: 0:00:13  lr: 0.000546  loss: 2.9020 (3.0720)  time: 0.6311  data: 0.0001  max mem: 8740
Epoch: [7]  [1990/2001]  eta: 0:00:06  lr: 0.000546  loss: 2.9020 (3.0730)  time: 0.6284  data: 0.0004  max mem: 8740
loss info: cls_loss=2.8430, ratio_loss=0.0515, cls_kl=0.0655, token_kl=0.0922
Epoch: [7]  [2000/2001]  eta: 0:00:00  lr: 0.000546  loss: 3.2891 (3.0736)  time: 0.6252  data: 0.0003  max mem: 8740
Epoch: [7] Total time: 0:21:07 (0.6332 s / it)
Averaged stats: lr: 0.000546  loss: 3.2891 (3.0764)
Test:  [ 0/53]  eta: 0:04:23  loss: 0.3561 (0.3561)  acc1: 93.3333 (93.3333)  acc5: 100.0000 (100.0000)  time: 4.9772  data: 4.5138  max mem: 8740
Test:  [10/53]  eta: 0:00:36  loss: 0.7151 (0.7660)  acc1: 83.3333 (83.1818)  acc5: 96.6667 (96.8939)  time: 0.8570  data: 0.4912  max mem: 8740
Test:  [20/53]  eta: 0:00:20  loss: 0.7104 (0.7619)  acc1: 82.5000 (83.2937)  acc5: 96.6667 (96.6270)  time: 0.3900  data: 0.0470  max mem: 8740
Test:  [30/53]  eta: 0:00:12  loss: 0.8656 (0.8511)  acc1: 79.1667 (80.8065)  acc5: 95.0000 (95.3226)  time: 0.3404  data: 0.0026  max mem: 8740
Test:  [40/53]  eta: 0:00:05  loss: 1.1497 (0.9225)  acc1: 75.8333 (79.3089)  acc5: 91.6667 (94.4512)  time: 0.3071  data: 0.0002  max mem: 8740
Test:  [50/53]  eta: 0:00:01  loss: 1.1522 (0.9549)  acc1: 75.8333 (78.4804)  acc5: 92.5000 (94.2974)  time: 0.2594  data: 0.0001  max mem: 8740
Test:  [52/53]  eta: 0:00:00  loss: 1.1497 (0.9420)  acc1: 76.6667 (78.6080)  acc5: 92.5000 (94.3840)  time: 0.2460  data: 0.0000  max mem: 8740
Test: Total time: 0:00:21 (0.4118 s / it)
Sparsity0:0.26820686868686866,Sparsity1:0.5441905527638191,Sparsity2:0.7725952,
* Acc@1 78.858 Acc@5 94.514 loss 0.944
Accuracy of the network on the 50000 test images: 78.9%
Max accuracy: 78.89%
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0005233 for PREDICTOR
Epoch: [8]  [   0/2001]  eta: 2:18:05  lr: 0.000523  loss: 3.3539 (3.3539)  time: 4.1407  data: 2.4873  max mem: 8740
Epoch: [8]  [  10/2001]  eta: 0:31:20  lr: 0.000523  loss: 3.0131 (2.9498)  time: 0.9446  data: 0.2262  max mem: 8740
Epoch: [8]  [  20/2001]  eta: 0:26:00  lr: 0.000523  loss: 2.9760 (2.9495)  time: 0.6201  data: 0.0001  max mem: 8740
Epoch: [8]  [  30/2001]  eta: 0:24:06  lr: 0.000523  loss: 3.1566 (3.0052)  time: 0.6184  data: 0.0001  max mem: 8740
Epoch: [8]  [  40/2001]  eta: 0:23:06  lr: 0.000523  loss: 3.2235 (3.0234)  time: 0.6219  data: 0.0001  max mem: 8740
Epoch: [8]  [  50/2001]  eta: 0:22:29  lr: 0.000523  loss: 2.9875 (2.9965)  time: 0.6254  data: 0.0001  max mem: 8740
Epoch: [8]  [  60/2001]  eta: 0:22:02  lr: 0.000523  loss: 2.9962 (3.0237)  time: 0.6292  data: 0.0001  max mem: 8740
Epoch: [8]  [  70/2001]  eta: 0:21:45  lr: 0.000523  loss: 3.3416 (3.0649)  time: 0.6362  data: 0.0001  max mem: 8740
Epoch: [8]  [  80/2001]  eta: 0:21:28  lr: 0.000523  loss: 3.2699 (3.0777)  time: 0.6380  data: 0.0001  max mem: 8740
Epoch: [8]  [  90/2001]  eta: 0:21:13  lr: 0.000523  loss: 3.1567 (3.0430)  time: 0.6335  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9345, ratio_loss=0.0541, cls_kl=0.0678, token_kl=0.0943
Epoch: [8]  [ 100/2001]  eta: 0:21:01  lr: 0.000523  loss: 2.7966 (3.0298)  time: 0.6336  data: 0.0001  max mem: 8740
Epoch: [8]  [ 110/2001]  eta: 0:20:49  lr: 0.000523  loss: 2.9010 (3.0420)  time: 0.6352  data: 0.0001  max mem: 8740
Epoch: [8]  [ 120/2001]  eta: 0:20:38  lr: 0.000523  loss: 3.2449 (3.0440)  time: 0.6350  data: 0.0001  max mem: 8740
Epoch: [8]  [ 130/2001]  eta: 0:20:28  lr: 0.000523  loss: 3.3667 (3.0690)  time: 0.6333  data: 0.0001  max mem: 8740
Epoch: [8]  [ 140/2001]  eta: 0:20:19  lr: 0.000523  loss: 3.4288 (3.0794)  time: 0.6336  data: 0.0001  max mem: 8740
Epoch: [8]  [ 150/2001]  eta: 0:20:10  lr: 0.000523  loss: 3.1230 (3.0852)  time: 0.6340  data: 0.0001  max mem: 8740
Epoch: [8]  [ 160/2001]  eta: 0:20:01  lr: 0.000523  loss: 3.1230 (3.0842)  time: 0.6348  data: 0.0001  max mem: 8740
Epoch: [8]  [ 170/2001]  eta: 0:19:53  lr: 0.000523  loss: 3.1474 (3.0696)  time: 0.6357  data: 0.0001  max mem: 8740
Epoch: [8]  [ 180/2001]  eta: 0:19:44  lr: 0.000523  loss: 2.9409 (3.0658)  time: 0.6355  data: 0.0002  max mem: 8740
Epoch: [8]  [ 190/2001]  eta: 0:19:36  lr: 0.000523  loss: 2.9783 (3.0684)  time: 0.6345  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9879, ratio_loss=0.0542, cls_kl=0.0663, token_kl=0.0930
Epoch: [8]  [ 200/2001]  eta: 0:19:29  lr: 0.000523  loss: 3.3000 (3.0847)  time: 0.6389  data: 0.0002  max mem: 8740
Epoch: [8]  [ 210/2001]  eta: 0:19:22  lr: 0.000523  loss: 3.2702 (3.0713)  time: 0.6420  data: 0.0002  max mem: 8740
Epoch: [8]  [ 220/2001]  eta: 0:19:14  lr: 0.000523  loss: 3.1182 (3.0761)  time: 0.6376  data: 0.0001  max mem: 8740
Epoch: [8]  [ 230/2001]  eta: 0:19:07  lr: 0.000523  loss: 3.0682 (3.0623)  time: 0.6350  data: 0.0001  max mem: 8740
Epoch: [8]  [ 240/2001]  eta: 0:18:59  lr: 0.000523  loss: 2.9585 (3.0612)  time: 0.6346  data: 0.0001  max mem: 8740
Epoch: [8]  [ 250/2001]  eta: 0:18:52  lr: 0.000523  loss: 3.0768 (3.0616)  time: 0.6344  data: 0.0001  max mem: 8740
Epoch: [8]  [ 260/2001]  eta: 0:18:45  lr: 0.000523  loss: 3.0905 (3.0643)  time: 0.6403  data: 0.0001  max mem: 8740
Epoch: [8]  [ 270/2001]  eta: 0:18:38  lr: 0.000523  loss: 3.0467 (3.0521)  time: 0.6404  data: 0.0001  max mem: 8740
Epoch: [8]  [ 280/2001]  eta: 0:18:31  lr: 0.000523  loss: 3.0655 (3.0601)  time: 0.6373  data: 0.0002  max mem: 8740
Epoch: [8]  [ 290/2001]  eta: 0:18:24  lr: 0.000523  loss: 3.2033 (3.0594)  time: 0.6372  data: 0.0002  max mem: 8740
loss info: cls_loss=2.9159, ratio_loss=0.0545, cls_kl=0.0661, token_kl=0.0930
Epoch: [8]  [ 300/2001]  eta: 0:18:17  lr: 0.000523  loss: 3.1265 (3.0606)  time: 0.6359  data: 0.0001  max mem: 8740
Epoch: [8]  [ 310/2001]  eta: 0:18:10  lr: 0.000523  loss: 3.1265 (3.0606)  time: 0.6359  data: 0.0001  max mem: 8740
Epoch: [8]  [ 320/2001]  eta: 0:18:03  lr: 0.000523  loss: 3.2081 (3.0658)  time: 0.6357  data: 0.0002  max mem: 8740
Epoch: [8]  [ 330/2001]  eta: 0:17:56  lr: 0.000523  loss: 3.2160 (3.0633)  time: 0.6361  data: 0.0001  max mem: 8740
Epoch: [8]  [ 340/2001]  eta: 0:17:50  lr: 0.000523  loss: 2.8653 (3.0578)  time: 0.6400  data: 0.0001  max mem: 8740
Epoch: [8]  [ 350/2001]  eta: 0:17:44  lr: 0.000523  loss: 2.7738 (3.0551)  time: 0.6445  data: 0.0001  max mem: 8740
Epoch: [8]  [ 360/2001]  eta: 0:17:37  lr: 0.000523  loss: 3.0736 (3.0575)  time: 0.6408  data: 0.0001  max mem: 8740
Epoch: [8]  [ 370/2001]  eta: 0:17:30  lr: 0.000523  loss: 3.1332 (3.0586)  time: 0.6350  data: 0.0001  max mem: 8740
Epoch: [8]  [ 380/2001]  eta: 0:17:23  lr: 0.000523  loss: 3.1332 (3.0552)  time: 0.6357  data: 0.0001  max mem: 8740
Epoch: [8]  [ 390/2001]  eta: 0:17:16  lr: 0.000523  loss: 3.2052 (3.0571)  time: 0.6367  data: 0.0001  max mem: 8740
loss info: cls_loss=2.9331, ratio_loss=0.0517, cls_kl=0.0646, token_kl=0.0933
Epoch: [8]  [ 400/2001]  eta: 0:17:10  lr: 0.000523  loss: 3.1899 (3.0581)  time: 0.6393  data: 0.0002  max mem: 8740
Epoch: [8]  [ 410/2001]  eta: 0:17:03  lr: 0.000523  loss: 2.8561 (3.0546)  time: 0.6401  data: 0.0002  max mem: 8740
Epoch: [8]  [ 420/2001]  eta: 0:16:57  lr: 0.000523  loss: 2.9259 (3.0537)  time: 0.6426  data: 0.0001  max mem: 8740
Epoch: [8]  [ 430/2001]  eta: 0:16:50  lr: 0.000523  loss: 3.1039 (3.0576)  time: 0.6418  data: 0.0001  max mem: 8740
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 6): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
| distributed init (rank 4): env://
| distributed init (rank 5): env://
| distributed init (rank 7): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp-3keep/checkpoint.pth', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0005233 for PREDICTOR
Epoch: [8]  [   0/2001]  eta: 3:35:18  lr: 0.000523  loss: 3.9806 (3.9806)  time: 6.4562  data: 2.8297  max mem: 8647
Epoch: [8]  [  10/2001]  eta: 0:37:44  lr: 0.000523  loss: 3.6480 (3.5340)  time: 1.1373  data: 0.2574  max mem: 8728
Epoch: [8]  [  20/2001]  eta: 0:28:53  lr: 0.000523  loss: 3.4630 (3.4120)  time: 0.5962  data: 0.0001  max mem: 8728
Epoch: [8]  [  30/2001]  eta: 0:25:57  lr: 0.000523  loss: 3.3612 (3.3918)  time: 0.5990  data: 0.0001  max mem: 8728
Epoch: [8]  [  40/2001]  eta: 0:24:11  lr: 0.000523  loss: 3.2574 (3.3180)  time: 0.5980  data: 0.0001  max mem: 8728
Epoch: [8]  [  50/2001]  eta: 0:23:07  lr: 0.000523  loss: 3.1203 (3.2837)  time: 0.5888  data: 0.0001  max mem: 8728
Epoch: [8]  [  60/2001]  eta: 0:22:23  lr: 0.000523  loss: 3.1446 (3.2445)  time: 0.5940  data: 0.0001  max mem: 8728
Epoch: [8]  [  70/2001]  eta: 0:21:48  lr: 0.000523  loss: 3.1446 (3.1991)  time: 0.5922  data: 0.0001  max mem: 8728
Epoch: [8]  [  80/2001]  eta: 0:21:20  lr: 0.000523  loss: 2.9421 (3.1835)  time: 0.5885  data: 0.0001  max mem: 8728
Epoch: [8]  [  90/2001]  eta: 0:20:57  lr: 0.000523  loss: 3.1834 (3.1661)  time: 0.5876  data: 0.0001  max mem: 8728
loss info: cls_loss=3.0568, ratio_loss=0.0571, cls_kl=0.0687, token_kl=0.0945
Epoch: [8]  [ 100/2001]  eta: 0:20:38  lr: 0.000523  loss: 3.2767 (3.1788)  time: 0.5901  data: 0.0001  max mem: 8728
Epoch: [8]  [ 110/2001]  eta: 0:20:22  lr: 0.000523  loss: 3.2767 (3.1722)  time: 0.5940  data: 0.0001  max mem: 8728
Epoch: [8]  [ 120/2001]  eta: 0:20:07  lr: 0.000523  loss: 3.2365 (3.1720)  time: 0.5941  data: 0.0002  max mem: 8728
Epoch: [8]  [ 130/2001]  eta: 0:19:54  lr: 0.000523  loss: 3.2257 (3.1645)  time: 0.5934  data: 0.0002  max mem: 8728
Epoch: [8]  [ 140/2001]  eta: 0:19:42  lr: 0.000523  loss: 3.1815 (3.1553)  time: 0.5955  data: 0.0001  max mem: 8728
Epoch: [8]  [ 150/2001]  eta: 0:19:32  lr: 0.000523  loss: 3.0876 (3.1458)  time: 0.5999  data: 0.0001  max mem: 8728
Epoch: [8]  [ 160/2001]  eta: 0:19:22  lr: 0.000523  loss: 3.1533 (3.1534)  time: 0.6034  data: 0.0001  max mem: 8728
Epoch: [8]  [ 170/2001]  eta: 0:19:13  lr: 0.000523  loss: 3.2682 (3.1485)  time: 0.6070  data: 0.0001  max mem: 8728
Epoch: [8]  [ 180/2001]  eta: 0:19:05  lr: 0.000523  loss: 3.0316 (3.1317)  time: 0.6096  data: 0.0001  max mem: 8728
Epoch: [8]  [ 190/2001]  eta: 0:18:58  lr: 0.000523  loss: 2.8636 (3.1270)  time: 0.6149  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9507, ratio_loss=0.0533, cls_kl=0.0634, token_kl=0.0915
Epoch: [8]  [ 200/2001]  eta: 0:18:50  lr: 0.000523  loss: 2.9124 (3.1195)  time: 0.6189  data: 0.0001  max mem: 8728
Epoch: [8]  [ 210/2001]  eta: 0:18:43  lr: 0.000523  loss: 3.1483 (3.1144)  time: 0.6157  data: 0.0001  max mem: 8728
Epoch: [8]  [ 220/2001]  eta: 0:18:36  lr: 0.000523  loss: 3.1483 (3.1060)  time: 0.6166  data: 0.0001  max mem: 8728
Epoch: [8]  [ 230/2001]  eta: 0:18:29  lr: 0.000523  loss: 2.9869 (3.1015)  time: 0.6191  data: 0.0002  max mem: 8728
Epoch: [8]  [ 240/2001]  eta: 0:18:23  lr: 0.000523  loss: 3.0534 (3.0964)  time: 0.6207  data: 0.0002  max mem: 8728
Epoch: [8]  [ 250/2001]  eta: 0:18:16  lr: 0.000523  loss: 3.0534 (3.0855)  time: 0.6219  data: 0.0001  max mem: 8728
Epoch: [8]  [ 260/2001]  eta: 0:18:10  lr: 0.000523  loss: 2.9761 (3.0795)  time: 0.6241  data: 0.0001  max mem: 8728
Epoch: [8]  [ 270/2001]  eta: 0:18:03  lr: 0.000523  loss: 2.9038 (3.0736)  time: 0.6232  data: 0.0002  max mem: 8728
Epoch: [8]  [ 280/2001]  eta: 0:17:57  lr: 0.000523  loss: 3.2978 (3.0798)  time: 0.6229  data: 0.0002  max mem: 8728
Epoch: [8]  [ 290/2001]  eta: 0:17:50  lr: 0.000523  loss: 3.3419 (3.0723)  time: 0.6226  data: 0.0002  max mem: 8728
loss info: cls_loss=2.8387, ratio_loss=0.0517, cls_kl=0.0652, token_kl=0.0923
Epoch: [8]  [ 300/2001]  eta: 0:17:44  lr: 0.000523  loss: 2.8621 (3.0633)  time: 0.6201  data: 0.0001  max mem: 8728
Epoch: [8]  [ 310/2001]  eta: 0:17:37  lr: 0.000523  loss: 2.9417 (3.0636)  time: 0.6207  data: 0.0001  max mem: 8728
Epoch: [8]  [ 320/2001]  eta: 0:17:31  lr: 0.000523  loss: 3.3875 (3.0736)  time: 0.6214  data: 0.0001  max mem: 8728
Epoch: [8]  [ 330/2001]  eta: 0:17:25  lr: 0.000523  loss: 3.3875 (3.0723)  time: 0.6248  data: 0.0001  max mem: 8728
Epoch: [8]  [ 340/2001]  eta: 0:17:18  lr: 0.000523  loss: 3.1905 (3.0754)  time: 0.6265  data: 0.0001  max mem: 8728
Epoch: [8]  [ 350/2001]  eta: 0:17:12  lr: 0.000523  loss: 3.2018 (3.0797)  time: 0.6273  data: 0.0001  max mem: 8728
Epoch: [8]  [ 360/2001]  eta: 0:17:06  lr: 0.000523  loss: 3.2250 (3.0802)  time: 0.6283  data: 0.0002  max mem: 8728
Epoch: [8]  [ 370/2001]  eta: 0:17:00  lr: 0.000523  loss: 3.2457 (3.0795)  time: 0.6290  data: 0.0001  max mem: 8728
Epoch: [8]  [ 380/2001]  eta: 0:16:54  lr: 0.000523  loss: 3.1730 (3.0750)  time: 0.6304  data: 0.0001  max mem: 8728
Epoch: [8]  [ 390/2001]  eta: 0:16:48  lr: 0.000523  loss: 2.9622 (3.0697)  time: 0.6320  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9812, ratio_loss=0.0542, cls_kl=0.0672, token_kl=0.0945
Epoch: [8]  [ 400/2001]  eta: 0:16:42  lr: 0.000523  loss: 3.1849 (3.0733)  time: 0.6330  data: 0.0001  max mem: 8728
Epoch: [8]  [ 410/2001]  eta: 0:16:36  lr: 0.000523  loss: 3.2430 (3.0759)  time: 0.6323  data: 0.0001  max mem: 8728
Epoch: [8]  [ 420/2001]  eta: 0:16:30  lr: 0.000523  loss: 3.1104 (3.0714)  time: 0.6318  data: 0.0001  max mem: 8728
Epoch: [8]  [ 430/2001]  eta: 0:16:24  lr: 0.000523  loss: 3.1644 (3.0760)  time: 0.6333  data: 0.0001  max mem: 8728
Epoch: [8]  [ 440/2001]  eta: 0:16:18  lr: 0.000523  loss: 3.2045 (3.0806)  time: 0.6346  data: 0.0001  max mem: 8728
Epoch: [8]  [ 450/2001]  eta: 0:16:12  lr: 0.000523  loss: 3.1087 (3.0798)  time: 0.6350  data: 0.0001  max mem: 8728
Epoch: [8]  [ 460/2001]  eta: 0:16:07  lr: 0.000523  loss: 3.0327 (3.0761)  time: 0.6436  data: 0.0001  max mem: 8728
Epoch: [8]  [ 470/2001]  eta: 0:16:01  lr: 0.000523  loss: 2.6842 (3.0674)  time: 0.6440  data: 0.0001  max mem: 8728
Epoch: [8]  [ 480/2001]  eta: 0:15:55  lr: 0.000523  loss: 2.8875 (3.0656)  time: 0.6368  data: 0.0001  max mem: 8728
Epoch: [8]  [ 490/2001]  eta: 0:15:49  lr: 0.000523  loss: 3.1942 (3.0719)  time: 0.6363  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9473, ratio_loss=0.0552, cls_kl=0.0685, token_kl=0.0960
Epoch: [8]  [ 500/2001]  eta: 0:15:43  lr: 0.000523  loss: 3.3579 (3.0719)  time: 0.6380  data: 0.0001  max mem: 8728
Epoch: [8]  [ 510/2001]  eta: 0:15:37  lr: 0.000523  loss: 3.2473 (3.0745)  time: 0.6436  data: 0.0001  max mem: 8728
Epoch: [8]  [ 520/2001]  eta: 0:15:31  lr: 0.000523  loss: 3.1837 (3.0742)  time: 0.6481  data: 0.0001  max mem: 8728
Epoch: [8]  [ 530/2001]  eta: 0:15:25  lr: 0.000523  loss: 3.1731 (3.0679)  time: 0.6435  data: 0.0001  max mem: 8728
Epoch: [8]  [ 540/2001]  eta: 0:15:19  lr: 0.000523  loss: 3.1655 (3.0660)  time: 0.6393  data: 0.0001  max mem: 8728
Epoch: [8]  [ 550/2001]  eta: 0:15:13  lr: 0.000523  loss: 3.1655 (3.0669)  time: 0.6398  data: 0.0001  max mem: 8728
Epoch: [8]  [ 560/2001]  eta: 0:15:07  lr: 0.000523  loss: 3.3808 (3.0714)  time: 0.6430  data: 0.0002  max mem: 8728
Epoch: [8]  [ 570/2001]  eta: 0:15:01  lr: 0.000523  loss: 3.3639 (3.0731)  time: 0.6441  data: 0.0002  max mem: 8728
Epoch: [8]  [ 580/2001]  eta: 0:14:55  lr: 0.000523  loss: 3.2628 (3.0732)  time: 0.6444  data: 0.0001  max mem: 8728
Epoch: [8]  [ 590/2001]  eta: 0:14:49  lr: 0.000523  loss: 3.3139 (3.0767)  time: 0.6467  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9859, ratio_loss=0.0553, cls_kl=0.0691, token_kl=0.0951
Epoch: [8]  [ 600/2001]  eta: 0:14:43  lr: 0.000523  loss: 3.3139 (3.0751)  time: 0.6421  data: 0.0001  max mem: 8728
Epoch: [8]  [ 610/2001]  eta: 0:14:37  lr: 0.000523  loss: 3.1057 (3.0751)  time: 0.6384  data: 0.0001  max mem: 8728
Epoch: [8]  [ 620/2001]  eta: 0:14:31  lr: 0.000523  loss: 3.1689 (3.0777)  time: 0.6444  data: 0.0001  max mem: 8728
Epoch: [8]  [ 630/2001]  eta: 0:14:25  lr: 0.000523  loss: 3.2394 (3.0813)  time: 0.6453  data: 0.0001  max mem: 8728
Epoch: [8]  [ 640/2001]  eta: 0:14:19  lr: 0.000523  loss: 3.0437 (3.0791)  time: 0.6383  data: 0.0001  max mem: 8728
Epoch: [8]  [ 650/2001]  eta: 0:14:13  lr: 0.000523  loss: 3.0814 (3.0796)  time: 0.6400  data: 0.0001  max mem: 8728
Epoch: [8]  [ 660/2001]  eta: 0:14:07  lr: 0.000523  loss: 3.0214 (3.0743)  time: 0.6395  data: 0.0001  max mem: 8728
Epoch: [8]  [ 670/2001]  eta: 0:14:00  lr: 0.000523  loss: 3.1247 (3.0785)  time: 0.6378  data: 0.0001  max mem: 8728
Epoch: [8]  [ 680/2001]  eta: 0:13:54  lr: 0.000523  loss: 3.2613 (3.0800)  time: 0.6378  data: 0.0001  max mem: 8728
Epoch: [8]  [ 690/2001]  eta: 0:13:48  lr: 0.000523  loss: 3.0454 (3.0772)  time: 0.6367  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9514, ratio_loss=0.0548, cls_kl=0.0665, token_kl=0.0947
Epoch: [8]  [ 700/2001]  eta: 0:13:42  lr: 0.000523  loss: 3.0454 (3.0760)  time: 0.6378  data: 0.0001  max mem: 8728
Epoch: [8]  [ 710/2001]  eta: 0:13:36  lr: 0.000523  loss: 3.0600 (3.0740)  time: 0.6372  data: 0.0001  max mem: 8728
Epoch: [8]  [ 720/2001]  eta: 0:13:30  lr: 0.000523  loss: 3.0766 (3.0719)  time: 0.6420  data: 0.0002  max mem: 8728
Epoch: [8]  [ 730/2001]  eta: 0:13:23  lr: 0.000523  loss: 3.0766 (3.0724)  time: 0.6457  data: 0.0002  max mem: 8728
Epoch: [8]  [ 740/2001]  eta: 0:13:17  lr: 0.000523  loss: 3.2384 (3.0762)  time: 0.6421  data: 0.0002  max mem: 8728
Epoch: [8]  [ 750/2001]  eta: 0:13:11  lr: 0.000523  loss: 3.2565 (3.0738)  time: 0.6397  data: 0.0002  max mem: 8728
Epoch: [8]  [ 760/2001]  eta: 0:13:05  lr: 0.000523  loss: 3.2166 (3.0728)  time: 0.6403  data: 0.0002  max mem: 8728
Epoch: [8]  [ 770/2001]  eta: 0:12:59  lr: 0.000523  loss: 3.2359 (3.0748)  time: 0.6473  data: 0.0002  max mem: 8728
Epoch: [8]  [ 780/2001]  eta: 0:12:53  lr: 0.000523  loss: 3.2526 (3.0757)  time: 0.6465  data: 0.0002  max mem: 8728
Epoch: [8]  [ 790/2001]  eta: 0:12:46  lr: 0.000523  loss: 2.9926 (3.0737)  time: 0.6403  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9471, ratio_loss=0.0534, cls_kl=0.0665, token_kl=0.0930
Epoch: [8]  [ 800/2001]  eta: 0:12:40  lr: 0.000523  loss: 3.0755 (3.0745)  time: 0.6410  data: 0.0001  max mem: 8728
Epoch: [8]  [ 810/2001]  eta: 0:12:34  lr: 0.000523  loss: 2.8538 (3.0680)  time: 0.6445  data: 0.0001  max mem: 8728
Epoch: [8]  [ 820/2001]  eta: 0:12:28  lr: 0.000523  loss: 2.8538 (3.0701)  time: 0.6491  data: 0.0002  max mem: 8728
Epoch: [8]  [ 830/2001]  eta: 0:12:22  lr: 0.000523  loss: 3.3426 (3.0666)  time: 0.6472  data: 0.0002  max mem: 8728
Epoch: [8]  [ 840/2001]  eta: 0:12:15  lr: 0.000523  loss: 2.8905 (3.0662)  time: 0.6413  data: 0.0002  max mem: 8728
Epoch: [8]  [ 850/2001]  eta: 0:12:09  lr: 0.000523  loss: 3.1667 (3.0652)  time: 0.6385  data: 0.0001  max mem: 8728
Epoch: [8]  [ 860/2001]  eta: 0:12:03  lr: 0.000523  loss: 3.1794 (3.0662)  time: 0.6379  data: 0.0001  max mem: 8728
Epoch: [8]  [ 870/2001]  eta: 0:11:57  lr: 0.000523  loss: 3.1695 (3.0669)  time: 0.6397  data: 0.0001  max mem: 8728
Epoch: [8]  [ 880/2001]  eta: 0:11:50  lr: 0.000523  loss: 3.0621 (3.0647)  time: 0.6389  data: 0.0001  max mem: 8728
Epoch: [8]  [ 890/2001]  eta: 0:11:44  lr: 0.000523  loss: 3.0621 (3.0624)  time: 0.6405  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8484, ratio_loss=0.0528, cls_kl=0.0649, token_kl=0.0950
Epoch: [8]  [ 900/2001]  eta: 0:11:38  lr: 0.000523  loss: 3.1004 (3.0621)  time: 0.6415  data: 0.0001  max mem: 8728
Epoch: [8]  [ 910/2001]  eta: 0:11:32  lr: 0.000523  loss: 3.1592 (3.0616)  time: 0.6370  data: 0.0001  max mem: 8728
Epoch: [8]  [ 920/2001]  eta: 0:11:25  lr: 0.000523  loss: 3.3057 (3.0626)  time: 0.6377  data: 0.0001  max mem: 8728
Epoch: [8]  [ 930/2001]  eta: 0:11:19  lr: 0.000523  loss: 3.3284 (3.0653)  time: 0.6396  data: 0.0001  max mem: 8728
Epoch: [8]  [ 940/2001]  eta: 0:11:13  lr: 0.000523  loss: 3.1590 (3.0655)  time: 0.6395  data: 0.0001  max mem: 8728
Epoch: [8]  [ 950/2001]  eta: 0:11:06  lr: 0.000523  loss: 2.7566 (3.0607)  time: 0.6377  data: 0.0001  max mem: 8728
Epoch: [8]  [ 960/2001]  eta: 0:11:00  lr: 0.000523  loss: 2.9395 (3.0616)  time: 0.6368  data: 0.0001  max mem: 8728
Epoch: [8]  [ 970/2001]  eta: 0:10:54  lr: 0.000523  loss: 3.2158 (3.0624)  time: 0.6380  data: 0.0002  max mem: 8728
Epoch: [8]  [ 980/2001]  eta: 0:10:47  lr: 0.000523  loss: 3.0740 (3.0619)  time: 0.6392  data: 0.0001  max mem: 8728
Epoch: [8]  [ 990/2001]  eta: 0:10:41  lr: 0.000523  loss: 3.2633 (3.0620)  time: 0.6408  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9558, ratio_loss=0.0525, cls_kl=0.0673, token_kl=0.0940
Epoch: [8]  [1000/2001]  eta: 0:10:35  lr: 0.000523  loss: 3.2749 (3.0625)  time: 0.6408  data: 0.0001  max mem: 8728
Epoch: [8]  [1010/2001]  eta: 0:10:29  lr: 0.000523  loss: 3.3727 (3.0646)  time: 0.6359  data: 0.0001  max mem: 8728
Epoch: [8]  [1020/2001]  eta: 0:10:22  lr: 0.000523  loss: 3.2850 (3.0634)  time: 0.6334  data: 0.0002  max mem: 8728
Epoch: [8]  [1030/2001]  eta: 0:10:16  lr: 0.000523  loss: 2.8566 (3.0613)  time: 0.6349  data: 0.0002  max mem: 8728
Epoch: [8]  [1040/2001]  eta: 0:10:10  lr: 0.000523  loss: 3.1458 (3.0633)  time: 0.6389  data: 0.0001  max mem: 8728
Epoch: [8]  [1050/2001]  eta: 0:10:03  lr: 0.000523  loss: 3.2057 (3.0630)  time: 0.6383  data: 0.0001  max mem: 8728
Epoch: [8]  [1060/2001]  eta: 0:09:57  lr: 0.000523  loss: 3.1500 (3.0640)  time: 0.6337  data: 0.0001  max mem: 8728
Epoch: [8]  [1070/2001]  eta: 0:09:50  lr: 0.000523  loss: 3.1593 (3.0635)  time: 0.6331  data: 0.0001  max mem: 8728
Epoch: [8]  [1080/2001]  eta: 0:09:44  lr: 0.000523  loss: 3.1185 (3.0634)  time: 0.6319  data: 0.0001  max mem: 8728
Epoch: [8]  [1090/2001]  eta: 0:09:38  lr: 0.000523  loss: 2.9794 (3.0625)  time: 0.6326  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9316, ratio_loss=0.0521, cls_kl=0.0665, token_kl=0.0937
Epoch: [8]  [1100/2001]  eta: 0:09:31  lr: 0.000523  loss: 2.9570 (3.0616)  time: 0.6320  data: 0.0001  max mem: 8728
Epoch: [8]  [1110/2001]  eta: 0:09:25  lr: 0.000523  loss: 3.2697 (3.0619)  time: 0.6309  data: 0.0001  max mem: 8728
Epoch: [8]  [1120/2001]  eta: 0:09:19  lr: 0.000523  loss: 3.3951 (3.0632)  time: 0.6337  data: 0.0001  max mem: 8728
Epoch: [8]  [1130/2001]  eta: 0:09:12  lr: 0.000523  loss: 3.1513 (3.0643)  time: 0.6345  data: 0.0001  max mem: 8728
Epoch: [8]  [1140/2001]  eta: 0:09:06  lr: 0.000523  loss: 3.0890 (3.0632)  time: 0.6344  data: 0.0001  max mem: 8728
Epoch: [8]  [1150/2001]  eta: 0:09:00  lr: 0.000523  loss: 3.0890 (3.0629)  time: 0.6341  data: 0.0001  max mem: 8728
Epoch: [8]  [1160/2001]  eta: 0:08:53  lr: 0.000523  loss: 3.1468 (3.0621)  time: 0.6299  data: 0.0001  max mem: 8728
Epoch: [8]  [1170/2001]  eta: 0:08:47  lr: 0.000523  loss: 3.1197 (3.0619)  time: 0.6261  data: 0.0002  max mem: 8728
Epoch: [8]  [1180/2001]  eta: 0:08:40  lr: 0.000523  loss: 3.3733 (3.0647)  time: 0.6265  data: 0.0001  max mem: 8728
Epoch: [8]  [1190/2001]  eta: 0:08:34  lr: 0.000523  loss: 3.3563 (3.0659)  time: 0.6279  data: 0.0001  max mem: 8728
loss info: cls_loss=3.0046, ratio_loss=0.0566, cls_kl=0.0675, token_kl=0.0924
Epoch: [8]  [1200/2001]  eta: 0:08:28  lr: 0.000523  loss: 3.2198 (3.0665)  time: 0.6261  data: 0.0001  max mem: 8728
Epoch: [8]  [1210/2001]  eta: 0:08:21  lr: 0.000523  loss: 3.0408 (3.0653)  time: 0.6246  data: 0.0001  max mem: 8728
Epoch: [8]  [1220/2001]  eta: 0:08:15  lr: 0.000523  loss: 3.0374 (3.0642)  time: 0.6287  data: 0.0001  max mem: 8728
Epoch: [8]  [1230/2001]  eta: 0:08:08  lr: 0.000523  loss: 3.1121 (3.0646)  time: 0.6291  data: 0.0001  max mem: 8728
Epoch: [8]  [1240/2001]  eta: 0:08:02  lr: 0.000523  loss: 3.1097 (3.0643)  time: 0.6253  data: 0.0001  max mem: 8728
Epoch: [8]  [1250/2001]  eta: 0:07:56  lr: 0.000523  loss: 3.0209 (3.0625)  time: 0.6243  data: 0.0001  max mem: 8728
Epoch: [8]  [1260/2001]  eta: 0:07:49  lr: 0.000523  loss: 3.0471 (3.0634)  time: 0.6250  data: 0.0001  max mem: 8728
Epoch: [8]  [1270/2001]  eta: 0:07:43  lr: 0.000523  loss: 3.2959 (3.0645)  time: 0.6266  data: 0.0001  max mem: 8728
Epoch: [8]  [1280/2001]  eta: 0:07:36  lr: 0.000523  loss: 3.2973 (3.0667)  time: 0.6253  data: 0.0001  max mem: 8728
Epoch: [8]  [1290/2001]  eta: 0:07:30  lr: 0.000523  loss: 3.2973 (3.0679)  time: 0.6278  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9660, ratio_loss=0.0548, cls_kl=0.0676, token_kl=0.0940
Epoch: [8]  [1300/2001]  eta: 0:07:24  lr: 0.000523  loss: 3.1071 (3.0678)  time: 0.6276  data: 0.0001  max mem: 8728
Epoch: [8]  [1310/2001]  eta: 0:07:17  lr: 0.000523  loss: 3.0738 (3.0667)  time: 0.6294  data: 0.0001  max mem: 8728
Epoch: [8]  [1320/2001]  eta: 0:07:11  lr: 0.000523  loss: 2.8648 (3.0644)  time: 0.6305  data: 0.0001  max mem: 8728
Epoch: [8]  [1330/2001]  eta: 0:07:05  lr: 0.000523  loss: 3.0051 (3.0652)  time: 0.6295  data: 0.0001  max mem: 8728
Epoch: [8]  [1340/2001]  eta: 0:06:58  lr: 0.000523  loss: 3.2729 (3.0657)  time: 0.6338  data: 0.0001  max mem: 8728
Epoch: [8]  [1350/2001]  eta: 0:06:52  lr: 0.000523  loss: 3.2729 (3.0659)  time: 0.6329  data: 0.0001  max mem: 8728
Epoch: [8]  [1360/2001]  eta: 0:06:46  lr: 0.000523  loss: 3.2231 (3.0672)  time: 0.6317  data: 0.0001  max mem: 8728
Epoch: [8]  [1370/2001]  eta: 0:06:39  lr: 0.000523  loss: 3.3720 (3.0689)  time: 0.6267  data: 0.0001  max mem: 8728
Epoch: [8]  [1380/2001]  eta: 0:06:33  lr: 0.000523  loss: 3.3720 (3.0705)  time: 0.6232  data: 0.0001  max mem: 8728
Epoch: [8]  [1390/2001]  eta: 0:06:27  lr: 0.000523  loss: 3.3453 (3.0705)  time: 0.6309  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9871, ratio_loss=0.0508, cls_kl=0.0678, token_kl=0.0932
Epoch: [8]  [1400/2001]  eta: 0:06:20  lr: 0.000523  loss: 3.3009 (3.0702)  time: 0.6363  data: 0.0001  max mem: 8728
Epoch: [8]  [1410/2001]  eta: 0:06:14  lr: 0.000523  loss: 3.4190 (3.0721)  time: 0.6342  data: 0.0001  max mem: 8728
Epoch: [8]  [1420/2001]  eta: 0:06:08  lr: 0.000523  loss: 3.4190 (3.0721)  time: 0.6328  data: 0.0001  max mem: 8728
Epoch: [8]  [1430/2001]  eta: 0:06:01  lr: 0.000523  loss: 3.1181 (3.0722)  time: 0.6324  data: 0.0001  max mem: 8728
Epoch: [8]  [1440/2001]  eta: 0:05:55  lr: 0.000523  loss: 3.1181 (3.0720)  time: 0.6264  data: 0.0001  max mem: 8728
Epoch: [8]  [1450/2001]  eta: 0:05:48  lr: 0.000523  loss: 3.1249 (3.0724)  time: 0.6224  data: 0.0001  max mem: 8728
Epoch: [8]  [1460/2001]  eta: 0:05:42  lr: 0.000523  loss: 3.3451 (3.0739)  time: 0.6249  data: 0.0001  max mem: 8728
Epoch: [8]  [1470/2001]  eta: 0:05:36  lr: 0.000523  loss: 3.2670 (3.0731)  time: 0.6284  data: 0.0001  max mem: 8728
Epoch: [8]  [1480/2001]  eta: 0:05:29  lr: 0.000523  loss: 2.8679 (3.0714)  time: 0.6269  data: 0.0001  max mem: 8728
Epoch: [8]  [1490/2001]  eta: 0:05:23  lr: 0.000523  loss: 2.6773 (3.0683)  time: 0.6235  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9140, ratio_loss=0.0514, cls_kl=0.0665, token_kl=0.0943
Epoch: [8]  [1500/2001]  eta: 0:05:17  lr: 0.000523  loss: 2.7617 (3.0673)  time: 0.6252  data: 0.0001  max mem: 8728
Epoch: [8]  [1510/2001]  eta: 0:05:10  lr: 0.000523  loss: 3.2178 (3.0692)  time: 0.6236  data: 0.0001  max mem: 8728
Epoch: [8]  [1520/2001]  eta: 0:05:04  lr: 0.000523  loss: 3.3266 (3.0706)  time: 0.6231  data: 0.0001  max mem: 8728
Epoch: [8]  [1530/2001]  eta: 0:04:58  lr: 0.000523  loss: 3.2041 (3.0698)  time: 0.6238  data: 0.0001  max mem: 8728
Epoch: [8]  [1540/2001]  eta: 0:04:51  lr: 0.000523  loss: 3.2041 (3.0704)  time: 0.6245  data: 0.0001  max mem: 8728
Epoch: [8]  [1550/2001]  eta: 0:04:45  lr: 0.000523  loss: 3.0091 (3.0692)  time: 0.6281  data: 0.0001  max mem: 8728
Epoch: [8]  [1560/2001]  eta: 0:04:39  lr: 0.000523  loss: 2.9443 (3.0687)  time: 0.6276  data: 0.0001  max mem: 8728
Epoch: [8]  [1570/2001]  eta: 0:04:32  lr: 0.000523  loss: 2.9379 (3.0670)  time: 0.6239  data: 0.0001  max mem: 8728
Epoch: [8]  [1580/2001]  eta: 0:04:26  lr: 0.000523  loss: 2.8254 (3.0659)  time: 0.6240  data: 0.0001  max mem: 8728
Epoch: [8]  [1590/2001]  eta: 0:04:20  lr: 0.000523  loss: 3.1782 (3.0669)  time: 0.6242  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9757, ratio_loss=0.0527, cls_kl=0.0655, token_kl=0.0933
Epoch: [8]  [1600/2001]  eta: 0:04:13  lr: 0.000523  loss: 3.2970 (3.0689)  time: 0.6245  data: 0.0001  max mem: 8728
Epoch: [8]  [1610/2001]  eta: 0:04:07  lr: 0.000523  loss: 3.3059 (3.0700)  time: 0.6259  data: 0.0001  max mem: 8728
Epoch: [8]  [1620/2001]  eta: 0:04:00  lr: 0.000523  loss: 3.2259 (3.0705)  time: 0.6268  data: 0.0001  max mem: 8728
Epoch: [8]  [1630/2001]  eta: 0:03:54  lr: 0.000523  loss: 3.2178 (3.0710)  time: 0.6313  data: 0.0002  max mem: 8728
Epoch: [8]  [1640/2001]  eta: 0:03:48  lr: 0.000523  loss: 3.2231 (3.0711)  time: 0.6311  data: 0.0002  max mem: 8728
Epoch: [8]  [1650/2001]  eta: 0:03:41  lr: 0.000523  loss: 2.9194 (3.0683)  time: 0.6282  data: 0.0001  max mem: 8728
Epoch: [8]  [1660/2001]  eta: 0:03:35  lr: 0.000523  loss: 2.3965 (3.0659)  time: 0.6267  data: 0.0001  max mem: 8728
Epoch: [8]  [1670/2001]  eta: 0:03:29  lr: 0.000523  loss: 2.9171 (3.0657)  time: 0.6250  data: 0.0001  max mem: 8728
Epoch: [8]  [1680/2001]  eta: 0:03:22  lr: 0.000523  loss: 3.0950 (3.0655)  time: 0.6244  data: 0.0002  max mem: 8728
Epoch: [8]  [1690/2001]  eta: 0:03:16  lr: 0.000523  loss: 3.0186 (3.0659)  time: 0.6272  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9273, ratio_loss=0.0526, cls_kl=0.0650, token_kl=0.0945
Epoch: [8]  [1700/2001]  eta: 0:03:10  lr: 0.000523  loss: 3.3149 (3.0675)  time: 0.6285  data: 0.0001  max mem: 8728
Epoch: [8]  [1710/2001]  eta: 0:03:03  lr: 0.000523  loss: 3.3156 (3.0676)  time: 0.6266  data: 0.0001  max mem: 8728
Epoch: [8]  [1720/2001]  eta: 0:02:57  lr: 0.000523  loss: 3.0343 (3.0668)  time: 0.6257  data: 0.0001  max mem: 8728
Epoch: [8]  [1730/2001]  eta: 0:02:51  lr: 0.000523  loss: 3.2738 (3.0684)  time: 0.6256  data: 0.0001  max mem: 8728
Epoch: [8]  [1740/2001]  eta: 0:02:44  lr: 0.000523  loss: 3.2947 (3.0680)  time: 0.6306  data: 0.0001  max mem: 8728
Epoch: [8]  [1750/2001]  eta: 0:02:38  lr: 0.000523  loss: 3.0551 (3.0667)  time: 0.6324  data: 0.0001  max mem: 8728
Epoch: [8]  [1760/2001]  eta: 0:02:32  lr: 0.000523  loss: 2.9975 (3.0663)  time: 0.6287  data: 0.0001  max mem: 8728
Epoch: [8]  [1770/2001]  eta: 0:02:26  lr: 0.000523  loss: 3.2626 (3.0672)  time: 0.6279  data: 0.0001  max mem: 8728
Epoch: [8]  [1780/2001]  eta: 0:02:19  lr: 0.000523  loss: 3.3457 (3.0679)  time: 0.6288  data: 0.0001  max mem: 8728
Epoch: [8]  [1790/2001]  eta: 0:02:13  lr: 0.000523  loss: 2.9798 (3.0665)  time: 0.6280  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9601, ratio_loss=0.0523, cls_kl=0.0665, token_kl=0.0933
Epoch: [8]  [1800/2001]  eta: 0:02:07  lr: 0.000523  loss: 3.1246 (3.0674)  time: 0.6284  data: 0.0001  max mem: 8728
Epoch: [8]  [1810/2001]  eta: 0:02:00  lr: 0.000523  loss: 3.2698 (3.0672)  time: 0.6284  data: 0.0001  max mem: 8728
Epoch: [8]  [1820/2001]  eta: 0:01:54  lr: 0.000523  loss: 3.0509 (3.0673)  time: 0.6282  data: 0.0001  max mem: 8728
Epoch: [8]  [1830/2001]  eta: 0:01:48  lr: 0.000523  loss: 3.2319 (3.0679)  time: 0.6305  data: 0.0001  max mem: 8728
Epoch: [8]  [1840/2001]  eta: 0:01:41  lr: 0.000523  loss: 3.1592 (3.0675)  time: 0.6313  data: 0.0001  max mem: 8728
Epoch: [8]  [1850/2001]  eta: 0:01:35  lr: 0.000523  loss: 3.0006 (3.0661)  time: 0.6309  data: 0.0001  max mem: 8728
Epoch: [8]  [1860/2001]  eta: 0:01:29  lr: 0.000523  loss: 2.8794 (3.0657)  time: 0.6312  data: 0.0001  max mem: 8728
Epoch: [8]  [1870/2001]  eta: 0:01:22  lr: 0.000523  loss: 2.8794 (3.0643)  time: 0.6327  data: 0.0001  max mem: 8728
Epoch: [8]  [1880/2001]  eta: 0:01:16  lr: 0.000523  loss: 3.3857 (3.0660)  time: 0.6321  data: 0.0001  max mem: 8728
Epoch: [8]  [1890/2001]  eta: 0:01:10  lr: 0.000523  loss: 3.4137 (3.0654)  time: 0.6298  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8991, ratio_loss=0.0515, cls_kl=0.0637, token_kl=0.0923
Epoch: [8]  [1900/2001]  eta: 0:01:03  lr: 0.000523  loss: 2.9199 (3.0647)  time: 0.6340  data: 0.0001  max mem: 8728
Epoch: [8]  [1910/2001]  eta: 0:00:57  lr: 0.000523  loss: 2.9409 (3.0656)  time: 0.6365  data: 0.0001  max mem: 8728
Epoch: [8]  [1920/2001]  eta: 0:00:51  lr: 0.000523  loss: 2.9355 (3.0637)  time: 0.6340  data: 0.0001  max mem: 8728
Epoch: [8]  [1930/2001]  eta: 0:00:44  lr: 0.000523  loss: 2.8187 (3.0630)  time: 0.6330  data: 0.0002  max mem: 8728
Epoch: [8]  [1940/2001]  eta: 0:00:38  lr: 0.000523  loss: 2.9367 (3.0627)  time: 0.6345  data: 0.0001  max mem: 8728
Epoch: [8]  [1950/2001]  eta: 0:00:32  lr: 0.000523  loss: 2.9266 (3.0616)  time: 0.6331  data: 0.0001  max mem: 8728
Epoch: [8]  [1960/2001]  eta: 0:00:25  lr: 0.000523  loss: 2.9339 (3.0610)  time: 0.6297  data: 0.0001  max mem: 8728
Epoch: [8]  [1970/2001]  eta: 0:00:19  lr: 0.000523  loss: 2.9193 (3.0590)  time: 0.6318  data: 0.0001  max mem: 8728
Epoch: [8]  [1980/2001]  eta: 0:00:13  lr: 0.000523  loss: 2.9771 (3.0590)  time: 0.6330  data: 0.0001  max mem: 8728
Epoch: [8]  [1990/2001]  eta: 0:00:06  lr: 0.000523  loss: 3.1962 (3.0585)  time: 0.6283  data: 0.0004  max mem: 8728
loss info: cls_loss=2.8130, ratio_loss=0.0479, cls_kl=0.0633, token_kl=0.0919
Epoch: [8]  [2000/2001]  eta: 0:00:00  lr: 0.000523  loss: 3.1490 (3.0577)  time: 0.6250  data: 0.0004  max mem: 8728
Epoch: [8] Total time: 0:21:05 (0.6323 s / it)
Averaged stats: lr: 0.000523  loss: 3.1490 (3.0688)
Test:  [ 0/53]  eta: 0:05:23  loss: 0.3622 (0.3622)  acc1: 94.1667 (94.1667)  acc5: 100.0000 (100.0000)  time: 6.0983  data: 4.7653  max mem: 8728
Test:  [10/53]  eta: 0:00:39  loss: 0.7776 (0.7818)  acc1: 83.3333 (83.4091)  acc5: 96.6667 (96.5152)  time: 0.9128  data: 0.4422  max mem: 8728
Test:  [20/53]  eta: 0:00:21  loss: 0.7671 (0.7804)  acc1: 83.3333 (83.0556)  acc5: 96.6667 (96.5873)  time: 0.3795  data: 0.0051  max mem: 8728
Test:  [30/53]  eta: 0:00:12  loss: 0.9122 (0.8675)  acc1: 79.1667 (80.7258)  acc5: 93.3333 (95.2957)  time: 0.3553  data: 0.0010  max mem: 8728
Test:  [40/53]  eta: 0:00:06  loss: 1.0800 (0.9308)  acc1: 75.8333 (79.2480)  acc5: 91.6667 (94.4715)  time: 0.3045  data: 0.0010  max mem: 8728
Test:  [50/53]  eta: 0:00:01  loss: 1.0934 (0.9594)  acc1: 75.8333 (78.6111)  acc5: 91.6667 (94.3301)  time: 0.2596  data: 0.0001  max mem: 8728
Test:  [52/53]  eta: 0:00:00  loss: 1.0924 (0.9446)  acc1: 75.8333 (78.8000)  acc5: 93.3333 (94.4160)  time: 0.2461  data: 0.0001  max mem: 8728
Test: Total time: 0:00:22 (0.4299 s / it)
Sparsity0:0.2858860606060606,Sparsity1:0.5488804020100503,Sparsity2:0.7721976,
* Acc@1 78.990 Acc@5 94.456 loss 0.945
Accuracy of the network on the 50000 test images: 79.0%
Max accuracy: 78.99%
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0004982 for PREDICTOR
Epoch: [9]  [   0/2001]  eta: 2:32:49  lr: 0.000498  loss: 2.6775 (2.6775)  time: 4.5826  data: 3.9188  max mem: 8728
Epoch: [9]  [  10/2001]  eta: 0:32:24  lr: 0.000498  loss: 3.3534 (3.2906)  time: 0.9767  data: 0.3564  max mem: 8730
Epoch: [9]  [  20/2001]  eta: 0:26:32  lr: 0.000498  loss: 3.1786 (3.1808)  time: 0.6150  data: 0.0001  max mem: 8730
Epoch: [9]  [  30/2001]  eta: 0:24:26  lr: 0.000498  loss: 3.1786 (3.1959)  time: 0.6158  data: 0.0001  max mem: 8730
Epoch: [9]  [  40/2001]  eta: 0:23:20  lr: 0.000498  loss: 3.2643 (3.1836)  time: 0.6199  data: 0.0001  max mem: 8730
Epoch: [9]  [  50/2001]  eta: 0:22:39  lr: 0.000498  loss: 3.0810 (3.1414)  time: 0.6235  data: 0.0001  max mem: 8730
Epoch: [9]  [  60/2001]  eta: 0:22:12  lr: 0.000498  loss: 2.8761 (3.0980)  time: 0.6298  data: 0.0001  max mem: 8730
Epoch: [9]  [  70/2001]  eta: 0:21:51  lr: 0.000498  loss: 3.1665 (3.1208)  time: 0.6354  data: 0.0001  max mem: 8730
Epoch: [9]  [  80/2001]  eta: 0:21:34  lr: 0.000498  loss: 3.1863 (3.0935)  time: 0.6346  data: 0.0001  max mem: 8730
Epoch: [9]  [  90/2001]  eta: 0:21:19  lr: 0.000498  loss: 3.1399 (3.1017)  time: 0.6353  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9739, ratio_loss=0.0533, cls_kl=0.0653, token_kl=0.0939
Epoch: [9]  [ 100/2001]  eta: 0:21:06  lr: 0.000498  loss: 3.0638 (3.0869)  time: 0.6360  data: 0.0001  max mem: 8730
Epoch: [9]  [ 110/2001]  eta: 0:20:54  lr: 0.000498  loss: 3.1438 (3.0992)  time: 0.6359  data: 0.0001  max mem: 8730
Epoch: [9]  [ 120/2001]  eta: 0:20:44  lr: 0.000498  loss: 3.2367 (3.0933)  time: 0.6392  data: 0.0001  max mem: 8730
Epoch: [9]  [ 130/2001]  eta: 0:20:38  lr: 0.000498  loss: 3.3443 (3.1058)  time: 0.6511  data: 0.0002  max mem: 8730
Epoch: [9]  [ 140/2001]  eta: 0:20:30  lr: 0.000498  loss: 3.3745 (3.1158)  time: 0.6560  data: 0.0002  max mem: 8730
Epoch: [9]  [ 150/2001]  eta: 0:20:20  lr: 0.000498  loss: 3.3091 (3.1085)  time: 0.6435  data: 0.0001  max mem: 8730
Epoch: [9]  [ 160/2001]  eta: 0:20:11  lr: 0.000498  loss: 3.3075 (3.1104)  time: 0.6374  data: 0.0001  max mem: 8730
Epoch: [9]  [ 170/2001]  eta: 0:20:03  lr: 0.000498  loss: 3.3075 (3.1152)  time: 0.6423  data: 0.0001  max mem: 8730
Epoch: [9]  [ 180/2001]  eta: 0:19:54  lr: 0.000498  loss: 3.2354 (3.1122)  time: 0.6416  data: 0.0001  max mem: 8730
Epoch: [9]  [ 190/2001]  eta: 0:19:47  lr: 0.000498  loss: 3.2339 (3.1175)  time: 0.6401  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9950, ratio_loss=0.0528, cls_kl=0.0663, token_kl=0.0929
Epoch: [9]  [ 200/2001]  eta: 0:19:38  lr: 0.000498  loss: 2.9717 (3.1005)  time: 0.6401  data: 0.0001  max mem: 8730
Epoch: [9]  [ 210/2001]  eta: 0:19:32  lr: 0.000498  loss: 2.9223 (3.0969)  time: 0.6457  data: 0.0001  max mem: 8730
Epoch: [9]  [ 220/2001]  eta: 0:19:24  lr: 0.000498  loss: 3.0171 (3.0913)  time: 0.6448  data: 0.0001  max mem: 8730
Epoch: [9]  [ 230/2001]  eta: 0:19:17  lr: 0.000498  loss: 3.0067 (3.0835)  time: 0.6410  data: 0.0001  max mem: 8730
Epoch: [9]  [ 240/2001]  eta: 0:19:09  lr: 0.000498  loss: 3.0888 (3.0835)  time: 0.6417  data: 0.0001  max mem: 8730
Epoch: [9]  [ 250/2001]  eta: 0:19:01  lr: 0.000498  loss: 3.0593 (3.0734)  time: 0.6372  data: 0.0001  max mem: 8730
Epoch: [9]  [ 260/2001]  eta: 0:18:54  lr: 0.000498  loss: 2.7862 (3.0698)  time: 0.6374  data: 0.0001  max mem: 8730
Epoch: [9]  [ 270/2001]  eta: 0:18:46  lr: 0.000498  loss: 3.1764 (3.0776)  time: 0.6380  data: 0.0001  max mem: 8730
Epoch: [9]  [ 280/2001]  eta: 0:18:39  lr: 0.000498  loss: 3.3897 (3.0850)  time: 0.6392  data: 0.0001  max mem: 8730
Epoch: [9]  [ 290/2001]  eta: 0:18:32  lr: 0.000498  loss: 3.3342 (3.0831)  time: 0.6385  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9374, ratio_loss=0.0511, cls_kl=0.0643, token_kl=0.0923
Epoch: [9]  [ 300/2001]  eta: 0:18:25  lr: 0.000498  loss: 2.9502 (3.0777)  time: 0.6372  data: 0.0001  max mem: 8730
Epoch: [9]  [ 310/2001]  eta: 0:18:19  lr: 0.000498  loss: 2.9502 (3.0749)  time: 0.6471  data: 0.0001  max mem: 8730
Epoch: [9]  [ 320/2001]  eta: 0:18:12  lr: 0.000498  loss: 3.1974 (3.0811)  time: 0.6524  data: 0.0001  max mem: 8730
Epoch: [9]  [ 330/2001]  eta: 0:18:05  lr: 0.000498  loss: 3.2345 (3.0887)  time: 0.6445  data: 0.0002  max mem: 8730
Epoch: [9]  [ 340/2001]  eta: 0:17:58  lr: 0.000498  loss: 3.2761 (3.0876)  time: 0.6399  data: 0.0001  max mem: 8730
Epoch: [9]  [ 350/2001]  eta: 0:17:51  lr: 0.000498  loss: 3.0250 (3.0846)  time: 0.6420  data: 0.0001  max mem: 8730
Epoch: [9]  [ 360/2001]  eta: 0:17:44  lr: 0.000498  loss: 2.9466 (3.0807)  time: 0.6415  data: 0.0001  max mem: 8730
Epoch: [9]  [ 370/2001]  eta: 0:17:37  lr: 0.000498  loss: 2.9438 (3.0781)  time: 0.6372  data: 0.0001  max mem: 8730
Epoch: [9]  [ 380/2001]  eta: 0:17:30  lr: 0.000498  loss: 3.0972 (3.0767)  time: 0.6356  data: 0.0001  max mem: 8730
Epoch: [9]  [ 390/2001]  eta: 0:17:24  lr: 0.000498  loss: 3.0432 (3.0703)  time: 0.6409  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9130, ratio_loss=0.0503, cls_kl=0.0672, token_kl=0.0934
Epoch: [9]  [ 400/2001]  eta: 0:17:17  lr: 0.000498  loss: 2.9692 (3.0698)  time: 0.6492  data: 0.0001  max mem: 8730
Epoch: [9]  [ 410/2001]  eta: 0:17:11  lr: 0.000498  loss: 3.1456 (3.0695)  time: 0.6460  data: 0.0001  max mem: 8730
Epoch: [9]  [ 420/2001]  eta: 0:17:04  lr: 0.000498  loss: 3.0231 (3.0662)  time: 0.6395  data: 0.0001  max mem: 8730
Epoch: [9]  [ 430/2001]  eta: 0:16:57  lr: 0.000498  loss: 3.3159 (3.0700)  time: 0.6348  data: 0.0001  max mem: 8730
Epoch: [9]  [ 440/2001]  eta: 0:16:50  lr: 0.000498  loss: 3.2902 (3.0720)  time: 0.6319  data: 0.0001  max mem: 8730
Epoch: [9]  [ 450/2001]  eta: 0:16:43  lr: 0.000498  loss: 3.1907 (3.0762)  time: 0.6321  data: 0.0001  max mem: 8730
Epoch: [9]  [ 460/2001]  eta: 0:16:36  lr: 0.000498  loss: 3.3927 (3.0742)  time: 0.6319  data: 0.0001  max mem: 8730
Epoch: [9]  [ 470/2001]  eta: 0:16:29  lr: 0.000498  loss: 3.3643 (3.0737)  time: 0.6342  data: 0.0001  max mem: 8730
Epoch: [9]  [ 480/2001]  eta: 0:16:22  lr: 0.000498  loss: 3.1278 (3.0723)  time: 0.6402  data: 0.0001  max mem: 8730
Epoch: [9]  [ 490/2001]  eta: 0:16:16  lr: 0.000498  loss: 3.1447 (3.0771)  time: 0.6408  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9704, ratio_loss=0.0540, cls_kl=0.0663, token_kl=0.0934
Epoch: [9]  [ 500/2001]  eta: 0:16:09  lr: 0.000498  loss: 3.0887 (3.0714)  time: 0.6393  data: 0.0001  max mem: 8730
Epoch: [9]  [ 510/2001]  eta: 0:16:03  lr: 0.000498  loss: 2.8501 (3.0695)  time: 0.6427  data: 0.0001  max mem: 8730
Epoch: [9]  [ 520/2001]  eta: 0:15:56  lr: 0.000498  loss: 3.0036 (3.0731)  time: 0.6428  data: 0.0001  max mem: 8730
Epoch: [9]  [ 530/2001]  eta: 0:15:50  lr: 0.000498  loss: 3.2121 (3.0738)  time: 0.6445  data: 0.0001  max mem: 8730
Epoch: [9]  [ 540/2001]  eta: 0:15:43  lr: 0.000498  loss: 3.1379 (3.0711)  time: 0.6426  data: 0.0001  max mem: 8730
Epoch: [9]  [ 550/2001]  eta: 0:15:36  lr: 0.000498  loss: 3.1509 (3.0743)  time: 0.6385  data: 0.0001  max mem: 8730
Epoch: [9]  [ 560/2001]  eta: 0:15:30  lr: 0.000498  loss: 3.2800 (3.0814)  time: 0.6447  data: 0.0001  max mem: 8730
Epoch: [9]  [ 570/2001]  eta: 0:15:23  lr: 0.000498  loss: 3.3998 (3.0853)  time: 0.6478  data: 0.0001  max mem: 8730
Epoch: [9]  [ 580/2001]  eta: 0:15:17  lr: 0.000498  loss: 3.3939 (3.0886)  time: 0.6394  data: 0.0001  max mem: 8730
Epoch: [9]  [ 590/2001]  eta: 0:15:10  lr: 0.000498  loss: 3.0611 (3.0855)  time: 0.6339  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0430, ratio_loss=0.0514, cls_kl=0.0671, token_kl=0.0929
Epoch: [9]  [ 600/2001]  eta: 0:15:03  lr: 0.000498  loss: 3.0865 (3.0864)  time: 0.6315  data: 0.0001  max mem: 8730
Epoch: [9]  [ 610/2001]  eta: 0:14:56  lr: 0.000498  loss: 3.0656 (3.0814)  time: 0.6271  data: 0.0001  max mem: 8730
Epoch: [9]  [ 620/2001]  eta: 0:14:49  lr: 0.000498  loss: 2.9697 (3.0836)  time: 0.6269  data: 0.0001  max mem: 8730
Epoch: [9]  [ 630/2001]  eta: 0:14:43  lr: 0.000498  loss: 3.1479 (3.0820)  time: 0.6264  data: 0.0001  max mem: 8730
Epoch: [9]  [ 640/2001]  eta: 0:14:36  lr: 0.000498  loss: 3.2823 (3.0851)  time: 0.6314  data: 0.0001  max mem: 8730
Epoch: [9]  [ 650/2001]  eta: 0:14:29  lr: 0.000498  loss: 3.3124 (3.0832)  time: 0.6327  data: 0.0001  max mem: 8730
Epoch: [9]  [ 660/2001]  eta: 0:14:23  lr: 0.000498  loss: 3.0172 (3.0838)  time: 0.6297  data: 0.0001  max mem: 8730
Epoch: [9]  [ 670/2001]  eta: 0:14:16  lr: 0.000498  loss: 3.3003 (3.0860)  time: 0.6286  data: 0.0001  max mem: 8730
Epoch: [9]  [ 680/2001]  eta: 0:14:09  lr: 0.000498  loss: 3.3463 (3.0891)  time: 0.6272  data: 0.0001  max mem: 8730
Epoch: [9]  [ 690/2001]  eta: 0:14:02  lr: 0.000498  loss: 3.3389 (3.0920)  time: 0.6304  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0203, ratio_loss=0.0542, cls_kl=0.0663, token_kl=0.0923
Epoch: [9]  [ 700/2001]  eta: 0:13:56  lr: 0.000498  loss: 3.3389 (3.0942)  time: 0.6308  data: 0.0001  max mem: 8730
Epoch: [9]  [ 710/2001]  eta: 0:13:49  lr: 0.000498  loss: 3.4254 (3.0981)  time: 0.6288  data: 0.0001  max mem: 8730
Epoch: [9]  [ 720/2001]  eta: 0:13:42  lr: 0.000498  loss: 3.1346 (3.0955)  time: 0.6262  data: 0.0001  max mem: 8730
Epoch: [9]  [ 730/2001]  eta: 0:13:36  lr: 0.000498  loss: 3.0947 (3.0987)  time: 0.6244  data: 0.0001  max mem: 8730
Epoch: [9]  [ 740/2001]  eta: 0:13:29  lr: 0.000498  loss: 2.9466 (3.0941)  time: 0.6256  data: 0.0001  max mem: 8730
Epoch: [9]  [ 750/2001]  eta: 0:13:22  lr: 0.000498  loss: 2.9351 (3.0931)  time: 0.6271  data: 0.0001  max mem: 8730
Epoch: [9]  [ 760/2001]  eta: 0:13:16  lr: 0.000498  loss: 3.1294 (3.0915)  time: 0.6274  data: 0.0001  max mem: 8730
Epoch: [9]  [ 770/2001]  eta: 0:13:09  lr: 0.000498  loss: 3.3343 (3.0935)  time: 0.6271  data: 0.0001  max mem: 8730
Epoch: [9]  [ 780/2001]  eta: 0:13:02  lr: 0.000498  loss: 3.1731 (3.0920)  time: 0.6307  data: 0.0001  max mem: 8730
Epoch: [9]  [ 790/2001]  eta: 0:12:56  lr: 0.000498  loss: 2.9542 (3.0909)  time: 0.6328  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9564, ratio_loss=0.0519, cls_kl=0.0655, token_kl=0.0919
Epoch: [9]  [ 800/2001]  eta: 0:12:49  lr: 0.000498  loss: 2.9621 (3.0898)  time: 0.6260  data: 0.0001  max mem: 8730
Epoch: [9]  [ 810/2001]  eta: 0:12:42  lr: 0.000498  loss: 3.2170 (3.0902)  time: 0.6220  data: 0.0001  max mem: 8730
Epoch: [9]  [ 820/2001]  eta: 0:12:36  lr: 0.000498  loss: 3.2216 (3.0911)  time: 0.6269  data: 0.0001  max mem: 8730
Epoch: [9]  [ 830/2001]  eta: 0:12:29  lr: 0.000498  loss: 2.9341 (3.0894)  time: 0.6332  data: 0.0001  max mem: 8730
Epoch: [9]  [ 840/2001]  eta: 0:12:23  lr: 0.000498  loss: 3.0142 (3.0901)  time: 0.6309  data: 0.0001  max mem: 8730
Epoch: [9]  [ 850/2001]  eta: 0:12:16  lr: 0.000498  loss: 2.9937 (3.0873)  time: 0.6271  data: 0.0001  max mem: 8730
Epoch: [9]  [ 860/2001]  eta: 0:12:10  lr: 0.000498  loss: 2.5967 (3.0808)  time: 0.6258  data: 0.0001  max mem: 8730
Epoch: [9]  [ 870/2001]  eta: 0:12:03  lr: 0.000498  loss: 2.5967 (3.0783)  time: 0.6248  data: 0.0001  max mem: 8730
Epoch: [9]  [ 880/2001]  eta: 0:11:56  lr: 0.000498  loss: 3.1019 (3.0776)  time: 0.6246  data: 0.0001  max mem: 8730
Epoch: [9]  [ 890/2001]  eta: 0:11:50  lr: 0.000498  loss: 3.0017 (3.0745)  time: 0.6253  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8609, ratio_loss=0.0480, cls_kl=0.0629, token_kl=0.0914
Epoch: [9]  [ 900/2001]  eta: 0:11:43  lr: 0.000498  loss: 3.0017 (3.0772)  time: 0.6265  data: 0.0001  max mem: 8730
Epoch: [9]  [ 910/2001]  eta: 0:11:37  lr: 0.000498  loss: 3.1116 (3.0746)  time: 0.6288  data: 0.0001  max mem: 8730
Epoch: [9]  [ 920/2001]  eta: 0:11:30  lr: 0.000498  loss: 3.0367 (3.0751)  time: 0.6291  data: 0.0001  max mem: 8730
Epoch: [9]  [ 930/2001]  eta: 0:11:24  lr: 0.000498  loss: 3.2625 (3.0767)  time: 0.6352  data: 0.0001  max mem: 8730
Epoch: [9]  [ 940/2001]  eta: 0:11:17  lr: 0.000498  loss: 3.3025 (3.0786)  time: 0.6352  data: 0.0001  max mem: 8730
Epoch: [9]  [ 950/2001]  eta: 0:11:11  lr: 0.000498  loss: 3.0500 (3.0750)  time: 0.6265  data: 0.0001  max mem: 8730
Epoch: [9]  [ 960/2001]  eta: 0:11:04  lr: 0.000498  loss: 3.0135 (3.0749)  time: 0.6249  data: 0.0001  max mem: 8730
Epoch: [9]  [ 970/2001]  eta: 0:10:58  lr: 0.000498  loss: 3.1681 (3.0760)  time: 0.6256  data: 0.0001  max mem: 8730
Epoch: [9]  [ 980/2001]  eta: 0:10:51  lr: 0.000498  loss: 3.1655 (3.0747)  time: 0.6340  data: 0.0001  max mem: 8730
Epoch: [9]  [ 990/2001]  eta: 0:10:45  lr: 0.000498  loss: 3.1655 (3.0765)  time: 0.6365  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9630, ratio_loss=0.0524, cls_kl=0.0662, token_kl=0.0922
Epoch: [9]  [1000/2001]  eta: 0:10:38  lr: 0.000498  loss: 3.3732 (3.0768)  time: 0.6282  data: 0.0001  max mem: 8730
Epoch: [9]  [1010/2001]  eta: 0:10:32  lr: 0.000498  loss: 3.2660 (3.0782)  time: 0.6235  data: 0.0001  max mem: 8730
Epoch: [9]  [1020/2001]  eta: 0:10:25  lr: 0.000498  loss: 3.2312 (3.0779)  time: 0.6227  data: 0.0001  max mem: 8730
Epoch: [9]  [1030/2001]  eta: 0:10:19  lr: 0.000498  loss: 3.0727 (3.0761)  time: 0.6251  data: 0.0001  max mem: 8730
Epoch: [9]  [1040/2001]  eta: 0:10:13  lr: 0.000498  loss: 3.1608 (3.0769)  time: 0.6294  data: 0.0001  max mem: 8730
Epoch: [9]  [1050/2001]  eta: 0:10:06  lr: 0.000498  loss: 3.2322 (3.0779)  time: 0.6276  data: 0.0001  max mem: 8730
Epoch: [9]  [1060/2001]  eta: 0:10:00  lr: 0.000498  loss: 3.1829 (3.0768)  time: 0.6262  data: 0.0001  max mem: 8730
Epoch: [9]  [1070/2001]  eta: 0:09:53  lr: 0.000498  loss: 3.1565 (3.0773)  time: 0.6294  data: 0.0001  max mem: 8730
Epoch: [9]  [1080/2001]  eta: 0:09:47  lr: 0.000498  loss: 3.0519 (3.0755)  time: 0.6298  data: 0.0001  max mem: 8730
Epoch: [9]  [1090/2001]  eta: 0:09:40  lr: 0.000498  loss: 3.0519 (3.0746)  time: 0.6321  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9493, ratio_loss=0.0470, cls_kl=0.0631, token_kl=0.0916
Epoch: [9]  [1100/2001]  eta: 0:09:34  lr: 0.000498  loss: 3.1924 (3.0750)  time: 0.6317  data: 0.0001  max mem: 8730
Epoch: [9]  [1110/2001]  eta: 0:09:27  lr: 0.000498  loss: 3.1989 (3.0747)  time: 0.6276  data: 0.0001  max mem: 8730
Epoch: [9]  [1120/2001]  eta: 0:09:21  lr: 0.000498  loss: 3.0000 (3.0739)  time: 0.6346  data: 0.0001  max mem: 8730
Epoch: [9]  [1130/2001]  eta: 0:09:15  lr: 0.000498  loss: 3.0102 (3.0744)  time: 0.6433  data: 0.0001  max mem: 8730
Epoch: [9]  [1140/2001]  eta: 0:09:08  lr: 0.000498  loss: 2.8697 (3.0717)  time: 0.6376  data: 0.0001  max mem: 8730
Epoch: [9]  [1150/2001]  eta: 0:09:02  lr: 0.000498  loss: 2.8697 (3.0725)  time: 0.6289  data: 0.0001  max mem: 8730
Epoch: [9]  [1160/2001]  eta: 0:08:55  lr: 0.000498  loss: 3.2967 (3.0712)  time: 0.6274  data: 0.0001  max mem: 8730
Epoch: [9]  [1170/2001]  eta: 0:08:49  lr: 0.000498  loss: 3.0389 (3.0716)  time: 0.6277  data: 0.0001  max mem: 8730
Epoch: [9]  [1180/2001]  eta: 0:08:43  lr: 0.000498  loss: 3.1916 (3.0720)  time: 0.6331  data: 0.0001  max mem: 8730
Epoch: [9]  [1190/2001]  eta: 0:08:36  lr: 0.000498  loss: 3.0633 (3.0691)  time: 0.6330  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9044, ratio_loss=0.0493, cls_kl=0.0643, token_kl=0.0919
Epoch: [9]  [1200/2001]  eta: 0:08:30  lr: 0.000498  loss: 3.0633 (3.0701)  time: 0.6307  data: 0.0001  max mem: 8730
Epoch: [9]  [1210/2001]  eta: 0:08:23  lr: 0.000498  loss: 3.3205 (3.0715)  time: 0.6307  data: 0.0001  max mem: 8730
Epoch: [9]  [1220/2001]  eta: 0:08:17  lr: 0.000498  loss: 3.2609 (3.0723)  time: 0.6295  data: 0.0001  max mem: 8730
Epoch: [9]  [1230/2001]  eta: 0:08:11  lr: 0.000498  loss: 3.2189 (3.0741)  time: 0.6339  data: 0.0001  max mem: 8730
Epoch: [9]  [1240/2001]  eta: 0:08:04  lr: 0.000498  loss: 3.4457 (3.0767)  time: 0.6347  data: 0.0001  max mem: 8730
Epoch: [9]  [1250/2001]  eta: 0:07:58  lr: 0.000498  loss: 3.4184 (3.0771)  time: 0.6411  data: 0.0001  max mem: 8730
Epoch: [9]  [1260/2001]  eta: 0:07:52  lr: 0.000498  loss: 2.9891 (3.0766)  time: 0.6446  data: 0.0001  max mem: 8730
Epoch: [9]  [1270/2001]  eta: 0:07:45  lr: 0.000498  loss: 3.0702 (3.0771)  time: 0.6377  data: 0.0001  max mem: 8730
Epoch: [9]  [1280/2001]  eta: 0:07:39  lr: 0.000498  loss: 3.0702 (3.0765)  time: 0.6346  data: 0.0001  max mem: 8730
Epoch: [9]  [1290/2001]  eta: 0:07:32  lr: 0.000498  loss: 3.0746 (3.0771)  time: 0.6343  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0543, ratio_loss=0.0565, cls_kl=0.0702, token_kl=0.0987
Epoch: [9]  [1300/2001]  eta: 0:07:26  lr: 0.000498  loss: 3.2342 (3.0778)  time: 0.6326  data: 0.0001  max mem: 8730
Epoch: [9]  [1310/2001]  eta: 0:07:20  lr: 0.000498  loss: 3.3214 (3.0790)  time: 0.6354  data: 0.0001  max mem: 8730
Epoch: [9]  [1320/2001]  eta: 0:07:13  lr: 0.000498  loss: 3.1798 (3.0789)  time: 0.6405  data: 0.0001  max mem: 8730
Epoch: [9]  [1330/2001]  eta: 0:07:07  lr: 0.000498  loss: 3.1798 (3.0766)  time: 0.6404  data: 0.0001  max mem: 8730
Epoch: [9]  [1340/2001]  eta: 0:07:01  lr: 0.000498  loss: 2.8494 (3.0748)  time: 0.6382  data: 0.0001  max mem: 8730
Epoch: [9]  [1350/2001]  eta: 0:06:54  lr: 0.000498  loss: 3.0935 (3.0749)  time: 0.6370  data: 0.0001  max mem: 8730
Epoch: [9]  [1360/2001]  eta: 0:06:48  lr: 0.000498  loss: 3.0935 (3.0744)  time: 0.6468  data: 0.0001  max mem: 8730
Epoch: [9]  [1370/2001]  eta: 0:06:41  lr: 0.000498  loss: 3.0647 (3.0741)  time: 0.6433  data: 0.0001  max mem: 8730
Epoch: [9]  [1380/2001]  eta: 0:06:35  lr: 0.000498  loss: 3.1298 (3.0742)  time: 0.6333  data: 0.0001  max mem: 8730
Epoch: [9]  [1390/2001]  eta: 0:06:29  lr: 0.000498  loss: 3.3766 (3.0764)  time: 0.6356  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9263, ratio_loss=0.0515, cls_kl=0.0654, token_kl=0.0936
Epoch: [9]  [1400/2001]  eta: 0:06:22  lr: 0.000498  loss: 3.2007 (3.0751)  time: 0.6332  data: 0.0001  max mem: 8730
Epoch: [9]  [1410/2001]  eta: 0:06:16  lr: 0.000498  loss: 3.0540 (3.0754)  time: 0.6422  data: 0.0001  max mem: 8730
Epoch: [9]  [1420/2001]  eta: 0:06:10  lr: 0.000498  loss: 3.3293 (3.0761)  time: 0.6419  data: 0.0001  max mem: 8730
Epoch: [9]  [1430/2001]  eta: 0:06:03  lr: 0.000498  loss: 2.9849 (3.0756)  time: 0.6335  data: 0.0001  max mem: 8730
Epoch: [9]  [1440/2001]  eta: 0:05:57  lr: 0.000498  loss: 2.8877 (3.0747)  time: 0.6377  data: 0.0001  max mem: 8730
Epoch: [9]  [1450/2001]  eta: 0:05:51  lr: 0.000498  loss: 2.8644 (3.0743)  time: 0.6373  data: 0.0001  max mem: 8730
Epoch: [9]  [1460/2001]  eta: 0:05:44  lr: 0.000498  loss: 3.2036 (3.0747)  time: 0.6347  data: 0.0001  max mem: 8730
Epoch: [9]  [1470/2001]  eta: 0:05:38  lr: 0.000498  loss: 2.7917 (3.0723)  time: 0.6341  data: 0.0001  max mem: 8730
Epoch: [9]  [1480/2001]  eta: 0:05:31  lr: 0.000498  loss: 2.8939 (3.0725)  time: 0.6386  data: 0.0001  max mem: 8730
Epoch: [9]  [1490/2001]  eta: 0:05:25  lr: 0.000498  loss: 3.1587 (3.0730)  time: 0.6452  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9029, ratio_loss=0.0495, cls_kl=0.0631, token_kl=0.0927
Epoch: [9]  [1500/2001]  eta: 0:05:19  lr: 0.000498  loss: 3.1239 (3.0718)  time: 0.6413  data: 0.0001  max mem: 8730
Epoch: [9]  [1510/2001]  eta: 0:05:12  lr: 0.000498  loss: 3.0898 (3.0719)  time: 0.6366  data: 0.0001  max mem: 8730
Epoch: [9]  [1520/2001]  eta: 0:05:06  lr: 0.000498  loss: 2.8918 (3.0701)  time: 0.6377  data: 0.0001  max mem: 8730
Epoch: [9]  [1530/2001]  eta: 0:05:00  lr: 0.000498  loss: 3.0586 (3.0704)  time: 0.6378  data: 0.0001  max mem: 8730
Epoch: [9]  [1540/2001]  eta: 0:04:53  lr: 0.000498  loss: 3.0477 (3.0699)  time: 0.6399  data: 0.0001  max mem: 8730
Epoch: [9]  [1550/2001]  eta: 0:04:47  lr: 0.000498  loss: 2.9021 (3.0688)  time: 0.6386  data: 0.0001  max mem: 8730
Epoch: [9]  [1560/2001]  eta: 0:04:40  lr: 0.000498  loss: 3.2863 (3.0706)  time: 0.6359  data: 0.0001  max mem: 8730
Epoch: [9]  [1570/2001]  eta: 0:04:34  lr: 0.000498  loss: 3.4563 (3.0709)  time: 0.6364  data: 0.0001  max mem: 8730
Epoch: [9]  [1580/2001]  eta: 0:04:28  lr: 0.000498  loss: 3.2861 (3.0719)  time: 0.6366  data: 0.0001  max mem: 8730
Epoch: [9]  [1590/2001]  eta: 0:04:21  lr: 0.000498  loss: 3.2640 (3.0729)  time: 0.6363  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9766, ratio_loss=0.0542, cls_kl=0.0672, token_kl=0.0946
Epoch: [9]  [1600/2001]  eta: 0:04:15  lr: 0.000498  loss: 3.1581 (3.0723)  time: 0.6381  data: 0.0001  max mem: 8730
Epoch: [9]  [1610/2001]  eta: 0:04:09  lr: 0.000498  loss: 3.1399 (3.0727)  time: 0.6377  data: 0.0001  max mem: 8730
Epoch: [9]  [1620/2001]  eta: 0:04:02  lr: 0.000498  loss: 3.4188 (3.0742)  time: 0.6405  data: 0.0001  max mem: 8730
Epoch: [9]  [1630/2001]  eta: 0:03:56  lr: 0.000498  loss: 3.3328 (3.0756)  time: 0.6479  data: 0.0001  max mem: 8730
Epoch: [9]  [1640/2001]  eta: 0:03:50  lr: 0.000498  loss: 3.2335 (3.0760)  time: 0.6438  data: 0.0001  max mem: 8730
Epoch: [9]  [1650/2001]  eta: 0:03:43  lr: 0.000498  loss: 3.2335 (3.0776)  time: 0.6369  data: 0.0001  max mem: 8730
Epoch: [9]  [1660/2001]  eta: 0:03:37  lr: 0.000498  loss: 3.2918 (3.0773)  time: 0.6355  data: 0.0001  max mem: 8730
Epoch: [9]  [1670/2001]  eta: 0:03:30  lr: 0.000498  loss: 3.2623 (3.0782)  time: 0.6345  data: 0.0001  max mem: 8730
Epoch: [9]  [1680/2001]  eta: 0:03:24  lr: 0.000498  loss: 3.2623 (3.0788)  time: 0.6470  data: 0.0001  max mem: 8730
Epoch: [9]  [1690/2001]  eta: 0:03:18  lr: 0.000498  loss: 3.1548 (3.0792)  time: 0.6468  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0633, ratio_loss=0.0508, cls_kl=0.0682, token_kl=0.0932
Epoch: [9]  [1700/2001]  eta: 0:03:11  lr: 0.000498  loss: 3.1548 (3.0793)  time: 0.6355  data: 0.0001  max mem: 8730
Epoch: [9]  [1710/2001]  eta: 0:03:05  lr: 0.000498  loss: 3.0421 (3.0785)  time: 0.6368  data: 0.0001  max mem: 8730
Epoch: [9]  [1720/2001]  eta: 0:02:59  lr: 0.000498  loss: 3.2156 (3.0795)  time: 0.6363  data: 0.0001  max mem: 8730
Epoch: [9]  [1730/2001]  eta: 0:02:52  lr: 0.000498  loss: 3.3337 (3.0807)  time: 0.6355  data: 0.0001  max mem: 8730
Epoch: [9]  [1740/2001]  eta: 0:02:46  lr: 0.000498  loss: 3.2713 (3.0811)  time: 0.6367  data: 0.0001  max mem: 8730
Epoch: [9]  [1750/2001]  eta: 0:02:39  lr: 0.000498  loss: 3.1361 (3.0803)  time: 0.6372  data: 0.0001  max mem: 8730
Epoch: [9]  [1760/2001]  eta: 0:02:33  lr: 0.000498  loss: 3.0353 (3.0809)  time: 0.6400  data: 0.0001  max mem: 8730
Epoch: [9]  [1770/2001]  eta: 0:02:27  lr: 0.000498  loss: 3.3568 (3.0815)  time: 0.6421  data: 0.0001  max mem: 8730
Epoch: [9]  [1780/2001]  eta: 0:02:20  lr: 0.000498  loss: 3.1608 (3.0800)  time: 0.6475  data: 0.0001  max mem: 8730
Epoch: [9]  [1790/2001]  eta: 0:02:14  lr: 0.000498  loss: 3.1506 (3.0809)  time: 0.6526  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0007, ratio_loss=0.0541, cls_kl=0.0686, token_kl=0.0940
Epoch: [9]  [1800/2001]  eta: 0:02:08  lr: 0.000498  loss: 3.1766 (3.0813)  time: 0.6447  data: 0.0001  max mem: 8730
Epoch: [9]  [1810/2001]  eta: 0:02:01  lr: 0.000498  loss: 3.1589 (3.0812)  time: 0.6384  data: 0.0001  max mem: 8730
Epoch: [9]  [1820/2001]  eta: 0:01:55  lr: 0.000498  loss: 3.0956 (3.0803)  time: 0.6384  data: 0.0001  max mem: 8730
Epoch: [9]  [1830/2001]  eta: 0:01:49  lr: 0.000498  loss: 3.2024 (3.0808)  time: 0.6408  data: 0.0001  max mem: 8730
Epoch: [9]  [1840/2001]  eta: 0:01:42  lr: 0.000498  loss: 3.1410 (3.0790)  time: 0.6442  data: 0.0001  max mem: 8730
Epoch: [9]  [1850/2001]  eta: 0:01:36  lr: 0.000498  loss: 3.1408 (3.0804)  time: 0.6398  data: 0.0001  max mem: 8730
Epoch: [9]  [1860/2001]  eta: 0:01:29  lr: 0.000498  loss: 3.0549 (3.0794)  time: 0.6332  data: 0.0001  max mem: 8730
Epoch: [9]  [1870/2001]  eta: 0:01:23  lr: 0.000498  loss: 2.9922 (3.0794)  time: 0.6322  data: 0.0001  max mem: 8730
Epoch: [9]  [1880/2001]  eta: 0:01:17  lr: 0.000498  loss: 3.0524 (3.0778)  time: 0.6325  data: 0.0001  max mem: 8730
Epoch: [9]  [1890/2001]  eta: 0:01:10  lr: 0.000498  loss: 2.9959 (3.0769)  time: 0.6322  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8720, ratio_loss=0.0498, cls_kl=0.0633, token_kl=0.0918
Epoch: [9]  [1900/2001]  eta: 0:01:04  lr: 0.000498  loss: 3.0108 (3.0758)  time: 0.6324  data: 0.0001  max mem: 8730
Epoch: [9]  [1910/2001]  eta: 0:00:58  lr: 0.000498  loss: 3.0352 (3.0759)  time: 0.6326  data: 0.0001  max mem: 8730
Epoch: [9]  [1920/2001]  eta: 0:00:51  lr: 0.000498  loss: 3.0537 (3.0757)  time: 0.6339  data: 0.0001  max mem: 8730
Epoch: [9]  [1930/2001]  eta: 0:00:45  lr: 0.000498  loss: 3.0898 (3.0749)  time: 0.6343  data: 0.0001  max mem: 8730
Epoch: [9]  [1940/2001]  eta: 0:00:38  lr: 0.000498  loss: 3.0275 (3.0740)  time: 0.6374  data: 0.0001  max mem: 8730
Epoch: [9]  [1950/2001]  eta: 0:00:32  lr: 0.000498  loss: 3.0275 (3.0730)  time: 0.6396  data: 0.0001  max mem: 8730
Epoch: [9]  [1960/2001]  eta: 0:00:26  lr: 0.000498  loss: 3.1461 (3.0739)  time: 0.6331  data: 0.0001  max mem: 8730
Epoch: [9]  [1970/2001]  eta: 0:00:19  lr: 0.000498  loss: 3.2104 (3.0747)  time: 0.6312  data: 0.0001  max mem: 8730
Epoch: [9]  [1980/2001]  eta: 0:00:13  lr: 0.000498  loss: 3.2104 (3.0747)  time: 0.6362  data: 0.0001  max mem: 8730
Epoch: [9]  [1990/2001]  eta: 0:00:07  lr: 0.000498  loss: 3.1052 (3.0743)  time: 0.6336  data: 0.0004  max mem: 8730
loss info: cls_loss=2.9146, ratio_loss=0.0546, cls_kl=0.0662, token_kl=0.0952
Epoch: [9]  [2000/2001]  eta: 0:00:00  lr: 0.000498  loss: 3.1085 (3.0742)  time: 0.6295  data: 0.0003  max mem: 8730
Epoch: [9] Total time: 0:21:15 (0.6376 s / it)
Averaged stats: lr: 0.000498  loss: 3.1085 (3.0629)
Test:  [ 0/53]  eta: 0:05:09  loss: 0.3581 (0.3581)  acc1: 93.3333 (93.3333)  acc5: 100.0000 (100.0000)  time: 5.8320  data: 4.7863  max mem: 8730
Test:  [10/53]  eta: 0:00:37  loss: 0.7239 (0.7718)  acc1: 84.1667 (83.1818)  acc5: 96.6667 (96.4394)  time: 0.8650  data: 0.4359  max mem: 8730
Test:  [20/53]  eta: 0:00:20  loss: 0.7239 (0.7826)  acc1: 80.8333 (82.5794)  acc5: 95.8333 (96.3492)  time: 0.3634  data: 0.0005  max mem: 8730
Test:  [30/53]  eta: 0:00:12  loss: 0.9059 (0.8637)  acc1: 80.0000 (80.7527)  acc5: 94.1667 (95.1075)  time: 0.3657  data: 0.0008  max mem: 8730
Test:  [40/53]  eta: 0:00:06  loss: 1.1268 (0.9327)  acc1: 75.8333 (78.9431)  acc5: 91.6667 (94.3089)  time: 0.3186  data: 0.0007  max mem: 8730
Test:  [50/53]  eta: 0:00:01  loss: 1.1229 (0.9606)  acc1: 74.1667 (78.1863)  acc5: 92.5000 (94.2157)  time: 0.2581  data: 0.0001  max mem: 8730
Test:  [52/53]  eta: 0:00:00  loss: 1.1206 (0.9439)  acc1: 75.0000 (78.3840)  acc5: 92.5000 (94.2880)  time: 0.2459  data: 0.0001  max mem: 8730
Test: Total time: 0:00:22 (0.4232 s / it)
Sparsity0:0.28235313131313133,Sparsity1:0.5464024120603015,Sparsity2:0.7730712,
* Acc@1 78.892 Acc@5 94.554 loss 0.941
Accuracy of the network on the 50000 test images: 78.9%
Max accuracy: 78.99%
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0004712 for PREDICTOR
Epoch: [10]  [   0/2001]  eta: 2:54:58  lr: 0.000471  loss: 1.8557 (1.8557)  time: 5.2464  data: 2.9290  max mem: 8730
Epoch: [10]  [  10/2001]  eta: 0:34:26  lr: 0.000471  loss: 3.1597 (2.8865)  time: 1.0380  data: 0.2664  max mem: 8730
Epoch: [10]  [  20/2001]  eta: 0:27:44  lr: 0.000471  loss: 3.3369 (3.0556)  time: 0.6198  data: 0.0001  max mem: 8730
Epoch: [10]  [  30/2001]  eta: 0:25:10  lr: 0.000471  loss: 3.0089 (3.0087)  time: 0.6173  data: 0.0001  max mem: 8730
Epoch: [10]  [  40/2001]  eta: 0:23:51  lr: 0.000471  loss: 3.0089 (3.0556)  time: 0.6143  data: 0.0002  max mem: 8730
Epoch: [10]  [  50/2001]  eta: 0:23:01  lr: 0.000471  loss: 3.3562 (3.1203)  time: 0.6179  data: 0.0002  max mem: 8730
Epoch: [10]  [  60/2001]  eta: 0:22:27  lr: 0.000471  loss: 3.3679 (3.1182)  time: 0.6212  data: 0.0002  max mem: 8730
Epoch: [10]  [  70/2001]  eta: 0:22:01  lr: 0.000471  loss: 2.9409 (3.0544)  time: 0.6242  data: 0.0002  max mem: 8730
Epoch: [10]  [  80/2001]  eta: 0:21:40  lr: 0.000471  loss: 2.5653 (3.0137)  time: 0.6251  data: 0.0002  max mem: 8730
Epoch: [10]  [  90/2001]  eta: 0:21:23  lr: 0.000471  loss: 2.7627 (3.0081)  time: 0.6249  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9008, ratio_loss=0.0508, cls_kl=0.0648, token_kl=0.0929
Epoch: [10]  [ 100/2001]  eta: 0:21:10  lr: 0.000471  loss: 2.9664 (2.9852)  time: 0.6316  data: 0.0001  max mem: 8730
Epoch: [10]  [ 110/2001]  eta: 0:20:56  lr: 0.000471  loss: 3.2241 (3.0103)  time: 0.6322  data: 0.0001  max mem: 8730
Epoch: [10]  [ 120/2001]  eta: 0:20:45  lr: 0.000471  loss: 3.2270 (3.0095)  time: 0.6325  data: 0.0001  max mem: 8730
Epoch: [10]  [ 130/2001]  eta: 0:20:36  lr: 0.000471  loss: 3.0303 (3.0114)  time: 0.6398  data: 0.0001  max mem: 8730
Epoch: [10]  [ 140/2001]  eta: 0:20:25  lr: 0.000471  loss: 3.0189 (3.0154)  time: 0.6359  data: 0.0001  max mem: 8730
Epoch: [10]  [ 150/2001]  eta: 0:20:15  lr: 0.000471  loss: 3.1617 (3.0183)  time: 0.6309  data: 0.0001  max mem: 8730
Epoch: [10]  [ 160/2001]  eta: 0:20:06  lr: 0.000471  loss: 3.0578 (3.0079)  time: 0.6323  data: 0.0001  max mem: 8730
Epoch: [10]  [ 170/2001]  eta: 0:19:56  lr: 0.000471  loss: 3.1203 (3.0219)  time: 0.6297  data: 0.0001  max mem: 8730
Epoch: [10]  [ 180/2001]  eta: 0:19:47  lr: 0.000471  loss: 3.2563 (3.0320)  time: 0.6289  data: 0.0001  max mem: 8730
Epoch: [10]  [ 190/2001]  eta: 0:19:38  lr: 0.000471  loss: 3.1194 (3.0303)  time: 0.6275  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9464, ratio_loss=0.0528, cls_kl=0.0664, token_kl=0.0957
Epoch: [10]  [ 200/2001]  eta: 0:19:30  lr: 0.000471  loss: 3.1634 (3.0376)  time: 0.6271  data: 0.0001  max mem: 8730
Epoch: [10]  [ 210/2001]  eta: 0:19:22  lr: 0.000471  loss: 3.1634 (3.0412)  time: 0.6317  data: 0.0001  max mem: 8730
Epoch: [10]  [ 220/2001]  eta: 0:19:13  lr: 0.000471  loss: 3.2714 (3.0466)  time: 0.6272  data: 0.0001  max mem: 8730
Epoch: [10]  [ 230/2001]  eta: 0:19:05  lr: 0.000471  loss: 3.2570 (3.0326)  time: 0.6234  data: 0.0001  max mem: 8730
Epoch: [10]  [ 240/2001]  eta: 0:18:58  lr: 0.000471  loss: 2.9995 (3.0342)  time: 0.6311  data: 0.0001  max mem: 8730
Epoch: [10]  [ 250/2001]  eta: 0:18:50  lr: 0.000471  loss: 3.1362 (3.0382)  time: 0.6304  data: 0.0001  max mem: 8730
Epoch: [10]  [ 260/2001]  eta: 0:18:42  lr: 0.000471  loss: 3.1128 (3.0371)  time: 0.6269  data: 0.0001  max mem: 8730
Epoch: [10]  [ 270/2001]  eta: 0:18:35  lr: 0.000471  loss: 3.0537 (3.0325)  time: 0.6310  data: 0.0001  max mem: 8730
Epoch: [10]  [ 280/2001]  eta: 0:18:27  lr: 0.000471  loss: 3.0537 (3.0353)  time: 0.6277  data: 0.0001  max mem: 8730
Epoch: [10]  [ 290/2001]  eta: 0:18:20  lr: 0.000471  loss: 3.2570 (3.0391)  time: 0.6251  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9427, ratio_loss=0.0492, cls_kl=0.0639, token_kl=0.0923
Epoch: [10]  [ 300/2001]  eta: 0:18:12  lr: 0.000471  loss: 3.0013 (3.0333)  time: 0.6244  data: 0.0001  max mem: 8730
Epoch: [10]  [ 310/2001]  eta: 0:18:05  lr: 0.000471  loss: 3.2502 (3.0414)  time: 0.6249  data: 0.0001  max mem: 8730
Epoch: [10]  [ 320/2001]  eta: 0:17:58  lr: 0.000471  loss: 3.2502 (3.0429)  time: 0.6267  data: 0.0001  max mem: 8730
Epoch: [10]  [ 330/2001]  eta: 0:17:50  lr: 0.000471  loss: 3.2323 (3.0433)  time: 0.6250  data: 0.0001  max mem: 8730
Epoch: [10]  [ 340/2001]  eta: 0:17:43  lr: 0.000471  loss: 3.1302 (3.0374)  time: 0.6220  data: 0.0001  max mem: 8730
Epoch: [10]  [ 350/2001]  eta: 0:17:36  lr: 0.000471  loss: 3.1438 (3.0403)  time: 0.6239  data: 0.0001  max mem: 8730
Epoch: [10]  [ 360/2001]  eta: 0:17:29  lr: 0.000471  loss: 3.2150 (3.0435)  time: 0.6251  data: 0.0001  max mem: 8730
Epoch: [10]  [ 370/2001]  eta: 0:17:22  lr: 0.000471  loss: 3.2527 (3.0482)  time: 0.6283  data: 0.0001  max mem: 8730
Epoch: [10]  [ 380/2001]  eta: 0:17:15  lr: 0.000471  loss: 3.2069 (3.0440)  time: 0.6301  data: 0.0001  max mem: 8730
Epoch: [10]  [ 390/2001]  eta: 0:17:08  lr: 0.000471  loss: 3.1808 (3.0509)  time: 0.6270  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9785, ratio_loss=0.0500, cls_kl=0.0653, token_kl=0.0914
Epoch: [10]  [ 400/2001]  eta: 0:17:02  lr: 0.000471  loss: 3.3531 (3.0551)  time: 0.6331  data: 0.0001  max mem: 8730
Epoch: [10]  [ 410/2001]  eta: 0:16:55  lr: 0.000471  loss: 3.2269 (3.0587)  time: 0.6347  data: 0.0001  max mem: 8730
Epoch: [10]  [ 420/2001]  eta: 0:16:48  lr: 0.000471  loss: 3.2313 (3.0582)  time: 0.6288  data: 0.0001  max mem: 8730
Epoch: [10]  [ 430/2001]  eta: 0:16:42  lr: 0.000471  loss: 3.1728 (3.0541)  time: 0.6301  data: 0.0001  max mem: 8730
Epoch: [10]  [ 440/2001]  eta: 0:16:35  lr: 0.000471  loss: 3.1875 (3.0553)  time: 0.6313  data: 0.0001  max mem: 8730
Epoch: [10]  [ 450/2001]  eta: 0:16:29  lr: 0.000471  loss: 3.1875 (3.0529)  time: 0.6285  data: 0.0001  max mem: 8730
Epoch: [10]  [ 460/2001]  eta: 0:16:22  lr: 0.000471  loss: 3.0658 (3.0512)  time: 0.6263  data: 0.0001  max mem: 8730
Epoch: [10]  [ 470/2001]  eta: 0:16:15  lr: 0.000471  loss: 3.3690 (3.0614)  time: 0.6251  data: 0.0001  max mem: 8730
Epoch: [10]  [ 480/2001]  eta: 0:16:08  lr: 0.000471  loss: 3.3799 (3.0635)  time: 0.6292  data: 0.0001  max mem: 8730
Epoch: [10]  [ 490/2001]  eta: 0:16:02  lr: 0.000471  loss: 3.1349 (3.0572)  time: 0.6316  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9609, ratio_loss=0.0502, cls_kl=0.0668, token_kl=0.0936
Epoch: [10]  [ 500/2001]  eta: 0:15:55  lr: 0.000471  loss: 2.8977 (3.0574)  time: 0.6301  data: 0.0001  max mem: 8730
Epoch: [10]  [ 510/2001]  eta: 0:15:49  lr: 0.000471  loss: 3.2882 (3.0603)  time: 0.6356  data: 0.0001  max mem: 8730
Epoch: [10]  [ 520/2001]  eta: 0:15:42  lr: 0.000471  loss: 3.2035 (3.0595)  time: 0.6346  data: 0.0001  max mem: 8730
Epoch: [10]  [ 530/2001]  eta: 0:15:36  lr: 0.000471  loss: 3.0668 (3.0584)  time: 0.6269  data: 0.0001  max mem: 8730
Epoch: [10]  [ 540/2001]  eta: 0:15:29  lr: 0.000471  loss: 3.0668 (3.0566)  time: 0.6301  data: 0.0001  max mem: 8730
Epoch: [10]  [ 550/2001]  eta: 0:15:23  lr: 0.000471  loss: 3.1765 (3.0599)  time: 0.6329  data: 0.0001  max mem: 8730
Epoch: [10]  [ 560/2001]  eta: 0:15:17  lr: 0.000471  loss: 3.3569 (3.0638)  time: 0.6350  data: 0.0001  max mem: 8730
Epoch: [10]  [ 570/2001]  eta: 0:15:10  lr: 0.000471  loss: 3.2444 (3.0629)  time: 0.6319  data: 0.0001  max mem: 8730
Epoch: [10]  [ 580/2001]  eta: 0:15:03  lr: 0.000471  loss: 3.2298 (3.0656)  time: 0.6293  data: 0.0001  max mem: 8730
Epoch: [10]  [ 590/2001]  eta: 0:14:57  lr: 0.000471  loss: 3.2689 (3.0671)  time: 0.6308  data: 0.0002  max mem: 8730
loss info: cls_loss=3.0012, ratio_loss=0.0516, cls_kl=0.0655, token_kl=0.0927
Epoch: [10]  [ 600/2001]  eta: 0:14:50  lr: 0.000471  loss: 3.2739 (3.0679)  time: 0.6276  data: 0.0001  max mem: 8730
Epoch: [10]  [ 610/2001]  eta: 0:14:44  lr: 0.000471  loss: 2.9513 (3.0638)  time: 0.6279  data: 0.0001  max mem: 8730
Epoch: [10]  [ 620/2001]  eta: 0:14:37  lr: 0.000471  loss: 3.0011 (3.0653)  time: 0.6294  data: 0.0002  max mem: 8730
Epoch: [10]  [ 630/2001]  eta: 0:14:31  lr: 0.000471  loss: 3.1588 (3.0643)  time: 0.6304  data: 0.0001  max mem: 8730
Epoch: [10]  [ 640/2001]  eta: 0:14:25  lr: 0.000471  loss: 3.1588 (3.0679)  time: 0.6359  data: 0.0001  max mem: 8730
Epoch: [10]  [ 650/2001]  eta: 0:14:18  lr: 0.000471  loss: 3.2379 (3.0672)  time: 0.6342  data: 0.0001  max mem: 8730
Epoch: [10]  [ 660/2001]  eta: 0:14:12  lr: 0.000471  loss: 3.2083 (3.0699)  time: 0.6281  data: 0.0001  max mem: 8730
Epoch: [10]  [ 670/2001]  eta: 0:14:05  lr: 0.000471  loss: 3.2083 (3.0689)  time: 0.6316  data: 0.0001  max mem: 8730
Epoch: [10]  [ 680/2001]  eta: 0:13:59  lr: 0.000471  loss: 3.1694 (3.0690)  time: 0.6324  data: 0.0001  max mem: 8730
Epoch: [10]  [ 690/2001]  eta: 0:13:52  lr: 0.000471  loss: 3.3167 (3.0722)  time: 0.6316  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9865, ratio_loss=0.0560, cls_kl=0.0685, token_kl=0.0971
Epoch: [10]  [ 700/2001]  eta: 0:13:46  lr: 0.000471  loss: 3.2425 (3.0730)  time: 0.6357  data: 0.0001  max mem: 8730
Epoch: [10]  [ 710/2001]  eta: 0:13:40  lr: 0.000471  loss: 3.0501 (3.0711)  time: 0.6341  data: 0.0002  max mem: 8730
Epoch: [10]  [ 720/2001]  eta: 0:13:33  lr: 0.000471  loss: 3.1806 (3.0738)  time: 0.6286  data: 0.0001  max mem: 8730
Epoch: [10]  [ 730/2001]  eta: 0:13:27  lr: 0.000471  loss: 3.2115 (3.0721)  time: 0.6318  data: 0.0001  max mem: 8730
Epoch: [10]  [ 740/2001]  eta: 0:13:21  lr: 0.000471  loss: 3.2075 (3.0738)  time: 0.6380  data: 0.0002  max mem: 8730
Epoch: [10]  [ 750/2001]  eta: 0:13:14  lr: 0.000471  loss: 3.2075 (3.0719)  time: 0.6361  data: 0.0001  max mem: 8730
Epoch: [10]  [ 760/2001]  eta: 0:13:08  lr: 0.000471  loss: 3.1278 (3.0730)  time: 0.6332  data: 0.0001  max mem: 8730
Epoch: [10]  [ 770/2001]  eta: 0:13:01  lr: 0.000471  loss: 3.1150 (3.0705)  time: 0.6343  data: 0.0001  max mem: 8730
Epoch: [10]  [ 780/2001]  eta: 0:12:55  lr: 0.000471  loss: 3.0071 (3.0694)  time: 0.6352  data: 0.0001  max mem: 8730
Epoch: [10]  [ 790/2001]  eta: 0:12:49  lr: 0.000471  loss: 3.1748 (3.0702)  time: 0.6336  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9365, ratio_loss=0.0496, cls_kl=0.0627, token_kl=0.0909
Epoch: [10]  [ 800/2001]  eta: 0:12:42  lr: 0.000471  loss: 3.1748 (3.0700)  time: 0.6368  data: 0.0001  max mem: 8730
Epoch: [10]  [ 810/2001]  eta: 0:12:36  lr: 0.000471  loss: 3.0827 (3.0710)  time: 0.6365  data: 0.0001  max mem: 8730
Epoch: [10]  [ 820/2001]  eta: 0:12:30  lr: 0.000471  loss: 3.2054 (3.0694)  time: 0.6334  data: 0.0001  max mem: 8730
Epoch: [10]  [ 830/2001]  eta: 0:12:23  lr: 0.000471  loss: 3.2162 (3.0706)  time: 0.6366  data: 0.0001  max mem: 8730
Epoch: [10]  [ 840/2001]  eta: 0:12:17  lr: 0.000471  loss: 3.2013 (3.0712)  time: 0.6352  data: 0.0001  max mem: 8730
Epoch: [10]  [ 850/2001]  eta: 0:12:11  lr: 0.000471  loss: 3.1932 (3.0689)  time: 0.6386  data: 0.0001  max mem: 8730
Epoch: [10]  [ 860/2001]  eta: 0:12:04  lr: 0.000471  loss: 2.9388 (3.0656)  time: 0.6391  data: 0.0001  max mem: 8730
Epoch: [10]  [ 870/2001]  eta: 0:11:58  lr: 0.000471  loss: 2.8732 (3.0621)  time: 0.6332  data: 0.0001  max mem: 8730
Epoch: [10]  [ 880/2001]  eta: 0:11:52  lr: 0.000471  loss: 2.9531 (3.0625)  time: 0.6315  data: 0.0001  max mem: 8730
Epoch: [10]  [ 890/2001]  eta: 0:11:45  lr: 0.000471  loss: 3.1145 (3.0620)  time: 0.6321  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8763, ratio_loss=0.0480, cls_kl=0.0648, token_kl=0.0926
Epoch: [10]  [ 900/2001]  eta: 0:11:39  lr: 0.000471  loss: 3.0622 (3.0599)  time: 0.6319  data: 0.0001  max mem: 8730
Epoch: [10]  [ 910/2001]  eta: 0:11:33  lr: 0.000471  loss: 2.9209 (3.0581)  time: 0.6366  data: 0.0001  max mem: 8730
Epoch: [10]  [ 920/2001]  eta: 0:11:26  lr: 0.000471  loss: 3.0556 (3.0594)  time: 0.6384  data: 0.0002  max mem: 8730
Epoch: [10]  [ 930/2001]  eta: 0:11:20  lr: 0.000471  loss: 3.1701 (3.0602)  time: 0.6331  data: 0.0001  max mem: 8730
Epoch: [10]  [ 940/2001]  eta: 0:11:14  lr: 0.000471  loss: 3.2495 (3.0620)  time: 0.6420  data: 0.0001  max mem: 8730
Epoch: [10]  [ 950/2001]  eta: 0:11:07  lr: 0.000471  loss: 3.2495 (3.0630)  time: 0.6429  data: 0.0001  max mem: 8730
Epoch: [10]  [ 960/2001]  eta: 0:11:01  lr: 0.000471  loss: 2.9950 (3.0609)  time: 0.6349  data: 0.0001  max mem: 8730
Epoch: [10]  [ 970/2001]  eta: 0:10:55  lr: 0.000471  loss: 2.9950 (3.0610)  time: 0.6382  data: 0.0001  max mem: 8730
Epoch: [10]  [ 980/2001]  eta: 0:10:48  lr: 0.000471  loss: 3.2151 (3.0636)  time: 0.6402  data: 0.0001  max mem: 8730
Epoch: [10]  [ 990/2001]  eta: 0:10:42  lr: 0.000471  loss: 3.1475 (3.0637)  time: 0.6386  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9977, ratio_loss=0.0524, cls_kl=0.0683, token_kl=0.0938
Epoch: [10]  [1000/2001]  eta: 0:10:36  lr: 0.000471  loss: 3.1369 (3.0647)  time: 0.6351  data: 0.0001  max mem: 8730
Epoch: [10]  [1010/2001]  eta: 0:10:29  lr: 0.000471  loss: 3.1958 (3.0661)  time: 0.6374  data: 0.0001  max mem: 8730
Epoch: [10]  [1020/2001]  eta: 0:10:23  lr: 0.000471  loss: 3.1495 (3.0648)  time: 0.6409  data: 0.0001  max mem: 8730
Epoch: [10]  [1030/2001]  eta: 0:10:17  lr: 0.000471  loss: 2.9931 (3.0638)  time: 0.6442  data: 0.0002  max mem: 8730
Epoch: [10]  [1040/2001]  eta: 0:10:10  lr: 0.000471  loss: 3.0707 (3.0626)  time: 0.6421  data: 0.0001  max mem: 8730
Epoch: [10]  [1050/2001]  eta: 0:10:04  lr: 0.000471  loss: 3.0681 (3.0621)  time: 0.6345  data: 0.0002  max mem: 8730
Epoch: [10]  [1060/2001]  eta: 0:09:58  lr: 0.000471  loss: 3.2856 (3.0640)  time: 0.6341  data: 0.0002  max mem: 8730
Epoch: [10]  [1070/2001]  eta: 0:09:51  lr: 0.000471  loss: 3.1940 (3.0619)  time: 0.6380  data: 0.0002  max mem: 8730
Epoch: [10]  [1080/2001]  eta: 0:09:45  lr: 0.000471  loss: 3.1326 (3.0621)  time: 0.6393  data: 0.0001  max mem: 8730
Epoch: [10]  [1090/2001]  eta: 0:09:39  lr: 0.000471  loss: 3.1326 (3.0605)  time: 0.6413  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8930, ratio_loss=0.0496, cls_kl=0.0639, token_kl=0.0928
Epoch: [10]  [1100/2001]  eta: 0:09:32  lr: 0.000471  loss: 3.0492 (3.0605)  time: 0.6430  data: 0.0002  max mem: 8730
Epoch: [10]  [1110/2001]  eta: 0:09:26  lr: 0.000471  loss: 3.1937 (3.0608)  time: 0.6382  data: 0.0002  max mem: 8730
Epoch: [10]  [1120/2001]  eta: 0:09:20  lr: 0.000471  loss: 3.0043 (3.0606)  time: 0.6379  data: 0.0001  max mem: 8730
Epoch: [10]  [1130/2001]  eta: 0:09:13  lr: 0.000471  loss: 3.1171 (3.0629)  time: 0.6375  data: 0.0001  max mem: 8730
Epoch: [10]  [1140/2001]  eta: 0:09:07  lr: 0.000471  loss: 3.2504 (3.0647)  time: 0.6371  data: 0.0001  max mem: 8730
Epoch: [10]  [1150/2001]  eta: 0:09:01  lr: 0.000471  loss: 3.1953 (3.0642)  time: 0.6370  data: 0.0001  max mem: 8730
Epoch: [10]  [1160/2001]  eta: 0:08:54  lr: 0.000471  loss: 3.1038 (3.0651)  time: 0.6352  data: 0.0001  max mem: 8730
Epoch: [10]  [1170/2001]  eta: 0:08:48  lr: 0.000471  loss: 3.0706 (3.0643)  time: 0.6368  data: 0.0002  max mem: 8730
Epoch: [10]  [1180/2001]  eta: 0:08:42  lr: 0.000471  loss: 3.1784 (3.0655)  time: 0.6373  data: 0.0002  max mem: 8730
Epoch: [10]  [1190/2001]  eta: 0:08:35  lr: 0.000471  loss: 3.1743 (3.0640)  time: 0.6374  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9979, ratio_loss=0.0502, cls_kl=0.0651, token_kl=0.0924
Epoch: [10]  [1200/2001]  eta: 0:08:29  lr: 0.000471  loss: 3.2317 (3.0655)  time: 0.6369  data: 0.0001  max mem: 8730
Epoch: [10]  [1210/2001]  eta: 0:08:22  lr: 0.000471  loss: 3.3861 (3.0660)  time: 0.6345  data: 0.0002  max mem: 8730
Epoch: [10]  [1220/2001]  eta: 0:08:16  lr: 0.000471  loss: 3.2237 (3.0673)  time: 0.6390  data: 0.0001  max mem: 8730
Epoch: [10]  [1230/2001]  eta: 0:08:10  lr: 0.000471  loss: 3.2186 (3.0663)  time: 0.6412  data: 0.0002  max mem: 8730
Epoch: [10]  [1240/2001]  eta: 0:08:03  lr: 0.000471  loss: 3.2186 (3.0675)  time: 0.6383  data: 0.0001  max mem: 8730
Epoch: [10]  [1250/2001]  eta: 0:07:57  lr: 0.000471  loss: 3.1862 (3.0681)  time: 0.6409  data: 0.0001  max mem: 8730
Epoch: [10]  [1260/2001]  eta: 0:07:51  lr: 0.000471  loss: 3.1534 (3.0693)  time: 0.6395  data: 0.0001  max mem: 8730
Epoch: [10]  [1270/2001]  eta: 0:07:44  lr: 0.000471  loss: 3.1594 (3.0695)  time: 0.6365  data: 0.0001  max mem: 8730
Epoch: [10]  [1280/2001]  eta: 0:07:38  lr: 0.000471  loss: 3.1299 (3.0697)  time: 0.6412  data: 0.0001  max mem: 8730
Epoch: [10]  [1290/2001]  eta: 0:07:32  lr: 0.000471  loss: 3.2921 (3.0707)  time: 0.6427  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0476, ratio_loss=0.0554, cls_kl=0.0707, token_kl=0.0961
Epoch: [10]  [1300/2001]  eta: 0:07:25  lr: 0.000471  loss: 3.3253 (3.0730)  time: 0.6427  data: 0.0001  max mem: 8730
Epoch: [10]  [1310/2001]  eta: 0:07:19  lr: 0.000471  loss: 3.2480 (3.0716)  time: 0.6398  data: 0.0001  max mem: 8730
Epoch: [10]  [1320/2001]  eta: 0:07:13  lr: 0.000471  loss: 3.0544 (3.0702)  time: 0.6352  data: 0.0001  max mem: 8730
Epoch: [10]  [1330/2001]  eta: 0:07:06  lr: 0.000471  loss: 3.0254 (3.0703)  time: 0.6365  data: 0.0001  max mem: 8730
Epoch: [10]  [1340/2001]  eta: 0:07:00  lr: 0.000471  loss: 3.1831 (3.0698)  time: 0.6383  data: 0.0001  max mem: 8730
Epoch: [10]  [1350/2001]  eta: 0:06:54  lr: 0.000471  loss: 3.2560 (3.0715)  time: 0.6346  data: 0.0001  max mem: 8730
Epoch: [10]  [1360/2001]  eta: 0:06:47  lr: 0.000471  loss: 3.1955 (3.0706)  time: 0.6353  data: 0.0001  max mem: 8730
Epoch: [10]  [1370/2001]  eta: 0:06:41  lr: 0.000471  loss: 2.9779 (3.0696)  time: 0.6357  data: 0.0001  max mem: 8730
Epoch: [10]  [1380/2001]  eta: 0:06:35  lr: 0.000471  loss: 2.9357 (3.0677)  time: 0.6310  data: 0.0001  max mem: 8730
Epoch: [10]  [1390/2001]  eta: 0:06:28  lr: 0.000471  loss: 2.9623 (3.0673)  time: 0.6322  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9116, ratio_loss=0.0489, cls_kl=0.0638, token_kl=0.0915
Epoch: [10]  [1400/2001]  eta: 0:06:22  lr: 0.000471  loss: 3.1996 (3.0686)  time: 0.6323  data: 0.0001  max mem: 8730
Epoch: [10]  [1410/2001]  eta: 0:06:15  lr: 0.000471  loss: 3.2765 (3.0694)  time: 0.6351  data: 0.0001  max mem: 8730
Epoch: [10]  [1420/2001]  eta: 0:06:09  lr: 0.000471  loss: 3.0919 (3.0674)  time: 0.6378  data: 0.0001  max mem: 8730
Epoch: [10]  [1430/2001]  eta: 0:06:03  lr: 0.000471  loss: 3.1636 (3.0671)  time: 0.6352  data: 0.0001  max mem: 8730
Epoch: [10]  [1440/2001]  eta: 0:05:56  lr: 0.000471  loss: 3.1974 (3.0672)  time: 0.6360  data: 0.0001  max mem: 8730
Epoch: [10]  [1450/2001]  eta: 0:05:50  lr: 0.000471  loss: 3.1852 (3.0676)  time: 0.6332  data: 0.0001  max mem: 8730
Epoch: [10]  [1460/2001]  eta: 0:05:44  lr: 0.000471  loss: 3.1846 (3.0667)  time: 0.6279  data: 0.0001  max mem: 8730
Epoch: [10]  [1470/2001]  eta: 0:05:37  lr: 0.000471  loss: 3.1790 (3.0668)  time: 0.6305  data: 0.0001  max mem: 8730
Epoch: [10]  [1480/2001]  eta: 0:05:31  lr: 0.000471  loss: 3.2156 (3.0678)  time: 0.6309  data: 0.0001  max mem: 8730
Epoch: [10]  [1490/2001]  eta: 0:05:24  lr: 0.000471  loss: 3.0759 (3.0673)  time: 0.6327  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9453, ratio_loss=0.0489, cls_kl=0.0645, token_kl=0.0913
Epoch: [10]  [1500/2001]  eta: 0:05:18  lr: 0.000471  loss: 3.1480 (3.0679)  time: 0.6330  data: 0.0001  max mem: 8730
Epoch: [10]  [1510/2001]  eta: 0:05:12  lr: 0.000471  loss: 3.1480 (3.0680)  time: 0.6299  data: 0.0001  max mem: 8730
Epoch: [10]  [1520/2001]  eta: 0:05:05  lr: 0.000471  loss: 3.0989 (3.0677)  time: 0.6328  data: 0.0001  max mem: 8730
Epoch: [10]  [1530/2001]  eta: 0:04:59  lr: 0.000471  loss: 3.0311 (3.0672)  time: 0.6328  data: 0.0001  max mem: 8730
Epoch: [10]  [1540/2001]  eta: 0:04:53  lr: 0.000471  loss: 3.0298 (3.0658)  time: 0.6311  data: 0.0001  max mem: 8730
Epoch: [10]  [1550/2001]  eta: 0:04:46  lr: 0.000471  loss: 2.9396 (3.0649)  time: 0.6311  data: 0.0001  max mem: 8730
Epoch: [10]  [1560/2001]  eta: 0:04:40  lr: 0.000471  loss: 3.0212 (3.0643)  time: 0.6279  data: 0.0001  max mem: 8730
Epoch: [10]  [1570/2001]  eta: 0:04:33  lr: 0.000471  loss: 3.0283 (3.0633)  time: 0.6267  data: 0.0001  max mem: 8730
Epoch: [10]  [1580/2001]  eta: 0:04:27  lr: 0.000471  loss: 3.1474 (3.0630)  time: 0.6255  data: 0.0001  max mem: 8730
Epoch: [10]  [1590/2001]  eta: 0:04:21  lr: 0.000471  loss: 3.1762 (3.0632)  time: 0.6234  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8941, ratio_loss=0.0527, cls_kl=0.0657, token_kl=0.0961
Epoch: [10]  [1600/2001]  eta: 0:04:14  lr: 0.000471  loss: 3.1788 (3.0635)  time: 0.6239  data: 0.0001  max mem: 8730
Epoch: [10]  [1610/2001]  eta: 0:04:08  lr: 0.000471  loss: 3.1790 (3.0632)  time: 0.6242  data: 0.0001  max mem: 8730
Epoch: [10]  [1620/2001]  eta: 0:04:02  lr: 0.000471  loss: 3.1155 (3.0626)  time: 0.6266  data: 0.0001  max mem: 8730
Epoch: [10]  [1630/2001]  eta: 0:03:55  lr: 0.000471  loss: 3.2273 (3.0644)  time: 0.6269  data: 0.0001  max mem: 8730
Epoch: [10]  [1640/2001]  eta: 0:03:49  lr: 0.000471  loss: 3.4030 (3.0666)  time: 0.6226  data: 0.0001  max mem: 8730
Epoch: [10]  [1650/2001]  eta: 0:03:42  lr: 0.000471  loss: 3.2988 (3.0650)  time: 0.6258  data: 0.0001  max mem: 8730
Epoch: [10]  [1660/2001]  eta: 0:03:36  lr: 0.000471  loss: 3.0282 (3.0654)  time: 0.6252  data: 0.0001  max mem: 8730
Epoch: [10]  [1670/2001]  eta: 0:03:30  lr: 0.000471  loss: 3.0282 (3.0645)  time: 0.6231  data: 0.0001  max mem: 8730
Epoch: [10]  [1680/2001]  eta: 0:03:23  lr: 0.000471  loss: 3.0287 (3.0651)  time: 0.6294  data: 0.0001  max mem: 8730
Epoch: [10]  [1690/2001]  eta: 0:03:17  lr: 0.000471  loss: 3.2016 (3.0662)  time: 0.6278  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9772, ratio_loss=0.0519, cls_kl=0.0643, token_kl=0.0929
Epoch: [10]  [1700/2001]  eta: 0:03:11  lr: 0.000471  loss: 3.3635 (3.0666)  time: 0.6253  data: 0.0001  max mem: 8730
Epoch: [10]  [1710/2001]  eta: 0:03:04  lr: 0.000471  loss: 3.2306 (3.0663)  time: 0.6276  data: 0.0001  max mem: 8730
Epoch: [10]  [1720/2001]  eta: 0:02:58  lr: 0.000471  loss: 2.9239 (3.0652)  time: 0.6272  data: 0.0001  max mem: 8730
Epoch: [10]  [1730/2001]  eta: 0:02:52  lr: 0.000471  loss: 2.8354 (3.0640)  time: 0.6246  data: 0.0001  max mem: 8730
Epoch: [10]  [1740/2001]  eta: 0:02:45  lr: 0.000471  loss: 3.0847 (3.0645)  time: 0.6235  data: 0.0001  max mem: 8730
Epoch: [10]  [1750/2001]  eta: 0:02:39  lr: 0.000471  loss: 3.2416 (3.0652)  time: 0.6252  data: 0.0001  max mem: 8730
Epoch: [10]  [1760/2001]  eta: 0:02:32  lr: 0.000471  loss: 3.1996 (3.0657)  time: 0.6263  data: 0.0001  max mem: 8730
Epoch: [10]  [1770/2001]  eta: 0:02:26  lr: 0.000471  loss: 3.1015 (3.0652)  time: 0.6294  data: 0.0001  max mem: 8730
Epoch: [10]  [1780/2001]  eta: 0:02:20  lr: 0.000471  loss: 3.0544 (3.0643)  time: 0.6271  data: 0.0001  max mem: 8730
Epoch: [10]  [1790/2001]  eta: 0:02:13  lr: 0.000471  loss: 3.0585 (3.0636)  time: 0.6273  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9270, ratio_loss=0.0490, cls_kl=0.0628, token_kl=0.0923
Epoch: [10]  [1800/2001]  eta: 0:02:07  lr: 0.000471  loss: 3.1373 (3.0640)  time: 0.6282  data: 0.0001  max mem: 8730
Epoch: [10]  [1810/2001]  eta: 0:02:01  lr: 0.000471  loss: 3.1788 (3.0644)  time: 0.6243  data: 0.0001  max mem: 8730
Epoch: [10]  [1820/2001]  eta: 0:01:54  lr: 0.000471  loss: 3.3381 (3.0655)  time: 0.6249  data: 0.0001  max mem: 8730
Epoch: [10]  [1830/2001]  eta: 0:01:48  lr: 0.000471  loss: 3.2804 (3.0665)  time: 0.6237  data: 0.0001  max mem: 8730
Epoch: [10]  [1840/2001]  eta: 0:01:42  lr: 0.000471  loss: 3.1492 (3.0661)  time: 0.6274  data: 0.0001  max mem: 8730
Epoch: [10]  [1850/2001]  eta: 0:01:35  lr: 0.000471  loss: 3.0389 (3.0654)  time: 0.6259  data: 0.0001  max mem: 8730
Epoch: [10]  [1860/2001]  eta: 0:01:29  lr: 0.000471  loss: 3.3442 (3.0674)  time: 0.6294  data: 0.0001  max mem: 8730
Epoch: [10]  [1870/2001]  eta: 0:01:23  lr: 0.000471  loss: 3.3801 (3.0690)  time: 0.6357  data: 0.0001  max mem: 8730
Epoch: [10]  [1880/2001]  eta: 0:01:16  lr: 0.000471  loss: 3.2525 (3.0695)  time: 0.6275  data: 0.0001  max mem: 8730
Epoch: [10]  [1890/2001]  eta: 0:01:10  lr: 0.000471  loss: 3.2926 (3.0700)  time: 0.6224  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0171, ratio_loss=0.0538, cls_kl=0.0662, token_kl=0.0950
Epoch: [10]  [1900/2001]  eta: 0:01:04  lr: 0.000471  loss: 3.0162 (3.0683)  time: 0.6273  data: 0.0001  max mem: 8730
Epoch: [10]  [1910/2001]  eta: 0:00:57  lr: 0.000471  loss: 2.9673 (3.0691)  time: 0.6285  data: 0.0001  max mem: 8730
Epoch: [10]  [1920/2001]  eta: 0:00:51  lr: 0.000471  loss: 3.3274 (3.0702)  time: 0.6280  data: 0.0001  max mem: 8730
Epoch: [10]  [1930/2001]  eta: 0:00:45  lr: 0.000471  loss: 3.3988 (3.0706)  time: 0.6271  data: 0.0001  max mem: 8730
Epoch: [10]  [1940/2001]  eta: 0:00:38  lr: 0.000471  loss: 3.3757 (3.0716)  time: 0.6249  data: 0.0001  max mem: 8730
Epoch: [10]  [1950/2001]  eta: 0:00:32  lr: 0.000471  loss: 3.1841 (3.0710)  time: 0.6367  data: 0.0001  max mem: 8730
Epoch: [10]  [1960/2001]  eta: 0:00:25  lr: 0.000471  loss: 2.8638 (3.0701)  time: 0.6408  data: 0.0001  max mem: 8730
Epoch: [10]  [1970/2001]  eta: 0:00:19  lr: 0.000471  loss: 3.1844 (3.0709)  time: 0.6336  data: 0.0001  max mem: 8730
Epoch: [10]  [1980/2001]  eta: 0:00:13  lr: 0.000471  loss: 3.2798 (3.0720)  time: 0.6297  data: 0.0001  max mem: 8730
Epoch: [10]  [1990/2001]  eta: 0:00:06  lr: 0.000471  loss: 3.2893 (3.0721)  time: 0.6231  data: 0.0004  max mem: 8730
loss info: cls_loss=3.0423, ratio_loss=0.0525, cls_kl=0.0667, token_kl=0.0933
Epoch: [10]  [2000/2001]  eta: 0:00:00  lr: 0.000471  loss: 3.1416 (3.0724)  time: 0.6187  data: 0.0004  max mem: 8730
Epoch: [10] Total time: 0:21:08 (0.6340 s / it)
Averaged stats: lr: 0.000471  loss: 3.1416 (3.0735)
Test:  [ 0/53]  eta: 0:05:13  loss: 0.3561 (0.3561)  acc1: 93.3333 (93.3333)  acc5: 99.1667 (99.1667)  time: 5.9075  data: 5.3050  max mem: 8730
Test:  [10/53]  eta: 0:00:38  loss: 0.7664 (0.7729)  acc1: 82.5000 (83.5606)  acc5: 96.6667 (96.4394)  time: 0.8842  data: 0.5000  max mem: 8730
Test:  [20/53]  eta: 0:00:20  loss: 0.7393 (0.7783)  acc1: 82.5000 (83.4127)  acc5: 96.6667 (96.4683)  time: 0.3605  data: 0.0099  max mem: 8730
Test:  [30/53]  eta: 0:00:12  loss: 0.8950 (0.8667)  acc1: 79.1667 (81.2903)  acc5: 94.1667 (95.2151)  time: 0.3368  data: 0.0011  max mem: 8730
Test:  [40/53]  eta: 0:00:06  loss: 1.1356 (0.9361)  acc1: 75.0000 (79.3496)  acc5: 90.8333 (94.3089)  time: 0.3007  data: 0.0011  max mem: 8730
Test:  [50/53]  eta: 0:00:01  loss: 1.0927 (0.9660)  acc1: 73.3333 (78.5131)  acc5: 92.5000 (94.1177)  time: 0.2580  data: 0.0001  max mem: 8730
Test:  [52/53]  eta: 0:00:00  loss: 1.0809 (0.9502)  acc1: 75.0000 (78.6720)  acc5: 92.5000 (94.1920)  time: 0.2454  data: 0.0000  max mem: 8730
Test: Total time: 0:00:22 (0.4168 s / it)
Sparsity0:0.28774222222222223,Sparsity1:0.55216,Sparsity2:0.7847112,
* Acc@1 79.044 Acc@5 94.462 loss 0.943
Accuracy of the network on the 50000 test images: 79.0%
Max accuracy: 79.04%
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0004426 for PREDICTOR
Epoch: [11]  [   0/2001]  eta: 2:33:52  lr: 0.000443  loss: 2.9602 (2.9602)  time: 4.6138  data: 4.0005  max mem: 8730
Epoch: [11]  [  10/2001]  eta: 0:32:18  lr: 0.000443  loss: 3.4245 (3.2066)  time: 0.9739  data: 0.3638  max mem: 8730
Epoch: [11]  [  20/2001]  eta: 0:26:33  lr: 0.000443  loss: 3.3288 (3.1218)  time: 0.6141  data: 0.0002  max mem: 8730
Epoch: [11]  [  30/2001]  eta: 0:24:25  lr: 0.000443  loss: 2.7081 (3.0022)  time: 0.6165  data: 0.0001  max mem: 8730
Epoch: [11]  [  40/2001]  eta: 0:23:16  lr: 0.000443  loss: 2.8771 (2.9976)  time: 0.6152  data: 0.0002  max mem: 8730
Epoch: [11]  [  50/2001]  eta: 0:22:36  lr: 0.000443  loss: 3.0226 (3.0112)  time: 0.6202  data: 0.0002  max mem: 8730
Epoch: [11]  [  60/2001]  eta: 0:22:06  lr: 0.000443  loss: 3.1540 (3.0261)  time: 0.6249  data: 0.0001  max mem: 8730
Epoch: [11]  [  70/2001]  eta: 0:21:44  lr: 0.000443  loss: 3.1479 (3.0587)  time: 0.6254  data: 0.0001  max mem: 8730
Epoch: [11]  [  80/2001]  eta: 0:21:26  lr: 0.000443  loss: 3.3766 (3.0886)  time: 0.6272  data: 0.0001  max mem: 8730
Epoch: [11]  [  90/2001]  eta: 0:21:11  lr: 0.000443  loss: 3.3937 (3.0876)  time: 0.6289  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9621, ratio_loss=0.0532, cls_kl=0.0654, token_kl=0.0946
Epoch: [11]  [ 100/2001]  eta: 0:20:57  lr: 0.000443  loss: 3.0800 (3.0846)  time: 0.6293  data: 0.0001  max mem: 8730
Epoch: [11]  [ 110/2001]  eta: 0:20:45  lr: 0.000443  loss: 2.7398 (3.0529)  time: 0.6292  data: 0.0001  max mem: 8730
Epoch: [11]  [ 120/2001]  eta: 0:20:34  lr: 0.000443  loss: 2.9732 (3.0638)  time: 0.6299  data: 0.0002  max mem: 8730
Epoch: [11]  [ 130/2001]  eta: 0:20:24  lr: 0.000443  loss: 3.2938 (3.0763)  time: 0.6301  data: 0.0001  max mem: 8730
Epoch: [11]  [ 140/2001]  eta: 0:20:14  lr: 0.000443  loss: 2.9314 (3.0526)  time: 0.6290  data: 0.0001  max mem: 8730
Epoch: [11]  [ 150/2001]  eta: 0:20:06  lr: 0.000443  loss: 2.8063 (3.0455)  time: 0.6335  data: 0.0001  max mem: 8730
Epoch: [11]  [ 160/2001]  eta: 0:19:58  lr: 0.000443  loss: 2.9503 (3.0449)  time: 0.6390  data: 0.0001  max mem: 8730
Epoch: [11]  [ 170/2001]  eta: 0:19:49  lr: 0.000443  loss: 3.1874 (3.0568)  time: 0.6362  data: 0.0001  max mem: 8730
Epoch: [11]  [ 180/2001]  eta: 0:19:41  lr: 0.000443  loss: 3.1537 (3.0557)  time: 0.6324  data: 0.0001  max mem: 8730
Epoch: [11]  [ 190/2001]  eta: 0:19:33  lr: 0.000443  loss: 3.2333 (3.0660)  time: 0.6314  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9610, ratio_loss=0.0495, cls_kl=0.0631, token_kl=0.0912
Epoch: [11]  [ 200/2001]  eta: 0:19:26  lr: 0.000443  loss: 3.2749 (3.0768)  time: 0.6352  data: 0.0001  max mem: 8730
Epoch: [11]  [ 210/2001]  eta: 0:19:19  lr: 0.000443  loss: 2.7940 (3.0567)  time: 0.6427  data: 0.0001  max mem: 8730
Epoch: [11]  [ 220/2001]  eta: 0:19:12  lr: 0.000443  loss: 2.9344 (3.0566)  time: 0.6408  data: 0.0001  max mem: 8730
Epoch: [11]  [ 230/2001]  eta: 0:19:04  lr: 0.000443  loss: 3.1030 (3.0517)  time: 0.6345  data: 0.0001  max mem: 8730
Epoch: [11]  [ 240/2001]  eta: 0:18:57  lr: 0.000443  loss: 3.2005 (3.0621)  time: 0.6345  data: 0.0001  max mem: 8730
Epoch: [11]  [ 250/2001]  eta: 0:18:49  lr: 0.000443  loss: 3.3747 (3.0727)  time: 0.6346  data: 0.0001  max mem: 8730
Epoch: [11]  [ 260/2001]  eta: 0:18:44  lr: 0.000443  loss: 3.2820 (3.0756)  time: 0.6445  data: 0.0001  max mem: 8730
Epoch: [11]  [ 270/2001]  eta: 0:18:36  lr: 0.000443  loss: 3.1829 (3.0828)  time: 0.6439  data: 0.0001  max mem: 8730
Epoch: [11]  [ 280/2001]  eta: 0:18:29  lr: 0.000443  loss: 3.1797 (3.0804)  time: 0.6328  data: 0.0001  max mem: 8730
Epoch: [11]  [ 290/2001]  eta: 0:18:22  lr: 0.000443  loss: 3.2043 (3.0868)  time: 0.6349  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0123, ratio_loss=0.0506, cls_kl=0.0653, token_kl=0.0930
Epoch: [11]  [ 300/2001]  eta: 0:18:15  lr: 0.000443  loss: 3.3138 (3.0951)  time: 0.6372  data: 0.0001  max mem: 8730
Epoch: [11]  [ 310/2001]  eta: 0:18:08  lr: 0.000443  loss: 3.3646 (3.1033)  time: 0.6362  data: 0.0001  max mem: 8730
Epoch: [11]  [ 320/2001]  eta: 0:18:01  lr: 0.000443  loss: 3.3168 (3.1025)  time: 0.6337  data: 0.0001  max mem: 8730
Epoch: [11]  [ 330/2001]  eta: 0:17:55  lr: 0.000443  loss: 3.1464 (3.0968)  time: 0.6345  data: 0.0001  max mem: 8730
Epoch: [11]  [ 340/2001]  eta: 0:17:48  lr: 0.000443  loss: 3.0902 (3.0969)  time: 0.6351  data: 0.0001  max mem: 8730
Epoch: [11]  [ 350/2001]  eta: 0:17:41  lr: 0.000443  loss: 3.2164 (3.0945)  time: 0.6352  data: 0.0001  max mem: 8730
Epoch: [11]  [ 360/2001]  eta: 0:17:34  lr: 0.000443  loss: 3.3305 (3.0983)  time: 0.6349  data: 0.0001  max mem: 8730
Epoch: [11]  [ 370/2001]  eta: 0:17:27  lr: 0.000443  loss: 3.4047 (3.1013)  time: 0.6336  data: 0.0001  max mem: 8730
Epoch: [11]  [ 380/2001]  eta: 0:17:21  lr: 0.000443  loss: 3.3167 (3.1065)  time: 0.6336  data: 0.0001  max mem: 8730
Epoch: [11]  [ 390/2001]  eta: 0:17:14  lr: 0.000443  loss: 3.2257 (3.1081)  time: 0.6346  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0333, ratio_loss=0.0534, cls_kl=0.0688, token_kl=0.0973
Epoch: [11]  [ 400/2001]  eta: 0:17:07  lr: 0.000443  loss: 3.0509 (3.1045)  time: 0.6391  data: 0.0001  max mem: 8730
Epoch: [11]  [ 410/2001]  eta: 0:17:01  lr: 0.000443  loss: 2.9731 (3.1033)  time: 0.6471  data: 0.0001  max mem: 8730
Epoch: [11]  [ 420/2001]  eta: 0:16:56  lr: 0.000443  loss: 3.2578 (3.1066)  time: 0.6543  data: 0.0002  max mem: 8730
Epoch: [11]  [ 430/2001]  eta: 0:16:49  lr: 0.000443  loss: 3.0203 (3.0981)  time: 0.6477  data: 0.0002  max mem: 8730
Epoch: [11]  [ 440/2001]  eta: 0:16:42  lr: 0.000443  loss: 3.0203 (3.0989)  time: 0.6363  data: 0.0001  max mem: 8730
Epoch: [11]  [ 450/2001]  eta: 0:16:36  lr: 0.000443  loss: 3.2054 (3.0961)  time: 0.6372  data: 0.0001  max mem: 8730
Epoch: [11]  [ 460/2001]  eta: 0:16:29  lr: 0.000443  loss: 2.8593 (3.0881)  time: 0.6410  data: 0.0001  max mem: 8730
Epoch: [11]  [ 470/2001]  eta: 0:16:23  lr: 0.000443  loss: 2.8440 (3.0822)  time: 0.6411  data: 0.0001  max mem: 8730
Epoch: [11]  [ 480/2001]  eta: 0:16:16  lr: 0.000443  loss: 2.9990 (3.0800)  time: 0.6373  data: 0.0001  max mem: 8730
Epoch: [11]  [ 490/2001]  eta: 0:16:09  lr: 0.000443  loss: 3.1942 (3.0818)  time: 0.6350  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8618, ratio_loss=0.0478, cls_kl=0.0626, token_kl=0.0932
Epoch: [11]  [ 500/2001]  eta: 0:16:03  lr: 0.000443  loss: 3.3359 (3.0812)  time: 0.6357  data: 0.0001  max mem: 8730
Epoch: [11]  [ 510/2001]  eta: 0:15:56  lr: 0.000443  loss: 3.2752 (3.0839)  time: 0.6355  data: 0.0001  max mem: 8730
Epoch: [11]  [ 520/2001]  eta: 0:15:50  lr: 0.000443  loss: 3.2752 (3.0844)  time: 0.6376  data: 0.0001  max mem: 8730
Epoch: [11]  [ 530/2001]  eta: 0:15:43  lr: 0.000443  loss: 3.2420 (3.0814)  time: 0.6382  data: 0.0001  max mem: 8730
Epoch: [11]  [ 540/2001]  eta: 0:15:37  lr: 0.000443  loss: 3.2277 (3.0856)  time: 0.6366  data: 0.0002  max mem: 8730
Epoch: [11]  [ 550/2001]  eta: 0:15:30  lr: 0.000443  loss: 3.2678 (3.0873)  time: 0.6381  data: 0.0002  max mem: 8730
Epoch: [11]  [ 560/2001]  eta: 0:15:24  lr: 0.000443  loss: 2.9450 (3.0836)  time: 0.6434  data: 0.0002  max mem: 8730
Epoch: [11]  [ 570/2001]  eta: 0:15:18  lr: 0.000443  loss: 3.1444 (3.0882)  time: 0.6458  data: 0.0001  max mem: 8730
Epoch: [11]  [ 580/2001]  eta: 0:15:11  lr: 0.000443  loss: 3.2588 (3.0837)  time: 0.6475  data: 0.0001  max mem: 8730
Epoch: [11]  [ 590/2001]  eta: 0:15:05  lr: 0.000443  loss: 3.1086 (3.0855)  time: 0.6446  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0051, ratio_loss=0.0529, cls_kl=0.0693, token_kl=0.0954
Epoch: [11]  [ 600/2001]  eta: 0:14:59  lr: 0.000443  loss: 3.1086 (3.0838)  time: 0.6414  data: 0.0001  max mem: 8730
Epoch: [11]  [ 610/2001]  eta: 0:14:52  lr: 0.000443  loss: 3.0036 (3.0811)  time: 0.6445  data: 0.0001  max mem: 8730
Epoch: [11]  [ 620/2001]  eta: 0:14:46  lr: 0.000443  loss: 3.1461 (3.0836)  time: 0.6411  data: 0.0001  max mem: 8730
Epoch: [11]  [ 630/2001]  eta: 0:14:40  lr: 0.000443  loss: 3.2601 (3.0815)  time: 0.6453  data: 0.0002  max mem: 8730
Epoch: [11]  [ 640/2001]  eta: 0:14:33  lr: 0.000443  loss: 3.2601 (3.0825)  time: 0.6448  data: 0.0002  max mem: 8730
Epoch: [11]  [ 650/2001]  eta: 0:14:27  lr: 0.000443  loss: 3.1159 (3.0817)  time: 0.6371  data: 0.0002  max mem: 8730
Epoch: [11]  [ 660/2001]  eta: 0:14:20  lr: 0.000443  loss: 3.0755 (3.0783)  time: 0.6406  data: 0.0002  max mem: 8730
Epoch: [11]  [ 670/2001]  eta: 0:14:14  lr: 0.000443  loss: 2.9668 (3.0755)  time: 0.6447  data: 0.0002  max mem: 8730
Epoch: [11]  [ 680/2001]  eta: 0:14:07  lr: 0.000443  loss: 2.9598 (3.0721)  time: 0.6445  data: 0.0002  max mem: 8730
Epoch: [11]  [ 690/2001]  eta: 0:14:01  lr: 0.000443  loss: 2.8659 (3.0682)  time: 0.6441  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8709, ratio_loss=0.0470, cls_kl=0.0622, token_kl=0.0906
Epoch: [11]  [ 700/2001]  eta: 0:13:55  lr: 0.000443  loss: 2.9576 (3.0695)  time: 0.6410  data: 0.0001  max mem: 8730
Epoch: [11]  [ 710/2001]  eta: 0:13:48  lr: 0.000443  loss: 3.1456 (3.0701)  time: 0.6364  data: 0.0001  max mem: 8730
Epoch: [11]  [ 720/2001]  eta: 0:13:42  lr: 0.000443  loss: 3.2310 (3.0738)  time: 0.6374  data: 0.0001  max mem: 8730
Epoch: [11]  [ 730/2001]  eta: 0:13:35  lr: 0.000443  loss: 3.2859 (3.0749)  time: 0.6414  data: 0.0001  max mem: 8730
Epoch: [11]  [ 740/2001]  eta: 0:13:29  lr: 0.000443  loss: 2.9265 (3.0708)  time: 0.6435  data: 0.0001  max mem: 8730
Epoch: [11]  [ 750/2001]  eta: 0:13:22  lr: 0.000443  loss: 2.8405 (3.0685)  time: 0.6400  data: 0.0001  max mem: 8730
Epoch: [11]  [ 760/2001]  eta: 0:13:16  lr: 0.000443  loss: 2.9063 (3.0664)  time: 0.6404  data: 0.0002  max mem: 8730
Epoch: [11]  [ 770/2001]  eta: 0:13:10  lr: 0.000443  loss: 2.9552 (3.0638)  time: 0.6458  data: 0.0002  max mem: 8730
Epoch: [11]  [ 780/2001]  eta: 0:13:03  lr: 0.000443  loss: 3.1556 (3.0649)  time: 0.6418  data: 0.0002  max mem: 8730
Epoch: [11]  [ 790/2001]  eta: 0:12:57  lr: 0.000443  loss: 3.2709 (3.0671)  time: 0.6356  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9265, ratio_loss=0.0485, cls_kl=0.0649, token_kl=0.0911
Epoch: [11]  [ 800/2001]  eta: 0:12:50  lr: 0.000443  loss: 3.2876 (3.0669)  time: 0.6394  data: 0.0001  max mem: 8730
Epoch: [11]  [ 810/2001]  eta: 0:12:44  lr: 0.000443  loss: 3.2431 (3.0674)  time: 0.6426  data: 0.0001  max mem: 8730
Epoch: [11]  [ 820/2001]  eta: 0:12:37  lr: 0.000443  loss: 3.2424 (3.0670)  time: 0.6385  data: 0.0002  max mem: 8730
Epoch: [11]  [ 830/2001]  eta: 0:12:31  lr: 0.000443  loss: 3.0577 (3.0671)  time: 0.6430  data: 0.0002  max mem: 8730
Epoch: [11]  [ 840/2001]  eta: 0:12:25  lr: 0.000443  loss: 3.2973 (3.0676)  time: 0.6486  data: 0.0002  max mem: 8730
Epoch: [11]  [ 850/2001]  eta: 0:12:18  lr: 0.000443  loss: 3.0133 (3.0641)  time: 0.6483  data: 0.0002  max mem: 8730
Epoch: [11]  [ 860/2001]  eta: 0:12:12  lr: 0.000443  loss: 2.7864 (3.0628)  time: 0.6451  data: 0.0002  max mem: 8730
Epoch: [11]  [ 870/2001]  eta: 0:12:05  lr: 0.000443  loss: 2.9043 (3.0629)  time: 0.6375  data: 0.0001  max mem: 8730
Epoch: [11]  [ 880/2001]  eta: 0:11:59  lr: 0.000443  loss: 3.0884 (3.0628)  time: 0.6322  data: 0.0001  max mem: 8730
Epoch: [11]  [ 890/2001]  eta: 0:11:52  lr: 0.000443  loss: 3.0884 (3.0621)  time: 0.6308  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9177, ratio_loss=0.0506, cls_kl=0.0643, token_kl=0.0952
Epoch: [11]  [ 900/2001]  eta: 0:11:46  lr: 0.000443  loss: 3.1754 (3.0613)  time: 0.6387  data: 0.0002  max mem: 8730
Epoch: [11]  [ 910/2001]  eta: 0:11:39  lr: 0.000443  loss: 3.0469 (3.0585)  time: 0.6383  data: 0.0002  max mem: 8730
Epoch: [11]  [ 920/2001]  eta: 0:11:33  lr: 0.000443  loss: 3.1135 (3.0599)  time: 0.6307  data: 0.0002  max mem: 8730
Epoch: [11]  [ 930/2001]  eta: 0:11:26  lr: 0.000443  loss: 3.1380 (3.0604)  time: 0.6307  data: 0.0002  max mem: 8730
Epoch: [11]  [ 940/2001]  eta: 0:11:20  lr: 0.000443  loss: 3.0382 (3.0593)  time: 0.6296  data: 0.0002  max mem: 8730
Epoch: [11]  [ 950/2001]  eta: 0:11:13  lr: 0.000443  loss: 3.0015 (3.0572)  time: 0.6298  data: 0.0002  max mem: 8730
Epoch: [11]  [ 960/2001]  eta: 0:11:07  lr: 0.000443  loss: 3.1115 (3.0575)  time: 0.6341  data: 0.0002  max mem: 8730
Epoch: [11]  [ 970/2001]  eta: 0:11:00  lr: 0.000443  loss: 3.2129 (3.0578)  time: 0.6349  data: 0.0002  max mem: 8730
Epoch: [11]  [ 980/2001]  eta: 0:10:54  lr: 0.000443  loss: 3.1077 (3.0564)  time: 0.6333  data: 0.0002  max mem: 8730
Epoch: [11]  [ 990/2001]  eta: 0:10:47  lr: 0.000443  loss: 2.9530 (3.0562)  time: 0.6327  data: 0.0002  max mem: 8730
loss info: cls_loss=2.8699, ratio_loss=0.0476, cls_kl=0.0644, token_kl=0.0921
Epoch: [11]  [1000/2001]  eta: 0:10:41  lr: 0.000443  loss: 2.8006 (3.0521)  time: 0.6285  data: 0.0002  max mem: 8730
Epoch: [11]  [1010/2001]  eta: 0:10:34  lr: 0.000443  loss: 2.6695 (3.0508)  time: 0.6349  data: 0.0002  max mem: 8730
Epoch: [11]  [1020/2001]  eta: 0:10:28  lr: 0.000443  loss: 3.0102 (3.0519)  time: 0.6344  data: 0.0002  max mem: 8730
Epoch: [11]  [1030/2001]  eta: 0:10:21  lr: 0.000443  loss: 3.1953 (3.0517)  time: 0.6279  data: 0.0002  max mem: 8730
Epoch: [11]  [1040/2001]  eta: 0:10:15  lr: 0.000443  loss: 3.0183 (3.0497)  time: 0.6331  data: 0.0002  max mem: 8730
Epoch: [11]  [1050/2001]  eta: 0:10:08  lr: 0.000443  loss: 3.1589 (3.0502)  time: 0.6361  data: 0.0002  max mem: 8730
Epoch: [11]  [1060/2001]  eta: 0:10:02  lr: 0.000443  loss: 3.3383 (3.0518)  time: 0.6337  data: 0.0002  max mem: 8730
Epoch: [11]  [1070/2001]  eta: 0:09:55  lr: 0.000443  loss: 3.3049 (3.0508)  time: 0.6275  data: 0.0002  max mem: 8730
Epoch: [11]  [1080/2001]  eta: 0:09:49  lr: 0.000443  loss: 2.8373 (3.0484)  time: 0.6269  data: 0.0002  max mem: 8730
Epoch: [11]  [1090/2001]  eta: 0:09:42  lr: 0.000443  loss: 3.1774 (3.0499)  time: 0.6298  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9057, ratio_loss=0.0461, cls_kl=0.0626, token_kl=0.0885
Epoch: [11]  [1100/2001]  eta: 0:09:36  lr: 0.000443  loss: 3.1959 (3.0492)  time: 0.6284  data: 0.0002  max mem: 8730
Epoch: [11]  [1110/2001]  eta: 0:09:29  lr: 0.000443  loss: 2.9821 (3.0480)  time: 0.6328  data: 0.0002  max mem: 8730
Epoch: [11]  [1120/2001]  eta: 0:09:23  lr: 0.000443  loss: 3.0020 (3.0477)  time: 0.6332  data: 0.0002  max mem: 8730
Epoch: [11]  [1130/2001]  eta: 0:09:16  lr: 0.000443  loss: 3.1319 (3.0490)  time: 0.6260  data: 0.0002  max mem: 8730
Epoch: [11]  [1140/2001]  eta: 0:09:10  lr: 0.000443  loss: 2.9925 (3.0471)  time: 0.6263  data: 0.0002  max mem: 8730
Epoch: [11]  [1150/2001]  eta: 0:09:03  lr: 0.000443  loss: 3.2934 (3.0513)  time: 0.6277  data: 0.0002  max mem: 8730
Epoch: [11]  [1160/2001]  eta: 0:08:57  lr: 0.000443  loss: 3.5012 (3.0541)  time: 0.6267  data: 0.0002  max mem: 8730
Epoch: [11]  [1170/2001]  eta: 0:08:50  lr: 0.000443  loss: 3.3492 (3.0549)  time: 0.6242  data: 0.0002  max mem: 8730
Epoch: [11]  [1180/2001]  eta: 0:08:44  lr: 0.000443  loss: 3.2355 (3.0536)  time: 0.6243  data: 0.0002  max mem: 8730
Epoch: [11]  [1190/2001]  eta: 0:08:38  lr: 0.000443  loss: 3.0139 (3.0513)  time: 0.6290  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9602, ratio_loss=0.0512, cls_kl=0.0657, token_kl=0.0939
Epoch: [11]  [1200/2001]  eta: 0:08:31  lr: 0.000443  loss: 3.0164 (3.0520)  time: 0.6275  data: 0.0002  max mem: 8730
Epoch: [11]  [1210/2001]  eta: 0:08:25  lr: 0.000443  loss: 3.0828 (3.0517)  time: 0.6243  data: 0.0002  max mem: 8730
Epoch: [11]  [1220/2001]  eta: 0:08:18  lr: 0.000443  loss: 3.2549 (3.0536)  time: 0.6240  data: 0.0002  max mem: 8730
Epoch: [11]  [1230/2001]  eta: 0:08:12  lr: 0.000443  loss: 3.2549 (3.0528)  time: 0.6249  data: 0.0002  max mem: 8730
Epoch: [11]  [1240/2001]  eta: 0:08:05  lr: 0.000443  loss: 3.1164 (3.0538)  time: 0.6300  data: 0.0002  max mem: 8730
Epoch: [11]  [1250/2001]  eta: 0:07:59  lr: 0.000443  loss: 3.1164 (3.0527)  time: 0.6299  data: 0.0002  max mem: 8730
Epoch: [11]  [1260/2001]  eta: 0:07:52  lr: 0.000443  loss: 3.2868 (3.0546)  time: 0.6276  data: 0.0002  max mem: 8730
Epoch: [11]  [1270/2001]  eta: 0:07:46  lr: 0.000443  loss: 3.2969 (3.0555)  time: 0.6327  data: 0.0002  max mem: 8730
Epoch: [11]  [1280/2001]  eta: 0:07:40  lr: 0.000443  loss: 2.8396 (3.0532)  time: 0.6386  data: 0.0002  max mem: 8730
Epoch: [11]  [1290/2001]  eta: 0:07:33  lr: 0.000443  loss: 3.1115 (3.0547)  time: 0.6329  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9560, ratio_loss=0.0494, cls_kl=0.0645, token_kl=0.0945
Epoch: [11]  [1300/2001]  eta: 0:07:27  lr: 0.000443  loss: 3.1178 (3.0546)  time: 0.6268  data: 0.0002  max mem: 8730
Epoch: [11]  [1310/2001]  eta: 0:07:20  lr: 0.000443  loss: 3.1178 (3.0551)  time: 0.6262  data: 0.0002  max mem: 8730
Epoch: [11]  [1320/2001]  eta: 0:07:14  lr: 0.000443  loss: 3.1027 (3.0553)  time: 0.6368  data: 0.0002  max mem: 8730
Epoch: [11]  [1330/2001]  eta: 0:07:08  lr: 0.000443  loss: 2.8662 (3.0535)  time: 0.6390  data: 0.0002  max mem: 8730
Epoch: [11]  [1340/2001]  eta: 0:07:01  lr: 0.000443  loss: 3.0247 (3.0548)  time: 0.6275  data: 0.0002  max mem: 8730
Epoch: [11]  [1350/2001]  eta: 0:06:55  lr: 0.000443  loss: 3.1079 (3.0560)  time: 0.6245  data: 0.0002  max mem: 8730
Epoch: [11]  [1360/2001]  eta: 0:06:48  lr: 0.000443  loss: 3.1996 (3.0552)  time: 0.6265  data: 0.0002  max mem: 8730
Epoch: [11]  [1370/2001]  eta: 0:06:42  lr: 0.000443  loss: 3.1996 (3.0554)  time: 0.6260  data: 0.0002  max mem: 8730
Epoch: [11]  [1380/2001]  eta: 0:06:35  lr: 0.000443  loss: 3.0350 (3.0544)  time: 0.6223  data: 0.0002  max mem: 8730
Epoch: [11]  [1390/2001]  eta: 0:06:29  lr: 0.000443  loss: 3.2445 (3.0560)  time: 0.6242  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9452, ratio_loss=0.0515, cls_kl=0.0673, token_kl=0.0962
Epoch: [11]  [1400/2001]  eta: 0:06:22  lr: 0.000443  loss: 3.1253 (3.0540)  time: 0.6262  data: 0.0002  max mem: 8730
Epoch: [11]  [1410/2001]  eta: 0:06:16  lr: 0.000443  loss: 2.9462 (3.0540)  time: 0.6289  data: 0.0002  max mem: 8730
Epoch: [11]  [1420/2001]  eta: 0:06:10  lr: 0.000443  loss: 3.1783 (3.0545)  time: 0.6311  data: 0.0002  max mem: 8730
Epoch: [11]  [1430/2001]  eta: 0:06:03  lr: 0.000443  loss: 3.1506 (3.0541)  time: 0.6312  data: 0.0002  max mem: 8730
Epoch: [11]  [1440/2001]  eta: 0:05:57  lr: 0.000443  loss: 2.9524 (3.0526)  time: 0.6315  data: 0.0002  max mem: 8730
Epoch: [11]  [1450/2001]  eta: 0:05:50  lr: 0.000443  loss: 2.8381 (3.0511)  time: 0.6288  data: 0.0002  max mem: 8730
Epoch: [11]  [1460/2001]  eta: 0:05:44  lr: 0.000443  loss: 2.9636 (3.0521)  time: 0.6260  data: 0.0002  max mem: 8730
Epoch: [11]  [1470/2001]  eta: 0:05:38  lr: 0.000443  loss: 3.3468 (3.0527)  time: 0.6308  data: 0.0002  max mem: 8730
Epoch: [11]  [1480/2001]  eta: 0:05:31  lr: 0.000443  loss: 3.0907 (3.0528)  time: 0.6364  data: 0.0002  max mem: 8730
Epoch: [11]  [1490/2001]  eta: 0:05:25  lr: 0.000443  loss: 2.9908 (3.0514)  time: 0.6306  data: 0.0002  max mem: 8730
loss info: cls_loss=2.8960, ratio_loss=0.0492, cls_kl=0.0642, token_kl=0.0919
Epoch: [11]  [1500/2001]  eta: 0:05:19  lr: 0.000443  loss: 2.9908 (3.0511)  time: 0.6247  data: 0.0001  max mem: 8730
Epoch: [11]  [1510/2001]  eta: 0:05:12  lr: 0.000443  loss: 3.1140 (3.0513)  time: 0.6285  data: 0.0001  max mem: 8730
Epoch: [11]  [1520/2001]  eta: 0:05:06  lr: 0.000443  loss: 3.0966 (3.0501)  time: 0.6285  data: 0.0001  max mem: 8730
Epoch: [11]  [1530/2001]  eta: 0:04:59  lr: 0.000443  loss: 3.2023 (3.0508)  time: 0.6281  data: 0.0001  max mem: 8730
Epoch: [11]  [1540/2001]  eta: 0:04:53  lr: 0.000443  loss: 3.2781 (3.0513)  time: 0.6373  data: 0.0002  max mem: 8730
Epoch: [11]  [1550/2001]  eta: 0:04:47  lr: 0.000443  loss: 3.2857 (3.0512)  time: 0.6389  data: 0.0002  max mem: 8730
Epoch: [11]  [1560/2001]  eta: 0:04:40  lr: 0.000443  loss: 2.7432 (3.0481)  time: 0.6314  data: 0.0002  max mem: 8730
Epoch: [11]  [1570/2001]  eta: 0:04:34  lr: 0.000443  loss: 2.7432 (3.0477)  time: 0.6347  data: 0.0002  max mem: 8730
Epoch: [11]  [1580/2001]  eta: 0:04:27  lr: 0.000443  loss: 3.0510 (3.0490)  time: 0.6339  data: 0.0002  max mem: 8730
Epoch: [11]  [1590/2001]  eta: 0:04:21  lr: 0.000443  loss: 3.2392 (3.0491)  time: 0.6308  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9170, ratio_loss=0.0469, cls_kl=0.0655, token_kl=0.0923
Epoch: [11]  [1600/2001]  eta: 0:04:15  lr: 0.000443  loss: 3.2392 (3.0492)  time: 0.6314  data: 0.0002  max mem: 8730
Epoch: [11]  [1610/2001]  eta: 0:04:08  lr: 0.000443  loss: 3.3610 (3.0496)  time: 0.6361  data: 0.0002  max mem: 8730
Epoch: [11]  [1620/2001]  eta: 0:04:02  lr: 0.000443  loss: 3.2859 (3.0496)  time: 0.6402  data: 0.0002  max mem: 8730
Epoch: [11]  [1630/2001]  eta: 0:03:56  lr: 0.000443  loss: 3.4406 (3.0515)  time: 0.6340  data: 0.0002  max mem: 8730
Epoch: [11]  [1640/2001]  eta: 0:03:49  lr: 0.000443  loss: 3.1371 (3.0503)  time: 0.6308  data: 0.0002  max mem: 8730
Epoch: [11]  [1650/2001]  eta: 0:03:43  lr: 0.000443  loss: 3.0222 (3.0509)  time: 0.6327  data: 0.0001  max mem: 8730
Epoch: [11]  [1660/2001]  eta: 0:03:37  lr: 0.000443  loss: 3.1588 (3.0524)  time: 0.6346  data: 0.0001  max mem: 8730
Epoch: [11]  [1670/2001]  eta: 0:03:30  lr: 0.000443  loss: 3.2445 (3.0526)  time: 0.6315  data: 0.0001  max mem: 8730
Epoch: [11]  [1680/2001]  eta: 0:03:24  lr: 0.000443  loss: 3.0491 (3.0518)  time: 0.6321  data: 0.0001  max mem: 8730
Epoch: [11]  [1690/2001]  eta: 0:03:17  lr: 0.000443  loss: 3.0034 (3.0520)  time: 0.6390  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9953, ratio_loss=0.0510, cls_kl=0.0655, token_kl=0.0931
Epoch: [11]  [1700/2001]  eta: 0:03:11  lr: 0.000443  loss: 3.2176 (3.0531)  time: 0.6450  data: 0.0001  max mem: 8730
Epoch: [11]  [1710/2001]  eta: 0:03:05  lr: 0.000443  loss: 3.2058 (3.0524)  time: 0.6429  data: 0.0002  max mem: 8730
Epoch: [11]  [1720/2001]  eta: 0:02:58  lr: 0.000443  loss: 2.7654 (3.0498)  time: 0.6363  data: 0.0002  max mem: 8730
Epoch: [11]  [1730/2001]  eta: 0:02:52  lr: 0.000443  loss: 2.8879 (3.0500)  time: 0.6369  data: 0.0001  max mem: 8730
Epoch: [11]  [1740/2001]  eta: 0:02:46  lr: 0.000443  loss: 3.0618 (3.0494)  time: 0.6385  data: 0.0001  max mem: 8730
Epoch: [11]  [1750/2001]  eta: 0:02:39  lr: 0.000443  loss: 3.0720 (3.0507)  time: 0.6367  data: 0.0001  max mem: 8730
Epoch: [11]  [1760/2001]  eta: 0:02:33  lr: 0.000443  loss: 3.0690 (3.0498)  time: 0.6325  data: 0.0001  max mem: 8730
Epoch: [11]  [1770/2001]  eta: 0:02:27  lr: 0.000443  loss: 2.8464 (3.0491)  time: 0.6306  data: 0.0001  max mem: 8730
Epoch: [11]  [1780/2001]  eta: 0:02:20  lr: 0.000443  loss: 3.0247 (3.0500)  time: 0.6316  data: 0.0001  max mem: 8730
Epoch: [11]  [1790/2001]  eta: 0:02:14  lr: 0.000443  loss: 3.2277 (3.0505)  time: 0.6316  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8811, ratio_loss=0.0472, cls_kl=0.0638, token_kl=0.0930
Epoch: [11]  [1800/2001]  eta: 0:02:07  lr: 0.000443  loss: 3.2277 (3.0504)  time: 0.6325  data: 0.0001  max mem: 8730
Epoch: [11]  [1810/2001]  eta: 0:02:01  lr: 0.000443  loss: 3.0991 (3.0505)  time: 0.6335  data: 0.0001  max mem: 8730
Epoch: [11]  [1820/2001]  eta: 0:01:55  lr: 0.000443  loss: 3.1948 (3.0512)  time: 0.6333  data: 0.0001  max mem: 8730
Epoch: [11]  [1830/2001]  eta: 0:01:48  lr: 0.000443  loss: 3.1948 (3.0505)  time: 0.6325  data: 0.0001  max mem: 8730
Epoch: [11]  [1840/2001]  eta: 0:01:42  lr: 0.000443  loss: 3.3247 (3.0512)  time: 0.6391  data: 0.0001  max mem: 8730
Epoch: [11]  [1850/2001]  eta: 0:01:36  lr: 0.000443  loss: 3.2797 (3.0511)  time: 0.6410  data: 0.0001  max mem: 8730
Epoch: [11]  [1860/2001]  eta: 0:01:29  lr: 0.000443  loss: 3.1980 (3.0509)  time: 0.6437  data: 0.0001  max mem: 8730
Epoch: [11]  [1870/2001]  eta: 0:01:23  lr: 0.000443  loss: 3.2531 (3.0521)  time: 0.6420  data: 0.0001  max mem: 8730
Epoch: [11]  [1880/2001]  eta: 0:01:17  lr: 0.000443  loss: 3.2555 (3.0519)  time: 0.6361  data: 0.0001  max mem: 8730
Epoch: [11]  [1890/2001]  eta: 0:01:10  lr: 0.000443  loss: 3.1038 (3.0515)  time: 0.6348  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9761, ratio_loss=0.0509, cls_kl=0.0657, token_kl=0.0939
Epoch: [11]  [1900/2001]  eta: 0:01:04  lr: 0.000443  loss: 3.1543 (3.0522)  time: 0.6316  data: 0.0001  max mem: 8730
Epoch: [11]  [1910/2001]  eta: 0:00:57  lr: 0.000443  loss: 3.0944 (3.0523)  time: 0.6362  data: 0.0001  max mem: 8730
Epoch: [11]  [1920/2001]  eta: 0:00:51  lr: 0.000443  loss: 3.0411 (3.0522)  time: 0.6411  data: 0.0001  max mem: 8730
Epoch: [11]  [1930/2001]  eta: 0:00:45  lr: 0.000443  loss: 3.0821 (3.0524)  time: 0.6387  data: 0.0001  max mem: 8730
Epoch: [11]  [1940/2001]  eta: 0:00:38  lr: 0.000443  loss: 3.1151 (3.0523)  time: 0.6387  data: 0.0001  max mem: 8730
Epoch: [11]  [1950/2001]  eta: 0:00:32  lr: 0.000443  loss: 3.0228 (3.0515)  time: 0.6400  data: 0.0001  max mem: 8730
Epoch: [11]  [1960/2001]  eta: 0:00:26  lr: 0.000443  loss: 3.1090 (3.0523)  time: 0.6379  data: 0.0001  max mem: 8730
Epoch: [11]  [1970/2001]  eta: 0:00:19  lr: 0.000443  loss: 3.1030 (3.0504)  time: 0.6394  data: 0.0001  max mem: 8730
Epoch: [11]  [1980/2001]  eta: 0:00:13  lr: 0.000443  loss: 2.9209 (3.0505)  time: 0.6396  data: 0.0001  max mem: 8730
Epoch: [11]  [1990/2001]  eta: 0:00:07  lr: 0.000443  loss: 2.9940 (3.0500)  time: 0.6332  data: 0.0004  max mem: 8730
loss info: cls_loss=2.9024, ratio_loss=0.0491, cls_kl=0.0647, token_kl=0.0913
Epoch: [11]  [2000/2001]  eta: 0:00:00  lr: 0.000443  loss: 2.9940 (3.0501)  time: 0.6291  data: 0.0004  max mem: 8730
Epoch: [11] Total time: 0:21:14 (0.6367 s / it)
Averaged stats: lr: 0.000443  loss: 2.9940 (3.0624)
Test:  [ 0/53]  eta: 0:04:15  loss: 0.3593 (0.3593)  acc1: 92.5000 (92.5000)  acc5: 98.3333 (98.3333)  time: 4.8233  data: 4.2571  max mem: 8730
Test:  [10/53]  eta: 0:00:36  loss: 0.6979 (0.7710)  acc1: 84.1667 (82.8030)  acc5: 96.6667 (96.3636)  time: 0.8427  data: 0.4633  max mem: 8730
Test:  [20/53]  eta: 0:00:20  loss: 0.7098 (0.7715)  acc1: 83.3333 (82.6191)  acc5: 96.6667 (96.6270)  time: 0.4073  data: 0.0423  max mem: 8730
Test:  [30/53]  eta: 0:00:12  loss: 0.9030 (0.8594)  acc1: 80.0000 (80.5376)  acc5: 95.0000 (95.2151)  time: 0.3514  data: 0.0005  max mem: 8730
Test:  [40/53]  eta: 0:00:06  loss: 1.1117 (0.9219)  acc1: 75.8333 (79.1260)  acc5: 91.6667 (94.4919)  time: 0.3014  data: 0.0002  max mem: 8730
Test:  [50/53]  eta: 0:00:01  loss: 1.1285 (0.9530)  acc1: 75.8333 (78.3660)  acc5: 92.5000 (94.3464)  time: 0.2633  data: 0.0001  max mem: 8730
Test:  [52/53]  eta: 0:00:00  loss: 1.1117 (0.9378)  acc1: 75.8333 (78.5440)  acc5: 92.5000 (94.4160)  time: 0.2502  data: 0.0001  max mem: 8730
Test: Total time: 0:00:22 (0.4155 s / it)
Sparsity0:0.2806480808080808,Sparsity1:0.557123216080402,Sparsity2:0.779724,
* Acc@1 78.992 Acc@5 94.480 loss 0.942
Accuracy of the network on the 50000 test images: 79.0%
Max accuracy: 79.04%
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0004125 for PREDICTOR
Epoch: [12]  [   0/2001]  eta: 2:20:34  lr: 0.000413  loss: 3.6259 (3.6259)  time: 4.2149  data: 2.7854  max mem: 8730
Epoch: [12]  [  10/2001]  eta: 0:32:15  lr: 0.000413  loss: 3.2380 (3.0543)  time: 0.9722  data: 0.2533  max mem: 8730
Epoch: [12]  [  20/2001]  eta: 0:26:31  lr: 0.000413  loss: 3.1285 (3.0041)  time: 0.6328  data: 0.0001  max mem: 8730
Epoch: [12]  [  30/2001]  eta: 0:24:27  lr: 0.000413  loss: 3.1334 (3.0132)  time: 0.6190  data: 0.0001  max mem: 8730
Epoch: [12]  [  40/2001]  eta: 0:23:25  lr: 0.000413  loss: 3.1579 (3.0235)  time: 0.6255  data: 0.0001  max mem: 8730
Epoch: [12]  [  50/2001]  eta: 0:22:45  lr: 0.000413  loss: 3.0343 (2.9725)  time: 0.6309  data: 0.0001  max mem: 8730
Epoch: [12]  [  60/2001]  eta: 0:22:19  lr: 0.000413  loss: 3.1380 (3.0115)  time: 0.6355  data: 0.0001  max mem: 8730
Epoch: [12]  [  70/2001]  eta: 0:21:57  lr: 0.000413  loss: 3.3001 (3.0135)  time: 0.6379  data: 0.0001  max mem: 8730
Epoch: [12]  [  80/2001]  eta: 0:21:39  lr: 0.000413  loss: 3.2683 (3.0270)  time: 0.6356  data: 0.0001  max mem: 8730
Epoch: [12]  [  90/2001]  eta: 0:21:24  lr: 0.000413  loss: 3.2586 (3.0609)  time: 0.6358  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9449, ratio_loss=0.0494, cls_kl=0.0659, token_kl=0.0953
Epoch: [12]  [ 100/2001]  eta: 0:21:11  lr: 0.000413  loss: 3.2586 (3.0477)  time: 0.6370  data: 0.0001  max mem: 8730
Epoch: [12]  [ 110/2001]  eta: 0:20:58  lr: 0.000413  loss: 3.0649 (3.0419)  time: 0.6362  data: 0.0001  max mem: 8730
Epoch: [12]  [ 120/2001]  eta: 0:20:48  lr: 0.000413  loss: 3.1191 (3.0482)  time: 0.6382  data: 0.0001  max mem: 8730
Epoch: [12]  [ 130/2001]  eta: 0:20:37  lr: 0.000413  loss: 3.3105 (3.0485)  time: 0.6391  data: 0.0001  max mem: 8730
Epoch: [12]  [ 140/2001]  eta: 0:20:28  lr: 0.000413  loss: 3.2610 (3.0574)  time: 0.6382  data: 0.0001  max mem: 8730
Epoch: [12]  [ 150/2001]  eta: 0:20:19  lr: 0.000413  loss: 3.1302 (3.0447)  time: 0.6400  data: 0.0001  max mem: 8730
Epoch: [12]  [ 160/2001]  eta: 0:20:12  lr: 0.000413  loss: 3.0579 (3.0356)  time: 0.6502  data: 0.0001  max mem: 8730
Epoch: [12]  [ 170/2001]  eta: 0:20:05  lr: 0.000413  loss: 3.1173 (3.0423)  time: 0.6548  data: 0.0001  max mem: 8730
Epoch: [12]  [ 180/2001]  eta: 0:19:56  lr: 0.000413  loss: 3.2782 (3.0518)  time: 0.6445  data: 0.0001  max mem: 8730
Epoch: [12]  [ 190/2001]  eta: 0:19:48  lr: 0.000413  loss: 3.2000 (3.0503)  time: 0.6375  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9259, ratio_loss=0.0481, cls_kl=0.0658, token_kl=0.0933
Epoch: [12]  [ 200/2001]  eta: 0:19:40  lr: 0.000413  loss: 3.1538 (3.0548)  time: 0.6382  data: 0.0001  max mem: 8730
Epoch: [12]  [ 210/2001]  eta: 0:19:33  lr: 0.000413  loss: 3.1373 (3.0454)  time: 0.6487  data: 0.0001  max mem: 8730
Epoch: [12]  [ 220/2001]  eta: 0:19:26  lr: 0.000413  loss: 2.8642 (3.0426)  time: 0.6511  data: 0.0001  max mem: 8730
Epoch: [12]  [ 230/2001]  eta: 0:19:18  lr: 0.000413  loss: 2.8642 (3.0357)  time: 0.6407  data: 0.0001  max mem: 8730
Epoch: [12]  [ 240/2001]  eta: 0:19:10  lr: 0.000413  loss: 3.0537 (3.0300)  time: 0.6345  data: 0.0001  max mem: 8730
Epoch: [12]  [ 250/2001]  eta: 0:19:02  lr: 0.000413  loss: 3.1037 (3.0301)  time: 0.6344  data: 0.0001  max mem: 8730
Epoch: [12]  [ 260/2001]  eta: 0:18:54  lr: 0.000413  loss: 3.3624 (3.0421)  time: 0.6354  data: 0.0001  max mem: 8730
Epoch: [12]  [ 270/2001]  eta: 0:18:47  lr: 0.000413  loss: 3.4132 (3.0490)  time: 0.6366  data: 0.0001  max mem: 8730
Epoch: [12]  [ 280/2001]  eta: 0:18:40  lr: 0.000413  loss: 3.2398 (3.0541)  time: 0.6363  data: 0.0001  max mem: 8730
Epoch: [12]  [ 290/2001]  eta: 0:18:32  lr: 0.000413  loss: 3.0821 (3.0574)  time: 0.6347  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9595, ratio_loss=0.0507, cls_kl=0.0660, token_kl=0.0955
Epoch: [12]  [ 300/2001]  eta: 0:18:24  lr: 0.000413  loss: 3.1005 (3.0561)  time: 0.6330  data: 0.0001  max mem: 8730
Epoch: [12]  [ 310/2001]  eta: 0:18:17  lr: 0.000413  loss: 2.9968 (3.0518)  time: 0.6319  data: 0.0001  max mem: 8730
Epoch: [12]  [ 320/2001]  eta: 0:18:10  lr: 0.000413  loss: 3.2085 (3.0539)  time: 0.6339  data: 0.0001  max mem: 8730
Epoch: [12]  [ 330/2001]  eta: 0:18:02  lr: 0.000413  loss: 3.2437 (3.0541)  time: 0.6328  data: 0.0001  max mem: 8730
Epoch: [12]  [ 340/2001]  eta: 0:17:55  lr: 0.000413  loss: 2.9874 (3.0494)  time: 0.6331  data: 0.0001  max mem: 8730
Epoch: [12]  [ 350/2001]  eta: 0:17:48  lr: 0.000413  loss: 2.9857 (3.0488)  time: 0.6336  data: 0.0001  max mem: 8730
Epoch: [12]  [ 360/2001]  eta: 0:17:41  lr: 0.000413  loss: 3.2603 (3.0502)  time: 0.6316  data: 0.0001  max mem: 8730
Epoch: [12]  [ 370/2001]  eta: 0:17:34  lr: 0.000413  loss: 3.3869 (3.0538)  time: 0.6311  data: 0.0001  max mem: 8730
Epoch: [12]  [ 380/2001]  eta: 0:17:27  lr: 0.000413  loss: 3.2699 (3.0553)  time: 0.6309  data: 0.0001  max mem: 8730
Epoch: [12]  [ 390/2001]  eta: 0:17:20  lr: 0.000413  loss: 3.2554 (3.0601)  time: 0.6311  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9611, ratio_loss=0.0504, cls_kl=0.0657, token_kl=0.0940
Epoch: [12]  [ 400/2001]  eta: 0:17:12  lr: 0.000413  loss: 3.2554 (3.0623)  time: 0.6301  data: 0.0001  max mem: 8730
Epoch: [12]  [ 410/2001]  eta: 0:17:05  lr: 0.000413  loss: 3.1316 (3.0592)  time: 0.6303  data: 0.0001  max mem: 8730
Epoch: [12]  [ 420/2001]  eta: 0:16:58  lr: 0.000413  loss: 2.8772 (3.0572)  time: 0.6300  data: 0.0001  max mem: 8730
Epoch: [12]  [ 430/2001]  eta: 0:16:52  lr: 0.000413  loss: 2.9739 (3.0538)  time: 0.6399  data: 0.0001  max mem: 8730
Epoch: [12]  [ 440/2001]  eta: 0:16:46  lr: 0.000413  loss: 3.2397 (3.0596)  time: 0.6466  data: 0.0001  max mem: 8730
Epoch: [12]  [ 450/2001]  eta: 0:16:39  lr: 0.000413  loss: 3.3191 (3.0637)  time: 0.6367  data: 0.0001  max mem: 8730
Epoch: [12]  [ 460/2001]  eta: 0:16:32  lr: 0.000413  loss: 3.2083 (3.0659)  time: 0.6302  data: 0.0001  max mem: 8730
Epoch: [12]  [ 470/2001]  eta: 0:16:25  lr: 0.000413  loss: 3.0727 (3.0605)  time: 0.6306  data: 0.0001  max mem: 8730
Epoch: [12]  [ 480/2001]  eta: 0:16:19  lr: 0.000413  loss: 2.8178 (3.0566)  time: 0.6394  data: 0.0001  max mem: 8730
Epoch: [12]  [ 490/2001]  eta: 0:16:12  lr: 0.000413  loss: 3.0032 (3.0608)  time: 0.6381  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9508, ratio_loss=0.0495, cls_kl=0.0660, token_kl=0.0949
Epoch: [12]  [ 500/2001]  eta: 0:16:05  lr: 0.000413  loss: 3.3223 (3.0619)  time: 0.6305  data: 0.0001  max mem: 8730
Epoch: [12]  [ 510/2001]  eta: 0:15:58  lr: 0.000413  loss: 3.3295 (3.0641)  time: 0.6306  data: 0.0001  max mem: 8730
Epoch: [12]  [ 520/2001]  eta: 0:15:51  lr: 0.000413  loss: 3.1602 (3.0620)  time: 0.6288  data: 0.0001  max mem: 8730
Epoch: [12]  [ 530/2001]  eta: 0:15:44  lr: 0.000413  loss: 3.1757 (3.0633)  time: 0.6273  data: 0.0001  max mem: 8730
Epoch: [12]  [ 540/2001]  eta: 0:15:38  lr: 0.000413  loss: 3.2522 (3.0655)  time: 0.6285  data: 0.0001  max mem: 8730
Epoch: [12]  [ 550/2001]  eta: 0:15:31  lr: 0.000413  loss: 3.3173 (3.0689)  time: 0.6292  data: 0.0001  max mem: 8730
Epoch: [12]  [ 560/2001]  eta: 0:15:24  lr: 0.000413  loss: 3.2790 (3.0703)  time: 0.6273  data: 0.0001  max mem: 8730
Epoch: [12]  [ 570/2001]  eta: 0:15:17  lr: 0.000413  loss: 3.2790 (3.0737)  time: 0.6267  data: 0.0001  max mem: 8730
Epoch: [12]  [ 580/2001]  eta: 0:15:11  lr: 0.000413  loss: 3.0680 (3.0692)  time: 0.6348  data: 0.0001  max mem: 8730
Epoch: [12]  [ 590/2001]  eta: 0:15:04  lr: 0.000413  loss: 3.1493 (3.0731)  time: 0.6350  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0151, ratio_loss=0.0493, cls_kl=0.0681, token_kl=0.0944
Epoch: [12]  [ 600/2001]  eta: 0:14:58  lr: 0.000413  loss: 3.2466 (3.0743)  time: 0.6340  data: 0.0001  max mem: 8730
Epoch: [12]  [ 610/2001]  eta: 0:14:51  lr: 0.000413  loss: 3.1953 (3.0726)  time: 0.6349  data: 0.0001  max mem: 8730
Epoch: [12]  [ 620/2001]  eta: 0:14:44  lr: 0.000413  loss: 3.0802 (3.0744)  time: 0.6284  data: 0.0001  max mem: 8730
Epoch: [12]  [ 630/2001]  eta: 0:14:38  lr: 0.000413  loss: 3.1666 (3.0740)  time: 0.6320  data: 0.0001  max mem: 8730
Epoch: [12]  [ 640/2001]  eta: 0:14:31  lr: 0.000413  loss: 3.2945 (3.0782)  time: 0.6318  data: 0.0001  max mem: 8730
Epoch: [12]  [ 650/2001]  eta: 0:14:24  lr: 0.000413  loss: 3.3557 (3.0768)  time: 0.6254  data: 0.0001  max mem: 8730
Epoch: [12]  [ 660/2001]  eta: 0:14:18  lr: 0.000413  loss: 2.9274 (3.0711)  time: 0.6250  data: 0.0001  max mem: 8730
Epoch: [12]  [ 670/2001]  eta: 0:14:11  lr: 0.000413  loss: 2.9650 (3.0733)  time: 0.6284  data: 0.0001  max mem: 8730
Epoch: [12]  [ 680/2001]  eta: 0:14:04  lr: 0.000413  loss: 2.9757 (3.0688)  time: 0.6267  data: 0.0001  max mem: 8730
Epoch: [12]  [ 690/2001]  eta: 0:13:58  lr: 0.000413  loss: 2.9323 (3.0679)  time: 0.6234  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9314, ratio_loss=0.0469, cls_kl=0.0665, token_kl=0.0949
Epoch: [12]  [ 700/2001]  eta: 0:13:51  lr: 0.000413  loss: 3.2345 (3.0700)  time: 0.6224  data: 0.0001  max mem: 8730
Epoch: [12]  [ 710/2001]  eta: 0:13:44  lr: 0.000413  loss: 3.1421 (3.0683)  time: 0.6220  data: 0.0001  max mem: 8730
Epoch: [12]  [ 720/2001]  eta: 0:13:38  lr: 0.000413  loss: 3.2090 (3.0716)  time: 0.6268  data: 0.0001  max mem: 8730
Epoch: [12]  [ 730/2001]  eta: 0:13:31  lr: 0.000413  loss: 3.2967 (3.0714)  time: 0.6281  data: 0.0001  max mem: 8730
Epoch: [12]  [ 740/2001]  eta: 0:13:24  lr: 0.000413  loss: 3.3420 (3.0749)  time: 0.6242  data: 0.0001  max mem: 8730
Epoch: [12]  [ 750/2001]  eta: 0:13:18  lr: 0.000413  loss: 3.2770 (3.0767)  time: 0.6255  data: 0.0001  max mem: 8730
Epoch: [12]  [ 760/2001]  eta: 0:13:11  lr: 0.000413  loss: 3.0907 (3.0767)  time: 0.6250  data: 0.0001  max mem: 8730
Epoch: [12]  [ 770/2001]  eta: 0:13:05  lr: 0.000413  loss: 3.2703 (3.0791)  time: 0.6227  data: 0.0001  max mem: 8730
Epoch: [12]  [ 780/2001]  eta: 0:12:58  lr: 0.000413  loss: 3.1447 (3.0771)  time: 0.6236  data: 0.0001  max mem: 8730
Epoch: [12]  [ 790/2001]  eta: 0:12:51  lr: 0.000413  loss: 3.1788 (3.0806)  time: 0.6238  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0408, ratio_loss=0.0510, cls_kl=0.0674, token_kl=0.0931
Epoch: [12]  [ 800/2001]  eta: 0:12:45  lr: 0.000413  loss: 3.1788 (3.0776)  time: 0.6255  data: 0.0001  max mem: 8730
Epoch: [12]  [ 810/2001]  eta: 0:12:38  lr: 0.000413  loss: 2.9561 (3.0763)  time: 0.6270  data: 0.0001  max mem: 8730
Epoch: [12]  [ 820/2001]  eta: 0:12:32  lr: 0.000413  loss: 3.0605 (3.0776)  time: 0.6273  data: 0.0001  max mem: 8730
Epoch: [12]  [ 830/2001]  eta: 0:12:25  lr: 0.000413  loss: 3.1999 (3.0779)  time: 0.6259  data: 0.0001  max mem: 8730
Epoch: [12]  [ 840/2001]  eta: 0:12:19  lr: 0.000413  loss: 3.0680 (3.0784)  time: 0.6239  data: 0.0001  max mem: 8730
Epoch: [12]  [ 850/2001]  eta: 0:12:13  lr: 0.000413  loss: 3.0805 (3.0783)  time: 0.6332  data: 0.0001  max mem: 8730
Epoch: [12]  [ 860/2001]  eta: 0:12:06  lr: 0.000413  loss: 3.1509 (3.0779)  time: 0.6357  data: 0.0001  max mem: 8730
Epoch: [12]  [ 870/2001]  eta: 0:12:00  lr: 0.000413  loss: 3.2830 (3.0774)  time: 0.6372  data: 0.0001  max mem: 8730
Epoch: [12]  [ 880/2001]  eta: 0:11:53  lr: 0.000413  loss: 3.2604 (3.0780)  time: 0.6385  data: 0.0001  max mem: 8730
Epoch: [12]  [ 890/2001]  eta: 0:11:47  lr: 0.000413  loss: 3.1766 (3.0756)  time: 0.6280  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9338, ratio_loss=0.0471, cls_kl=0.0650, token_kl=0.0916
Epoch: [12]  [ 900/2001]  eta: 0:11:40  lr: 0.000413  loss: 2.8311 (3.0745)  time: 0.6297  data: 0.0001  max mem: 8730
Epoch: [12]  [ 910/2001]  eta: 0:11:34  lr: 0.000413  loss: 3.2026 (3.0772)  time: 0.6339  data: 0.0001  max mem: 8730
Epoch: [12]  [ 920/2001]  eta: 0:11:28  lr: 0.000413  loss: 3.1797 (3.0766)  time: 0.6290  data: 0.0001  max mem: 8730
Epoch: [12]  [ 930/2001]  eta: 0:11:21  lr: 0.000413  loss: 3.1797 (3.0791)  time: 0.6312  data: 0.0001  max mem: 8730
Epoch: [12]  [ 940/2001]  eta: 0:11:15  lr: 0.000413  loss: 3.2305 (3.0788)  time: 0.6320  data: 0.0001  max mem: 8730
Epoch: [12]  [ 950/2001]  eta: 0:11:08  lr: 0.000413  loss: 3.0146 (3.0777)  time: 0.6266  data: 0.0001  max mem: 8730
Epoch: [12]  [ 960/2001]  eta: 0:11:02  lr: 0.000413  loss: 3.3618 (3.0814)  time: 0.6279  data: 0.0001  max mem: 8730
Epoch: [12]  [ 970/2001]  eta: 0:10:55  lr: 0.000413  loss: 3.4016 (3.0824)  time: 0.6299  data: 0.0001  max mem: 8730
Epoch: [12]  [ 980/2001]  eta: 0:10:49  lr: 0.000413  loss: 3.2997 (3.0805)  time: 0.6284  data: 0.0001  max mem: 8730
Epoch: [12]  [ 990/2001]  eta: 0:10:42  lr: 0.000413  loss: 3.0851 (3.0801)  time: 0.6291  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0006, ratio_loss=0.0522, cls_kl=0.0681, token_kl=0.0955
Epoch: [12]  [1000/2001]  eta: 0:10:36  lr: 0.000413  loss: 2.9426 (3.0757)  time: 0.6293  data: 0.0001  max mem: 8730
Epoch: [12]  [1010/2001]  eta: 0:10:30  lr: 0.000413  loss: 2.7825 (3.0744)  time: 0.6399  data: 0.0001  max mem: 8730
Epoch: [12]  [1020/2001]  eta: 0:10:23  lr: 0.000413  loss: 3.1871 (3.0752)  time: 0.6447  data: 0.0001  max mem: 8730
Epoch: [12]  [1030/2001]  eta: 0:10:17  lr: 0.000413  loss: 3.3061 (3.0771)  time: 0.6359  data: 0.0001  max mem: 8730
Epoch: [12]  [1040/2001]  eta: 0:10:11  lr: 0.000413  loss: 3.1085 (3.0755)  time: 0.6306  data: 0.0001  max mem: 8730
Epoch: [12]  [1050/2001]  eta: 0:10:04  lr: 0.000413  loss: 2.7285 (3.0738)  time: 0.6274  data: 0.0001  max mem: 8730
Epoch: [12]  [1060/2001]  eta: 0:09:58  lr: 0.000413  loss: 3.0974 (3.0724)  time: 0.6389  data: 0.0001  max mem: 8730
Epoch: [12]  [1070/2001]  eta: 0:09:52  lr: 0.000413  loss: 3.0997 (3.0720)  time: 0.6424  data: 0.0001  max mem: 8730
Epoch: [12]  [1080/2001]  eta: 0:09:45  lr: 0.000413  loss: 3.0997 (3.0716)  time: 0.6365  data: 0.0001  max mem: 8730
Epoch: [12]  [1090/2001]  eta: 0:09:39  lr: 0.000413  loss: 3.1990 (3.0722)  time: 0.6365  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8775, ratio_loss=0.0486, cls_kl=0.0632, token_kl=0.0931
Epoch: [12]  [1100/2001]  eta: 0:09:33  lr: 0.000413  loss: 3.0917 (3.0711)  time: 0.6318  data: 0.0001  max mem: 8730
Epoch: [12]  [1110/2001]  eta: 0:09:26  lr: 0.000413  loss: 3.1634 (3.0717)  time: 0.6281  data: 0.0001  max mem: 8730
Epoch: [12]  [1120/2001]  eta: 0:09:20  lr: 0.000413  loss: 3.0557 (3.0702)  time: 0.6285  data: 0.0001  max mem: 8730
Epoch: [12]  [1130/2001]  eta: 0:09:13  lr: 0.000413  loss: 3.0210 (3.0716)  time: 0.6286  data: 0.0001  max mem: 8730
Epoch: [12]  [1140/2001]  eta: 0:09:07  lr: 0.000413  loss: 3.2861 (3.0701)  time: 0.6296  data: 0.0001  max mem: 8730
Epoch: [12]  [1150/2001]  eta: 0:09:01  lr: 0.000413  loss: 2.9980 (3.0689)  time: 0.6333  data: 0.0001  max mem: 8730
Epoch: [12]  [1160/2001]  eta: 0:08:54  lr: 0.000413  loss: 3.0371 (3.0696)  time: 0.6372  data: 0.0001  max mem: 8730
Epoch: [12]  [1170/2001]  eta: 0:08:48  lr: 0.000413  loss: 3.0527 (3.0690)  time: 0.6356  data: 0.0001  max mem: 8730
Epoch: [12]  [1180/2001]  eta: 0:08:41  lr: 0.000413  loss: 3.0346 (3.0672)  time: 0.6304  data: 0.0001  max mem: 8730
Epoch: [12]  [1190/2001]  eta: 0:08:35  lr: 0.000413  loss: 2.9262 (3.0665)  time: 0.6282  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9240, ratio_loss=0.0463, cls_kl=0.0627, token_kl=0.0909
Epoch: [12]  [1200/2001]  eta: 0:08:29  lr: 0.000413  loss: 3.0998 (3.0674)  time: 0.6302  data: 0.0001  max mem: 8730
Epoch: [12]  [1210/2001]  eta: 0:08:22  lr: 0.000413  loss: 3.3122 (3.0675)  time: 0.6312  data: 0.0001  max mem: 8730
Epoch: [12]  [1220/2001]  eta: 0:08:16  lr: 0.000413  loss: 3.4248 (3.0701)  time: 0.6301  data: 0.0001  max mem: 8730
Epoch: [12]  [1230/2001]  eta: 0:08:09  lr: 0.000413  loss: 3.1707 (3.0694)  time: 0.6299  data: 0.0001  max mem: 8730
Epoch: [12]  [1240/2001]  eta: 0:08:03  lr: 0.000413  loss: 2.9367 (3.0680)  time: 0.6314  data: 0.0001  max mem: 8730
Epoch: [12]  [1250/2001]  eta: 0:07:57  lr: 0.000413  loss: 3.0615 (3.0681)  time: 0.6320  data: 0.0001  max mem: 8730
Epoch: [12]  [1260/2001]  eta: 0:07:50  lr: 0.000413  loss: 3.1947 (3.0685)  time: 0.6374  data: 0.0001  max mem: 8730
Epoch: [12]  [1270/2001]  eta: 0:07:44  lr: 0.000413  loss: 3.1947 (3.0687)  time: 0.6447  data: 0.0001  max mem: 8730
Epoch: [12]  [1280/2001]  eta: 0:07:38  lr: 0.000413  loss: 3.0980 (3.0696)  time: 0.6568  data: 0.0001  max mem: 8730
Epoch: [12]  [1290/2001]  eta: 0:07:32  lr: 0.000413  loss: 3.1506 (3.0701)  time: 0.6581  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9749, ratio_loss=0.0480, cls_kl=0.0646, token_kl=0.0928
Epoch: [12]  [1300/2001]  eta: 0:07:25  lr: 0.000413  loss: 3.1623 (3.0696)  time: 0.6414  data: 0.0001  max mem: 8730
Epoch: [12]  [1310/2001]  eta: 0:07:19  lr: 0.000413  loss: 3.0443 (3.0681)  time: 0.6363  data: 0.0001  max mem: 8730
Epoch: [12]  [1320/2001]  eta: 0:07:13  lr: 0.000413  loss: 3.2606 (3.0691)  time: 0.6410  data: 0.0001  max mem: 8730
Epoch: [12]  [1330/2001]  eta: 0:07:06  lr: 0.000413  loss: 2.9842 (3.0672)  time: 0.6464  data: 0.0001  max mem: 8730
Epoch: [12]  [1340/2001]  eta: 0:07:00  lr: 0.000413  loss: 2.9688 (3.0675)  time: 0.6421  data: 0.0001  max mem: 8730
Epoch: [12]  [1350/2001]  eta: 0:06:54  lr: 0.000413  loss: 2.9916 (3.0667)  time: 0.6352  data: 0.0001  max mem: 8730
Epoch: [12]  [1360/2001]  eta: 0:06:47  lr: 0.000413  loss: 3.1251 (3.0674)  time: 0.6351  data: 0.0001  max mem: 8730
Epoch: [12]  [1370/2001]  eta: 0:06:41  lr: 0.000413  loss: 3.2565 (3.0677)  time: 0.6342  data: 0.0001  max mem: 8730
Epoch: [12]  [1380/2001]  eta: 0:06:34  lr: 0.000413  loss: 3.2794 (3.0674)  time: 0.6329  data: 0.0001  max mem: 8730
Epoch: [12]  [1390/2001]  eta: 0:06:28  lr: 0.000413  loss: 3.2155 (3.0688)  time: 0.6335  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9459, ratio_loss=0.0493, cls_kl=0.0660, token_kl=0.0934
Epoch: [12]  [1400/2001]  eta: 0:06:22  lr: 0.000413  loss: 3.1712 (3.0678)  time: 0.6358  data: 0.0001  max mem: 8730
Epoch: [12]  [1410/2001]  eta: 0:06:15  lr: 0.000413  loss: 3.1712 (3.0696)  time: 0.6398  data: 0.0001  max mem: 8730
Epoch: [12]  [1420/2001]  eta: 0:06:09  lr: 0.000413  loss: 3.3917 (3.0715)  time: 0.6395  data: 0.0001  max mem: 8730
Epoch: [12]  [1430/2001]  eta: 0:06:03  lr: 0.000413  loss: 3.3557 (3.0720)  time: 0.6347  data: 0.0001  max mem: 8730
Epoch: [12]  [1440/2001]  eta: 0:05:56  lr: 0.000413  loss: 3.1501 (3.0719)  time: 0.6431  data: 0.0001  max mem: 8730
Epoch: [12]  [1450/2001]  eta: 0:05:50  lr: 0.000413  loss: 3.0814 (3.0725)  time: 0.6490  data: 0.0001  max mem: 8730
Epoch: [12]  [1460/2001]  eta: 0:05:44  lr: 0.000413  loss: 3.1573 (3.0732)  time: 0.6383  data: 0.0001  max mem: 8730
Epoch: [12]  [1470/2001]  eta: 0:05:37  lr: 0.000413  loss: 3.2405 (3.0736)  time: 0.6337  data: 0.0001  max mem: 8730
Epoch: [12]  [1480/2001]  eta: 0:05:31  lr: 0.000413  loss: 3.2653 (3.0746)  time: 0.6405  data: 0.0001  max mem: 8730
Epoch: [12]  [1490/2001]  eta: 0:05:25  lr: 0.000413  loss: 3.1997 (3.0742)  time: 0.6496  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0316, ratio_loss=0.0533, cls_kl=0.0698, token_kl=0.0964
Epoch: [12]  [1500/2001]  eta: 0:05:18  lr: 0.000413  loss: 2.8418 (3.0716)  time: 0.6500  data: 0.0001  max mem: 8730
Epoch: [12]  [1510/2001]  eta: 0:05:12  lr: 0.000413  loss: 2.5392 (3.0687)  time: 0.6398  data: 0.0001  max mem: 8730
Epoch: [12]  [1520/2001]  eta: 0:05:06  lr: 0.000413  loss: 2.8006 (3.0684)  time: 0.6346  data: 0.0001  max mem: 8730
Epoch: [12]  [1530/2001]  eta: 0:04:59  lr: 0.000413  loss: 3.2421 (3.0698)  time: 0.6361  data: 0.0001  max mem: 8730
Epoch: [12]  [1540/2001]  eta: 0:04:53  lr: 0.000413  loss: 3.2006 (3.0704)  time: 0.6351  data: 0.0001  max mem: 8730
Epoch: [12]  [1550/2001]  eta: 0:04:46  lr: 0.000413  loss: 3.0473 (3.0697)  time: 0.6345  data: 0.0001  max mem: 8730
Epoch: [12]  [1560/2001]  eta: 0:04:40  lr: 0.000413  loss: 2.9493 (3.0693)  time: 0.6351  data: 0.0001  max mem: 8730
Epoch: [12]  [1570/2001]  eta: 0:04:34  lr: 0.000413  loss: 3.0450 (3.0702)  time: 0.6361  data: 0.0001  max mem: 8730
Epoch: [12]  [1580/2001]  eta: 0:04:27  lr: 0.000413  loss: 3.1522 (3.0695)  time: 0.6367  data: 0.0001  max mem: 8730
Epoch: [12]  [1590/2001]  eta: 0:04:21  lr: 0.000413  loss: 3.0056 (3.0684)  time: 0.6365  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8754, ratio_loss=0.0495, cls_kl=0.0639, token_kl=0.0950
Epoch: [12]  [1600/2001]  eta: 0:04:15  lr: 0.000413  loss: 3.0410 (3.0685)  time: 0.6365  data: 0.0001  max mem: 8730
Epoch: [12]  [1610/2001]  eta: 0:04:08  lr: 0.000413  loss: 3.0929 (3.0680)  time: 0.6360  data: 0.0001  max mem: 8730
Epoch: [12]  [1620/2001]  eta: 0:04:02  lr: 0.000413  loss: 3.0723 (3.0673)  time: 0.6373  data: 0.0001  max mem: 8730
Epoch: [12]  [1630/2001]  eta: 0:03:56  lr: 0.000413  loss: 3.1861 (3.0674)  time: 0.6385  data: 0.0001  max mem: 8730
Epoch: [12]  [1640/2001]  eta: 0:03:49  lr: 0.000413  loss: 2.9106 (3.0657)  time: 0.6374  data: 0.0001  max mem: 8730
Epoch: [12]  [1650/2001]  eta: 0:03:43  lr: 0.000413  loss: 3.0968 (3.0673)  time: 0.6388  data: 0.0001  max mem: 8730
Epoch: [12]  [1660/2001]  eta: 0:03:37  lr: 0.000413  loss: 3.0647 (3.0670)  time: 0.6386  data: 0.0001  max mem: 8730
Epoch: [12]  [1670/2001]  eta: 0:03:30  lr: 0.000413  loss: 3.0700 (3.0686)  time: 0.6360  data: 0.0001  max mem: 8730
Epoch: [12]  [1680/2001]  eta: 0:03:24  lr: 0.000413  loss: 3.3165 (3.0695)  time: 0.6353  data: 0.0001  max mem: 8730
Epoch: [12]  [1690/2001]  eta: 0:03:17  lr: 0.000413  loss: 3.0776 (3.0695)  time: 0.6367  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9899, ratio_loss=0.0517, cls_kl=0.0660, token_kl=0.0935
Epoch: [12]  [1700/2001]  eta: 0:03:11  lr: 0.000413  loss: 3.1668 (3.0709)  time: 0.6371  data: 0.0001  max mem: 8730
Epoch: [12]  [1710/2001]  eta: 0:03:05  lr: 0.000413  loss: 3.3697 (3.0721)  time: 0.6464  data: 0.0001  max mem: 8730
Epoch: [12]  [1720/2001]  eta: 0:02:58  lr: 0.000413  loss: 3.3197 (3.0715)  time: 0.6527  data: 0.0001  max mem: 8730
Epoch: [12]  [1730/2001]  eta: 0:02:52  lr: 0.000413  loss: 3.1169 (3.0716)  time: 0.6422  data: 0.0001  max mem: 8730
Epoch: [12]  [1740/2001]  eta: 0:02:46  lr: 0.000413  loss: 3.2095 (3.0721)  time: 0.6340  data: 0.0001  max mem: 8730
Epoch: [12]  [1750/2001]  eta: 0:02:39  lr: 0.000413  loss: 3.0521 (3.0713)  time: 0.6376  data: 0.0001  max mem: 8730
Epoch: [12]  [1760/2001]  eta: 0:02:33  lr: 0.000413  loss: 3.0521 (3.0717)  time: 0.6468  data: 0.0001  max mem: 8730
| distributed init (rank 3): env://
| distributed init (rank 0): env://
| distributed init (rank 4): env://
| distributed init (rank 7): env://
| distributed init (rank 5): env://
| distributed init (rank 2): env://
| distributed init (rank 6): env://
| distributed init (rank 1): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp-3keep/checkpoint.pth', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0004125 for PREDICTOR
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Epoch: [12]  [   0/2001]  eta: 3:42:01  lr: 0.000413  loss: 3.8328 (3.8328)  time: 6.6575  data: 3.0517  max mem: 8647
Epoch: [12]  [  10/2001]  eta: 0:38:30  lr: 0.000413  loss: 3.5093 (3.4464)  time: 1.1602  data: 0.2776  max mem: 8728
Epoch: [12]  [  20/2001]  eta: 0:29:23  lr: 0.000413  loss: 3.4002 (3.3410)  time: 0.6019  data: 0.0002  max mem: 8728
Epoch: [12]  [  30/2001]  eta: 0:26:10  lr: 0.000413  loss: 3.3083 (3.3241)  time: 0.5966  data: 0.0002  max mem: 8728
Epoch: [12]  [  40/2001]  eta: 0:24:25  lr: 0.000413  loss: 3.2844 (3.2682)  time: 0.5970  data: 0.0002  max mem: 8728
Epoch: [12]  [  50/2001]  eta: 0:23:21  lr: 0.000413  loss: 3.1643 (3.2535)  time: 0.5972  data: 0.0002  max mem: 8728
Epoch: [12]  [  60/2001]  eta: 0:22:39  lr: 0.000413  loss: 3.2410 (3.2384)  time: 0.6046  data: 0.0002  max mem: 8728
Epoch: [12]  [  70/2001]  eta: 0:22:07  lr: 0.000413  loss: 3.2349 (3.2002)  time: 0.6086  data: 0.0002  max mem: 8728
Epoch: [12]  [  80/2001]  eta: 0:21:42  lr: 0.000413  loss: 3.1257 (3.1901)  time: 0.6106  data: 0.0002  max mem: 8728
Epoch: [12]  [  90/2001]  eta: 0:21:22  lr: 0.000413  loss: 3.1932 (3.1763)  time: 0.6139  data: 0.0002  max mem: 8728
loss info: cls_loss=3.0649, ratio_loss=0.0517, cls_kl=0.0675, token_kl=0.0947
Epoch: [12]  [ 100/2001]  eta: 0:21:05  lr: 0.000413  loss: 3.2918 (3.1839)  time: 0.6139  data: 0.0002  max mem: 8728
Epoch: [12]  [ 110/2001]  eta: 0:20:50  lr: 0.000413  loss: 3.3797 (3.1793)  time: 0.6157  data: 0.0002  max mem: 8728
Epoch: [12]  [ 120/2001]  eta: 0:20:38  lr: 0.000413  loss: 3.2559 (3.1763)  time: 0.6238  data: 0.0001  max mem: 8728
Epoch: [12]  [ 130/2001]  eta: 0:20:27  lr: 0.000413  loss: 3.1740 (3.1708)  time: 0.6281  data: 0.0001  max mem: 8728
Epoch: [12]  [ 140/2001]  eta: 0:20:17  lr: 0.000413  loss: 3.1584 (3.1611)  time: 0.6265  data: 0.0002  max mem: 8728
Epoch: [12]  [ 150/2001]  eta: 0:20:07  lr: 0.000413  loss: 3.0557 (3.1452)  time: 0.6272  data: 0.0002  max mem: 8728
Epoch: [12]  [ 160/2001]  eta: 0:19:58  lr: 0.000413  loss: 3.1121 (3.1477)  time: 0.6300  data: 0.0001  max mem: 8728
Epoch: [12]  [ 170/2001]  eta: 0:19:49  lr: 0.000413  loss: 3.1860 (3.1419)  time: 0.6297  data: 0.0003  max mem: 8728
Epoch: [12]  [ 180/2001]  eta: 0:19:40  lr: 0.000413  loss: 3.1096 (3.1323)  time: 0.6277  data: 0.0003  max mem: 8728
Epoch: [12]  [ 190/2001]  eta: 0:19:33  lr: 0.000413  loss: 3.0778 (3.1325)  time: 0.6349  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9449, ratio_loss=0.0481, cls_kl=0.0646, token_kl=0.0913
Epoch: [12]  [ 200/2001]  eta: 0:19:25  lr: 0.000413  loss: 2.9006 (3.1166)  time: 0.6361  data: 0.0002  max mem: 8728
Epoch: [12]  [ 210/2001]  eta: 0:19:17  lr: 0.000413  loss: 2.9345 (3.1095)  time: 0.6297  data: 0.0001  max mem: 8728
Epoch: [12]  [ 220/2001]  eta: 0:19:10  lr: 0.000413  loss: 3.1176 (3.1020)  time: 0.6314  data: 0.0001  max mem: 8728
Epoch: [12]  [ 230/2001]  eta: 0:19:02  lr: 0.000413  loss: 3.0936 (3.0970)  time: 0.6318  data: 0.0001  max mem: 8728
Epoch: [12]  [ 240/2001]  eta: 0:18:54  lr: 0.000413  loss: 2.9757 (3.0903)  time: 0.6300  data: 0.0001  max mem: 8728
Epoch: [12]  [ 250/2001]  eta: 0:18:47  lr: 0.000413  loss: 2.8330 (3.0790)  time: 0.6305  data: 0.0001  max mem: 8728
Epoch: [12]  [ 260/2001]  eta: 0:18:40  lr: 0.000413  loss: 2.8239 (3.0710)  time: 0.6305  data: 0.0001  max mem: 8728
Epoch: [12]  [ 270/2001]  eta: 0:18:33  lr: 0.000413  loss: 3.0720 (3.0694)  time: 0.6333  data: 0.0001  max mem: 8728
Epoch: [12]  [ 280/2001]  eta: 0:18:26  lr: 0.000413  loss: 3.1194 (3.0727)  time: 0.6372  data: 0.0001  max mem: 8728
Epoch: [12]  [ 290/2001]  eta: 0:18:19  lr: 0.000413  loss: 3.0878 (3.0685)  time: 0.6351  data: 0.0002  max mem: 8728
loss info: cls_loss=2.8357, ratio_loss=0.0468, cls_kl=0.0628, token_kl=0.0921
Epoch: [12]  [ 300/2001]  eta: 0:18:12  lr: 0.000413  loss: 2.6858 (3.0602)  time: 0.6334  data: 0.0002  max mem: 8728
Epoch: [12]  [ 310/2001]  eta: 0:18:05  lr: 0.000413  loss: 3.0032 (3.0607)  time: 0.6328  data: 0.0002  max mem: 8728
Epoch: [12]  [ 320/2001]  eta: 0:17:58  lr: 0.000413  loss: 3.2497 (3.0694)  time: 0.6304  data: 0.0001  max mem: 8728
Epoch: [12]  [ 330/2001]  eta: 0:17:51  lr: 0.000413  loss: 3.3870 (3.0688)  time: 0.6314  data: 0.0001  max mem: 8728
Epoch: [12]  [ 340/2001]  eta: 0:17:44  lr: 0.000413  loss: 3.2278 (3.0698)  time: 0.6337  data: 0.0001  max mem: 8728
Epoch: [12]  [ 350/2001]  eta: 0:17:38  lr: 0.000413  loss: 3.1374 (3.0723)  time: 0.6334  data: 0.0002  max mem: 8728
Epoch: [12]  [ 360/2001]  eta: 0:17:31  lr: 0.000413  loss: 3.1374 (3.0699)  time: 0.6325  data: 0.0002  max mem: 8728
Epoch: [12]  [ 370/2001]  eta: 0:17:24  lr: 0.000413  loss: 3.0109 (3.0667)  time: 0.6320  data: 0.0002  max mem: 8728
Epoch: [12]  [ 380/2001]  eta: 0:17:17  lr: 0.000413  loss: 3.1020 (3.0639)  time: 0.6299  data: 0.0001  max mem: 8728
Epoch: [12]  [ 390/2001]  eta: 0:17:10  lr: 0.000413  loss: 3.1020 (3.0603)  time: 0.6281  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9662, ratio_loss=0.0504, cls_kl=0.0638, token_kl=0.0937
Epoch: [12]  [ 400/2001]  eta: 0:17:03  lr: 0.000413  loss: 3.1374 (3.0654)  time: 0.6295  data: 0.0002  max mem: 8728
Epoch: [12]  [ 410/2001]  eta: 0:16:57  lr: 0.000413  loss: 3.0958 (3.0678)  time: 0.6334  data: 0.0002  max mem: 8728
Epoch: [12]  [ 420/2001]  eta: 0:16:50  lr: 0.000413  loss: 3.0958 (3.0658)  time: 0.6335  data: 0.0002  max mem: 8728
Epoch: [12]  [ 430/2001]  eta: 0:16:44  lr: 0.000413  loss: 3.3896 (3.0730)  time: 0.6319  data: 0.0002  max mem: 8728
Epoch: [12]  [ 440/2001]  eta: 0:16:37  lr: 0.000413  loss: 3.3948 (3.0756)  time: 0.6319  data: 0.0001  max mem: 8728
Epoch: [12]  [ 450/2001]  eta: 0:16:30  lr: 0.000413  loss: 3.1649 (3.0756)  time: 0.6295  data: 0.0001  max mem: 8728
Epoch: [12]  [ 460/2001]  eta: 0:16:24  lr: 0.000413  loss: 3.0383 (3.0708)  time: 0.6371  data: 0.0002  max mem: 8728
Epoch: [12]  [ 470/2001]  eta: 0:16:17  lr: 0.000413  loss: 2.6930 (3.0623)  time: 0.6393  data: 0.0001  max mem: 8728
Epoch: [12]  [ 480/2001]  eta: 0:16:11  lr: 0.000413  loss: 2.7806 (3.0599)  time: 0.6325  data: 0.0001  max mem: 8728
Epoch: [12]  [ 490/2001]  eta: 0:16:04  lr: 0.000413  loss: 3.1191 (3.0649)  time: 0.6339  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9360, ratio_loss=0.0511, cls_kl=0.0635, token_kl=0.0944
Epoch: [12]  [ 500/2001]  eta: 0:15:58  lr: 0.000413  loss: 3.1547 (3.0619)  time: 0.6353  data: 0.0002  max mem: 8728
Epoch: [12]  [ 510/2001]  eta: 0:15:51  lr: 0.000413  loss: 3.1733 (3.0660)  time: 0.6358  data: 0.0001  max mem: 8728
Epoch: [12]  [ 520/2001]  eta: 0:15:45  lr: 0.000413  loss: 3.2093 (3.0667)  time: 0.6376  data: 0.0001  max mem: 8728
Epoch: [12]  [ 530/2001]  eta: 0:15:38  lr: 0.000413  loss: 3.1550 (3.0626)  time: 0.6348  data: 0.0001  max mem: 8728
Epoch: [12]  [ 540/2001]  eta: 0:15:32  lr: 0.000413  loss: 3.0948 (3.0601)  time: 0.6331  data: 0.0001  max mem: 8728
Epoch: [12]  [ 550/2001]  eta: 0:15:25  lr: 0.000413  loss: 3.0948 (3.0595)  time: 0.6350  data: 0.0002  max mem: 8728
Epoch: [12]  [ 560/2001]  eta: 0:15:19  lr: 0.000413  loss: 3.2409 (3.0621)  time: 0.6330  data: 0.0002  max mem: 8728
Epoch: [12]  [ 570/2001]  eta: 0:15:12  lr: 0.000413  loss: 3.3498 (3.0662)  time: 0.6318  data: 0.0001  max mem: 8728
Epoch: [12]  [ 580/2001]  eta: 0:15:06  lr: 0.000413  loss: 3.3498 (3.0687)  time: 0.6335  data: 0.0001  max mem: 8728
Epoch: [12]  [ 590/2001]  eta: 0:14:59  lr: 0.000413  loss: 3.2755 (3.0696)  time: 0.6346  data: 0.0001  max mem: 8728
loss info: cls_loss=3.0048, ratio_loss=0.0503, cls_kl=0.0674, token_kl=0.0936
Epoch: [12]  [ 600/2001]  eta: 0:14:53  lr: 0.000413  loss: 3.1631 (3.0692)  time: 0.6383  data: 0.0001  max mem: 8728
Epoch: [12]  [ 610/2001]  eta: 0:14:47  lr: 0.000413  loss: 3.0933 (3.0706)  time: 0.6369  data: 0.0001  max mem: 8728
Epoch: [12]  [ 620/2001]  eta: 0:14:41  lr: 0.000413  loss: 3.2063 (3.0724)  time: 0.6403  data: 0.0001  max mem: 8728
Epoch: [12]  [ 630/2001]  eta: 0:14:34  lr: 0.000413  loss: 3.1531 (3.0731)  time: 0.6390  data: 0.0001  max mem: 8728
Epoch: [12]  [ 640/2001]  eta: 0:14:28  lr: 0.000413  loss: 3.0181 (3.0710)  time: 0.6319  data: 0.0002  max mem: 8728
Epoch: [12]  [ 650/2001]  eta: 0:14:21  lr: 0.000413  loss: 3.0181 (3.0712)  time: 0.6351  data: 0.0002  max mem: 8728
Epoch: [12]  [ 660/2001]  eta: 0:14:15  lr: 0.000413  loss: 3.0075 (3.0670)  time: 0.6350  data: 0.0001  max mem: 8728
Epoch: [12]  [ 670/2001]  eta: 0:14:08  lr: 0.000413  loss: 3.1289 (3.0697)  time: 0.6348  data: 0.0001  max mem: 8728
Epoch: [12]  [ 680/2001]  eta: 0:14:02  lr: 0.000413  loss: 3.1771 (3.0702)  time: 0.6368  data: 0.0001  max mem: 8728
Epoch: [12]  [ 690/2001]  eta: 0:13:55  lr: 0.000413  loss: 2.8467 (3.0671)  time: 0.6369  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9056, ratio_loss=0.0504, cls_kl=0.0663, token_kl=0.0954
Epoch: [12]  [ 700/2001]  eta: 0:13:49  lr: 0.000413  loss: 2.8403 (3.0649)  time: 0.6350  data: 0.0002  max mem: 8728
Epoch: [12]  [ 710/2001]  eta: 0:13:43  lr: 0.000413  loss: 3.0049 (3.0634)  time: 0.6334  data: 0.0001  max mem: 8728
Epoch: [12]  [ 720/2001]  eta: 0:13:36  lr: 0.000413  loss: 3.1673 (3.0613)  time: 0.6339  data: 0.0001  max mem: 8728
Epoch: [12]  [ 730/2001]  eta: 0:13:30  lr: 0.000413  loss: 3.1826 (3.0616)  time: 0.6354  data: 0.0001  max mem: 8728
Epoch: [12]  [ 740/2001]  eta: 0:13:23  lr: 0.000413  loss: 3.3046 (3.0668)  time: 0.6344  data: 0.0001  max mem: 8728
Epoch: [12]  [ 750/2001]  eta: 0:13:17  lr: 0.000413  loss: 3.3670 (3.0653)  time: 0.6339  data: 0.0002  max mem: 8728
Epoch: [12]  [ 760/2001]  eta: 0:13:10  lr: 0.000413  loss: 3.2802 (3.0654)  time: 0.6332  data: 0.0002  max mem: 8728
Epoch: [12]  [ 770/2001]  eta: 0:13:04  lr: 0.000413  loss: 3.3308 (3.0676)  time: 0.6324  data: 0.0002  max mem: 8728
Epoch: [12]  [ 780/2001]  eta: 0:12:58  lr: 0.000413  loss: 3.3308 (3.0689)  time: 0.6338  data: 0.0002  max mem: 8728
Epoch: [12]  [ 790/2001]  eta: 0:12:51  lr: 0.000413  loss: 3.1029 (3.0684)  time: 0.6348  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9825, ratio_loss=0.0497, cls_kl=0.0660, token_kl=0.0924
Epoch: [12]  [ 800/2001]  eta: 0:12:45  lr: 0.000413  loss: 3.1029 (3.0679)  time: 0.6341  data: 0.0002  max mem: 8728
Epoch: [12]  [ 810/2001]  eta: 0:12:38  lr: 0.000413  loss: 2.7942 (3.0608)  time: 0.6353  data: 0.0002  max mem: 8728
Epoch: [12]  [ 820/2001]  eta: 0:12:32  lr: 0.000413  loss: 2.8213 (3.0630)  time: 0.6367  data: 0.0002  max mem: 8728
Epoch: [12]  [ 830/2001]  eta: 0:12:26  lr: 0.000413  loss: 3.2377 (3.0588)  time: 0.6366  data: 0.0002  max mem: 8728
Epoch: [12]  [ 840/2001]  eta: 0:12:19  lr: 0.000413  loss: 2.8861 (3.0585)  time: 0.6371  data: 0.0002  max mem: 8728
Epoch: [12]  [ 850/2001]  eta: 0:12:13  lr: 0.000413  loss: 3.1687 (3.0571)  time: 0.6377  data: 0.0002  max mem: 8728
Epoch: [12]  [ 860/2001]  eta: 0:12:07  lr: 0.000413  loss: 3.1687 (3.0587)  time: 0.6397  data: 0.0001  max mem: 8728
Epoch: [12]  [ 870/2001]  eta: 0:12:00  lr: 0.000413  loss: 3.1150 (3.0599)  time: 0.6402  data: 0.0002  max mem: 8728
Epoch: [12]  [ 880/2001]  eta: 0:11:54  lr: 0.000413  loss: 3.0969 (3.0582)  time: 0.6377  data: 0.0001  max mem: 8728
Epoch: [12]  [ 890/2001]  eta: 0:11:48  lr: 0.000413  loss: 3.0107 (3.0560)  time: 0.6434  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8487, ratio_loss=0.0476, cls_kl=0.0636, token_kl=0.0949
Epoch: [12]  [ 900/2001]  eta: 0:11:41  lr: 0.000413  loss: 3.1319 (3.0562)  time: 0.6446  data: 0.0001  max mem: 8728
Epoch: [12]  [ 910/2001]  eta: 0:11:35  lr: 0.000413  loss: 3.1579 (3.0570)  time: 0.6380  data: 0.0001  max mem: 8728
Epoch: [12]  [ 920/2001]  eta: 0:11:28  lr: 0.000413  loss: 3.3459 (3.0596)  time: 0.6370  data: 0.0001  max mem: 8728
Epoch: [12]  [ 930/2001]  eta: 0:11:22  lr: 0.000413  loss: 3.3811 (3.0624)  time: 0.6373  data: 0.0001  max mem: 8728
Epoch: [12]  [ 940/2001]  eta: 0:11:16  lr: 0.000413  loss: 3.1955 (3.0619)  time: 0.6418  data: 0.0001  max mem: 8728
Epoch: [12]  [ 950/2001]  eta: 0:11:10  lr: 0.000413  loss: 2.6204 (3.0559)  time: 0.6475  data: 0.0002  max mem: 8728
Epoch: [12]  [ 960/2001]  eta: 0:11:03  lr: 0.000413  loss: 2.9046 (3.0566)  time: 0.6454  data: 0.0002  max mem: 8728
Epoch: [12]  [ 970/2001]  eta: 0:10:57  lr: 0.000413  loss: 3.2447 (3.0571)  time: 0.6390  data: 0.0001  max mem: 8728
Epoch: [12]  [ 980/2001]  eta: 0:10:51  lr: 0.000413  loss: 3.1127 (3.0569)  time: 0.6390  data: 0.0001  max mem: 8728
Epoch: [12]  [ 990/2001]  eta: 0:10:44  lr: 0.000413  loss: 3.1404 (3.0566)  time: 0.6417  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9548, ratio_loss=0.0478, cls_kl=0.0654, token_kl=0.0924
Epoch: [12]  [1000/2001]  eta: 0:10:38  lr: 0.000413  loss: 3.1558 (3.0561)  time: 0.6397  data: 0.0002  max mem: 8728
Epoch: [12]  [1010/2001]  eta: 0:10:31  lr: 0.000413  loss: 3.2113 (3.0583)  time: 0.6396  data: 0.0001  max mem: 8728
Epoch: [12]  [1020/2001]  eta: 0:10:25  lr: 0.000413  loss: 3.1930 (3.0577)  time: 0.6421  data: 0.0001  max mem: 8728
Epoch: [12]  [1030/2001]  eta: 0:10:19  lr: 0.000413  loss: 2.9180 (3.0556)  time: 0.6432  data: 0.0001  max mem: 8728
Epoch: [12]  [1040/2001]  eta: 0:10:13  lr: 0.000413  loss: 3.1815 (3.0577)  time: 0.6484  data: 0.0001  max mem: 8728
Epoch: [12]  [1050/2001]  eta: 0:10:06  lr: 0.000413  loss: 3.1815 (3.0563)  time: 0.6453  data: 0.0001  max mem: 8728
Epoch: [12]  [1060/2001]  eta: 0:10:00  lr: 0.000413  loss: 3.1387 (3.0570)  time: 0.6380  data: 0.0001  max mem: 8728
Epoch: [12]  [1070/2001]  eta: 0:09:53  lr: 0.000413  loss: 3.2793 (3.0575)  time: 0.6382  data: 0.0001  max mem: 8728
Epoch: [12]  [1080/2001]  eta: 0:09:47  lr: 0.000413  loss: 3.2592 (3.0572)  time: 0.6399  data: 0.0002  max mem: 8728
Epoch: [12]  [1090/2001]  eta: 0:09:41  lr: 0.000413  loss: 3.0458 (3.0559)  time: 0.6408  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9249, ratio_loss=0.0473, cls_kl=0.0633, token_kl=0.0923
Epoch: [12]  [1100/2001]  eta: 0:09:34  lr: 0.000413  loss: 2.9220 (3.0549)  time: 0.6397  data: 0.0002  max mem: 8728
Epoch: [12]  [1110/2001]  eta: 0:09:28  lr: 0.000413  loss: 3.0558 (3.0546)  time: 0.6396  data: 0.0002  max mem: 8728
Epoch: [12]  [1120/2001]  eta: 0:09:22  lr: 0.000413  loss: 3.2067 (3.0557)  time: 0.6384  data: 0.0002  max mem: 8728
Epoch: [12]  [1130/2001]  eta: 0:09:15  lr: 0.000413  loss: 3.2717 (3.0579)  time: 0.6376  data: 0.0002  max mem: 8728
Epoch: [12]  [1140/2001]  eta: 0:09:09  lr: 0.000413  loss: 3.0834 (3.0567)  time: 0.6389  data: 0.0001  max mem: 8728
Epoch: [12]  [1150/2001]  eta: 0:09:03  lr: 0.000413  loss: 3.0490 (3.0569)  time: 0.6414  data: 0.0001  max mem: 8728
Epoch: [12]  [1160/2001]  eta: 0:08:56  lr: 0.000413  loss: 3.1629 (3.0566)  time: 0.6443  data: 0.0002  max mem: 8728
Epoch: [12]  [1170/2001]  eta: 0:08:50  lr: 0.000413  loss: 3.0801 (3.0566)  time: 0.6417  data: 0.0002  max mem: 8728
Epoch: [12]  [1180/2001]  eta: 0:08:43  lr: 0.000413  loss: 3.2862 (3.0594)  time: 0.6387  data: 0.0001  max mem: 8728
Epoch: [12]  [1190/2001]  eta: 0:08:37  lr: 0.000413  loss: 3.2911 (3.0610)  time: 0.6415  data: 0.0002  max mem: 8728
loss info: cls_loss=3.0228, ratio_loss=0.0499, cls_kl=0.0652, token_kl=0.0923
Epoch: [12]  [1200/2001]  eta: 0:08:31  lr: 0.000413  loss: 3.2035 (3.0614)  time: 0.6421  data: 0.0002  max mem: 8728
Epoch: [12]  [1210/2001]  eta: 0:08:24  lr: 0.000413  loss: 3.1244 (3.0608)  time: 0.6394  data: 0.0001  max mem: 8728
Epoch: [12]  [1220/2001]  eta: 0:08:18  lr: 0.000413  loss: 3.0740 (3.0602)  time: 0.6423  data: 0.0001  max mem: 8728
Epoch: [12]  [1230/2001]  eta: 0:08:12  lr: 0.000413  loss: 3.0740 (3.0603)  time: 0.6429  data: 0.0002  max mem: 8728
Epoch: [12]  [1240/2001]  eta: 0:08:05  lr: 0.000413  loss: 3.0635 (3.0597)  time: 0.6394  data: 0.0002  max mem: 8728
Epoch: [12]  [1250/2001]  eta: 0:07:59  lr: 0.000413  loss: 2.9467 (3.0579)  time: 0.6408  data: 0.0002  max mem: 8728
Epoch: [12]  [1260/2001]  eta: 0:07:53  lr: 0.000413  loss: 3.0101 (3.0588)  time: 0.6432  data: 0.0002  max mem: 8728
Epoch: [12]  [1270/2001]  eta: 0:07:46  lr: 0.000413  loss: 3.1850 (3.0600)  time: 0.6424  data: 0.0001  max mem: 8728
Epoch: [12]  [1280/2001]  eta: 0:07:40  lr: 0.000413  loss: 3.3895 (3.0624)  time: 0.6417  data: 0.0002  max mem: 8728
Epoch: [12]  [1290/2001]  eta: 0:07:33  lr: 0.000413  loss: 3.3987 (3.0638)  time: 0.6430  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9793, ratio_loss=0.0509, cls_kl=0.0673, token_kl=0.0941
Epoch: [12]  [1300/2001]  eta: 0:07:27  lr: 0.000413  loss: 3.2770 (3.0642)  time: 0.6411  data: 0.0001  max mem: 8728
Epoch: [12]  [1310/2001]  eta: 0:07:21  lr: 0.000413  loss: 2.9709 (3.0629)  time: 0.6447  data: 0.0001  max mem: 8728
Epoch: [12]  [1320/2001]  eta: 0:07:14  lr: 0.000413  loss: 2.9173 (3.0609)  time: 0.6444  data: 0.0001  max mem: 8728
Epoch: [12]  [1330/2001]  eta: 0:07:08  lr: 0.000413  loss: 3.0512 (3.0615)  time: 0.6387  data: 0.0001  max mem: 8728
Epoch: [12]  [1340/2001]  eta: 0:07:02  lr: 0.000413  loss: 3.2295 (3.0627)  time: 0.6414  data: 0.0001  max mem: 8728
Epoch: [12]  [1350/2001]  eta: 0:06:55  lr: 0.000413  loss: 3.0986 (3.0625)  time: 0.6435  data: 0.0002  max mem: 8728
Epoch: [12]  [1360/2001]  eta: 0:06:49  lr: 0.000413  loss: 3.0986 (3.0635)  time: 0.6443  data: 0.0002  max mem: 8728
Epoch: [12]  [1370/2001]  eta: 0:06:43  lr: 0.000413  loss: 3.2452 (3.0649)  time: 0.6467  data: 0.0002  max mem: 8728
Epoch: [12]  [1380/2001]  eta: 0:06:36  lr: 0.000413  loss: 3.3668 (3.0660)  time: 0.6440  data: 0.0002  max mem: 8728
Epoch: [12]  [1390/2001]  eta: 0:06:30  lr: 0.000413  loss: 3.3215 (3.0665)  time: 0.6385  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9888, ratio_loss=0.0497, cls_kl=0.0656, token_kl=0.0924
Epoch: [12]  [1400/2001]  eta: 0:06:23  lr: 0.000413  loss: 3.2277 (3.0667)  time: 0.6384  data: 0.0002  max mem: 8728
Epoch: [12]  [1410/2001]  eta: 0:06:17  lr: 0.000413  loss: 3.3457 (3.0684)  time: 0.6381  data: 0.0002  max mem: 8728
Epoch: [12]  [1420/2001]  eta: 0:06:11  lr: 0.000413  loss: 3.3316 (3.0689)  time: 0.6368  data: 0.0002  max mem: 8728
Epoch: [12]  [1430/2001]  eta: 0:06:04  lr: 0.000413  loss: 3.1323 (3.0691)  time: 0.6374  data: 0.0002  max mem: 8728
Epoch: [12]  [1440/2001]  eta: 0:05:58  lr: 0.000413  loss: 3.1305 (3.0686)  time: 0.6369  data: 0.0001  max mem: 8728
Epoch: [12]  [1450/2001]  eta: 0:05:51  lr: 0.000413  loss: 3.2063 (3.0692)  time: 0.6390  data: 0.0001  max mem: 8728
Epoch: [12]  [1460/2001]  eta: 0:05:45  lr: 0.000413  loss: 3.4511 (3.0710)  time: 0.6457  data: 0.0002  max mem: 8728
Epoch: [12]  [1470/2001]  eta: 0:05:39  lr: 0.000413  loss: 3.2137 (3.0704)  time: 0.6565  data: 0.0002  max mem: 8728
Epoch: [12]  [1480/2001]  eta: 0:05:32  lr: 0.000413  loss: 3.0011 (3.0691)  time: 0.6530  data: 0.0001  max mem: 8728
Epoch: [12]  [1490/2001]  eta: 0:05:26  lr: 0.000413  loss: 2.7119 (3.0659)  time: 0.6374  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9416, ratio_loss=0.0494, cls_kl=0.0656, token_kl=0.0935
Epoch: [12]  [1500/2001]  eta: 0:05:20  lr: 0.000413  loss: 2.8052 (3.0655)  time: 0.6330  data: 0.0001  max mem: 8728
Epoch: [12]  [1510/2001]  eta: 0:05:13  lr: 0.000413  loss: 3.1089 (3.0663)  time: 0.6340  data: 0.0001  max mem: 8728
Epoch: [12]  [1520/2001]  eta: 0:05:07  lr: 0.000413  loss: 3.2139 (3.0671)  time: 0.6347  data: 0.0002  max mem: 8728
Epoch: [12]  [1530/2001]  eta: 0:05:00  lr: 0.000413  loss: 3.2139 (3.0660)  time: 0.6356  data: 0.0002  max mem: 8728
Epoch: [12]  [1540/2001]  eta: 0:04:54  lr: 0.000413  loss: 3.1513 (3.0666)  time: 0.6347  data: 0.0001  max mem: 8728
Epoch: [12]  [1550/2001]  eta: 0:04:48  lr: 0.000413  loss: 3.1513 (3.0655)  time: 0.6374  data: 0.0002  max mem: 8728
Epoch: [12]  [1560/2001]  eta: 0:04:41  lr: 0.000413  loss: 3.0683 (3.0647)  time: 0.6369  data: 0.0002  max mem: 8728
Epoch: [12]  [1570/2001]  eta: 0:04:35  lr: 0.000413  loss: 2.9503 (3.0637)  time: 0.6356  data: 0.0001  max mem: 8728
Epoch: [12]  [1580/2001]  eta: 0:04:28  lr: 0.000413  loss: 2.9503 (3.0635)  time: 0.6360  data: 0.0001  max mem: 8728
Epoch: [12]  [1590/2001]  eta: 0:04:22  lr: 0.000413  loss: 3.1428 (3.0646)  time: 0.6331  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9575, ratio_loss=0.0484, cls_kl=0.0642, token_kl=0.0914
Epoch: [12]  [1600/2001]  eta: 0:04:16  lr: 0.000413  loss: 3.1428 (3.0658)  time: 0.6320  data: 0.0002  max mem: 8728
Epoch: [12]  [1610/2001]  eta: 0:04:09  lr: 0.000413  loss: 3.1546 (3.0661)  time: 0.6314  data: 0.0002  max mem: 8728
Epoch: [12]  [1620/2001]  eta: 0:04:03  lr: 0.000413  loss: 3.1494 (3.0659)  time: 0.6301  data: 0.0001  max mem: 8728
Epoch: [12]  [1630/2001]  eta: 0:03:56  lr: 0.000413  loss: 3.1837 (3.0663)  time: 0.6279  data: 0.0001  max mem: 8728
Epoch: [12]  [1640/2001]  eta: 0:03:50  lr: 0.000413  loss: 3.1837 (3.0664)  time: 0.6288  data: 0.0001  max mem: 8728
Epoch: [12]  [1650/2001]  eta: 0:03:44  lr: 0.000413  loss: 2.9327 (3.0635)  time: 0.6333  data: 0.0001  max mem: 8728
Epoch: [12]  [1660/2001]  eta: 0:03:37  lr: 0.000413  loss: 2.5435 (3.0609)  time: 0.6338  data: 0.0001  max mem: 8728
Epoch: [12]  [1670/2001]  eta: 0:03:31  lr: 0.000413  loss: 2.8442 (3.0613)  time: 0.6310  data: 0.0002  max mem: 8728
Epoch: [12]  [1680/2001]  eta: 0:03:24  lr: 0.000413  loss: 3.1553 (3.0617)  time: 0.6291  data: 0.0002  max mem: 8728
Epoch: [12]  [1690/2001]  eta: 0:03:18  lr: 0.000413  loss: 3.1367 (3.0618)  time: 0.6261  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9071, ratio_loss=0.0486, cls_kl=0.0648, token_kl=0.0936
Epoch: [12]  [1700/2001]  eta: 0:03:12  lr: 0.000413  loss: 3.1904 (3.0631)  time: 0.6269  data: 0.0002  max mem: 8728
Epoch: [12]  [1710/2001]  eta: 0:03:05  lr: 0.000413  loss: 3.2794 (3.0630)  time: 0.6318  data: 0.0001  max mem: 8728
Epoch: [12]  [1720/2001]  eta: 0:02:59  lr: 0.000413  loss: 2.9554 (3.0628)  time: 0.6299  data: 0.0001  max mem: 8728
Epoch: [12]  [1730/2001]  eta: 0:02:52  lr: 0.000413  loss: 3.2529 (3.0644)  time: 0.6267  data: 0.0001  max mem: 8728
Epoch: [12]  [1740/2001]  eta: 0:02:46  lr: 0.000413  loss: 3.1954 (3.0638)  time: 0.6340  data: 0.0001  max mem: 8728
Epoch: [12]  [1750/2001]  eta: 0:02:40  lr: 0.000413  loss: 2.8805 (3.0630)  time: 0.6351  data: 0.0001  max mem: 8728
Epoch: [12]  [1760/2001]  eta: 0:02:33  lr: 0.000413  loss: 2.9269 (3.0628)  time: 0.6308  data: 0.0001  max mem: 8728
Epoch: [12]  [1770/2001]  eta: 0:02:27  lr: 0.000413  loss: 3.1792 (3.0629)  time: 0.6264  data: 0.0001  max mem: 8728
Epoch: [12]  [1780/2001]  eta: 0:02:20  lr: 0.000413  loss: 3.2431 (3.0635)  time: 0.6251  data: 0.0001  max mem: 8728
Epoch: [12]  [1790/2001]  eta: 0:02:14  lr: 0.000413  loss: 3.0886 (3.0624)  time: 0.6260  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9560, ratio_loss=0.0487, cls_kl=0.0634, token_kl=0.0927
Epoch: [12]  [1800/2001]  eta: 0:02:08  lr: 0.000413  loss: 3.1404 (3.0630)  time: 0.6267  data: 0.0001  max mem: 8728
Epoch: [12]  [1810/2001]  eta: 0:02:01  lr: 0.000413  loss: 3.1193 (3.0619)  time: 0.6287  data: 0.0001  max mem: 8728
Epoch: [12]  [1820/2001]  eta: 0:01:55  lr: 0.000413  loss: 2.9691 (3.0623)  time: 0.6287  data: 0.0001  max mem: 8728
Epoch: [12]  [1830/2001]  eta: 0:01:49  lr: 0.000413  loss: 3.1741 (3.0629)  time: 0.6284  data: 0.0001  max mem: 8728
Epoch: [12]  [1840/2001]  eta: 0:01:42  lr: 0.000413  loss: 3.0253 (3.0622)  time: 0.6282  data: 0.0001  max mem: 8728
Epoch: [12]  [1850/2001]  eta: 0:01:36  lr: 0.000413  loss: 2.9527 (3.0608)  time: 0.6289  data: 0.0001  max mem: 8728
Epoch: [12]  [1860/2001]  eta: 0:01:29  lr: 0.000413  loss: 3.0396 (3.0607)  time: 0.6262  data: 0.0001  max mem: 8728
Epoch: [12]  [1870/2001]  eta: 0:01:23  lr: 0.000413  loss: 3.0964 (3.0594)  time: 0.6238  data: 0.0001  max mem: 8728
Epoch: [12]  [1880/2001]  eta: 0:01:17  lr: 0.000413  loss: 3.2187 (3.0606)  time: 0.6259  data: 0.0001  max mem: 8728
Epoch: [12]  [1890/2001]  eta: 0:01:10  lr: 0.000413  loss: 3.2187 (3.0602)  time: 0.6272  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8769, ratio_loss=0.0473, cls_kl=0.0637, token_kl=0.0927
Epoch: [12]  [1900/2001]  eta: 0:01:04  lr: 0.000413  loss: 3.0758 (3.0593)  time: 0.6329  data: 0.0001  max mem: 8728
Epoch: [12]  [1910/2001]  eta: 0:00:57  lr: 0.000413  loss: 3.1497 (3.0598)  time: 0.6330  data: 0.0001  max mem: 8728
Epoch: [12]  [1920/2001]  eta: 0:00:51  lr: 0.000413  loss: 2.9335 (3.0576)  time: 0.6290  data: 0.0001  max mem: 8728
Epoch: [12]  [1930/2001]  eta: 0:00:45  lr: 0.000413  loss: 2.8614 (3.0577)  time: 0.6282  data: 0.0001  max mem: 8728
Epoch: [12]  [1940/2001]  eta: 0:00:38  lr: 0.000413  loss: 2.8642 (3.0572)  time: 0.6348  data: 0.0001  max mem: 8728
Epoch: [12]  [1950/2001]  eta: 0:00:32  lr: 0.000413  loss: 2.9244 (3.0564)  time: 0.6403  data: 0.0001  max mem: 8728
Epoch: [12]  [1960/2001]  eta: 0:00:26  lr: 0.000413  loss: 3.0701 (3.0559)  time: 0.6359  data: 0.0002  max mem: 8728
Epoch: [12]  [1970/2001]  eta: 0:00:19  lr: 0.000413  loss: 3.0155 (3.0541)  time: 0.6319  data: 0.0002  max mem: 8728
Epoch: [12]  [1980/2001]  eta: 0:00:13  lr: 0.000413  loss: 2.8123 (3.0536)  time: 0.6298  data: 0.0002  max mem: 8728
Epoch: [12]  [1990/2001]  eta: 0:00:07  lr: 0.000413  loss: 3.1252 (3.0534)  time: 0.6271  data: 0.0004  max mem: 8728
loss info: cls_loss=2.8247, ratio_loss=0.0433, cls_kl=0.0606, token_kl=0.0902
Epoch: [12]  [2000/2001]  eta: 0:00:00  lr: 0.000413  loss: 3.0584 (3.0527)  time: 0.6238  data: 0.0004  max mem: 8728
Epoch: [12] Total time: 0:21:14 (0.6372 s / it)
Averaged stats: lr: 0.000413  loss: 3.0584 (3.0586)
Test:  [ 0/53]  eta: 0:05:41  loss: 0.3513 (0.3513)  acc1: 93.3333 (93.3333)  acc5: 99.1667 (99.1667)  time: 6.4414  data: 5.4535  max mem: 8728
Test:  [10/53]  eta: 0:00:41  loss: 0.7698 (0.7716)  acc1: 84.1667 (83.6364)  acc5: 96.6667 (96.5152)  time: 0.9598  data: 0.4960  max mem: 8728
Test:  [20/53]  eta: 0:00:22  loss: 0.7493 (0.7737)  acc1: 83.3333 (83.3730)  acc5: 96.6667 (96.4683)  time: 0.3960  data: 0.0003  max mem: 8728
Test:  [30/53]  eta: 0:00:13  loss: 0.8996 (0.8573)  acc1: 79.1667 (80.9677)  acc5: 95.0000 (95.3226)  time: 0.3585  data: 0.0003  max mem: 8728
Test:  [40/53]  eta: 0:00:06  loss: 1.0762 (0.9212)  acc1: 75.8333 (79.3902)  acc5: 92.5000 (94.5732)  time: 0.2994  data: 0.0002  max mem: 8728
Test:  [50/53]  eta: 0:00:01  loss: 1.1103 (0.9514)  acc1: 75.8333 (78.6111)  acc5: 92.5000 (94.3628)  time: 0.2560  data: 0.0001  max mem: 8728
Test:  [52/53]  eta: 0:00:00  loss: 1.0765 (0.9378)  acc1: 77.5000 (78.7840)  acc5: 92.5000 (94.4480)  time: 0.2437  data: 0.0001  max mem: 8728
Test: Total time: 0:00:23 (0.4401 s / it)
Sparsity0:0.2792282828282828,Sparsity1:0.5399718592964824,Sparsity2:0.781324,
* Acc@1 79.072 Acc@5 94.516 loss 0.939
Accuracy of the network on the 50000 test images: 79.1%
Max accuracy: 79.07%
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0003814 for PREDICTOR
Epoch: [13]  [   0/2001]  eta: 2:42:55  lr: 0.000381  loss: 2.9076 (2.9076)  time: 4.8854  data: 4.2225  max mem: 8728
Epoch: [13]  [  10/2001]  eta: 0:33:05  lr: 0.000381  loss: 3.3255 (3.3275)  time: 0.9973  data: 0.3840  max mem: 8730
Epoch: [13]  [  20/2001]  eta: 0:26:54  lr: 0.000381  loss: 3.2595 (3.1943)  time: 0.6117  data: 0.0001  max mem: 8730
Epoch: [13]  [  30/2001]  eta: 0:24:42  lr: 0.000381  loss: 3.1478 (3.1976)  time: 0.6172  data: 0.0002  max mem: 8730
Epoch: [13]  [  40/2001]  eta: 0:23:32  lr: 0.000381  loss: 3.1352 (3.1502)  time: 0.6203  data: 0.0002  max mem: 8730
Epoch: [13]  [  50/2001]  eta: 0:22:47  lr: 0.000381  loss: 3.0246 (3.1235)  time: 0.6217  data: 0.0001  max mem: 8730
Epoch: [13]  [  60/2001]  eta: 0:22:16  lr: 0.000381  loss: 2.8963 (3.0813)  time: 0.6241  data: 0.0002  max mem: 8730
Epoch: [13]  [  70/2001]  eta: 0:21:53  lr: 0.000381  loss: 3.0964 (3.0993)  time: 0.6272  data: 0.0002  max mem: 8730
Epoch: [13]  [  80/2001]  eta: 0:21:37  lr: 0.000381  loss: 3.0964 (3.0728)  time: 0.6343  data: 0.0002  max mem: 8730
Epoch: [13]  [  90/2001]  eta: 0:21:20  lr: 0.000381  loss: 3.0764 (3.0958)  time: 0.6353  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9729, ratio_loss=0.0501, cls_kl=0.0645, token_kl=0.0935
Epoch: [13]  [ 100/2001]  eta: 0:21:07  lr: 0.000381  loss: 3.1686 (3.0841)  time: 0.6325  data: 0.0002  max mem: 8730
Epoch: [13]  [ 110/2001]  eta: 0:20:55  lr: 0.000381  loss: 3.1686 (3.0983)  time: 0.6352  data: 0.0002  max mem: 8730
Epoch: [13]  [ 120/2001]  eta: 0:20:43  lr: 0.000381  loss: 3.2431 (3.0954)  time: 0.6339  data: 0.0001  max mem: 8730
Epoch: [13]  [ 130/2001]  eta: 0:20:34  lr: 0.000381  loss: 3.2431 (3.1045)  time: 0.6359  data: 0.0002  max mem: 8730
Epoch: [13]  [ 140/2001]  eta: 0:20:24  lr: 0.000381  loss: 3.3159 (3.1201)  time: 0.6378  data: 0.0001  max mem: 8730
Epoch: [13]  [ 150/2001]  eta: 0:20:14  lr: 0.000381  loss: 3.3278 (3.1133)  time: 0.6337  data: 0.0001  max mem: 8730
Epoch: [13]  [ 160/2001]  eta: 0:20:05  lr: 0.000381  loss: 3.2609 (3.1117)  time: 0.6318  data: 0.0002  max mem: 8730
Epoch: [13]  [ 170/2001]  eta: 0:19:56  lr: 0.000381  loss: 3.2609 (3.1213)  time: 0.6337  data: 0.0002  max mem: 8730
Epoch: [13]  [ 180/2001]  eta: 0:19:48  lr: 0.000381  loss: 3.1676 (3.1153)  time: 0.6363  data: 0.0001  max mem: 8730
Epoch: [13]  [ 190/2001]  eta: 0:19:40  lr: 0.000381  loss: 3.2778 (3.1197)  time: 0.6390  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0020, ratio_loss=0.0494, cls_kl=0.0650, token_kl=0.0929
Epoch: [13]  [ 200/2001]  eta: 0:19:33  lr: 0.000381  loss: 3.2080 (3.1020)  time: 0.6393  data: 0.0002  max mem: 8730
Epoch: [13]  [ 210/2001]  eta: 0:19:25  lr: 0.000381  loss: 3.0286 (3.0983)  time: 0.6374  data: 0.0001  max mem: 8730
Epoch: [13]  [ 220/2001]  eta: 0:19:17  lr: 0.000381  loss: 3.1091 (3.0896)  time: 0.6347  data: 0.0001  max mem: 8730
Epoch: [13]  [ 230/2001]  eta: 0:19:10  lr: 0.000381  loss: 2.8700 (3.0800)  time: 0.6397  data: 0.0001  max mem: 8730
Epoch: [13]  [ 240/2001]  eta: 0:19:03  lr: 0.000381  loss: 2.8498 (3.0741)  time: 0.6464  data: 0.0002  max mem: 8730
Epoch: [13]  [ 250/2001]  eta: 0:18:56  lr: 0.000381  loss: 2.8892 (3.0703)  time: 0.6415  data: 0.0002  max mem: 8730
Epoch: [13]  [ 260/2001]  eta: 0:18:49  lr: 0.000381  loss: 2.8892 (3.0723)  time: 0.6371  data: 0.0002  max mem: 8730
Epoch: [13]  [ 270/2001]  eta: 0:18:42  lr: 0.000381  loss: 3.1564 (3.0744)  time: 0.6386  data: 0.0002  max mem: 8730
Epoch: [13]  [ 280/2001]  eta: 0:18:35  lr: 0.000381  loss: 3.2981 (3.0811)  time: 0.6390  data: 0.0002  max mem: 8730
Epoch: [13]  [ 290/2001]  eta: 0:18:27  lr: 0.000381  loss: 3.2464 (3.0764)  time: 0.6352  data: 0.0002  max mem: 8730
loss info: cls_loss=2.8936, ratio_loss=0.0467, cls_kl=0.0641, token_kl=0.0928
Epoch: [13]  [ 300/2001]  eta: 0:18:20  lr: 0.000381  loss: 2.8348 (3.0630)  time: 0.6358  data: 0.0002  max mem: 8730
Epoch: [13]  [ 310/2001]  eta: 0:18:13  lr: 0.000381  loss: 2.8376 (3.0590)  time: 0.6389  data: 0.0002  max mem: 8730
Epoch: [13]  [ 320/2001]  eta: 0:18:07  lr: 0.000381  loss: 3.1359 (3.0648)  time: 0.6394  data: 0.0002  max mem: 8730
Epoch: [13]  [ 330/2001]  eta: 0:18:00  lr: 0.000381  loss: 3.3329 (3.0713)  time: 0.6391  data: 0.0002  max mem: 8730
Epoch: [13]  [ 340/2001]  eta: 0:17:53  lr: 0.000381  loss: 3.1919 (3.0710)  time: 0.6374  data: 0.0002  max mem: 8730
Epoch: [13]  [ 350/2001]  eta: 0:17:46  lr: 0.000381  loss: 3.0116 (3.0706)  time: 0.6427  data: 0.0002  max mem: 8730
Epoch: [13]  [ 360/2001]  eta: 0:17:39  lr: 0.000381  loss: 2.9754 (3.0658)  time: 0.6428  data: 0.0002  max mem: 8730
Epoch: [13]  [ 370/2001]  eta: 0:17:33  lr: 0.000381  loss: 3.0437 (3.0641)  time: 0.6367  data: 0.0002  max mem: 8730
Epoch: [13]  [ 380/2001]  eta: 0:17:26  lr: 0.000381  loss: 3.2178 (3.0670)  time: 0.6360  data: 0.0001  max mem: 8730
Epoch: [13]  [ 390/2001]  eta: 0:17:19  lr: 0.000381  loss: 3.1819 (3.0611)  time: 0.6377  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9231, ratio_loss=0.0469, cls_kl=0.0643, token_kl=0.0933
Epoch: [13]  [ 400/2001]  eta: 0:17:13  lr: 0.000381  loss: 2.9135 (3.0601)  time: 0.6430  data: 0.0001  max mem: 8730
Epoch: [13]  [ 410/2001]  eta: 0:17:06  lr: 0.000381  loss: 3.2368 (3.0639)  time: 0.6446  data: 0.0001  max mem: 8730
Epoch: [13]  [ 420/2001]  eta: 0:16:59  lr: 0.000381  loss: 3.1559 (3.0573)  time: 0.6411  data: 0.0001  max mem: 8730
Epoch: [13]  [ 430/2001]  eta: 0:16:53  lr: 0.000381  loss: 3.2092 (3.0603)  time: 0.6402  data: 0.0001  max mem: 8730
Epoch: [13]  [ 440/2001]  eta: 0:16:46  lr: 0.000381  loss: 3.1675 (3.0609)  time: 0.6407  data: 0.0001  max mem: 8730
Epoch: [13]  [ 450/2001]  eta: 0:16:40  lr: 0.000381  loss: 3.1482 (3.0641)  time: 0.6405  data: 0.0001  max mem: 8730
Epoch: [13]  [ 460/2001]  eta: 0:16:33  lr: 0.000381  loss: 3.3377 (3.0645)  time: 0.6378  data: 0.0001  max mem: 8730
Epoch: [13]  [ 470/2001]  eta: 0:16:26  lr: 0.000381  loss: 3.1843 (3.0623)  time: 0.6368  data: 0.0001  max mem: 8730
Epoch: [13]  [ 480/2001]  eta: 0:16:20  lr: 0.000381  loss: 2.9958 (3.0623)  time: 0.6391  data: 0.0001  max mem: 8730
Epoch: [13]  [ 490/2001]  eta: 0:16:13  lr: 0.000381  loss: 3.0842 (3.0669)  time: 0.6392  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9754, ratio_loss=0.0487, cls_kl=0.0652, token_kl=0.0932
Epoch: [13]  [ 500/2001]  eta: 0:16:06  lr: 0.000381  loss: 3.0842 (3.0638)  time: 0.6407  data: 0.0001  max mem: 8730
Epoch: [13]  [ 510/2001]  eta: 0:16:00  lr: 0.000381  loss: 2.8589 (3.0637)  time: 0.6477  data: 0.0001  max mem: 8730
Epoch: [13]  [ 520/2001]  eta: 0:15:54  lr: 0.000381  loss: 3.1443 (3.0657)  time: 0.6449  data: 0.0001  max mem: 8730
Epoch: [13]  [ 530/2001]  eta: 0:15:47  lr: 0.000381  loss: 3.1931 (3.0664)  time: 0.6359  data: 0.0001  max mem: 8730
Epoch: [13]  [ 540/2001]  eta: 0:15:40  lr: 0.000381  loss: 3.1931 (3.0633)  time: 0.6366  data: 0.0001  max mem: 8730
Epoch: [13]  [ 550/2001]  eta: 0:15:34  lr: 0.000381  loss: 3.2812 (3.0681)  time: 0.6409  data: 0.0001  max mem: 8730
Epoch: [13]  [ 560/2001]  eta: 0:15:28  lr: 0.000381  loss: 3.4368 (3.0765)  time: 0.6473  data: 0.0001  max mem: 8730
Epoch: [13]  [ 570/2001]  eta: 0:15:21  lr: 0.000381  loss: 3.4112 (3.0797)  time: 0.6457  data: 0.0001  max mem: 8730
Epoch: [13]  [ 580/2001]  eta: 0:15:14  lr: 0.000381  loss: 3.1980 (3.0814)  time: 0.6382  data: 0.0001  max mem: 8730
Epoch: [13]  [ 590/2001]  eta: 0:15:08  lr: 0.000381  loss: 3.1083 (3.0793)  time: 0.6419  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0473, ratio_loss=0.0486, cls_kl=0.0675, token_kl=0.0937
Epoch: [13]  [ 600/2001]  eta: 0:15:02  lr: 0.000381  loss: 3.1364 (3.0806)  time: 0.6438  data: 0.0001  max mem: 8730
Epoch: [13]  [ 610/2001]  eta: 0:14:55  lr: 0.000381  loss: 2.9988 (3.0765)  time: 0.6375  data: 0.0001  max mem: 8730
Epoch: [13]  [ 620/2001]  eta: 0:14:48  lr: 0.000381  loss: 2.9330 (3.0783)  time: 0.6356  data: 0.0002  max mem: 8730
Epoch: [13]  [ 630/2001]  eta: 0:14:42  lr: 0.000381  loss: 2.9725 (3.0769)  time: 0.6399  data: 0.0001  max mem: 8730
Epoch: [13]  [ 640/2001]  eta: 0:14:35  lr: 0.000381  loss: 3.1280 (3.0807)  time: 0.6428  data: 0.0001  max mem: 8730
Epoch: [13]  [ 650/2001]  eta: 0:14:29  lr: 0.000381  loss: 3.3205 (3.0785)  time: 0.6420  data: 0.0002  max mem: 8730
Epoch: [13]  [ 660/2001]  eta: 0:14:23  lr: 0.000381  loss: 3.1893 (3.0807)  time: 0.6440  data: 0.0002  max mem: 8730
Epoch: [13]  [ 670/2001]  eta: 0:14:16  lr: 0.000381  loss: 3.1893 (3.0815)  time: 0.6476  data: 0.0001  max mem: 8730
Epoch: [13]  [ 680/2001]  eta: 0:14:10  lr: 0.000381  loss: 3.3290 (3.0837)  time: 0.6450  data: 0.0001  max mem: 8730
Epoch: [13]  [ 690/2001]  eta: 0:14:03  lr: 0.000381  loss: 3.3437 (3.0869)  time: 0.6385  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0230, ratio_loss=0.0490, cls_kl=0.0660, token_kl=0.0934
Epoch: [13]  [ 700/2001]  eta: 0:13:57  lr: 0.000381  loss: 3.2431 (3.0885)  time: 0.6419  data: 0.0001  max mem: 8730
Epoch: [13]  [ 710/2001]  eta: 0:13:50  lr: 0.000381  loss: 3.2383 (3.0907)  time: 0.6443  data: 0.0001  max mem: 8730
Epoch: [13]  [ 720/2001]  eta: 0:13:44  lr: 0.000381  loss: 3.1659 (3.0881)  time: 0.6405  data: 0.0001  max mem: 8730
Epoch: [13]  [ 730/2001]  eta: 0:13:37  lr: 0.000381  loss: 3.2377 (3.0911)  time: 0.6393  data: 0.0001  max mem: 8730
Epoch: [13]  [ 740/2001]  eta: 0:13:31  lr: 0.000381  loss: 3.2507 (3.0866)  time: 0.6409  data: 0.0001  max mem: 8730
Epoch: [13]  [ 750/2001]  eta: 0:13:24  lr: 0.000381  loss: 3.2502 (3.0876)  time: 0.6393  data: 0.0001  max mem: 8730
Epoch: [13]  [ 760/2001]  eta: 0:13:18  lr: 0.000381  loss: 3.2432 (3.0841)  time: 0.6366  data: 0.0002  max mem: 8730
Epoch: [13]  [ 770/2001]  eta: 0:13:11  lr: 0.000381  loss: 3.1949 (3.0867)  time: 0.6388  data: 0.0002  max mem: 8730
Epoch: [13]  [ 780/2001]  eta: 0:13:05  lr: 0.000381  loss: 3.1519 (3.0858)  time: 0.6434  data: 0.0002  max mem: 8730
Epoch: [13]  [ 790/2001]  eta: 0:12:58  lr: 0.000381  loss: 2.9413 (3.0826)  time: 0.6406  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9283, ratio_loss=0.0473, cls_kl=0.0648, token_kl=0.0925
Epoch: [13]  [ 800/2001]  eta: 0:12:52  lr: 0.000381  loss: 2.6897 (3.0808)  time: 0.6366  data: 0.0002  max mem: 8730
Epoch: [13]  [ 810/2001]  eta: 0:12:45  lr: 0.000381  loss: 3.1269 (3.0808)  time: 0.6374  data: 0.0002  max mem: 8730
Epoch: [13]  [ 820/2001]  eta: 0:12:39  lr: 0.000381  loss: 3.1951 (3.0811)  time: 0.6362  data: 0.0002  max mem: 8730
Epoch: [13]  [ 830/2001]  eta: 0:12:32  lr: 0.000381  loss: 3.0080 (3.0802)  time: 0.6411  data: 0.0001  max mem: 8730
Epoch: [13]  [ 840/2001]  eta: 0:12:26  lr: 0.000381  loss: 3.0669 (3.0811)  time: 0.6414  data: 0.0001  max mem: 8730
Epoch: [13]  [ 850/2001]  eta: 0:12:19  lr: 0.000381  loss: 3.0987 (3.0793)  time: 0.6348  data: 0.0001  max mem: 8730
Epoch: [13]  [ 860/2001]  eta: 0:12:13  lr: 0.000381  loss: 2.7027 (3.0730)  time: 0.6325  data: 0.0001  max mem: 8730
Epoch: [13]  [ 870/2001]  eta: 0:12:06  lr: 0.000381  loss: 2.7027 (3.0710)  time: 0.6317  data: 0.0001  max mem: 8730
Epoch: [13]  [ 880/2001]  eta: 0:12:00  lr: 0.000381  loss: 3.2015 (3.0712)  time: 0.6329  data: 0.0001  max mem: 8730
Epoch: [13]  [ 890/2001]  eta: 0:11:53  lr: 0.000381  loss: 3.0112 (3.0688)  time: 0.6371  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8705, ratio_loss=0.0449, cls_kl=0.0616, token_kl=0.0914
Epoch: [13]  [ 900/2001]  eta: 0:11:47  lr: 0.000381  loss: 3.0061 (3.0702)  time: 0.6366  data: 0.0002  max mem: 8730
Epoch: [13]  [ 910/2001]  eta: 0:11:40  lr: 0.000381  loss: 3.1632 (3.0684)  time: 0.6345  data: 0.0001  max mem: 8730
Epoch: [13]  [ 920/2001]  eta: 0:11:34  lr: 0.000381  loss: 3.1406 (3.0694)  time: 0.6363  data: 0.0001  max mem: 8730
Epoch: [13]  [ 930/2001]  eta: 0:11:27  lr: 0.000381  loss: 3.2775 (3.0720)  time: 0.6368  data: 0.0001  max mem: 8730
Epoch: [13]  [ 940/2001]  eta: 0:11:21  lr: 0.000381  loss: 3.3175 (3.0746)  time: 0.6435  data: 0.0001  max mem: 8730
Epoch: [13]  [ 950/2001]  eta: 0:11:14  lr: 0.000381  loss: 3.0919 (3.0706)  time: 0.6414  data: 0.0001  max mem: 8730
Epoch: [13]  [ 960/2001]  eta: 0:11:08  lr: 0.000381  loss: 2.9448 (3.0701)  time: 0.6308  data: 0.0001  max mem: 8730
Epoch: [13]  [ 970/2001]  eta: 0:11:01  lr: 0.000381  loss: 3.0665 (3.0713)  time: 0.6286  data: 0.0001  max mem: 8730
Epoch: [13]  [ 980/2001]  eta: 0:10:55  lr: 0.000381  loss: 3.1230 (3.0705)  time: 0.6305  data: 0.0001  max mem: 8730
Epoch: [13]  [ 990/2001]  eta: 0:10:48  lr: 0.000381  loss: 3.2545 (3.0712)  time: 0.6379  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9670, ratio_loss=0.0477, cls_kl=0.0646, token_kl=0.0927
Epoch: [13]  [1000/2001]  eta: 0:10:42  lr: 0.000381  loss: 3.2350 (3.0706)  time: 0.6369  data: 0.0001  max mem: 8730
Epoch: [13]  [1010/2001]  eta: 0:10:35  lr: 0.000381  loss: 3.1209 (3.0702)  time: 0.6306  data: 0.0001  max mem: 8730
Epoch: [13]  [1020/2001]  eta: 0:10:29  lr: 0.000381  loss: 3.0673 (3.0698)  time: 0.6307  data: 0.0002  max mem: 8730
Epoch: [13]  [1030/2001]  eta: 0:10:22  lr: 0.000381  loss: 3.0373 (3.0683)  time: 0.6306  data: 0.0001  max mem: 8730
Epoch: [13]  [1040/2001]  eta: 0:10:16  lr: 0.000381  loss: 3.1765 (3.0687)  time: 0.6294  data: 0.0001  max mem: 8730
Epoch: [13]  [1050/2001]  eta: 0:10:09  lr: 0.000381  loss: 3.1702 (3.0690)  time: 0.6298  data: 0.0001  max mem: 8730
Epoch: [13]  [1060/2001]  eta: 0:10:03  lr: 0.000381  loss: 3.0913 (3.0682)  time: 0.6335  data: 0.0001  max mem: 8730
Epoch: [13]  [1070/2001]  eta: 0:09:56  lr: 0.000381  loss: 3.0385 (3.0674)  time: 0.6346  data: 0.0001  max mem: 8730
Epoch: [13]  [1080/2001]  eta: 0:09:50  lr: 0.000381  loss: 2.9574 (3.0653)  time: 0.6296  data: 0.0001  max mem: 8730
Epoch: [13]  [1090/2001]  eta: 0:09:43  lr: 0.000381  loss: 2.9936 (3.0639)  time: 0.6368  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9012, ratio_loss=0.0446, cls_kl=0.0611, token_kl=0.0900
Epoch: [13]  [1100/2001]  eta: 0:09:37  lr: 0.000381  loss: 3.1583 (3.0648)  time: 0.6389  data: 0.0001  max mem: 8730
Epoch: [13]  [1110/2001]  eta: 0:09:30  lr: 0.000381  loss: 3.2388 (3.0653)  time: 0.6285  data: 0.0001  max mem: 8730
Epoch: [13]  [1120/2001]  eta: 0:09:24  lr: 0.000381  loss: 3.0584 (3.0653)  time: 0.6250  data: 0.0001  max mem: 8730
Epoch: [13]  [1130/2001]  eta: 0:09:17  lr: 0.000381  loss: 3.1120 (3.0666)  time: 0.6245  data: 0.0001  max mem: 8730
Epoch: [13]  [1140/2001]  eta: 0:09:11  lr: 0.000381  loss: 3.1113 (3.0635)  time: 0.6255  data: 0.0001  max mem: 8730
Epoch: [13]  [1150/2001]  eta: 0:09:04  lr: 0.000381  loss: 2.9215 (3.0633)  time: 0.6289  data: 0.0001  max mem: 8730
Epoch: [13]  [1160/2001]  eta: 0:08:58  lr: 0.000381  loss: 3.2543 (3.0614)  time: 0.6325  data: 0.0002  max mem: 8730
Epoch: [13]  [1170/2001]  eta: 0:08:51  lr: 0.000381  loss: 2.9188 (3.0619)  time: 0.6344  data: 0.0001  max mem: 8730
Epoch: [13]  [1180/2001]  eta: 0:08:45  lr: 0.000381  loss: 3.3175 (3.0629)  time: 0.6323  data: 0.0001  max mem: 8730
Epoch: [13]  [1190/2001]  eta: 0:08:38  lr: 0.000381  loss: 3.0560 (3.0604)  time: 0.6240  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9246, ratio_loss=0.0469, cls_kl=0.0621, token_kl=0.0922
Epoch: [13]  [1200/2001]  eta: 0:08:32  lr: 0.000381  loss: 3.1310 (3.0623)  time: 0.6233  data: 0.0001  max mem: 8730
Epoch: [13]  [1210/2001]  eta: 0:08:25  lr: 0.000381  loss: 3.4234 (3.0639)  time: 0.6298  data: 0.0001  max mem: 8730
Epoch: [13]  [1220/2001]  eta: 0:08:19  lr: 0.000381  loss: 3.2712 (3.0645)  time: 0.6330  data: 0.0001  max mem: 8730
Epoch: [13]  [1230/2001]  eta: 0:08:13  lr: 0.000381  loss: 3.2952 (3.0671)  time: 0.6352  data: 0.0001  max mem: 8730
Epoch: [13]  [1240/2001]  eta: 0:08:06  lr: 0.000381  loss: 3.3373 (3.0697)  time: 0.6368  data: 0.0001  max mem: 8730
Epoch: [13]  [1250/2001]  eta: 0:08:00  lr: 0.000381  loss: 3.3373 (3.0702)  time: 0.6340  data: 0.0001  max mem: 8730
Epoch: [13]  [1260/2001]  eta: 0:07:53  lr: 0.000381  loss: 3.1369 (3.0699)  time: 0.6400  data: 0.0002  max mem: 8730
Epoch: [13]  [1270/2001]  eta: 0:07:47  lr: 0.000381  loss: 3.1369 (3.0691)  time: 0.6374  data: 0.0002  max mem: 8730
Epoch: [13]  [1280/2001]  eta: 0:07:40  lr: 0.000381  loss: 3.0073 (3.0683)  time: 0.6289  data: 0.0002  max mem: 8730
Epoch: [13]  [1290/2001]  eta: 0:07:34  lr: 0.000381  loss: 3.0073 (3.0678)  time: 0.6284  data: 0.0002  max mem: 8730
loss info: cls_loss=3.0301, ratio_loss=0.0526, cls_kl=0.0666, token_kl=0.0967
Epoch: [13]  [1300/2001]  eta: 0:07:28  lr: 0.000381  loss: 3.1399 (3.0682)  time: 0.6257  data: 0.0001  max mem: 8730
Epoch: [13]  [1310/2001]  eta: 0:07:21  lr: 0.000381  loss: 3.2311 (3.0690)  time: 0.6273  data: 0.0001  max mem: 8730
Epoch: [13]  [1320/2001]  eta: 0:07:15  lr: 0.000381  loss: 3.2500 (3.0696)  time: 0.6292  data: 0.0002  max mem: 8730
Epoch: [13]  [1330/2001]  eta: 0:07:08  lr: 0.000381  loss: 3.1631 (3.0682)  time: 0.6285  data: 0.0001  max mem: 8730
Epoch: [13]  [1340/2001]  eta: 0:07:02  lr: 0.000381  loss: 3.0354 (3.0666)  time: 0.6266  data: 0.0001  max mem: 8730
Epoch: [13]  [1350/2001]  eta: 0:06:55  lr: 0.000381  loss: 3.1260 (3.0670)  time: 0.6254  data: 0.0001  max mem: 8730
Epoch: [13]  [1360/2001]  eta: 0:06:49  lr: 0.000381  loss: 3.1788 (3.0668)  time: 0.6401  data: 0.0001  max mem: 8730
Epoch: [13]  [1370/2001]  eta: 0:06:43  lr: 0.000381  loss: 3.0272 (3.0663)  time: 0.6411  data: 0.0001  max mem: 8730
Epoch: [13]  [1380/2001]  eta: 0:06:36  lr: 0.000381  loss: 3.2026 (3.0665)  time: 0.6266  data: 0.0001  max mem: 8730
Epoch: [13]  [1390/2001]  eta: 0:06:30  lr: 0.000381  loss: 3.3053 (3.0675)  time: 0.6259  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9248, ratio_loss=0.0487, cls_kl=0.0647, token_kl=0.0938
Epoch: [13]  [1400/2001]  eta: 0:06:23  lr: 0.000381  loss: 3.0255 (3.0664)  time: 0.6241  data: 0.0001  max mem: 8730
Epoch: [13]  [1410/2001]  eta: 0:06:17  lr: 0.000381  loss: 3.0486 (3.0674)  time: 0.6305  data: 0.0001  max mem: 8730
Epoch: [13]  [1420/2001]  eta: 0:06:10  lr: 0.000381  loss: 3.3017 (3.0682)  time: 0.6341  data: 0.0001  max mem: 8730
Epoch: [13]  [1430/2001]  eta: 0:06:04  lr: 0.000381  loss: 2.9679 (3.0669)  time: 0.6287  data: 0.0001  max mem: 8730
Epoch: [13]  [1440/2001]  eta: 0:05:58  lr: 0.000381  loss: 2.7102 (3.0653)  time: 0.6256  data: 0.0001  max mem: 8730
Epoch: [13]  [1450/2001]  eta: 0:05:51  lr: 0.000381  loss: 2.8919 (3.0656)  time: 0.6270  data: 0.0001  max mem: 8730
Epoch: [13]  [1460/2001]  eta: 0:05:45  lr: 0.000381  loss: 3.0949 (3.0654)  time: 0.6327  data: 0.0001  max mem: 8730
Epoch: [13]  [1470/2001]  eta: 0:05:38  lr: 0.000381  loss: 2.9209 (3.0638)  time: 0.6319  data: 0.0001  max mem: 8730
Epoch: [13]  [1480/2001]  eta: 0:05:32  lr: 0.000381  loss: 2.9414 (3.0642)  time: 0.6284  data: 0.0001  max mem: 8730
Epoch: [13]  [1490/2001]  eta: 0:05:25  lr: 0.000381  loss: 2.9414 (3.0634)  time: 0.6287  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8989, ratio_loss=0.0456, cls_kl=0.0615, token_kl=0.0917
Epoch: [13]  [1500/2001]  eta: 0:05:19  lr: 0.000381  loss: 3.0742 (3.0630)  time: 0.6289  data: 0.0001  max mem: 8730
Epoch: [13]  [1510/2001]  eta: 0:05:13  lr: 0.000381  loss: 3.1499 (3.0629)  time: 0.6347  data: 0.0001  max mem: 8730
Epoch: [13]  [1520/2001]  eta: 0:05:06  lr: 0.000381  loss: 2.9964 (3.0615)  time: 0.6380  data: 0.0001  max mem: 8730
Epoch: [13]  [1530/2001]  eta: 0:05:00  lr: 0.000381  loss: 3.0544 (3.0612)  time: 0.6339  data: 0.0001  max mem: 8730
Epoch: [13]  [1540/2001]  eta: 0:04:54  lr: 0.000381  loss: 3.0544 (3.0610)  time: 0.6299  data: 0.0001  max mem: 8730
Epoch: [13]  [1550/2001]  eta: 0:04:47  lr: 0.000381  loss: 3.0190 (3.0599)  time: 0.6288  data: 0.0001  max mem: 8730
Epoch: [13]  [1560/2001]  eta: 0:04:41  lr: 0.000381  loss: 3.1804 (3.0608)  time: 0.6316  data: 0.0001  max mem: 8730
Epoch: [13]  [1570/2001]  eta: 0:04:34  lr: 0.000381  loss: 3.2454 (3.0602)  time: 0.6326  data: 0.0001  max mem: 8730
Epoch: [13]  [1580/2001]  eta: 0:04:28  lr: 0.000381  loss: 3.1805 (3.0612)  time: 0.6305  data: 0.0001  max mem: 8730
Epoch: [13]  [1590/2001]  eta: 0:04:22  lr: 0.000381  loss: 3.2613 (3.0624)  time: 0.6292  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9357, ratio_loss=0.0523, cls_kl=0.0666, token_kl=0.0952
Epoch: [13]  [1600/2001]  eta: 0:04:15  lr: 0.000381  loss: 3.2149 (3.0611)  time: 0.6305  data: 0.0001  max mem: 8730
Epoch: [13]  [1610/2001]  eta: 0:04:09  lr: 0.000381  loss: 3.1442 (3.0619)  time: 0.6299  data: 0.0001  max mem: 8730
Epoch: [13]  [1620/2001]  eta: 0:04:02  lr: 0.000381  loss: 3.1703 (3.0627)  time: 0.6312  data: 0.0002  max mem: 8730
Epoch: [13]  [1630/2001]  eta: 0:03:56  lr: 0.000381  loss: 3.2449 (3.0646)  time: 0.6361  data: 0.0002  max mem: 8730
Epoch: [13]  [1640/2001]  eta: 0:03:50  lr: 0.000381  loss: 3.2633 (3.0643)  time: 0.6342  data: 0.0001  max mem: 8730
Epoch: [13]  [1650/2001]  eta: 0:03:43  lr: 0.000381  loss: 3.1990 (3.0659)  time: 0.6317  data: 0.0001  max mem: 8730
Epoch: [13]  [1660/2001]  eta: 0:03:37  lr: 0.000381  loss: 3.1990 (3.0659)  time: 0.6332  data: 0.0001  max mem: 8730
Epoch: [13]  [1670/2001]  eta: 0:03:30  lr: 0.000381  loss: 3.2283 (3.0666)  time: 0.6322  data: 0.0001  max mem: 8730
Epoch: [13]  [1680/2001]  eta: 0:03:24  lr: 0.000381  loss: 3.1400 (3.0668)  time: 0.6368  data: 0.0001  max mem: 8730
Epoch: [13]  [1690/2001]  eta: 0:03:18  lr: 0.000381  loss: 3.1394 (3.0670)  time: 0.6398  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0123, ratio_loss=0.0479, cls_kl=0.0643, token_kl=0.0912
Epoch: [13]  [1700/2001]  eta: 0:03:11  lr: 0.000381  loss: 3.0625 (3.0654)  time: 0.6357  data: 0.0001  max mem: 8730
Epoch: [13]  [1710/2001]  eta: 0:03:05  lr: 0.000381  loss: 2.9548 (3.0646)  time: 0.6339  data: 0.0001  max mem: 8730
Epoch: [13]  [1720/2001]  eta: 0:02:59  lr: 0.000381  loss: 3.1040 (3.0658)  time: 0.6335  data: 0.0001  max mem: 8730
Epoch: [13]  [1730/2001]  eta: 0:02:52  lr: 0.000381  loss: 3.3732 (3.0664)  time: 0.6338  data: 0.0001  max mem: 8730
Epoch: [13]  [1740/2001]  eta: 0:02:46  lr: 0.000381  loss: 3.3035 (3.0673)  time: 0.6342  data: 0.0001  max mem: 8730
Epoch: [13]  [1750/2001]  eta: 0:02:39  lr: 0.000381  loss: 3.0826 (3.0667)  time: 0.6354  data: 0.0001  max mem: 8730
Epoch: [13]  [1760/2001]  eta: 0:02:33  lr: 0.000381  loss: 3.1916 (3.0682)  time: 0.6352  data: 0.0001  max mem: 8730
Epoch: [13]  [1770/2001]  eta: 0:02:27  lr: 0.000381  loss: 3.3180 (3.0687)  time: 0.6349  data: 0.0001  max mem: 8730
Epoch: [13]  [1780/2001]  eta: 0:02:20  lr: 0.000381  loss: 3.0943 (3.0681)  time: 0.6439  data: 0.0001  max mem: 8730
Epoch: [13]  [1790/2001]  eta: 0:02:14  lr: 0.000381  loss: 3.2166 (3.0693)  time: 0.6494  data: 0.0002  max mem: 8730
loss info: cls_loss=3.0204, ratio_loss=0.0494, cls_kl=0.0665, token_kl=0.0939
Epoch: [13]  [1800/2001]  eta: 0:02:08  lr: 0.000381  loss: 3.1892 (3.0690)  time: 0.6408  data: 0.0001  max mem: 8730
Epoch: [13]  [1810/2001]  eta: 0:02:01  lr: 0.000381  loss: 3.0649 (3.0688)  time: 0.6351  data: 0.0001  max mem: 8730
Epoch: [13]  [1820/2001]  eta: 0:01:55  lr: 0.000381  loss: 3.1095 (3.0682)  time: 0.6363  data: 0.0001  max mem: 8730
Epoch: [13]  [1830/2001]  eta: 0:01:48  lr: 0.000381  loss: 3.2447 (3.0687)  time: 0.6407  data: 0.0001  max mem: 8730
Epoch: [13]  [1840/2001]  eta: 0:01:42  lr: 0.000381  loss: 3.1822 (3.0670)  time: 0.6474  data: 0.0001  max mem: 8730
Epoch: [13]  [1850/2001]  eta: 0:01:36  lr: 0.000381  loss: 3.1822 (3.0689)  time: 0.6448  data: 0.0001  max mem: 8730
Epoch: [13]  [1860/2001]  eta: 0:01:29  lr: 0.000381  loss: 3.1561 (3.0674)  time: 0.6379  data: 0.0001  max mem: 8730
Epoch: [13]  [1870/2001]  eta: 0:01:23  lr: 0.000381  loss: 2.9616 (3.0677)  time: 0.6367  data: 0.0001  max mem: 8730
Epoch: [13]  [1880/2001]  eta: 0:01:17  lr: 0.000381  loss: 2.9798 (3.0663)  time: 0.6384  data: 0.0001  max mem: 8730
Epoch: [13]  [1890/2001]  eta: 0:01:10  lr: 0.000381  loss: 2.9498 (3.0650)  time: 0.6423  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8686, ratio_loss=0.0458, cls_kl=0.0625, token_kl=0.0925
Epoch: [13]  [1900/2001]  eta: 0:01:04  lr: 0.000381  loss: 3.0651 (3.0644)  time: 0.6415  data: 0.0001  max mem: 8730
Epoch: [13]  [1910/2001]  eta: 0:00:58  lr: 0.000381  loss: 3.1540 (3.0650)  time: 0.6400  data: 0.0001  max mem: 8730
Epoch: [13]  [1920/2001]  eta: 0:00:51  lr: 0.000381  loss: 3.2204 (3.0650)  time: 0.6441  data: 0.0001  max mem: 8730
Epoch: [13]  [1930/2001]  eta: 0:00:45  lr: 0.000381  loss: 3.1370 (3.0640)  time: 0.6411  data: 0.0001  max mem: 8730
Epoch: [13]  [1940/2001]  eta: 0:00:38  lr: 0.000381  loss: 2.7905 (3.0628)  time: 0.6420  data: 0.0001  max mem: 8730
Epoch: [13]  [1950/2001]  eta: 0:00:32  lr: 0.000381  loss: 2.7905 (3.0614)  time: 0.6483  data: 0.0001  max mem: 8730
Epoch: [13]  [1960/2001]  eta: 0:00:26  lr: 0.000381  loss: 3.0647 (3.0622)  time: 0.6442  data: 0.0001  max mem: 8730
Epoch: [13]  [1970/2001]  eta: 0:00:19  lr: 0.000381  loss: 3.3264 (3.0637)  time: 0.6389  data: 0.0002  max mem: 8730
Epoch: [13]  [1980/2001]  eta: 0:00:13  lr: 0.000381  loss: 3.2678 (3.0640)  time: 0.6378  data: 0.0002  max mem: 8730
Epoch: [13]  [1990/2001]  eta: 0:00:07  lr: 0.000381  loss: 3.1629 (3.0641)  time: 0.6351  data: 0.0004  max mem: 8730
loss info: cls_loss=2.9427, ratio_loss=0.0475, cls_kl=0.0645, token_kl=0.0948
Epoch: [13]  [2000/2001]  eta: 0:00:00  lr: 0.000381  loss: 3.3089 (3.0642)  time: 0.6322  data: 0.0004  max mem: 8730
Epoch: [13] Total time: 0:21:16 (0.6380 s / it)
Averaged stats: lr: 0.000381  loss: 3.3089 (3.0545)
Test:  [ 0/53]  eta: 0:05:09  loss: 0.3503 (0.3503)  acc1: 92.5000 (92.5000)  acc5: 100.0000 (100.0000)  time: 5.8485  data: 4.9583  max mem: 8730
Test:  [10/53]  eta: 0:00:37  loss: 0.7031 (0.7719)  acc1: 84.1667 (83.1061)  acc5: 96.6667 (96.6667)  time: 0.8638  data: 0.4510  max mem: 8730
Test:  [20/53]  eta: 0:00:20  loss: 0.7031 (0.7792)  acc1: 82.5000 (82.7381)  acc5: 96.6667 (96.4683)  time: 0.3575  data: 0.0002  max mem: 8730
Test:  [30/53]  eta: 0:00:12  loss: 0.8958 (0.8576)  acc1: 80.0000 (80.8871)  acc5: 95.0000 (95.2957)  time: 0.3498  data: 0.0003  max mem: 8730
Test:  [40/53]  eta: 0:00:06  loss: 1.1223 (0.9252)  acc1: 75.8333 (79.2276)  acc5: 91.6667 (94.5935)  time: 0.3069  data: 0.0002  max mem: 8730
Test:  [50/53]  eta: 0:00:01  loss: 1.1223 (0.9555)  acc1: 73.3333 (78.3987)  acc5: 92.5000 (94.4608)  time: 0.2614  data: 0.0001  max mem: 8730
Test:  [52/53]  eta: 0:00:00  loss: 1.1161 (0.9397)  acc1: 74.1667 (78.5920)  acc5: 93.3333 (94.5280)  time: 0.2490  data: 0.0001  max mem: 8730
Test: Total time: 0:00:22 (0.4183 s / it)
Sparsity0:0.2950480808080808,Sparsity1:0.5493411055276382,Sparsity2:0.7843216,
* Acc@1 78.924 Acc@5 94.576 loss 0.941
Accuracy of the network on the 50000 test images: 78.9%
Max accuracy: 79.07%
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0003496 for PREDICTOR
Epoch: [14]  [   0/2001]  eta: 2:16:34  lr: 0.000350  loss: 1.9713 (1.9713)  time: 4.0954  data: 2.6992  max mem: 8730
Epoch: [14]  [  10/2001]  eta: 0:31:54  lr: 0.000350  loss: 3.0427 (2.8393)  time: 0.9616  data: 0.2455  max mem: 8730
Epoch: [14]  [  20/2001]  eta: 0:26:24  lr: 0.000350  loss: 3.2512 (3.0207)  time: 0.6350  data: 0.0002  max mem: 8730
Epoch: [14]  [  30/2001]  eta: 0:24:24  lr: 0.000350  loss: 3.0720 (2.9951)  time: 0.6227  data: 0.0001  max mem: 8730
Epoch: [14]  [  40/2001]  eta: 0:23:23  lr: 0.000350  loss: 3.0796 (3.0583)  time: 0.6271  data: 0.0002  max mem: 8730
Epoch: [14]  [  50/2001]  eta: 0:22:44  lr: 0.000350  loss: 3.2665 (3.1008)  time: 0.6325  data: 0.0002  max mem: 8730
Epoch: [14]  [  60/2001]  eta: 0:22:18  lr: 0.000350  loss: 3.3136 (3.1224)  time: 0.6360  data: 0.0002  max mem: 8730
Epoch: [14]  [  70/2001]  eta: 0:21:57  lr: 0.000350  loss: 2.7793 (3.0557)  time: 0.6375  data: 0.0001  max mem: 8730
Epoch: [14]  [  80/2001]  eta: 0:21:41  lr: 0.000350  loss: 2.5837 (3.0265)  time: 0.6406  data: 0.0002  max mem: 8730
Epoch: [14]  [  90/2001]  eta: 0:21:27  lr: 0.000350  loss: 2.7820 (3.0217)  time: 0.6431  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9243, ratio_loss=0.0481, cls_kl=0.0651, token_kl=0.0931
Epoch: [14]  [ 100/2001]  eta: 0:21:14  lr: 0.000350  loss: 2.9212 (3.0114)  time: 0.6417  data: 0.0001  max mem: 8730
Epoch: [14]  [ 110/2001]  eta: 0:21:02  lr: 0.000350  loss: 3.0943 (3.0184)  time: 0.6416  data: 0.0001  max mem: 8730
Epoch: [14]  [ 120/2001]  eta: 0:20:51  lr: 0.000350  loss: 3.0917 (3.0091)  time: 0.6413  data: 0.0001  max mem: 8730
Epoch: [14]  [ 130/2001]  eta: 0:20:42  lr: 0.000350  loss: 3.0099 (3.0166)  time: 0.6429  data: 0.0001  max mem: 8730
Epoch: [14]  [ 140/2001]  eta: 0:20:32  lr: 0.000350  loss: 3.1495 (3.0274)  time: 0.6431  data: 0.0001  max mem: 8730
Epoch: [14]  [ 150/2001]  eta: 0:20:24  lr: 0.000350  loss: 3.1829 (3.0287)  time: 0.6458  data: 0.0002  max mem: 8730
Epoch: [14]  [ 160/2001]  eta: 0:20:15  lr: 0.000350  loss: 2.9835 (3.0255)  time: 0.6446  data: 0.0001  max mem: 8730
Epoch: [14]  [ 170/2001]  eta: 0:20:07  lr: 0.000350  loss: 3.1810 (3.0383)  time: 0.6457  data: 0.0001  max mem: 8730
Epoch: [14]  [ 180/2001]  eta: 0:19:59  lr: 0.000350  loss: 3.1810 (3.0496)  time: 0.6491  data: 0.0002  max mem: 8730
Epoch: [14]  [ 190/2001]  eta: 0:19:51  lr: 0.000350  loss: 3.1249 (3.0401)  time: 0.6433  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9373, ratio_loss=0.0502, cls_kl=0.0653, token_kl=0.0945
Epoch: [14]  [ 200/2001]  eta: 0:19:43  lr: 0.000350  loss: 3.0826 (3.0445)  time: 0.6411  data: 0.0001  max mem: 8730
Epoch: [14]  [ 210/2001]  eta: 0:19:35  lr: 0.000350  loss: 3.2200 (3.0485)  time: 0.6411  data: 0.0001  max mem: 8730
Epoch: [14]  [ 220/2001]  eta: 0:19:27  lr: 0.000350  loss: 3.3077 (3.0568)  time: 0.6401  data: 0.0001  max mem: 8730
Epoch: [14]  [ 230/2001]  eta: 0:19:19  lr: 0.000350  loss: 3.2560 (3.0458)  time: 0.6371  data: 0.0001  max mem: 8730
Epoch: [14]  [ 240/2001]  eta: 0:19:11  lr: 0.000350  loss: 3.0253 (3.0501)  time: 0.6379  data: 0.0001  max mem: 8730
Epoch: [14]  [ 250/2001]  eta: 0:19:04  lr: 0.000350  loss: 3.2351 (3.0541)  time: 0.6402  data: 0.0001  max mem: 8730
Epoch: [14]  [ 260/2001]  eta: 0:18:57  lr: 0.000350  loss: 3.1906 (3.0549)  time: 0.6432  data: 0.0001  max mem: 8730
Epoch: [14]  [ 270/2001]  eta: 0:18:50  lr: 0.000350  loss: 2.9804 (3.0466)  time: 0.6431  data: 0.0001  max mem: 8730
Epoch: [14]  [ 280/2001]  eta: 0:18:42  lr: 0.000350  loss: 3.0606 (3.0470)  time: 0.6411  data: 0.0001  max mem: 8730
Epoch: [14]  [ 290/2001]  eta: 0:18:36  lr: 0.000350  loss: 3.1795 (3.0480)  time: 0.6456  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9657, ratio_loss=0.0463, cls_kl=0.0630, token_kl=0.0925
Epoch: [14]  [ 300/2001]  eta: 0:18:28  lr: 0.000350  loss: 3.0818 (3.0444)  time: 0.6441  data: 0.0001  max mem: 8730
Epoch: [14]  [ 310/2001]  eta: 0:18:22  lr: 0.000350  loss: 3.1216 (3.0512)  time: 0.6463  data: 0.0001  max mem: 8730
Epoch: [14]  [ 320/2001]  eta: 0:18:15  lr: 0.000350  loss: 3.2079 (3.0543)  time: 0.6465  data: 0.0001  max mem: 8730
Epoch: [14]  [ 330/2001]  eta: 0:18:07  lr: 0.000350  loss: 3.2079 (3.0536)  time: 0.6373  data: 0.0001  max mem: 8730
Epoch: [14]  [ 340/2001]  eta: 0:18:00  lr: 0.000350  loss: 3.1081 (3.0485)  time: 0.6357  data: 0.0001  max mem: 8730
Epoch: [14]  [ 350/2001]  eta: 0:17:53  lr: 0.000350  loss: 3.1081 (3.0478)  time: 0.6360  data: 0.0001  max mem: 8730
Epoch: [14]  [ 360/2001]  eta: 0:17:46  lr: 0.000350  loss: 3.2948 (3.0511)  time: 0.6360  data: 0.0001  max mem: 8730
Epoch: [14]  [ 370/2001]  eta: 0:17:39  lr: 0.000350  loss: 3.2933 (3.0558)  time: 0.6376  data: 0.0001  max mem: 8730
Epoch: [14]  [ 380/2001]  eta: 0:17:32  lr: 0.000350  loss: 3.1172 (3.0508)  time: 0.6394  data: 0.0001  max mem: 8730
Epoch: [14]  [ 390/2001]  eta: 0:17:25  lr: 0.000350  loss: 3.0827 (3.0558)  time: 0.6393  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9633, ratio_loss=0.0460, cls_kl=0.0632, token_kl=0.0911
Epoch: [14]  [ 400/2001]  eta: 0:17:18  lr: 0.000350  loss: 3.1855 (3.0572)  time: 0.6374  data: 0.0001  max mem: 8730
Epoch: [14]  [ 410/2001]  eta: 0:17:12  lr: 0.000350  loss: 3.2388 (3.0593)  time: 0.6449  data: 0.0001  max mem: 8730
Epoch: [14]  [ 420/2001]  eta: 0:17:05  lr: 0.000350  loss: 3.2231 (3.0577)  time: 0.6512  data: 0.0001  max mem: 8730
Epoch: [14]  [ 430/2001]  eta: 0:16:58  lr: 0.000350  loss: 3.0363 (3.0525)  time: 0.6396  data: 0.0001  max mem: 8730
Epoch: [14]  [ 440/2001]  eta: 0:16:51  lr: 0.000350  loss: 3.0603 (3.0541)  time: 0.6308  data: 0.0001  max mem: 8730
Epoch: [14]  [ 450/2001]  eta: 0:16:44  lr: 0.000350  loss: 3.3158 (3.0533)  time: 0.6325  data: 0.0001  max mem: 8730
Epoch: [14]  [ 460/2001]  eta: 0:16:37  lr: 0.000350  loss: 3.0240 (3.0496)  time: 0.6361  data: 0.0001  max mem: 8730
Epoch: [14]  [ 470/2001]  eta: 0:16:30  lr: 0.000350  loss: 3.2344 (3.0572)  time: 0.6343  data: 0.0001  max mem: 8730
Epoch: [14]  [ 480/2001]  eta: 0:16:23  lr: 0.000350  loss: 3.3162 (3.0575)  time: 0.6308  data: 0.0001  max mem: 8730
Epoch: [14]  [ 490/2001]  eta: 0:16:16  lr: 0.000350  loss: 2.9196 (3.0504)  time: 0.6311  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9255, ratio_loss=0.0482, cls_kl=0.0627, token_kl=0.0913
Epoch: [14]  [ 500/2001]  eta: 0:16:10  lr: 0.000350  loss: 2.9710 (3.0541)  time: 0.6358  data: 0.0001  max mem: 8730
Epoch: [14]  [ 510/2001]  eta: 0:16:03  lr: 0.000350  loss: 3.3347 (3.0564)  time: 0.6353  data: 0.0001  max mem: 8730
Epoch: [14]  [ 520/2001]  eta: 0:15:56  lr: 0.000350  loss: 3.2583 (3.0542)  time: 0.6280  data: 0.0001  max mem: 8730
Epoch: [14]  [ 530/2001]  eta: 0:15:49  lr: 0.000350  loss: 3.1740 (3.0561)  time: 0.6270  data: 0.0001  max mem: 8730
Epoch: [14]  [ 540/2001]  eta: 0:15:42  lr: 0.000350  loss: 3.2198 (3.0552)  time: 0.6298  data: 0.0001  max mem: 8730
Epoch: [14]  [ 550/2001]  eta: 0:15:35  lr: 0.000350  loss: 3.2054 (3.0555)  time: 0.6328  data: 0.0001  max mem: 8730
Epoch: [14]  [ 560/2001]  eta: 0:15:29  lr: 0.000350  loss: 3.2038 (3.0566)  time: 0.6427  data: 0.0001  max mem: 8730
Epoch: [14]  [ 570/2001]  eta: 0:15:22  lr: 0.000350  loss: 3.2848 (3.0588)  time: 0.6449  data: 0.0001  max mem: 8730
Epoch: [14]  [ 580/2001]  eta: 0:15:16  lr: 0.000350  loss: 3.3988 (3.0625)  time: 0.6364  data: 0.0001  max mem: 8730
Epoch: [14]  [ 590/2001]  eta: 0:15:09  lr: 0.000350  loss: 3.4097 (3.0638)  time: 0.6299  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0091, ratio_loss=0.0486, cls_kl=0.0648, token_kl=0.0921
Epoch: [14]  [ 600/2001]  eta: 0:15:02  lr: 0.000350  loss: 3.1701 (3.0641)  time: 0.6261  data: 0.0001  max mem: 8730
Epoch: [14]  [ 610/2001]  eta: 0:14:55  lr: 0.000350  loss: 2.9160 (3.0609)  time: 0.6294  data: 0.0001  max mem: 8730
Epoch: [14]  [ 620/2001]  eta: 0:14:48  lr: 0.000350  loss: 2.8914 (3.0627)  time: 0.6289  data: 0.0001  max mem: 8730
Epoch: [14]  [ 630/2001]  eta: 0:14:41  lr: 0.000350  loss: 3.3012 (3.0634)  time: 0.6273  data: 0.0001  max mem: 8730
Epoch: [14]  [ 640/2001]  eta: 0:14:35  lr: 0.000350  loss: 3.1978 (3.0662)  time: 0.6297  data: 0.0001  max mem: 8730
Epoch: [14]  [ 650/2001]  eta: 0:14:28  lr: 0.000350  loss: 3.1756 (3.0663)  time: 0.6304  data: 0.0001  max mem: 8730
Epoch: [14]  [ 660/2001]  eta: 0:14:21  lr: 0.000350  loss: 3.2386 (3.0711)  time: 0.6281  data: 0.0001  max mem: 8730
Epoch: [14]  [ 670/2001]  eta: 0:14:15  lr: 0.000350  loss: 3.2386 (3.0706)  time: 0.6280  data: 0.0001  max mem: 8730
Epoch: [14]  [ 680/2001]  eta: 0:14:08  lr: 0.000350  loss: 3.0983 (3.0696)  time: 0.6302  data: 0.0001  max mem: 8730
Epoch: [14]  [ 690/2001]  eta: 0:14:01  lr: 0.000350  loss: 3.3802 (3.0740)  time: 0.6347  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0362, ratio_loss=0.0528, cls_kl=0.0668, token_kl=0.0958
Epoch: [14]  [ 700/2001]  eta: 0:13:55  lr: 0.000350  loss: 3.3802 (3.0768)  time: 0.6351  data: 0.0001  max mem: 8730
Epoch: [14]  [ 710/2001]  eta: 0:13:48  lr: 0.000350  loss: 3.1122 (3.0751)  time: 0.6258  data: 0.0001  max mem: 8730
Epoch: [14]  [ 720/2001]  eta: 0:13:41  lr: 0.000350  loss: 3.2620 (3.0786)  time: 0.6252  data: 0.0001  max mem: 8730
Epoch: [14]  [ 730/2001]  eta: 0:13:35  lr: 0.000350  loss: 3.2689 (3.0772)  time: 0.6276  data: 0.0001  max mem: 8730
Epoch: [14]  [ 740/2001]  eta: 0:13:28  lr: 0.000350  loss: 3.2113 (3.0788)  time: 0.6270  data: 0.0001  max mem: 8730
Epoch: [14]  [ 750/2001]  eta: 0:13:21  lr: 0.000350  loss: 3.2113 (3.0774)  time: 0.6275  data: 0.0001  max mem: 8730
Epoch: [14]  [ 760/2001]  eta: 0:13:15  lr: 0.000350  loss: 3.0850 (3.0785)  time: 0.6265  data: 0.0001  max mem: 8730
Epoch: [14]  [ 770/2001]  eta: 0:13:08  lr: 0.000350  loss: 3.0406 (3.0756)  time: 0.6273  data: 0.0001  max mem: 8730
Epoch: [14]  [ 780/2001]  eta: 0:13:02  lr: 0.000350  loss: 3.0306 (3.0745)  time: 0.6301  data: 0.0001  max mem: 8730
Epoch: [14]  [ 790/2001]  eta: 0:12:55  lr: 0.000350  loss: 3.1805 (3.0749)  time: 0.6294  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9517, ratio_loss=0.0472, cls_kl=0.0641, token_kl=0.0911
Epoch: [14]  [ 800/2001]  eta: 0:12:48  lr: 0.000350  loss: 3.1805 (3.0747)  time: 0.6259  data: 0.0001  max mem: 8730
Epoch: [14]  [ 810/2001]  eta: 0:12:42  lr: 0.000350  loss: 3.1268 (3.0748)  time: 0.6259  data: 0.0001  max mem: 8730
Epoch: [14]  [ 820/2001]  eta: 0:12:35  lr: 0.000350  loss: 3.1482 (3.0744)  time: 0.6261  data: 0.0001  max mem: 8730
Epoch: [14]  [ 830/2001]  eta: 0:12:29  lr: 0.000350  loss: 3.2660 (3.0761)  time: 0.6342  data: 0.0002  max mem: 8730
Epoch: [14]  [ 840/2001]  eta: 0:12:23  lr: 0.000350  loss: 3.3260 (3.0771)  time: 0.6475  data: 0.0001  max mem: 8730
Epoch: [14]  [ 850/2001]  eta: 0:12:16  lr: 0.000350  loss: 3.2521 (3.0741)  time: 0.6431  data: 0.0001  max mem: 8730
Epoch: [14]  [ 860/2001]  eta: 0:12:10  lr: 0.000350  loss: 2.9090 (3.0707)  time: 0.6315  data: 0.0001  max mem: 8730
Epoch: [14]  [ 870/2001]  eta: 0:12:03  lr: 0.000350  loss: 2.7590 (3.0678)  time: 0.6304  data: 0.0001  max mem: 8730
Epoch: [14]  [ 880/2001]  eta: 0:11:56  lr: 0.000350  loss: 3.0579 (3.0698)  time: 0.6296  data: 0.0001  max mem: 8730
Epoch: [14]  [ 890/2001]  eta: 0:11:50  lr: 0.000350  loss: 3.0579 (3.0678)  time: 0.6319  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8901, ratio_loss=0.0452, cls_kl=0.0642, token_kl=0.0924
Epoch: [14]  [ 900/2001]  eta: 0:11:44  lr: 0.000350  loss: 2.7999 (3.0650)  time: 0.6343  data: 0.0001  max mem: 8730
Epoch: [14]  [ 910/2001]  eta: 0:11:37  lr: 0.000350  loss: 3.0101 (3.0647)  time: 0.6341  data: 0.0001  max mem: 8730
Epoch: [14]  [ 920/2001]  eta: 0:11:31  lr: 0.000350  loss: 3.1201 (3.0660)  time: 0.6315  data: 0.0001  max mem: 8730
Epoch: [14]  [ 930/2001]  eta: 0:11:24  lr: 0.000350  loss: 3.1542 (3.0669)  time: 0.6289  data: 0.0001  max mem: 8730
Epoch: [14]  [ 940/2001]  eta: 0:11:18  lr: 0.000350  loss: 3.2288 (3.0686)  time: 0.6319  data: 0.0001  max mem: 8730
Epoch: [14]  [ 950/2001]  eta: 0:11:11  lr: 0.000350  loss: 3.2288 (3.0688)  time: 0.6322  data: 0.0001  max mem: 8730
Epoch: [14]  [ 960/2001]  eta: 0:11:05  lr: 0.000350  loss: 3.0141 (3.0664)  time: 0.6315  data: 0.0001  max mem: 8730
Epoch: [14]  [ 970/2001]  eta: 0:10:58  lr: 0.000350  loss: 3.1078 (3.0669)  time: 0.6315  data: 0.0001  max mem: 8730
Epoch: [14]  [ 980/2001]  eta: 0:10:52  lr: 0.000350  loss: 3.3471 (3.0704)  time: 0.6339  data: 0.0001  max mem: 8730
Epoch: [14]  [ 990/2001]  eta: 0:10:46  lr: 0.000350  loss: 3.2904 (3.0702)  time: 0.6441  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0039, ratio_loss=0.0495, cls_kl=0.0668, token_kl=0.0941
Epoch: [14]  [1000/2001]  eta: 0:10:39  lr: 0.000350  loss: 3.1607 (3.0702)  time: 0.6427  data: 0.0001  max mem: 8730
Epoch: [14]  [1010/2001]  eta: 0:10:33  lr: 0.000350  loss: 3.1607 (3.0708)  time: 0.6359  data: 0.0001  max mem: 8730
Epoch: [14]  [1020/2001]  eta: 0:10:26  lr: 0.000350  loss: 3.0809 (3.0694)  time: 0.6347  data: 0.0001  max mem: 8730
Epoch: [14]  [1030/2001]  eta: 0:10:20  lr: 0.000350  loss: 3.0809 (3.0686)  time: 0.6340  data: 0.0001  max mem: 8730
Epoch: [14]  [1040/2001]  eta: 0:10:13  lr: 0.000350  loss: 2.9786 (3.0678)  time: 0.6352  data: 0.0001  max mem: 8730
Epoch: [14]  [1050/2001]  eta: 0:10:07  lr: 0.000350  loss: 2.9928 (3.0668)  time: 0.6332  data: 0.0001  max mem: 8730
Epoch: [14]  [1060/2001]  eta: 0:10:01  lr: 0.000350  loss: 3.1815 (3.0683)  time: 0.6334  data: 0.0001  max mem: 8730
Epoch: [14]  [1070/2001]  eta: 0:09:54  lr: 0.000350  loss: 3.1815 (3.0667)  time: 0.6342  data: 0.0001  max mem: 8730
Epoch: [14]  [1080/2001]  eta: 0:09:48  lr: 0.000350  loss: 3.1980 (3.0679)  time: 0.6338  data: 0.0001  max mem: 8730
Epoch: [14]  [1090/2001]  eta: 0:09:41  lr: 0.000350  loss: 3.0876 (3.0656)  time: 0.6317  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8928, ratio_loss=0.0449, cls_kl=0.0622, token_kl=0.0918
Epoch: [14]  [1100/2001]  eta: 0:09:35  lr: 0.000350  loss: 3.0255 (3.0649)  time: 0.6328  data: 0.0001  max mem: 8730
Epoch: [14]  [1110/2001]  eta: 0:09:28  lr: 0.000350  loss: 3.0555 (3.0655)  time: 0.6413  data: 0.0001  max mem: 8730
Epoch: [14]  [1120/2001]  eta: 0:09:22  lr: 0.000350  loss: 3.0555 (3.0647)  time: 0.6430  data: 0.0001  max mem: 8730
Epoch: [14]  [1130/2001]  eta: 0:09:16  lr: 0.000350  loss: 3.1273 (3.0658)  time: 0.6387  data: 0.0001  max mem: 8730
Epoch: [14]  [1140/2001]  eta: 0:09:09  lr: 0.000350  loss: 3.2528 (3.0678)  time: 0.6359  data: 0.0001  max mem: 8730
Epoch: [14]  [1150/2001]  eta: 0:09:03  lr: 0.000350  loss: 3.2246 (3.0670)  time: 0.6356  data: 0.0001  max mem: 8730
Epoch: [14]  [1160/2001]  eta: 0:08:56  lr: 0.000350  loss: 3.1665 (3.0685)  time: 0.6358  data: 0.0001  max mem: 8730
Epoch: [14]  [1170/2001]  eta: 0:08:50  lr: 0.000350  loss: 3.1828 (3.0682)  time: 0.6351  data: 0.0001  max mem: 8730
Epoch: [14]  [1180/2001]  eta: 0:08:44  lr: 0.000350  loss: 3.3411 (3.0697)  time: 0.6359  data: 0.0001  max mem: 8730
Epoch: [14]  [1190/2001]  eta: 0:08:37  lr: 0.000350  loss: 3.1767 (3.0681)  time: 0.6346  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0083, ratio_loss=0.0483, cls_kl=0.0652, token_kl=0.0926
Epoch: [14]  [1200/2001]  eta: 0:08:31  lr: 0.000350  loss: 3.1767 (3.0698)  time: 0.6345  data: 0.0001  max mem: 8730
Epoch: [14]  [1210/2001]  eta: 0:08:24  lr: 0.000350  loss: 3.4692 (3.0704)  time: 0.6359  data: 0.0001  max mem: 8730
Epoch: [14]  [1220/2001]  eta: 0:08:18  lr: 0.000350  loss: 3.2851 (3.0720)  time: 0.6358  data: 0.0001  max mem: 8730
Epoch: [14]  [1230/2001]  eta: 0:08:12  lr: 0.000350  loss: 3.2851 (3.0709)  time: 0.6348  data: 0.0001  max mem: 8730
Epoch: [14]  [1240/2001]  eta: 0:08:05  lr: 0.000350  loss: 3.1911 (3.0720)  time: 0.6362  data: 0.0001  max mem: 8730
Epoch: [14]  [1250/2001]  eta: 0:07:59  lr: 0.000350  loss: 3.1903 (3.0716)  time: 0.6373  data: 0.0001  max mem: 8730
Epoch: [14]  [1260/2001]  eta: 0:07:53  lr: 0.000350  loss: 3.1670 (3.0716)  time: 0.6444  data: 0.0001  max mem: 8730
Epoch: [14]  [1270/2001]  eta: 0:07:46  lr: 0.000350  loss: 3.1670 (3.0726)  time: 0.6524  data: 0.0001  max mem: 8730
Epoch: [14]  [1280/2001]  eta: 0:07:40  lr: 0.000350  loss: 3.2817 (3.0721)  time: 0.6499  data: 0.0001  max mem: 8730
Epoch: [14]  [1290/2001]  eta: 0:07:34  lr: 0.000350  loss: 3.2817 (3.0736)  time: 0.6432  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0284, ratio_loss=0.0526, cls_kl=0.0672, token_kl=0.0953
Epoch: [14]  [1300/2001]  eta: 0:07:27  lr: 0.000350  loss: 3.4098 (3.0756)  time: 0.6392  data: 0.0001  max mem: 8730
Epoch: [14]  [1310/2001]  eta: 0:07:21  lr: 0.000350  loss: 3.3128 (3.0744)  time: 0.6364  data: 0.0001  max mem: 8730
Epoch: [14]  [1320/2001]  eta: 0:07:14  lr: 0.000350  loss: 2.9981 (3.0739)  time: 0.6362  data: 0.0001  max mem: 8730
Epoch: [14]  [1330/2001]  eta: 0:07:08  lr: 0.000350  loss: 3.0912 (3.0744)  time: 0.6378  data: 0.0001  max mem: 8730
Epoch: [14]  [1340/2001]  eta: 0:07:02  lr: 0.000350  loss: 3.0605 (3.0741)  time: 0.6414  data: 0.0001  max mem: 8730
Epoch: [14]  [1350/2001]  eta: 0:06:55  lr: 0.000350  loss: 3.2512 (3.0749)  time: 0.6435  data: 0.0001  max mem: 8730
Epoch: [14]  [1360/2001]  eta: 0:06:49  lr: 0.000350  loss: 3.1716 (3.0740)  time: 0.6386  data: 0.0001  max mem: 8730
Epoch: [14]  [1370/2001]  eta: 0:06:42  lr: 0.000350  loss: 3.0540 (3.0732)  time: 0.6348  data: 0.0001  max mem: 8730
Epoch: [14]  [1380/2001]  eta: 0:06:36  lr: 0.000350  loss: 3.0461 (3.0718)  time: 0.6337  data: 0.0001  max mem: 8730
Epoch: [14]  [1390/2001]  eta: 0:06:30  lr: 0.000350  loss: 2.9799 (3.0708)  time: 0.6398  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9384, ratio_loss=0.0458, cls_kl=0.0639, token_kl=0.0917
Epoch: [14]  [1400/2001]  eta: 0:06:23  lr: 0.000350  loss: 3.2534 (3.0725)  time: 0.6416  data: 0.0001  max mem: 8730
Epoch: [14]  [1410/2001]  eta: 0:06:17  lr: 0.000350  loss: 3.2541 (3.0732)  time: 0.6394  data: 0.0001  max mem: 8730
Epoch: [14]  [1420/2001]  eta: 0:06:11  lr: 0.000350  loss: 3.0623 (3.0720)  time: 0.6526  data: 0.0001  max mem: 8730
Epoch: [14]  [1430/2001]  eta: 0:06:04  lr: 0.000350  loss: 3.1661 (3.0718)  time: 0.6535  data: 0.0001  max mem: 8730
Epoch: [14]  [1440/2001]  eta: 0:05:58  lr: 0.000350  loss: 3.2657 (3.0718)  time: 0.6473  data: 0.0001  max mem: 8730
Epoch: [14]  [1450/2001]  eta: 0:05:52  lr: 0.000350  loss: 3.2680 (3.0730)  time: 0.6439  data: 0.0001  max mem: 8730
Epoch: [14]  [1460/2001]  eta: 0:05:45  lr: 0.000350  loss: 3.1478 (3.0718)  time: 0.6389  data: 0.0001  max mem: 8730
Epoch: [14]  [1470/2001]  eta: 0:05:39  lr: 0.000350  loss: 3.0523 (3.0722)  time: 0.6419  data: 0.0001  max mem: 8730
Epoch: [14]  [1480/2001]  eta: 0:05:32  lr: 0.000350  loss: 3.1834 (3.0724)  time: 0.6444  data: 0.0001  max mem: 8730
Epoch: [14]  [1490/2001]  eta: 0:05:26  lr: 0.000350  loss: 3.1731 (3.0721)  time: 0.6426  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9594, ratio_loss=0.0457, cls_kl=0.0644, token_kl=0.0908
Epoch: [14]  [1500/2001]  eta: 0:05:20  lr: 0.000350  loss: 3.2395 (3.0727)  time: 0.6387  data: 0.0001  max mem: 8730
Epoch: [14]  [1510/2001]  eta: 0:05:13  lr: 0.000350  loss: 3.3011 (3.0727)  time: 0.6393  data: 0.0001  max mem: 8730
Epoch: [14]  [1520/2001]  eta: 0:05:07  lr: 0.000350  loss: 3.3011 (3.0726)  time: 0.6399  data: 0.0001  max mem: 8730
Epoch: [14]  [1530/2001]  eta: 0:05:00  lr: 0.000350  loss: 2.9422 (3.0716)  time: 0.6413  data: 0.0001  max mem: 8730
Epoch: [14]  [1540/2001]  eta: 0:04:54  lr: 0.000350  loss: 2.9812 (3.0702)  time: 0.6456  data: 0.0001  max mem: 8730
Epoch: [14]  [1550/2001]  eta: 0:04:48  lr: 0.000350  loss: 3.0155 (3.0696)  time: 0.6449  data: 0.0001  max mem: 8730
Epoch: [14]  [1560/2001]  eta: 0:04:41  lr: 0.000350  loss: 3.1342 (3.0691)  time: 0.6423  data: 0.0001  max mem: 8730
Epoch: [14]  [1570/2001]  eta: 0:04:35  lr: 0.000350  loss: 3.1342 (3.0685)  time: 0.6443  data: 0.0001  max mem: 8730
Epoch: [14]  [1580/2001]  eta: 0:04:29  lr: 0.000350  loss: 3.1359 (3.0677)  time: 0.6468  data: 0.0001  max mem: 8730
Epoch: [14]  [1590/2001]  eta: 0:04:22  lr: 0.000350  loss: 3.1359 (3.0683)  time: 0.6436  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9056, ratio_loss=0.0512, cls_kl=0.0646, token_kl=0.0955
Epoch: [14]  [1600/2001]  eta: 0:04:16  lr: 0.000350  loss: 3.2014 (3.0682)  time: 0.6413  data: 0.0001  max mem: 8730
Epoch: [14]  [1610/2001]  eta: 0:04:09  lr: 0.000350  loss: 3.3648 (3.0685)  time: 0.6402  data: 0.0001  max mem: 8730
Epoch: [14]  [1620/2001]  eta: 0:04:03  lr: 0.000350  loss: 3.1745 (3.0682)  time: 0.6376  data: 0.0001  max mem: 8730
Epoch: [14]  [1630/2001]  eta: 0:03:57  lr: 0.000350  loss: 3.2722 (3.0694)  time: 0.6407  data: 0.0001  max mem: 8730
Epoch: [14]  [1640/2001]  eta: 0:03:50  lr: 0.000350  loss: 3.2851 (3.0703)  time: 0.6406  data: 0.0001  max mem: 8730
Epoch: [14]  [1650/2001]  eta: 0:03:44  lr: 0.000350  loss: 3.1324 (3.0690)  time: 0.6379  data: 0.0001  max mem: 8730
Epoch: [14]  [1660/2001]  eta: 0:03:37  lr: 0.000350  loss: 3.0436 (3.0692)  time: 0.6407  data: 0.0001  max mem: 8730
Epoch: [14]  [1670/2001]  eta: 0:03:31  lr: 0.000350  loss: 3.0743 (3.0681)  time: 0.6399  data: 0.0001  max mem: 8730
Epoch: [14]  [1680/2001]  eta: 0:03:25  lr: 0.000350  loss: 3.0986 (3.0690)  time: 0.6400  data: 0.0001  max mem: 8730
Epoch: [14]  [1690/2001]  eta: 0:03:18  lr: 0.000350  loss: 3.1701 (3.0697)  time: 0.6487  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9606, ratio_loss=0.0482, cls_kl=0.0653, token_kl=0.0934
Epoch: [14]  [1700/2001]  eta: 0:03:12  lr: 0.000350  loss: 3.1701 (3.0703)  time: 0.6497  data: 0.0001  max mem: 8730
Epoch: [14]  [1710/2001]  eta: 0:03:06  lr: 0.000350  loss: 3.0556 (3.0691)  time: 0.6437  data: 0.0001  max mem: 8730
Epoch: [14]  [1720/2001]  eta: 0:02:59  lr: 0.000350  loss: 2.9841 (3.0689)  time: 0.6410  data: 0.0001  max mem: 8730
Epoch: [14]  [1730/2001]  eta: 0:02:53  lr: 0.000350  loss: 2.8252 (3.0672)  time: 0.6393  data: 0.0001  max mem: 8730
Epoch: [14]  [1740/2001]  eta: 0:02:46  lr: 0.000350  loss: 2.8484 (3.0675)  time: 0.6417  data: 0.0001  max mem: 8730
Epoch: [14]  [1750/2001]  eta: 0:02:40  lr: 0.000350  loss: 3.2014 (3.0677)  time: 0.6418  data: 0.0001  max mem: 8730
Epoch: [14]  [1760/2001]  eta: 0:02:34  lr: 0.000350  loss: 3.1312 (3.0685)  time: 0.6388  data: 0.0001  max mem: 8730
Epoch: [14]  [1770/2001]  eta: 0:02:27  lr: 0.000350  loss: 3.1288 (3.0674)  time: 0.6396  data: 0.0001  max mem: 8730
Epoch: [14]  [1780/2001]  eta: 0:02:21  lr: 0.000350  loss: 3.0166 (3.0669)  time: 0.6371  data: 0.0001  max mem: 8730
Epoch: [14]  [1790/2001]  eta: 0:02:14  lr: 0.000350  loss: 3.1234 (3.0666)  time: 0.6336  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9263, ratio_loss=0.0444, cls_kl=0.0633, token_kl=0.0921
Epoch: [14]  [1800/2001]  eta: 0:02:08  lr: 0.000350  loss: 3.2926 (3.0678)  time: 0.6348  data: 0.0001  max mem: 8730
Epoch: [14]  [1810/2001]  eta: 0:02:02  lr: 0.000350  loss: 3.2725 (3.0679)  time: 0.6345  data: 0.0001  max mem: 8730
Epoch: [14]  [1820/2001]  eta: 0:01:55  lr: 0.000350  loss: 3.2576 (3.0685)  time: 0.6356  data: 0.0001  max mem: 8730
Epoch: [14]  [1830/2001]  eta: 0:01:49  lr: 0.000350  loss: 3.2509 (3.0697)  time: 0.6360  data: 0.0001  max mem: 8730
Epoch: [14]  [1840/2001]  eta: 0:01:42  lr: 0.000350  loss: 3.1981 (3.0693)  time: 0.6371  data: 0.0001  max mem: 8730
Epoch: [14]  [1850/2001]  eta: 0:01:36  lr: 0.000350  loss: 2.9980 (3.0690)  time: 0.6463  data: 0.0001  max mem: 8730
Epoch: [14]  [1860/2001]  eta: 0:01:30  lr: 0.000350  loss: 3.2445 (3.0702)  time: 0.6450  data: 0.0001  max mem: 8730
Epoch: [14]  [1870/2001]  eta: 0:01:23  lr: 0.000350  loss: 3.4025 (3.0722)  time: 0.6344  data: 0.0001  max mem: 8730
Epoch: [14]  [1880/2001]  eta: 0:01:17  lr: 0.000350  loss: 3.3092 (3.0724)  time: 0.6321  data: 0.0001  max mem: 8730
Epoch: [14]  [1890/2001]  eta: 0:01:10  lr: 0.000350  loss: 3.1817 (3.0727)  time: 0.6312  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0155, ratio_loss=0.0486, cls_kl=0.0670, token_kl=0.0943
Epoch: [14]  [1900/2001]  eta: 0:01:04  lr: 0.000350  loss: 2.9435 (3.0712)  time: 0.6298  data: 0.0001  max mem: 8730
Epoch: [14]  [1910/2001]  eta: 0:00:58  lr: 0.000350  loss: 3.0527 (3.0720)  time: 0.6301  data: 0.0001  max mem: 8730
Epoch: [14]  [1920/2001]  eta: 0:00:51  lr: 0.000350  loss: 3.2188 (3.0724)  time: 0.6317  data: 0.0001  max mem: 8730
Epoch: [14]  [1930/2001]  eta: 0:00:45  lr: 0.000350  loss: 3.3209 (3.0722)  time: 0.6311  data: 0.0001  max mem: 8730
Epoch: [14]  [1940/2001]  eta: 0:00:38  lr: 0.000350  loss: 3.2671 (3.0730)  time: 0.6293  data: 0.0001  max mem: 8730
Epoch: [14]  [1950/2001]  eta: 0:00:32  lr: 0.000350  loss: 3.1936 (3.0729)  time: 0.6292  data: 0.0001  max mem: 8730
Epoch: [14]  [1960/2001]  eta: 0:00:26  lr: 0.000350  loss: 3.0668 (3.0717)  time: 0.6305  data: 0.0001  max mem: 8730
Epoch: [14]  [1970/2001]  eta: 0:00:19  lr: 0.000350  loss: 3.1760 (3.0726)  time: 0.6361  data: 0.0001  max mem: 8730
Epoch: [14]  [1980/2001]  eta: 0:00:13  lr: 0.000350  loss: 3.2887 (3.0728)  time: 0.6361  data: 0.0001  max mem: 8730
Epoch: [14]  [1990/2001]  eta: 0:00:07  lr: 0.000350  loss: 3.1248 (3.0729)  time: 0.6289  data: 0.0004  max mem: 8730
loss info: cls_loss=3.0155, ratio_loss=0.0488, cls_kl=0.0656, token_kl=0.0932
Epoch: [14]  [2000/2001]  eta: 0:00:00  lr: 0.000350  loss: 3.1203 (3.0733)  time: 0.6238  data: 0.0004  max mem: 8730
Epoch: [14] Total time: 0:21:18 (0.6390 s / it)
Averaged stats: lr: 0.000350  loss: 3.1203 (3.0664)
Test:  [ 0/53]  eta: 0:04:51  loss: 0.3423 (0.3423)  acc1: 93.3333 (93.3333)  acc5: 99.1667 (99.1667)  time: 5.4997  data: 5.0501  max mem: 8730
Test:  [10/53]  eta: 0:00:35  loss: 0.7568 (0.7624)  acc1: 84.1667 (83.7879)  acc5: 96.6667 (96.7424)  time: 0.8272  data: 0.4593  max mem: 8730
Test:  [20/53]  eta: 0:00:20  loss: 0.7214 (0.7697)  acc1: 84.1667 (83.5318)  acc5: 96.6667 (96.6270)  time: 0.3656  data: 0.0005  max mem: 8730
Test:  [30/53]  eta: 0:00:12  loss: 0.8896 (0.8593)  acc1: 78.3333 (81.1290)  acc5: 95.0000 (95.3763)  time: 0.3540  data: 0.0005  max mem: 8730
Test:  [40/53]  eta: 0:00:05  loss: 1.1321 (0.9272)  acc1: 74.1667 (79.3902)  acc5: 91.6667 (94.4919)  time: 0.3027  data: 0.0002  max mem: 8730
Test:  [50/53]  eta: 0:00:01  loss: 1.1045 (0.9579)  acc1: 74.1667 (78.5294)  acc5: 91.6667 (94.3137)  time: 0.2645  data: 0.0001  max mem: 8730
Test:  [52/53]  eta: 0:00:00  loss: 1.0793 (0.9421)  acc1: 75.8333 (78.6880)  acc5: 93.3333 (94.3840)  time: 0.2530  data: 0.0000  max mem: 8730
Test: Total time: 0:00:21 (0.4140 s / it)
Sparsity0:0.29037575757575756,Sparsity1:0.5466588944723618,Sparsity2:0.7787312,
* Acc@1 79.036 Acc@5 94.526 loss 0.938
Accuracy of the network on the 50000 test images: 79.0%
Max accuracy: 79.07%
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0003175 for PREDICTOR
Epoch: [15]  [   0/2001]  eta: 2:13:49  lr: 0.000318  loss: 2.9317 (2.9317)  time: 4.0130  data: 2.6387  max mem: 8730
Epoch: [15]  [  10/2001]  eta: 0:31:57  lr: 0.000318  loss: 3.2173 (3.1460)  time: 0.9633  data: 0.2400  max mem: 8730
Epoch: [15]  [  20/2001]  eta: 0:26:24  lr: 0.000318  loss: 3.1989 (3.0669)  time: 0.6390  data: 0.0002  max mem: 8730
Epoch: [15]  [  30/2001]  eta: 0:24:17  lr: 0.000318  loss: 3.0023 (2.9577)  time: 0.6162  data: 0.0002  max mem: 8730
Epoch: [15]  [  40/2001]  eta: 0:23:11  lr: 0.000318  loss: 2.9825 (2.9745)  time: 0.6145  data: 0.0002  max mem: 8730
Epoch: [15]  [  50/2001]  eta: 0:22:29  lr: 0.000318  loss: 3.0507 (2.9937)  time: 0.6171  data: 0.0002  max mem: 8730
Epoch: [15]  [  60/2001]  eta: 0:22:02  lr: 0.000318  loss: 3.1126 (3.0179)  time: 0.6233  data: 0.0001  max mem: 8730
Epoch: [15]  [  70/2001]  eta: 0:21:38  lr: 0.000318  loss: 3.1864 (3.0502)  time: 0.6246  data: 0.0002  max mem: 8730
Epoch: [15]  [  80/2001]  eta: 0:21:21  lr: 0.000318  loss: 3.1974 (3.0589)  time: 0.6233  data: 0.0002  max mem: 8730
Epoch: [15]  [  90/2001]  eta: 0:21:05  lr: 0.000318  loss: 3.1974 (3.0615)  time: 0.6245  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9423, ratio_loss=0.0489, cls_kl=0.0639, token_kl=0.0945
Epoch: [15]  [ 100/2001]  eta: 0:20:53  lr: 0.000318  loss: 3.0510 (3.0688)  time: 0.6278  data: 0.0001  max mem: 8730
Epoch: [15]  [ 110/2001]  eta: 0:20:41  lr: 0.000318  loss: 2.7222 (3.0303)  time: 0.6303  data: 0.0001  max mem: 8730
Epoch: [15]  [ 120/2001]  eta: 0:20:29  lr: 0.000318  loss: 2.7274 (3.0410)  time: 0.6268  data: 0.0002  max mem: 8730
Epoch: [15]  [ 130/2001]  eta: 0:20:19  lr: 0.000318  loss: 3.2530 (3.0514)  time: 0.6274  data: 0.0002  max mem: 8730
Epoch: [15]  [ 140/2001]  eta: 0:20:12  lr: 0.000318  loss: 2.9596 (3.0279)  time: 0.6374  data: 0.0001  max mem: 8730
Epoch: [15]  [ 150/2001]  eta: 0:20:04  lr: 0.000318  loss: 2.9596 (3.0309)  time: 0.6417  data: 0.0001  max mem: 8730
Epoch: [15]  [ 160/2001]  eta: 0:19:56  lr: 0.000318  loss: 3.1197 (3.0295)  time: 0.6375  data: 0.0001  max mem: 8730
Epoch: [15]  [ 170/2001]  eta: 0:19:47  lr: 0.000318  loss: 3.1197 (3.0461)  time: 0.6328  data: 0.0001  max mem: 8730
Epoch: [15]  [ 180/2001]  eta: 0:19:38  lr: 0.000318  loss: 3.0686 (3.0439)  time: 0.6279  data: 0.0001  max mem: 8730
Epoch: [15]  [ 190/2001]  eta: 0:19:30  lr: 0.000318  loss: 3.2857 (3.0567)  time: 0.6296  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9693, ratio_loss=0.0468, cls_kl=0.0627, token_kl=0.0916
Epoch: [15]  [ 200/2001]  eta: 0:19:22  lr: 0.000318  loss: 3.2944 (3.0690)  time: 0.6315  data: 0.0001  max mem: 8730
Epoch: [15]  [ 210/2001]  eta: 0:19:16  lr: 0.000318  loss: 2.9258 (3.0529)  time: 0.6358  data: 0.0001  max mem: 8730
Epoch: [15]  [ 220/2001]  eta: 0:19:09  lr: 0.000318  loss: 2.9258 (3.0546)  time: 0.6410  data: 0.0002  max mem: 8730
Epoch: [15]  [ 230/2001]  eta: 0:19:01  lr: 0.000318  loss: 3.1021 (3.0508)  time: 0.6365  data: 0.0002  max mem: 8730
Epoch: [15]  [ 240/2001]  eta: 0:18:54  lr: 0.000318  loss: 3.2583 (3.0636)  time: 0.6338  data: 0.0002  max mem: 8730
Epoch: [15]  [ 250/2001]  eta: 0:18:47  lr: 0.000318  loss: 3.2873 (3.0708)  time: 0.6325  data: 0.0002  max mem: 8730
Epoch: [15]  [ 260/2001]  eta: 0:18:40  lr: 0.000318  loss: 3.2869 (3.0767)  time: 0.6313  data: 0.0002  max mem: 8730
Epoch: [15]  [ 270/2001]  eta: 0:18:33  lr: 0.000318  loss: 3.2267 (3.0806)  time: 0.6368  data: 0.0002  max mem: 8730
Epoch: [15]  [ 280/2001]  eta: 0:18:27  lr: 0.000318  loss: 3.2783 (3.0799)  time: 0.6421  data: 0.0002  max mem: 8730
Epoch: [15]  [ 290/2001]  eta: 0:18:19  lr: 0.000318  loss: 3.3453 (3.0864)  time: 0.6360  data: 0.0002  max mem: 8730
loss info: cls_loss=3.0285, ratio_loss=0.0494, cls_kl=0.0648, token_kl=0.0937
Epoch: [15]  [ 300/2001]  eta: 0:18:12  lr: 0.000318  loss: 3.4027 (3.0956)  time: 0.6314  data: 0.0002  max mem: 8730
Epoch: [15]  [ 310/2001]  eta: 0:18:05  lr: 0.000318  loss: 3.4336 (3.1005)  time: 0.6342  data: 0.0002  max mem: 8730
Epoch: [15]  [ 320/2001]  eta: 0:17:59  lr: 0.000318  loss: 3.4147 (3.1016)  time: 0.6335  data: 0.0002  max mem: 8730
Epoch: [15]  [ 330/2001]  eta: 0:17:52  lr: 0.000318  loss: 3.0620 (3.0982)  time: 0.6318  data: 0.0002  max mem: 8730
Epoch: [15]  [ 340/2001]  eta: 0:17:45  lr: 0.000318  loss: 3.0419 (3.0959)  time: 0.6375  data: 0.0002  max mem: 8730
Epoch: [15]  [ 350/2001]  eta: 0:17:38  lr: 0.000318  loss: 3.1067 (3.0917)  time: 0.6381  data: 0.0002  max mem: 8730
Epoch: [15]  [ 360/2001]  eta: 0:17:31  lr: 0.000318  loss: 3.2598 (3.0941)  time: 0.6294  data: 0.0002  max mem: 8730
Epoch: [15]  [ 370/2001]  eta: 0:17:25  lr: 0.000318  loss: 3.3472 (3.0959)  time: 0.6344  data: 0.0002  max mem: 8730
Epoch: [15]  [ 380/2001]  eta: 0:17:18  lr: 0.000318  loss: 3.2982 (3.0995)  time: 0.6366  data: 0.0002  max mem: 8730
Epoch: [15]  [ 390/2001]  eta: 0:17:12  lr: 0.000318  loss: 3.2318 (3.1008)  time: 0.6400  data: 0.0002  max mem: 8730
loss info: cls_loss=3.0113, ratio_loss=0.0500, cls_kl=0.0671, token_kl=0.0972
Epoch: [15]  [ 400/2001]  eta: 0:17:05  lr: 0.000318  loss: 3.0248 (3.0985)  time: 0.6408  data: 0.0002  max mem: 8730
Epoch: [15]  [ 410/2001]  eta: 0:16:59  lr: 0.000318  loss: 3.1278 (3.0987)  time: 0.6348  data: 0.0002  max mem: 8730
Epoch: [15]  [ 420/2001]  eta: 0:16:52  lr: 0.000318  loss: 3.2550 (3.1012)  time: 0.6328  data: 0.0002  max mem: 8730
Epoch: [15]  [ 430/2001]  eta: 0:16:46  lr: 0.000318  loss: 2.9984 (3.0952)  time: 0.6378  data: 0.0001  max mem: 8730
Epoch: [15]  [ 440/2001]  eta: 0:16:39  lr: 0.000318  loss: 2.9984 (3.0963)  time: 0.6403  data: 0.0001  max mem: 8730
Epoch: [15]  [ 450/2001]  eta: 0:16:33  lr: 0.000318  loss: 3.2673 (3.0950)  time: 0.6385  data: 0.0002  max mem: 8730
Epoch: [15]  [ 460/2001]  eta: 0:16:26  lr: 0.000318  loss: 2.8353 (3.0874)  time: 0.6365  data: 0.0002  max mem: 8730
Epoch: [15]  [ 470/2001]  eta: 0:16:19  lr: 0.000318  loss: 2.7392 (3.0810)  time: 0.6325  data: 0.0002  max mem: 8730
Epoch: [15]  [ 480/2001]  eta: 0:16:13  lr: 0.000318  loss: 2.8764 (3.0803)  time: 0.6334  data: 0.0001  max mem: 8730
Epoch: [15]  [ 490/2001]  eta: 0:16:07  lr: 0.000318  loss: 3.2353 (3.0811)  time: 0.6399  data: 0.0002  max mem: 8730
loss info: cls_loss=2.8725, ratio_loss=0.0435, cls_kl=0.0622, token_kl=0.0929
Epoch: [15]  [ 500/2001]  eta: 0:16:00  lr: 0.000318  loss: 3.2007 (3.0787)  time: 0.6407  data: 0.0002  max mem: 8730
Epoch: [15]  [ 510/2001]  eta: 0:15:54  lr: 0.000318  loss: 3.2604 (3.0812)  time: 0.6370  data: 0.0002  max mem: 8730
Epoch: [15]  [ 520/2001]  eta: 0:15:47  lr: 0.000318  loss: 3.2604 (3.0806)  time: 0.6373  data: 0.0001  max mem: 8730
Epoch: [15]  [ 530/2001]  eta: 0:15:41  lr: 0.000318  loss: 3.1460 (3.0786)  time: 0.6367  data: 0.0001  max mem: 8730
Epoch: [15]  [ 540/2001]  eta: 0:15:34  lr: 0.000318  loss: 3.2425 (3.0823)  time: 0.6375  data: 0.0002  max mem: 8730
Epoch: [15]  [ 550/2001]  eta: 0:15:28  lr: 0.000318  loss: 3.3198 (3.0852)  time: 0.6378  data: 0.0002  max mem: 8730
Epoch: [15]  [ 560/2001]  eta: 0:15:22  lr: 0.000318  loss: 2.9319 (3.0822)  time: 0.6412  data: 0.0001  max mem: 8730
Epoch: [15]  [ 570/2001]  eta: 0:15:15  lr: 0.000318  loss: 3.0914 (3.0874)  time: 0.6395  data: 0.0001  max mem: 8730
Epoch: [15]  [ 580/2001]  eta: 0:15:09  lr: 0.000318  loss: 3.2356 (3.0824)  time: 0.6382  data: 0.0001  max mem: 8730
Epoch: [15]  [ 590/2001]  eta: 0:15:02  lr: 0.000318  loss: 3.0661 (3.0832)  time: 0.6375  data: 0.0002  max mem: 8730
loss info: cls_loss=3.0129, ratio_loss=0.0500, cls_kl=0.0672, token_kl=0.0959
Epoch: [15]  [ 600/2001]  eta: 0:14:55  lr: 0.000318  loss: 3.0880 (3.0834)  time: 0.6324  data: 0.0001  max mem: 8730
Epoch: [15]  [ 610/2001]  eta: 0:14:49  lr: 0.000318  loss: 2.9454 (3.0807)  time: 0.6332  data: 0.0001  max mem: 8730
Epoch: [15]  [ 620/2001]  eta: 0:14:42  lr: 0.000318  loss: 3.0903 (3.0824)  time: 0.6349  data: 0.0002  max mem: 8730
Epoch: [15]  [ 630/2001]  eta: 0:14:36  lr: 0.000318  loss: 3.1661 (3.0784)  time: 0.6358  data: 0.0001  max mem: 8730
Epoch: [15]  [ 640/2001]  eta: 0:14:30  lr: 0.000318  loss: 3.1632 (3.0799)  time: 0.6359  data: 0.0002  max mem: 8730
Epoch: [15]  [ 650/2001]  eta: 0:14:23  lr: 0.000318  loss: 3.1075 (3.0802)  time: 0.6441  data: 0.0002  max mem: 8730
Epoch: [15]  [ 660/2001]  eta: 0:14:17  lr: 0.000318  loss: 3.0435 (3.0771)  time: 0.6436  data: 0.0001  max mem: 8730
Epoch: [15]  [ 670/2001]  eta: 0:14:11  lr: 0.000318  loss: 3.0871 (3.0757)  time: 0.6366  data: 0.0001  max mem: 8730
Epoch: [15]  [ 680/2001]  eta: 0:14:04  lr: 0.000318  loss: 3.0871 (3.0716)  time: 0.6353  data: 0.0001  max mem: 8730
Epoch: [15]  [ 690/2001]  eta: 0:13:57  lr: 0.000318  loss: 2.7637 (3.0673)  time: 0.6305  data: 0.0002  max mem: 8730
loss info: cls_loss=2.8749, ratio_loss=0.0463, cls_kl=0.0603, token_kl=0.0909
Epoch: [15]  [ 700/2001]  eta: 0:13:51  lr: 0.000318  loss: 3.0589 (3.0693)  time: 0.6355  data: 0.0001  max mem: 8730
Epoch: [15]  [ 710/2001]  eta: 0:13:45  lr: 0.000318  loss: 3.2687 (3.0712)  time: 0.6413  data: 0.0001  max mem: 8730
Epoch: [15]  [ 720/2001]  eta: 0:13:38  lr: 0.000318  loss: 3.2828 (3.0750)  time: 0.6377  data: 0.0001  max mem: 8730
Epoch: [15]  [ 730/2001]  eta: 0:13:32  lr: 0.000318  loss: 3.2625 (3.0750)  time: 0.6324  data: 0.0001  max mem: 8730
Epoch: [15]  [ 740/2001]  eta: 0:13:25  lr: 0.000318  loss: 3.0115 (3.0711)  time: 0.6329  data: 0.0001  max mem: 8730
Epoch: [15]  [ 750/2001]  eta: 0:13:19  lr: 0.000318  loss: 2.8732 (3.0682)  time: 0.6359  data: 0.0003  max mem: 8730
Epoch: [15]  [ 760/2001]  eta: 0:13:12  lr: 0.000318  loss: 2.9465 (3.0679)  time: 0.6381  data: 0.0003  max mem: 8730
Epoch: [15]  [ 770/2001]  eta: 0:13:06  lr: 0.000318  loss: 2.9955 (3.0675)  time: 0.6375  data: 0.0002  max mem: 8730
Epoch: [15]  [ 780/2001]  eta: 0:13:00  lr: 0.000318  loss: 3.2719 (3.0689)  time: 0.6362  data: 0.0002  max mem: 8730
Epoch: [15]  [ 790/2001]  eta: 0:12:53  lr: 0.000318  loss: 3.3840 (3.0722)  time: 0.6358  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9694, ratio_loss=0.0456, cls_kl=0.0638, token_kl=0.0921
Epoch: [15]  [ 800/2001]  eta: 0:12:47  lr: 0.000318  loss: 3.1984 (3.0709)  time: 0.6385  data: 0.0001  max mem: 8730
Epoch: [15]  [ 810/2001]  eta: 0:12:40  lr: 0.000318  loss: 3.1546 (3.0711)  time: 0.6411  data: 0.0002  max mem: 8730
Epoch: [15]  [ 820/2001]  eta: 0:12:34  lr: 0.000318  loss: 2.9777 (3.0696)  time: 0.6408  data: 0.0002  max mem: 8730
Epoch: [15]  [ 830/2001]  eta: 0:12:28  lr: 0.000318  loss: 2.9696 (3.0685)  time: 0.6384  data: 0.0002  max mem: 8730
Epoch: [15]  [ 840/2001]  eta: 0:12:21  lr: 0.000318  loss: 3.1493 (3.0687)  time: 0.6399  data: 0.0002  max mem: 8730
Epoch: [15]  [ 850/2001]  eta: 0:12:15  lr: 0.000318  loss: 2.9933 (3.0654)  time: 0.6469  data: 0.0002  max mem: 8730
Epoch: [15]  [ 860/2001]  eta: 0:12:09  lr: 0.000318  loss: 2.8528 (3.0636)  time: 0.6454  data: 0.0002  max mem: 8730
Epoch: [15]  [ 870/2001]  eta: 0:12:02  lr: 0.000318  loss: 3.0527 (3.0641)  time: 0.6436  data: 0.0002  max mem: 8730
Epoch: [15]  [ 880/2001]  eta: 0:11:56  lr: 0.000318  loss: 3.1581 (3.0630)  time: 0.6413  data: 0.0001  max mem: 8730
Epoch: [15]  [ 890/2001]  eta: 0:11:50  lr: 0.000318  loss: 2.9646 (3.0614)  time: 0.6373  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8862, ratio_loss=0.0490, cls_kl=0.0633, token_kl=0.0956
Epoch: [15]  [ 900/2001]  eta: 0:11:43  lr: 0.000318  loss: 2.9816 (3.0611)  time: 0.6375  data: 0.0001  max mem: 8730
Epoch: [15]  [ 910/2001]  eta: 0:11:37  lr: 0.000318  loss: 3.1513 (3.0584)  time: 0.6371  data: 0.0001  max mem: 8730
Epoch: [15]  [ 920/2001]  eta: 0:11:31  lr: 0.000318  loss: 3.1513 (3.0603)  time: 0.6451  data: 0.0002  max mem: 8730
Epoch: [15]  [ 930/2001]  eta: 0:11:24  lr: 0.000318  loss: 3.1562 (3.0594)  time: 0.6455  data: 0.0002  max mem: 8730
Epoch: [15]  [ 940/2001]  eta: 0:11:18  lr: 0.000318  loss: 3.1364 (3.0594)  time: 0.6413  data: 0.0001  max mem: 8730
Epoch: [15]  [ 950/2001]  eta: 0:11:11  lr: 0.000318  loss: 3.0989 (3.0575)  time: 0.6405  data: 0.0001  max mem: 8730
Epoch: [15]  [ 960/2001]  eta: 0:11:05  lr: 0.000318  loss: 3.0543 (3.0579)  time: 0.6403  data: 0.0001  max mem: 8730
Epoch: [15]  [ 970/2001]  eta: 0:10:59  lr: 0.000318  loss: 3.1025 (3.0577)  time: 0.6406  data: 0.0002  max mem: 8730
Epoch: [15]  [ 980/2001]  eta: 0:10:52  lr: 0.000318  loss: 3.1308 (3.0580)  time: 0.6373  data: 0.0002  max mem: 8730
Epoch: [15]  [ 990/2001]  eta: 0:10:46  lr: 0.000318  loss: 3.0769 (3.0566)  time: 0.6396  data: 0.0002  max mem: 8730
loss info: cls_loss=2.8765, ratio_loss=0.0451, cls_kl=0.0618, token_kl=0.0937
Epoch: [15]  [1000/2001]  eta: 0:10:39  lr: 0.000318  loss: 2.8284 (3.0524)  time: 0.6398  data: 0.0002  max mem: 8730
Epoch: [15]  [1010/2001]  eta: 0:10:33  lr: 0.000318  loss: 2.7196 (3.0517)  time: 0.6423  data: 0.0002  max mem: 8730
Epoch: [15]  [1020/2001]  eta: 0:10:27  lr: 0.000318  loss: 3.1465 (3.0536)  time: 0.6425  data: 0.0002  max mem: 8730
Epoch: [15]  [1030/2001]  eta: 0:10:20  lr: 0.000318  loss: 3.1178 (3.0531)  time: 0.6401  data: 0.0002  max mem: 8730
Epoch: [15]  [1040/2001]  eta: 0:10:14  lr: 0.000318  loss: 3.0533 (3.0509)  time: 0.6382  data: 0.0002  max mem: 8730
Epoch: [15]  [1050/2001]  eta: 0:10:07  lr: 0.000318  loss: 3.1875 (3.0517)  time: 0.6358  data: 0.0002  max mem: 8730
Epoch: [15]  [1060/2001]  eta: 0:10:01  lr: 0.000318  loss: 3.3721 (3.0531)  time: 0.6375  data: 0.0002  max mem: 8730
Epoch: [15]  [1070/2001]  eta: 0:09:55  lr: 0.000318  loss: 3.1194 (3.0521)  time: 0.6444  data: 0.0002  max mem: 8730
Epoch: [15]  [1080/2001]  eta: 0:09:48  lr: 0.000318  loss: 2.8578 (3.0497)  time: 0.6440  data: 0.0002  max mem: 8730
Epoch: [15]  [1090/2001]  eta: 0:09:42  lr: 0.000318  loss: 3.0927 (3.0514)  time: 0.6399  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9115, ratio_loss=0.0425, cls_kl=0.0610, token_kl=0.0893
Epoch: [15]  [1100/2001]  eta: 0:09:36  lr: 0.000318  loss: 3.0927 (3.0504)  time: 0.6407  data: 0.0002  max mem: 8730
Epoch: [15]  [1110/2001]  eta: 0:09:29  lr: 0.000318  loss: 2.9992 (3.0494)  time: 0.6367  data: 0.0002  max mem: 8730
Epoch: [15]  [1120/2001]  eta: 0:09:23  lr: 0.000318  loss: 3.0951 (3.0488)  time: 0.6386  data: 0.0002  max mem: 8730
Epoch: [15]  [1130/2001]  eta: 0:09:16  lr: 0.000318  loss: 3.1874 (3.0502)  time: 0.6423  data: 0.0002  max mem: 8730
Epoch: [15]  [1140/2001]  eta: 0:09:10  lr: 0.000318  loss: 3.1874 (3.0492)  time: 0.6424  data: 0.0001  max mem: 8730
Epoch: [15]  [1150/2001]  eta: 0:09:04  lr: 0.000318  loss: 3.3464 (3.0526)  time: 0.6436  data: 0.0001  max mem: 8730
Epoch: [15]  [1160/2001]  eta: 0:08:57  lr: 0.000318  loss: 3.4332 (3.0554)  time: 0.6387  data: 0.0001  max mem: 8730
Epoch: [15]  [1170/2001]  eta: 0:08:51  lr: 0.000318  loss: 3.3807 (3.0565)  time: 0.6341  data: 0.0001  max mem: 8730
Epoch: [15]  [1180/2001]  eta: 0:08:44  lr: 0.000318  loss: 3.2556 (3.0564)  time: 0.6351  data: 0.0001  max mem: 8730
Epoch: [15]  [1190/2001]  eta: 0:08:38  lr: 0.000318  loss: 3.1292 (3.0542)  time: 0.6344  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9781, ratio_loss=0.0488, cls_kl=0.0652, token_kl=0.0932
Epoch: [15]  [1200/2001]  eta: 0:08:32  lr: 0.000318  loss: 3.0022 (3.0544)  time: 0.6334  data: 0.0001  max mem: 8730
Epoch: [15]  [1210/2001]  eta: 0:08:25  lr: 0.000318  loss: 3.1242 (3.0535)  time: 0.6333  data: 0.0001  max mem: 8730
Epoch: [15]  [1220/2001]  eta: 0:08:19  lr: 0.000318  loss: 3.1503 (3.0561)  time: 0.6319  data: 0.0001  max mem: 8730
Epoch: [15]  [1230/2001]  eta: 0:08:12  lr: 0.000318  loss: 3.2958 (3.0564)  time: 0.6400  data: 0.0001  max mem: 8730
Epoch: [15]  [1240/2001]  eta: 0:08:06  lr: 0.000318  loss: 3.2172 (3.0573)  time: 0.6437  data: 0.0001  max mem: 8730
Epoch: [15]  [1250/2001]  eta: 0:08:00  lr: 0.000318  loss: 3.2172 (3.0567)  time: 0.6417  data: 0.0001  max mem: 8730
Epoch: [15]  [1260/2001]  eta: 0:07:53  lr: 0.000318  loss: 3.2404 (3.0579)  time: 0.6406  data: 0.0002  max mem: 8730
Epoch: [15]  [1270/2001]  eta: 0:07:47  lr: 0.000318  loss: 3.2404 (3.0588)  time: 0.6403  data: 0.0002  max mem: 8730
Epoch: [15]  [1280/2001]  eta: 0:07:40  lr: 0.000318  loss: 3.0421 (3.0563)  time: 0.6437  data: 0.0002  max mem: 8730
Epoch: [15]  [1290/2001]  eta: 0:07:34  lr: 0.000318  loss: 2.9942 (3.0578)  time: 0.6366  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9748, ratio_loss=0.0479, cls_kl=0.0657, token_kl=0.0944
Epoch: [15]  [1300/2001]  eta: 0:07:28  lr: 0.000318  loss: 3.1576 (3.0578)  time: 0.6338  data: 0.0001  max mem: 8730
Epoch: [15]  [1310/2001]  eta: 0:07:21  lr: 0.000318  loss: 2.9683 (3.0576)  time: 0.6333  data: 0.0001  max mem: 8730
Epoch: [15]  [1320/2001]  eta: 0:07:15  lr: 0.000318  loss: 2.9683 (3.0574)  time: 0.6319  data: 0.0001  max mem: 8730
Epoch: [15]  [1330/2001]  eta: 0:07:08  lr: 0.000318  loss: 2.8835 (3.0557)  time: 0.6295  data: 0.0001  max mem: 8730
Epoch: [15]  [1340/2001]  eta: 0:07:02  lr: 0.000318  loss: 3.1312 (3.0568)  time: 0.6365  data: 0.0001  max mem: 8730
Epoch: [15]  [1350/2001]  eta: 0:06:56  lr: 0.000318  loss: 3.2236 (3.0576)  time: 0.6428  data: 0.0002  max mem: 8730
Epoch: [15]  [1360/2001]  eta: 0:06:49  lr: 0.000318  loss: 3.2236 (3.0574)  time: 0.6350  data: 0.0001  max mem: 8730
Epoch: [15]  [1370/2001]  eta: 0:06:43  lr: 0.000318  loss: 3.1015 (3.0575)  time: 0.6287  data: 0.0001  max mem: 8730
Epoch: [15]  [1380/2001]  eta: 0:06:36  lr: 0.000318  loss: 3.0922 (3.0565)  time: 0.6316  data: 0.0001  max mem: 8730
Epoch: [15]  [1390/2001]  eta: 0:06:30  lr: 0.000318  loss: 3.1550 (3.0580)  time: 0.6332  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9342, ratio_loss=0.0497, cls_kl=0.0646, token_kl=0.0948
Epoch: [15]  [1400/2001]  eta: 0:06:23  lr: 0.000318  loss: 3.0664 (3.0560)  time: 0.6287  data: 0.0001  max mem: 8730
Epoch: [15]  [1410/2001]  eta: 0:06:17  lr: 0.000318  loss: 2.9333 (3.0562)  time: 0.6282  data: 0.0001  max mem: 8730
Epoch: [15]  [1420/2001]  eta: 0:06:11  lr: 0.000318  loss: 3.0579 (3.0565)  time: 0.6328  data: 0.0001  max mem: 8730
Epoch: [15]  [1430/2001]  eta: 0:06:04  lr: 0.000318  loss: 3.0600 (3.0569)  time: 0.6329  data: 0.0001  max mem: 8730
Epoch: [15]  [1440/2001]  eta: 0:05:58  lr: 0.000318  loss: 3.0247 (3.0557)  time: 0.6327  data: 0.0001  max mem: 8730
Epoch: [15]  [1450/2001]  eta: 0:05:51  lr: 0.000318  loss: 2.7578 (3.0544)  time: 0.6296  data: 0.0001  max mem: 8730
Epoch: [15]  [1460/2001]  eta: 0:05:45  lr: 0.000318  loss: 3.0673 (3.0550)  time: 0.6193  data: 0.0002  max mem: 8730
Epoch: [15]  [1470/2001]  eta: 0:05:38  lr: 0.000318  loss: 3.2286 (3.0562)  time: 0.6227  data: 0.0002  max mem: 8730
Epoch: [15]  [1480/2001]  eta: 0:05:32  lr: 0.000318  loss: 3.2218 (3.0569)  time: 0.6266  data: 0.0001  max mem: 8730
Epoch: [15]  [1490/2001]  eta: 0:05:26  lr: 0.000318  loss: 3.1400 (3.0558)  time: 0.6250  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9324, ratio_loss=0.0467, cls_kl=0.0642, token_kl=0.0927
Epoch: [15]  [1500/2001]  eta: 0:05:19  lr: 0.000318  loss: 2.9835 (3.0551)  time: 0.6270  data: 0.0001  max mem: 8730
Epoch: [15]  [1510/2001]  eta: 0:05:13  lr: 0.000318  loss: 3.0150 (3.0549)  time: 0.6271  data: 0.0001  max mem: 8730
Epoch: [15]  [1520/2001]  eta: 0:05:06  lr: 0.000318  loss: 3.0150 (3.0534)  time: 0.6281  data: 0.0001  max mem: 8730
Epoch: [15]  [1530/2001]  eta: 0:05:00  lr: 0.000318  loss: 3.0872 (3.0541)  time: 0.6254  data: 0.0001  max mem: 8730
Epoch: [15]  [1540/2001]  eta: 0:04:53  lr: 0.000318  loss: 3.2536 (3.0554)  time: 0.6253  data: 0.0001  max mem: 8730
Epoch: [15]  [1550/2001]  eta: 0:04:47  lr: 0.000318  loss: 3.1598 (3.0553)  time: 0.6324  data: 0.0001  max mem: 8730
Epoch: [15]  [1560/2001]  eta: 0:04:41  lr: 0.000318  loss: 2.8055 (3.0520)  time: 0.6285  data: 0.0001  max mem: 8730
Epoch: [15]  [1570/2001]  eta: 0:04:34  lr: 0.000318  loss: 2.8393 (3.0524)  time: 0.6341  data: 0.0001  max mem: 8730
Epoch: [15]  [1580/2001]  eta: 0:04:28  lr: 0.000318  loss: 3.1903 (3.0530)  time: 0.6314  data: 0.0001  max mem: 8730
Epoch: [15]  [1590/2001]  eta: 0:04:22  lr: 0.000318  loss: 3.1903 (3.0529)  time: 0.6252  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9151, ratio_loss=0.0459, cls_kl=0.0628, token_kl=0.0917
Epoch: [15]  [1600/2001]  eta: 0:04:15  lr: 0.000318  loss: 2.9553 (3.0527)  time: 0.6267  data: 0.0001  max mem: 8730
Epoch: [15]  [1610/2001]  eta: 0:04:09  lr: 0.000318  loss: 3.0707 (3.0530)  time: 0.6252  data: 0.0001  max mem: 8730
Epoch: [15]  [1620/2001]  eta: 0:04:02  lr: 0.000318  loss: 3.2341 (3.0523)  time: 0.6296  data: 0.0001  max mem: 8730
Epoch: [15]  [1630/2001]  eta: 0:03:56  lr: 0.000318  loss: 3.3190 (3.0541)  time: 0.6283  data: 0.0001  max mem: 8730
Epoch: [15]  [1640/2001]  eta: 0:03:50  lr: 0.000318  loss: 3.2853 (3.0531)  time: 0.6263  data: 0.0001  max mem: 8730
Epoch: [15]  [1650/2001]  eta: 0:03:43  lr: 0.000318  loss: 2.9430 (3.0534)  time: 0.6250  data: 0.0001  max mem: 8730
Epoch: [15]  [1660/2001]  eta: 0:03:37  lr: 0.000318  loss: 3.2819 (3.0552)  time: 0.6257  data: 0.0001  max mem: 8730
Epoch: [15]  [1670/2001]  eta: 0:03:30  lr: 0.000318  loss: 3.2986 (3.0557)  time: 0.6239  data: 0.0001  max mem: 8730
Epoch: [15]  [1680/2001]  eta: 0:03:24  lr: 0.000318  loss: 3.1109 (3.0550)  time: 0.6236  data: 0.0001  max mem: 8730
Epoch: [15]  [1690/2001]  eta: 0:03:18  lr: 0.000318  loss: 3.1109 (3.0558)  time: 0.6283  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0018, ratio_loss=0.0475, cls_kl=0.0646, token_kl=0.0925
Epoch: [15]  [1700/2001]  eta: 0:03:11  lr: 0.000318  loss: 3.2999 (3.0570)  time: 0.6266  data: 0.0001  max mem: 8730
Epoch: [15]  [1710/2001]  eta: 0:03:05  lr: 0.000318  loss: 3.2593 (3.0568)  time: 0.6300  data: 0.0001  max mem: 8730
Epoch: [15]  [1720/2001]  eta: 0:02:58  lr: 0.000318  loss: 2.6994 (3.0537)  time: 0.6360  data: 0.0001  max mem: 8730
Epoch: [15]  [1730/2001]  eta: 0:02:52  lr: 0.000318  loss: 2.8440 (3.0542)  time: 0.6322  data: 0.0001  max mem: 8730
Epoch: [15]  [1740/2001]  eta: 0:02:46  lr: 0.000318  loss: 3.1935 (3.0538)  time: 0.6232  data: 0.0001  max mem: 8730
Epoch: [15]  [1750/2001]  eta: 0:02:39  lr: 0.000318  loss: 3.1178 (3.0543)  time: 0.6217  data: 0.0001  max mem: 8730
Epoch: [15]  [1760/2001]  eta: 0:02:33  lr: 0.000318  loss: 3.1801 (3.0540)  time: 0.6259  data: 0.0001  max mem: 8730
Epoch: [15]  [1770/2001]  eta: 0:02:27  lr: 0.000318  loss: 3.0003 (3.0533)  time: 0.6279  data: 0.0001  max mem: 8730
Epoch: [15]  [1780/2001]  eta: 0:02:20  lr: 0.000318  loss: 2.9511 (3.0537)  time: 0.6275  data: 0.0001  max mem: 8730
Epoch: [15]  [1790/2001]  eta: 0:02:14  lr: 0.000318  loss: 2.9511 (3.0539)  time: 0.6301  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8728, ratio_loss=0.0438, cls_kl=0.0626, token_kl=0.0927
Epoch: [15]  [1800/2001]  eta: 0:02:07  lr: 0.000318  loss: 2.9865 (3.0528)  time: 0.6303  data: 0.0001  max mem: 8730
Epoch: [15]  [1810/2001]  eta: 0:02:01  lr: 0.000318  loss: 3.0417 (3.0524)  time: 0.6336  data: 0.0001  max mem: 8730
Epoch: [15]  [1820/2001]  eta: 0:01:55  lr: 0.000318  loss: 3.0722 (3.0528)  time: 0.6376  data: 0.0001  max mem: 8730
Epoch: [15]  [1830/2001]  eta: 0:01:48  lr: 0.000318  loss: 3.0599 (3.0524)  time: 0.6299  data: 0.0001  max mem: 8730
Epoch: [15]  [1840/2001]  eta: 0:01:42  lr: 0.000318  loss: 3.2758 (3.0541)  time: 0.6277  data: 0.0001  max mem: 8730
Epoch: [15]  [1850/2001]  eta: 0:01:36  lr: 0.000318  loss: 3.1658 (3.0533)  time: 0.6314  data: 0.0002  max mem: 8730
Epoch: [15]  [1860/2001]  eta: 0:01:29  lr: 0.000318  loss: 3.0559 (3.0528)  time: 0.6301  data: 0.0001  max mem: 8730
Epoch: [15]  [1870/2001]  eta: 0:01:23  lr: 0.000318  loss: 3.2767 (3.0549)  time: 0.6337  data: 0.0001  max mem: 8730
Epoch: [15]  [1880/2001]  eta: 0:01:16  lr: 0.000318  loss: 3.4141 (3.0554)  time: 0.6361  data: 0.0001  max mem: 8730
Epoch: [15]  [1890/2001]  eta: 0:01:10  lr: 0.000318  loss: 3.2192 (3.0549)  time: 0.6380  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9873, ratio_loss=0.0493, cls_kl=0.0660, token_kl=0.0946
Epoch: [15]  [1900/2001]  eta: 0:01:04  lr: 0.000318  loss: 3.1815 (3.0554)  time: 0.6333  data: 0.0001  max mem: 8730
Epoch: [15]  [1910/2001]  eta: 0:00:57  lr: 0.000318  loss: 2.9326 (3.0555)  time: 0.6258  data: 0.0001  max mem: 8730
Epoch: [15]  [1920/2001]  eta: 0:00:51  lr: 0.000318  loss: 2.9326 (3.0547)  time: 0.6279  data: 0.0001  max mem: 8730
Epoch: [15]  [1930/2001]  eta: 0:00:45  lr: 0.000318  loss: 2.9581 (3.0545)  time: 0.6295  data: 0.0001  max mem: 8730
Epoch: [15]  [1940/2001]  eta: 0:00:38  lr: 0.000318  loss: 3.1596 (3.0548)  time: 0.6347  data: 0.0001  max mem: 8730
Epoch: [15]  [1950/2001]  eta: 0:00:32  lr: 0.000318  loss: 2.9714 (3.0540)  time: 0.6373  data: 0.0001  max mem: 8730
Epoch: [15]  [1960/2001]  eta: 0:00:26  lr: 0.000318  loss: 2.8805 (3.0538)  time: 0.6339  data: 0.0001  max mem: 8730
Epoch: [15]  [1970/2001]  eta: 0:00:19  lr: 0.000318  loss: 2.9004 (3.0519)  time: 0.6307  data: 0.0001  max mem: 8730
Epoch: [15]  [1980/2001]  eta: 0:00:13  lr: 0.000318  loss: 3.0286 (3.0524)  time: 0.6351  data: 0.0001  max mem: 8730
Epoch: [15]  [1990/2001]  eta: 0:00:06  lr: 0.000318  loss: 3.0525 (3.0516)  time: 0.6343  data: 0.0002  max mem: 8730
loss info: cls_loss=2.8742, ratio_loss=0.0463, cls_kl=0.0606, token_kl=0.0903
Epoch: [15]  [2000/2001]  eta: 0:00:00  lr: 0.000318  loss: 2.9505 (3.0513)  time: 0.6279  data: 0.0002  max mem: 8730
Epoch: [15] Total time: 0:21:13 (0.6362 s / it)
Averaged stats: lr: 0.000318  loss: 2.9505 (3.0578)
Test:  [ 0/53]  eta: 0:04:32  loss: 0.4030 (0.4030)  acc1: 91.6667 (91.6667)  acc5: 98.3333 (98.3333)  time: 5.1376  data: 4.6699  max mem: 8730
Test:  [10/53]  eta: 0:00:35  loss: 0.6930 (0.7645)  acc1: 84.1667 (83.1061)  acc5: 96.6667 (96.4394)  time: 0.8246  data: 0.4437  max mem: 8730
Test:  [20/53]  eta: 0:00:20  loss: 0.7173 (0.7701)  acc1: 83.3333 (82.6984)  acc5: 96.6667 (96.7064)  time: 0.3947  data: 0.0107  max mem: 8730
Test:  [30/53]  eta: 0:00:12  loss: 0.8940 (0.8556)  acc1: 78.3333 (80.6183)  acc5: 94.1667 (95.5108)  time: 0.3707  data: 0.0002  max mem: 8730
Test:  [40/53]  eta: 0:00:06  loss: 1.1094 (0.9171)  acc1: 75.8333 (79.1057)  acc5: 91.6667 (94.7764)  time: 0.3122  data: 0.0002  max mem: 8730
Test:  [50/53]  eta: 0:00:01  loss: 1.1094 (0.9470)  acc1: 75.8333 (78.3824)  acc5: 92.5000 (94.5098)  time: 0.2659  data: 0.0001  max mem: 8730
Test:  [52/53]  eta: 0:00:00  loss: 1.1045 (0.9316)  acc1: 75.8333 (78.5440)  acc5: 93.3333 (94.5760)  time: 0.2491  data: 0.0000  max mem: 8730
Test: Total time: 0:00:22 (0.4195 s / it)
Sparsity0:0.29823838383838386,Sparsity1:0.554091256281407,Sparsity2:0.785372,
* Acc@1 79.000 Acc@5 94.608 loss 0.939
Accuracy of the network on the 50000 test images: 79.0%
Max accuracy: 79.07%
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0002854 for PREDICTOR
Epoch: [16]  [   0/2001]  eta: 2:36:06  lr: 0.000285  loss: 3.2804 (3.2804)  time: 4.6811  data: 2.7435  max mem: 8730
Epoch: [16]  [  10/2001]  eta: 0:32:42  lr: 0.000285  loss: 3.2127 (2.9962)  time: 0.9857  data: 0.2496  max mem: 8730
Epoch: [16]  [  20/2001]  eta: 0:26:53  lr: 0.000285  loss: 2.9935 (2.9776)  time: 0.6211  data: 0.0001  max mem: 8730
Epoch: [16]  [  30/2001]  eta: 0:24:39  lr: 0.000285  loss: 3.0164 (2.9875)  time: 0.6212  data: 0.0001  max mem: 8730
Epoch: [16]  [  40/2001]  eta: 0:23:36  lr: 0.000285  loss: 3.0412 (2.9981)  time: 0.6254  data: 0.0002  max mem: 8730
Epoch: [16]  [  50/2001]  eta: 0:22:52  lr: 0.000285  loss: 2.9267 (2.9347)  time: 0.6310  data: 0.0002  max mem: 8730
Epoch: [16]  [  60/2001]  eta: 0:22:21  lr: 0.000285  loss: 3.0261 (2.9738)  time: 0.6276  data: 0.0002  max mem: 8730
Epoch: [16]  [  70/2001]  eta: 0:21:58  lr: 0.000285  loss: 3.2789 (2.9883)  time: 0.6293  data: 0.0001  max mem: 8730
Epoch: [16]  [  80/2001]  eta: 0:21:40  lr: 0.000285  loss: 3.2550 (3.0097)  time: 0.6334  data: 0.0002  max mem: 8730
Epoch: [16]  [  90/2001]  eta: 0:21:24  lr: 0.000285  loss: 3.3493 (3.0455)  time: 0.6351  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9309, ratio_loss=0.0471, cls_kl=0.0636, token_kl=0.0934
Epoch: [16]  [ 100/2001]  eta: 0:21:10  lr: 0.000285  loss: 3.2802 (3.0375)  time: 0.6349  data: 0.0001  max mem: 8730
Epoch: [16]  [ 110/2001]  eta: 0:20:59  lr: 0.000285  loss: 3.1194 (3.0392)  time: 0.6390  data: 0.0001  max mem: 8730
Epoch: [16]  [ 120/2001]  eta: 0:20:48  lr: 0.000285  loss: 3.1194 (3.0415)  time: 0.6391  data: 0.0002  max mem: 8730
Epoch: [16]  [ 130/2001]  eta: 0:20:37  lr: 0.000285  loss: 3.1158 (3.0359)  time: 0.6349  data: 0.0002  max mem: 8730
Epoch: [16]  [ 140/2001]  eta: 0:20:27  lr: 0.000285  loss: 3.0579 (3.0405)  time: 0.6343  data: 0.0001  max mem: 8730
Epoch: [16]  [ 150/2001]  eta: 0:20:17  lr: 0.000285  loss: 3.0190 (3.0317)  time: 0.6341  data: 0.0001  max mem: 8730
Epoch: [16]  [ 160/2001]  eta: 0:20:08  lr: 0.000285  loss: 2.9950 (3.0251)  time: 0.6345  data: 0.0002  max mem: 8730
Epoch: [16]  [ 170/2001]  eta: 0:19:59  lr: 0.000285  loss: 3.1581 (3.0302)  time: 0.6341  data: 0.0002  max mem: 8730
Epoch: [16]  [ 180/2001]  eta: 0:19:51  lr: 0.000285  loss: 3.1931 (3.0360)  time: 0.6367  data: 0.0001  max mem: 8730
Epoch: [16]  [ 190/2001]  eta: 0:19:43  lr: 0.000285  loss: 3.2253 (3.0329)  time: 0.6396  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9165, ratio_loss=0.0461, cls_kl=0.0625, token_kl=0.0913
Epoch: [16]  [ 200/2001]  eta: 0:19:35  lr: 0.000285  loss: 3.2478 (3.0411)  time: 0.6414  data: 0.0001  max mem: 8730
Epoch: [16]  [ 210/2001]  eta: 0:19:28  lr: 0.000285  loss: 3.0840 (3.0311)  time: 0.6402  data: 0.0001  max mem: 8730
Epoch: [16]  [ 220/2001]  eta: 0:19:20  lr: 0.000285  loss: 3.0059 (3.0288)  time: 0.6395  data: 0.0001  max mem: 8730
Epoch: [16]  [ 230/2001]  eta: 0:19:13  lr: 0.000285  loss: 2.9412 (3.0230)  time: 0.6435  data: 0.0001  max mem: 8730
Epoch: [16]  [ 240/2001]  eta: 0:19:06  lr: 0.000285  loss: 3.1284 (3.0220)  time: 0.6426  data: 0.0002  max mem: 8730
Epoch: [16]  [ 250/2001]  eta: 0:18:59  lr: 0.000285  loss: 3.1629 (3.0284)  time: 0.6443  data: 0.0002  max mem: 8730
Epoch: [16]  [ 260/2001]  eta: 0:18:53  lr: 0.000285  loss: 3.3536 (3.0385)  time: 0.6495  data: 0.0001  max mem: 8730
Epoch: [16]  [ 270/2001]  eta: 0:18:46  lr: 0.000285  loss: 3.3969 (3.0481)  time: 0.6514  data: 0.0002  max mem: 8730
Epoch: [16]  [ 280/2001]  eta: 0:18:39  lr: 0.000285  loss: 3.2502 (3.0531)  time: 0.6455  data: 0.0002  max mem: 8730
Epoch: [16]  [ 290/2001]  eta: 0:18:32  lr: 0.000285  loss: 2.9213 (3.0514)  time: 0.6382  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9680, ratio_loss=0.0477, cls_kl=0.0660, token_kl=0.0958
Epoch: [16]  [ 300/2001]  eta: 0:18:24  lr: 0.000285  loss: 2.9722 (3.0494)  time: 0.6366  data: 0.0002  max mem: 8730
Epoch: [16]  [ 310/2001]  eta: 0:18:17  lr: 0.000285  loss: 2.9722 (3.0437)  time: 0.6369  data: 0.0002  max mem: 8730
Epoch: [16]  [ 320/2001]  eta: 0:18:10  lr: 0.000285  loss: 3.0662 (3.0462)  time: 0.6385  data: 0.0002  max mem: 8730
Epoch: [16]  [ 330/2001]  eta: 0:18:03  lr: 0.000285  loss: 3.3064 (3.0512)  time: 0.6380  data: 0.0002  max mem: 8730
Epoch: [16]  [ 340/2001]  eta: 0:17:56  lr: 0.000285  loss: 3.0340 (3.0466)  time: 0.6367  data: 0.0002  max mem: 8730
Epoch: [16]  [ 350/2001]  eta: 0:17:49  lr: 0.000285  loss: 2.9805 (3.0491)  time: 0.6383  data: 0.0002  max mem: 8730
Epoch: [16]  [ 360/2001]  eta: 0:17:42  lr: 0.000285  loss: 3.2793 (3.0501)  time: 0.6411  data: 0.0002  max mem: 8730
Epoch: [16]  [ 370/2001]  eta: 0:17:36  lr: 0.000285  loss: 3.3202 (3.0530)  time: 0.6430  data: 0.0002  max mem: 8730
Epoch: [16]  [ 380/2001]  eta: 0:17:29  lr: 0.000285  loss: 3.1523 (3.0538)  time: 0.6423  data: 0.0002  max mem: 8730
Epoch: [16]  [ 390/2001]  eta: 0:17:22  lr: 0.000285  loss: 3.0799 (3.0586)  time: 0.6394  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9803, ratio_loss=0.0470, cls_kl=0.0633, token_kl=0.0931
Epoch: [16]  [ 400/2001]  eta: 0:17:15  lr: 0.000285  loss: 3.2950 (3.0590)  time: 0.6377  data: 0.0001  max mem: 8730
Epoch: [16]  [ 410/2001]  eta: 0:17:08  lr: 0.000285  loss: 3.0444 (3.0558)  time: 0.6357  data: 0.0002  max mem: 8730
Epoch: [16]  [ 420/2001]  eta: 0:17:02  lr: 0.000285  loss: 3.0444 (3.0559)  time: 0.6424  data: 0.0002  max mem: 8730
Epoch: [16]  [ 430/2001]  eta: 0:16:55  lr: 0.000285  loss: 2.9896 (3.0495)  time: 0.6430  data: 0.0002  max mem: 8730
Epoch: [16]  [ 440/2001]  eta: 0:16:48  lr: 0.000285  loss: 3.1173 (3.0547)  time: 0.6372  data: 0.0002  max mem: 8730
Epoch: [16]  [ 450/2001]  eta: 0:16:42  lr: 0.000285  loss: 3.2696 (3.0569)  time: 0.6442  data: 0.0001  max mem: 8730
Epoch: [16]  [ 460/2001]  eta: 0:16:36  lr: 0.000285  loss: 3.1610 (3.0583)  time: 0.6465  data: 0.0001  max mem: 8730
Epoch: [16]  [ 470/2001]  eta: 0:16:29  lr: 0.000285  loss: 3.0926 (3.0538)  time: 0.6480  data: 0.0001  max mem: 8730
Epoch: [16]  [ 480/2001]  eta: 0:16:23  lr: 0.000285  loss: 2.9982 (3.0518)  time: 0.6481  data: 0.0002  max mem: 8730
Epoch: [16]  [ 490/2001]  eta: 0:16:17  lr: 0.000285  loss: 3.1196 (3.0558)  time: 0.6498  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9332, ratio_loss=0.0477, cls_kl=0.0625, token_kl=0.0928
Epoch: [16]  [ 500/2001]  eta: 0:16:10  lr: 0.000285  loss: 3.2137 (3.0579)  time: 0.6463  data: 0.0002  max mem: 8730
Epoch: [16]  [ 510/2001]  eta: 0:16:03  lr: 0.000285  loss: 3.1506 (3.0591)  time: 0.6359  data: 0.0001  max mem: 8730
Epoch: [16]  [ 520/2001]  eta: 0:15:57  lr: 0.000285  loss: 3.0779 (3.0575)  time: 0.6406  data: 0.0002  max mem: 8730
Epoch: [16]  [ 530/2001]  eta: 0:15:50  lr: 0.000285  loss: 3.1285 (3.0604)  time: 0.6454  data: 0.0002  max mem: 8730
Epoch: [16]  [ 540/2001]  eta: 0:15:43  lr: 0.000285  loss: 3.2038 (3.0607)  time: 0.6405  data: 0.0002  max mem: 8730
Epoch: [16]  [ 550/2001]  eta: 0:15:37  lr: 0.000285  loss: 3.2071 (3.0628)  time: 0.6361  data: 0.0002  max mem: 8730
Epoch: [16]  [ 560/2001]  eta: 0:15:30  lr: 0.000285  loss: 3.2286 (3.0652)  time: 0.6373  data: 0.0002  max mem: 8730
Epoch: [16]  [ 570/2001]  eta: 0:15:23  lr: 0.000285  loss: 3.3404 (3.0693)  time: 0.6382  data: 0.0002  max mem: 8730
Epoch: [16]  [ 580/2001]  eta: 0:15:17  lr: 0.000285  loss: 3.2722 (3.0654)  time: 0.6366  data: 0.0001  max mem: 8730
Epoch: [16]  [ 590/2001]  eta: 0:15:10  lr: 0.000285  loss: 3.4149 (3.0700)  time: 0.6362  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0416, ratio_loss=0.0474, cls_kl=0.0647, token_kl=0.0937
Epoch: [16]  [ 600/2001]  eta: 0:15:03  lr: 0.000285  loss: 3.4441 (3.0739)  time: 0.6408  data: 0.0002  max mem: 8730
Epoch: [16]  [ 610/2001]  eta: 0:14:57  lr: 0.000285  loss: 3.2446 (3.0736)  time: 0.6399  data: 0.0002  max mem: 8730
Epoch: [16]  [ 620/2001]  eta: 0:14:50  lr: 0.000285  loss: 3.2441 (3.0740)  time: 0.6428  data: 0.0002  max mem: 8730
Epoch: [16]  [ 630/2001]  eta: 0:14:44  lr: 0.000285  loss: 3.2832 (3.0731)  time: 0.6468  data: 0.0002  max mem: 8730
Epoch: [16]  [ 640/2001]  eta: 0:14:37  lr: 0.000285  loss: 3.2781 (3.0756)  time: 0.6414  data: 0.0002  max mem: 8730
Epoch: [16]  [ 650/2001]  eta: 0:14:31  lr: 0.000285  loss: 3.1320 (3.0732)  time: 0.6416  data: 0.0002  max mem: 8730
Epoch: [16]  [ 660/2001]  eta: 0:14:24  lr: 0.000285  loss: 2.8796 (3.0698)  time: 0.6396  data: 0.0002  max mem: 8730
Epoch: [16]  [ 670/2001]  eta: 0:14:18  lr: 0.000285  loss: 3.0188 (3.0710)  time: 0.6356  data: 0.0002  max mem: 8730
Epoch: [16]  [ 680/2001]  eta: 0:14:11  lr: 0.000285  loss: 3.0188 (3.0665)  time: 0.6359  data: 0.0002  max mem: 8730
Epoch: [16]  [ 690/2001]  eta: 0:14:05  lr: 0.000285  loss: 2.8174 (3.0649)  time: 0.6410  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9155, ratio_loss=0.0454, cls_kl=0.0617, token_kl=0.0926
Epoch: [16]  [ 700/2001]  eta: 0:13:58  lr: 0.000285  loss: 3.2575 (3.0679)  time: 0.6378  data: 0.0002  max mem: 8730
Epoch: [16]  [ 710/2001]  eta: 0:13:51  lr: 0.000285  loss: 3.0066 (3.0655)  time: 0.6304  data: 0.0002  max mem: 8730
Epoch: [16]  [ 720/2001]  eta: 0:13:44  lr: 0.000285  loss: 3.0021 (3.0677)  time: 0.6294  data: 0.0002  max mem: 8730
Epoch: [16]  [ 730/2001]  eta: 0:13:38  lr: 0.000285  loss: 3.1241 (3.0676)  time: 0.6275  data: 0.0002  max mem: 8730
Epoch: [16]  [ 740/2001]  eta: 0:13:31  lr: 0.000285  loss: 3.2866 (3.0715)  time: 0.6309  data: 0.0002  max mem: 8730
Epoch: [16]  [ 750/2001]  eta: 0:13:25  lr: 0.000285  loss: 3.3101 (3.0726)  time: 0.6343  data: 0.0001  max mem: 8730
Epoch: [16]  [ 760/2001]  eta: 0:13:18  lr: 0.000285  loss: 3.1840 (3.0733)  time: 0.6320  data: 0.0001  max mem: 8730
Epoch: [16]  [ 770/2001]  eta: 0:13:11  lr: 0.000285  loss: 3.2296 (3.0751)  time: 0.6287  data: 0.0001  max mem: 8730
Epoch: [16]  [ 780/2001]  eta: 0:13:05  lr: 0.000285  loss: 3.2618 (3.0739)  time: 0.6285  data: 0.0001  max mem: 8730
Epoch: [16]  [ 790/2001]  eta: 0:12:58  lr: 0.000285  loss: 3.2226 (3.0767)  time: 0.6332  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0410, ratio_loss=0.0481, cls_kl=0.0652, token_kl=0.0926
Epoch: [16]  [ 800/2001]  eta: 0:12:51  lr: 0.000285  loss: 3.2178 (3.0757)  time: 0.6343  data: 0.0001  max mem: 8730
Epoch: [16]  [ 810/2001]  eta: 0:12:45  lr: 0.000285  loss: 2.9623 (3.0744)  time: 0.6300  data: 0.0001  max mem: 8730
Epoch: [16]  [ 820/2001]  eta: 0:12:38  lr: 0.000285  loss: 3.0394 (3.0757)  time: 0.6231  data: 0.0001  max mem: 8730
Epoch: [16]  [ 830/2001]  eta: 0:12:31  lr: 0.000285  loss: 3.1802 (3.0765)  time: 0.6229  data: 0.0001  max mem: 8730
Epoch: [16]  [ 840/2001]  eta: 0:12:25  lr: 0.000285  loss: 3.0880 (3.0766)  time: 0.6328  data: 0.0001  max mem: 8730
Epoch: [16]  [ 850/2001]  eta: 0:12:18  lr: 0.000285  loss: 3.1099 (3.0767)  time: 0.6339  data: 0.0002  max mem: 8730
Epoch: [16]  [ 860/2001]  eta: 0:12:12  lr: 0.000285  loss: 3.1099 (3.0761)  time: 0.6281  data: 0.0002  max mem: 8730
Epoch: [16]  [ 870/2001]  eta: 0:12:05  lr: 0.000285  loss: 3.0172 (3.0746)  time: 0.6313  data: 0.0002  max mem: 8730
Epoch: [16]  [ 880/2001]  eta: 0:11:59  lr: 0.000285  loss: 3.2001 (3.0740)  time: 0.6327  data: 0.0001  max mem: 8730
Epoch: [16]  [ 890/2001]  eta: 0:11:52  lr: 0.000285  loss: 3.1120 (3.0706)  time: 0.6314  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9162, ratio_loss=0.0460, cls_kl=0.0619, token_kl=0.0906
Epoch: [16]  [ 900/2001]  eta: 0:11:46  lr: 0.000285  loss: 2.8307 (3.0684)  time: 0.6317  data: 0.0001  max mem: 8730
Epoch: [16]  [ 910/2001]  eta: 0:11:39  lr: 0.000285  loss: 3.2381 (3.0717)  time: 0.6283  data: 0.0001  max mem: 8730
Epoch: [16]  [ 920/2001]  eta: 0:11:33  lr: 0.000285  loss: 3.2168 (3.0709)  time: 0.6338  data: 0.0001  max mem: 8730
Epoch: [16]  [ 930/2001]  eta: 0:11:26  lr: 0.000285  loss: 3.0152 (3.0724)  time: 0.6310  data: 0.0001  max mem: 8730
Epoch: [16]  [ 940/2001]  eta: 0:11:19  lr: 0.000285  loss: 3.0928 (3.0717)  time: 0.6228  data: 0.0001  max mem: 8730
Epoch: [16]  [ 950/2001]  eta: 0:11:13  lr: 0.000285  loss: 2.8640 (3.0702)  time: 0.6274  data: 0.0001  max mem: 8730
Epoch: [16]  [ 960/2001]  eta: 0:11:06  lr: 0.000285  loss: 3.3428 (3.0739)  time: 0.6306  data: 0.0001  max mem: 8730
Epoch: [16]  [ 970/2001]  eta: 0:11:00  lr: 0.000285  loss: 3.3754 (3.0752)  time: 0.6277  data: 0.0001  max mem: 8730
Epoch: [16]  [ 980/2001]  eta: 0:10:53  lr: 0.000285  loss: 3.0247 (3.0732)  time: 0.6250  data: 0.0002  max mem: 8730
Epoch: [16]  [ 990/2001]  eta: 0:10:47  lr: 0.000285  loss: 3.0021 (3.0728)  time: 0.6240  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9823, ratio_loss=0.0485, cls_kl=0.0669, token_kl=0.0959
Epoch: [16]  [1000/2001]  eta: 0:10:40  lr: 0.000285  loss: 2.9971 (3.0697)  time: 0.6255  data: 0.0002  max mem: 8730
Epoch: [16]  [1010/2001]  eta: 0:10:34  lr: 0.000285  loss: 2.9118 (3.0685)  time: 0.6266  data: 0.0001  max mem: 8730
Epoch: [16]  [1020/2001]  eta: 0:10:27  lr: 0.000285  loss: 3.1556 (3.0696)  time: 0.6248  data: 0.0001  max mem: 8730
Epoch: [16]  [1030/2001]  eta: 0:10:20  lr: 0.000285  loss: 3.1615 (3.0700)  time: 0.6280  data: 0.0001  max mem: 8730
Epoch: [16]  [1040/2001]  eta: 0:10:14  lr: 0.000285  loss: 3.0408 (3.0685)  time: 0.6303  data: 0.0001  max mem: 8730
Epoch: [16]  [1050/2001]  eta: 0:10:08  lr: 0.000285  loss: 2.8402 (3.0664)  time: 0.6320  data: 0.0001  max mem: 8730
Epoch: [16]  [1060/2001]  eta: 0:10:01  lr: 0.000285  loss: 3.0648 (3.0651)  time: 0.6277  data: 0.0001  max mem: 8730
Epoch: [16]  [1070/2001]  eta: 0:09:55  lr: 0.000285  loss: 3.0648 (3.0650)  time: 0.6248  data: 0.0001  max mem: 8730
Epoch: [16]  [1080/2001]  eta: 0:09:48  lr: 0.000285  loss: 3.0813 (3.0654)  time: 0.6303  data: 0.0001  max mem: 8730
Epoch: [16]  [1090/2001]  eta: 0:09:42  lr: 0.000285  loss: 3.1012 (3.0662)  time: 0.6294  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8885, ratio_loss=0.0447, cls_kl=0.0625, token_kl=0.0932
Epoch: [16]  [1100/2001]  eta: 0:09:35  lr: 0.000285  loss: 3.1028 (3.0661)  time: 0.6269  data: 0.0001  max mem: 8730
Epoch: [16]  [1110/2001]  eta: 0:09:29  lr: 0.000285  loss: 3.1028 (3.0661)  time: 0.6274  data: 0.0001  max mem: 8730
Epoch: [16]  [1120/2001]  eta: 0:09:22  lr: 0.000285  loss: 2.9555 (3.0641)  time: 0.6313  data: 0.0002  max mem: 8730
Epoch: [16]  [1130/2001]  eta: 0:09:16  lr: 0.000285  loss: 2.8430 (3.0657)  time: 0.6285  data: 0.0002  max mem: 8730
Epoch: [16]  [1140/2001]  eta: 0:09:09  lr: 0.000285  loss: 3.1367 (3.0639)  time: 0.6260  data: 0.0001  max mem: 8730
Epoch: [16]  [1150/2001]  eta: 0:09:03  lr: 0.000285  loss: 3.0406 (3.0632)  time: 0.6254  data: 0.0001  max mem: 8730
Epoch: [16]  [1160/2001]  eta: 0:08:56  lr: 0.000285  loss: 3.1510 (3.0638)  time: 0.6223  data: 0.0001  max mem: 8730
Epoch: [16]  [1170/2001]  eta: 0:08:50  lr: 0.000285  loss: 3.2144 (3.0633)  time: 0.6250  data: 0.0001  max mem: 8730
Epoch: [16]  [1180/2001]  eta: 0:08:43  lr: 0.000285  loss: 3.0295 (3.0622)  time: 0.6273  data: 0.0001  max mem: 8730
Epoch: [16]  [1190/2001]  eta: 0:08:37  lr: 0.000285  loss: 3.0287 (3.0618)  time: 0.6246  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9375, ratio_loss=0.0423, cls_kl=0.0629, token_kl=0.0904
Epoch: [16]  [1200/2001]  eta: 0:08:30  lr: 0.000285  loss: 3.1056 (3.0632)  time: 0.6262  data: 0.0001  max mem: 8730
Epoch: [16]  [1210/2001]  eta: 0:08:24  lr: 0.000285  loss: 3.3218 (3.0632)  time: 0.6304  data: 0.0001  max mem: 8730
Epoch: [16]  [1220/2001]  eta: 0:08:18  lr: 0.000285  loss: 3.3534 (3.0658)  time: 0.6345  data: 0.0001  max mem: 8730
Epoch: [16]  [1230/2001]  eta: 0:08:11  lr: 0.000285  loss: 3.2632 (3.0648)  time: 0.6347  data: 0.0001  max mem: 8730
Epoch: [16]  [1240/2001]  eta: 0:08:05  lr: 0.000285  loss: 2.9884 (3.0643)  time: 0.6312  data: 0.0001  max mem: 8730
Epoch: [16]  [1250/2001]  eta: 0:07:58  lr: 0.000285  loss: 3.0919 (3.0650)  time: 0.6350  data: 0.0001  max mem: 8730
Epoch: [16]  [1260/2001]  eta: 0:07:52  lr: 0.000285  loss: 3.1245 (3.0648)  time: 0.6321  data: 0.0001  max mem: 8730
Epoch: [16]  [1270/2001]  eta: 0:07:46  lr: 0.000285  loss: 2.9950 (3.0644)  time: 0.6281  data: 0.0001  max mem: 8730
Epoch: [16]  [1280/2001]  eta: 0:07:39  lr: 0.000285  loss: 3.1401 (3.0642)  time: 0.6327  data: 0.0002  max mem: 8730
Epoch: [16]  [1290/2001]  eta: 0:07:33  lr: 0.000285  loss: 3.2100 (3.0647)  time: 0.6350  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9530, ratio_loss=0.0454, cls_kl=0.0638, token_kl=0.0919
Epoch: [16]  [1300/2001]  eta: 0:07:26  lr: 0.000285  loss: 3.1473 (3.0635)  time: 0.6388  data: 0.0001  max mem: 8730
Epoch: [16]  [1310/2001]  eta: 0:07:20  lr: 0.000285  loss: 3.1473 (3.0621)  time: 0.6345  data: 0.0001  max mem: 8730
Epoch: [16]  [1320/2001]  eta: 0:07:14  lr: 0.000285  loss: 3.1784 (3.0622)  time: 0.6308  data: 0.0001  max mem: 8730
Epoch: [16]  [1330/2001]  eta: 0:07:07  lr: 0.000285  loss: 3.0543 (3.0601)  time: 0.6297  data: 0.0001  max mem: 8730
Epoch: [16]  [1340/2001]  eta: 0:07:01  lr: 0.000285  loss: 2.8778 (3.0594)  time: 0.6311  data: 0.0001  max mem: 8730
Epoch: [16]  [1350/2001]  eta: 0:06:54  lr: 0.000285  loss: 2.9899 (3.0589)  time: 0.6358  data: 0.0001  max mem: 8730
Epoch: [16]  [1360/2001]  eta: 0:06:48  lr: 0.000285  loss: 3.1478 (3.0603)  time: 0.6323  data: 0.0001  max mem: 8730
Epoch: [16]  [1370/2001]  eta: 0:06:42  lr: 0.000285  loss: 3.1795 (3.0598)  time: 0.6352  data: 0.0001  max mem: 8730
Epoch: [16]  [1380/2001]  eta: 0:06:35  lr: 0.000285  loss: 3.1644 (3.0599)  time: 0.6368  data: 0.0001  max mem: 8730
Epoch: [16]  [1390/2001]  eta: 0:06:29  lr: 0.000285  loss: 3.2124 (3.0613)  time: 0.6321  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9186, ratio_loss=0.0462, cls_kl=0.0634, token_kl=0.0925
Epoch: [16]  [1400/2001]  eta: 0:06:22  lr: 0.000285  loss: 3.2040 (3.0606)  time: 0.6311  data: 0.0001  max mem: 8730
Epoch: [16]  [1410/2001]  eta: 0:06:16  lr: 0.000285  loss: 3.1856 (3.0624)  time: 0.6313  data: 0.0001  max mem: 8730
Epoch: [16]  [1420/2001]  eta: 0:06:10  lr: 0.000285  loss: 3.3374 (3.0644)  time: 0.6321  data: 0.0002  max mem: 8730
Epoch: [16]  [1430/2001]  eta: 0:06:03  lr: 0.000285  loss: 3.2574 (3.0643)  time: 0.6341  data: 0.0002  max mem: 8730
Epoch: [16]  [1440/2001]  eta: 0:05:57  lr: 0.000285  loss: 3.1360 (3.0647)  time: 0.6306  data: 0.0002  max mem: 8730
Epoch: [16]  [1450/2001]  eta: 0:05:50  lr: 0.000285  loss: 3.1360 (3.0650)  time: 0.6307  data: 0.0001  max mem: 8730
Epoch: [16]  [1460/2001]  eta: 0:05:44  lr: 0.000285  loss: 3.0242 (3.0655)  time: 0.6383  data: 0.0002  max mem: 8730
Epoch: [16]  [1470/2001]  eta: 0:05:38  lr: 0.000285  loss: 3.1815 (3.0663)  time: 0.6332  data: 0.0001  max mem: 8730
Epoch: [16]  [1480/2001]  eta: 0:05:31  lr: 0.000285  loss: 3.2761 (3.0674)  time: 0.6327  data: 0.0001  max mem: 8730
Epoch: [16]  [1490/2001]  eta: 0:05:25  lr: 0.000285  loss: 3.3267 (3.0678)  time: 0.6398  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0470, ratio_loss=0.0504, cls_kl=0.0686, token_kl=0.0957
Epoch: [16]  [1500/2001]  eta: 0:05:19  lr: 0.000285  loss: 2.8261 (3.0656)  time: 0.6428  data: 0.0001  max mem: 8730
Epoch: [16]  [1510/2001]  eta: 0:05:12  lr: 0.000285  loss: 2.6046 (3.0627)  time: 0.6405  data: 0.0001  max mem: 8730
Epoch: [16]  [1520/2001]  eta: 0:05:06  lr: 0.000285  loss: 2.7870 (3.0625)  time: 0.6337  data: 0.0001  max mem: 8730
Epoch: [16]  [1530/2001]  eta: 0:05:00  lr: 0.000285  loss: 3.3219 (3.0643)  time: 0.6336  data: 0.0001  max mem: 8730
Epoch: [16]  [1540/2001]  eta: 0:04:53  lr: 0.000285  loss: 3.2027 (3.0652)  time: 0.6358  data: 0.0001  max mem: 8730
Epoch: [16]  [1550/2001]  eta: 0:04:47  lr: 0.000285  loss: 3.1719 (3.0651)  time: 0.6375  data: 0.0001  max mem: 8730
Epoch: [16]  [1560/2001]  eta: 0:04:40  lr: 0.000285  loss: 3.1714 (3.0650)  time: 0.6332  data: 0.0001  max mem: 8730
Epoch: [16]  [1570/2001]  eta: 0:04:34  lr: 0.000285  loss: 3.0453 (3.0647)  time: 0.6318  data: 0.0001  max mem: 8730
Epoch: [16]  [1580/2001]  eta: 0:04:28  lr: 0.000285  loss: 3.0557 (3.0642)  time: 0.6332  data: 0.0001  max mem: 8730
Epoch: [16]  [1590/2001]  eta: 0:04:21  lr: 0.000285  loss: 3.2051 (3.0635)  time: 0.6318  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8869, ratio_loss=0.0470, cls_kl=0.0665, token_kl=0.0952
Epoch: [16]  [1600/2001]  eta: 0:04:15  lr: 0.000285  loss: 3.1099 (3.0637)  time: 0.6320  data: 0.0001  max mem: 8730
Epoch: [16]  [1610/2001]  eta: 0:04:08  lr: 0.000285  loss: 3.0254 (3.0635)  time: 0.6312  data: 0.0001  max mem: 8730
Epoch: [16]  [1620/2001]  eta: 0:04:02  lr: 0.000285  loss: 2.9267 (3.0629)  time: 0.6372  data: 0.0001  max mem: 8730
Epoch: [16]  [1630/2001]  eta: 0:03:56  lr: 0.000285  loss: 3.0466 (3.0632)  time: 0.6390  data: 0.0002  max mem: 8730
Epoch: [16]  [1640/2001]  eta: 0:03:49  lr: 0.000285  loss: 2.9946 (3.0616)  time: 0.6375  data: 0.0001  max mem: 8730
Epoch: [16]  [1650/2001]  eta: 0:03:43  lr: 0.000285  loss: 3.0310 (3.0631)  time: 0.6403  data: 0.0001  max mem: 8730
Epoch: [16]  [1660/2001]  eta: 0:03:37  lr: 0.000285  loss: 3.0817 (3.0631)  time: 0.6339  data: 0.0001  max mem: 8730
Epoch: [16]  [1670/2001]  eta: 0:03:30  lr: 0.000285  loss: 3.0817 (3.0644)  time: 0.6328  data: 0.0001  max mem: 8730
Epoch: [16]  [1680/2001]  eta: 0:03:24  lr: 0.000285  loss: 3.0893 (3.0645)  time: 0.6361  data: 0.0001  max mem: 8730
Epoch: [16]  [1690/2001]  eta: 0:03:18  lr: 0.000285  loss: 3.0408 (3.0644)  time: 0.6349  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9917, ratio_loss=0.0477, cls_kl=0.0654, token_kl=0.0943
Epoch: [16]  [1700/2001]  eta: 0:03:11  lr: 0.000285  loss: 3.2124 (3.0657)  time: 0.6375  data: 0.0001  max mem: 8730
Epoch: [16]  [1710/2001]  eta: 0:03:05  lr: 0.000285  loss: 3.2209 (3.0664)  time: 0.6448  data: 0.0001  max mem: 8730
Epoch: [16]  [1720/2001]  eta: 0:02:58  lr: 0.000285  loss: 3.2039 (3.0657)  time: 0.6421  data: 0.0001  max mem: 8730
Epoch: [16]  [1730/2001]  eta: 0:02:52  lr: 0.000285  loss: 3.0112 (3.0654)  time: 0.6407  data: 0.0001  max mem: 8730
Epoch: [16]  [1740/2001]  eta: 0:02:46  lr: 0.000285  loss: 3.0856 (3.0657)  time: 0.6389  data: 0.0001  max mem: 8730
Epoch: [16]  [1750/2001]  eta: 0:02:39  lr: 0.000285  loss: 2.9449 (3.0648)  time: 0.6358  data: 0.0001  max mem: 8730
Epoch: [16]  [1760/2001]  eta: 0:02:33  lr: 0.000285  loss: 3.0120 (3.0649)  time: 0.6374  data: 0.0001  max mem: 8730
Epoch: [16]  [1770/2001]  eta: 0:02:27  lr: 0.000285  loss: 3.0120 (3.0647)  time: 0.6376  data: 0.0001  max mem: 8730
Epoch: [16]  [1780/2001]  eta: 0:02:20  lr: 0.000285  loss: 2.9675 (3.0643)  time: 0.6429  data: 0.0001  max mem: 8730
Epoch: [16]  [1790/2001]  eta: 0:02:14  lr: 0.000285  loss: 3.1686 (3.0648)  time: 0.6396  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9443, ratio_loss=0.0445, cls_kl=0.0626, token_kl=0.0911
Epoch: [16]  [1800/2001]  eta: 0:02:08  lr: 0.000285  loss: 3.1876 (3.0649)  time: 0.6384  data: 0.0001  max mem: 8730
Epoch: [16]  [1810/2001]  eta: 0:02:01  lr: 0.000285  loss: 3.1952 (3.0645)  time: 0.6413  data: 0.0001  max mem: 8730
Epoch: [16]  [1820/2001]  eta: 0:01:55  lr: 0.000285  loss: 3.0823 (3.0645)  time: 0.6372  data: 0.0001  max mem: 8730
Epoch: [16]  [1830/2001]  eta: 0:01:48  lr: 0.000285  loss: 3.0823 (3.0638)  time: 0.6375  data: 0.0001  max mem: 8730
Epoch: [16]  [1840/2001]  eta: 0:01:42  lr: 0.000285  loss: 3.1514 (3.0641)  time: 0.6386  data: 0.0001  max mem: 8730
Epoch: [16]  [1850/2001]  eta: 0:01:36  lr: 0.000285  loss: 2.7838 (3.0618)  time: 0.6350  data: 0.0001  max mem: 8730
Epoch: [16]  [1860/2001]  eta: 0:01:29  lr: 0.000285  loss: 2.7838 (3.0622)  time: 0.6339  data: 0.0001  max mem: 8730
Epoch: [16]  [1870/2001]  eta: 0:01:23  lr: 0.000285  loss: 3.1807 (3.0625)  time: 0.6355  data: 0.0001  max mem: 8730
Epoch: [16]  [1880/2001]  eta: 0:01:17  lr: 0.000285  loss: 3.2586 (3.0634)  time: 0.6392  data: 0.0001  max mem: 8730
Epoch: [16]  [1890/2001]  eta: 0:01:10  lr: 0.000285  loss: 3.2586 (3.0630)  time: 0.6456  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9137, ratio_loss=0.0440, cls_kl=0.0618, token_kl=0.0894
Epoch: [16]  [1900/2001]  eta: 0:01:04  lr: 0.000285  loss: 3.0447 (3.0627)  time: 0.6526  data: 0.0001  max mem: 8730
Epoch: [16]  [1910/2001]  eta: 0:00:57  lr: 0.000285  loss: 3.1527 (3.0632)  time: 0.6448  data: 0.0001  max mem: 8730
Epoch: [16]  [1920/2001]  eta: 0:00:51  lr: 0.000285  loss: 3.3006 (3.0639)  time: 0.6363  data: 0.0001  max mem: 8730
Epoch: [16]  [1930/2001]  eta: 0:00:45  lr: 0.000285  loss: 3.2356 (3.0633)  time: 0.6428  data: 0.0001  max mem: 8730
Epoch: [16]  [1940/2001]  eta: 0:00:38  lr: 0.000285  loss: 3.2356 (3.0638)  time: 0.6449  data: 0.0001  max mem: 8730
Epoch: [16]  [1950/2001]  eta: 0:00:32  lr: 0.000285  loss: 3.2032 (3.0631)  time: 0.6403  data: 0.0001  max mem: 8730
Epoch: [16]  [1960/2001]  eta: 0:00:26  lr: 0.000285  loss: 2.9912 (3.0625)  time: 0.6353  data: 0.0001  max mem: 8730
Epoch: [16]  [1970/2001]  eta: 0:00:19  lr: 0.000285  loss: 3.0061 (3.0625)  time: 0.6393  data: 0.0001  max mem: 8730
Epoch: [16]  [1980/2001]  eta: 0:00:13  lr: 0.000285  loss: 3.2344 (3.0632)  time: 0.6489  data: 0.0001  max mem: 8730
Epoch: [16]  [1990/2001]  eta: 0:00:07  lr: 0.000285  loss: 3.2088 (3.0628)  time: 0.6396  data: 0.0003  max mem: 8730
loss info: cls_loss=2.9609, ratio_loss=0.0433, cls_kl=0.0650, token_kl=0.0921
Epoch: [16]  [2000/2001]  eta: 0:00:00  lr: 0.000285  loss: 3.0375 (3.0632)  time: 0.6279  data: 0.0003  max mem: 8730
Epoch: [16] Total time: 0:21:15 (0.6375 s / it)
Averaged stats: lr: 0.000285  loss: 3.0375 (3.0520)
Test:  [ 0/53]  eta: 0:04:39  loss: 0.3639 (0.3639)  acc1: 94.1667 (94.1667)  acc5: 99.1667 (99.1667)  time: 5.2671  data: 4.6102  max mem: 8730
Test:  [10/53]  eta: 0:00:36  loss: 0.6791 (0.7630)  acc1: 82.5000 (82.8788)  acc5: 97.5000 (96.8182)  time: 0.8573  data: 0.4420  max mem: 8730
Test:  [20/53]  eta: 0:00:20  loss: 0.7015 (0.7696)  acc1: 81.6667 (82.6587)  acc5: 96.6667 (96.8651)  time: 0.3800  data: 0.0130  max mem: 8730
Test:  [30/53]  eta: 0:00:12  loss: 0.8820 (0.8517)  acc1: 78.3333 (80.5108)  acc5: 95.0000 (95.5108)  time: 0.3454  data: 0.0005  max mem: 8730
Test:  [40/53]  eta: 0:00:06  loss: 1.1190 (0.9227)  acc1: 75.8333 (79.0041)  acc5: 91.6667 (94.5529)  time: 0.3114  data: 0.0002  max mem: 8730
Test:  [50/53]  eta: 0:00:01  loss: 1.1189 (0.9514)  acc1: 74.1667 (78.1046)  acc5: 92.5000 (94.3301)  time: 0.2648  data: 0.0001  max mem: 8730
Test:  [52/53]  eta: 0:00:00  loss: 1.1186 (0.9389)  acc1: 75.0000 (78.2720)  acc5: 92.5000 (94.4000)  time: 0.2505  data: 0.0001  max mem: 8730
Test: Total time: 0:00:22 (0.4164 s / it)
Sparsity0:0.2892759595959596,Sparsity1:0.53918391959799,Sparsity2:0.7718688,
* Acc@1 78.976 Acc@5 94.584 loss 0.936
Accuracy of the network on the 50000 test images: 79.0%
Max accuracy: 79.07%
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0002536 for PREDICTOR
Epoch: [17]  [   0/2001]  eta: 2:27:07  lr: 0.000254  loss: 2.5190 (2.5190)  time: 4.4113  data: 2.6483  max mem: 8730
Epoch: [17]  [  10/2001]  eta: 0:32:45  lr: 0.000254  loss: 3.2823 (3.1737)  time: 0.9872  data: 0.2409  max mem: 8730
Epoch: [17]  [  20/2001]  eta: 0:27:00  lr: 0.000254  loss: 3.2171 (3.0947)  time: 0.6386  data: 0.0002  max mem: 8730
Epoch: [17]  [  30/2001]  eta: 0:24:49  lr: 0.000254  loss: 3.1955 (3.1453)  time: 0.6283  data: 0.0002  max mem: 8730
Epoch: [17]  [  40/2001]  eta: 0:23:40  lr: 0.000254  loss: 3.3341 (3.1320)  time: 0.6261  data: 0.0002  max mem: 8730
Epoch: [17]  [  50/2001]  eta: 0:22:56  lr: 0.000254  loss: 3.3149 (3.1287)  time: 0.6274  data: 0.0001  max mem: 8730
Epoch: [17]  [  60/2001]  eta: 0:22:25  lr: 0.000254  loss: 3.2880 (3.1420)  time: 0.6289  data: 0.0001  max mem: 8730
Epoch: [17]  [  70/2001]  eta: 0:22:02  lr: 0.000254  loss: 3.1776 (3.1280)  time: 0.6327  data: 0.0001  max mem: 8730
Epoch: [17]  [  80/2001]  eta: 0:21:44  lr: 0.000254  loss: 3.1664 (3.1356)  time: 0.6351  data: 0.0001  max mem: 8730
Epoch: [17]  [  90/2001]  eta: 0:21:28  lr: 0.000254  loss: 3.1664 (3.1335)  time: 0.6354  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0197, ratio_loss=0.0518, cls_kl=0.0658, token_kl=0.0970
Epoch: [17]  [ 100/2001]  eta: 0:21:13  lr: 0.000254  loss: 3.1238 (3.1112)  time: 0.6330  data: 0.0002  max mem: 8730
Epoch: [17]  [ 110/2001]  eta: 0:21:00  lr: 0.000254  loss: 3.2188 (3.1245)  time: 0.6322  data: 0.0002  max mem: 8730
Epoch: [17]  [ 120/2001]  eta: 0:20:48  lr: 0.000254  loss: 3.2219 (3.1269)  time: 0.6323  data: 0.0002  max mem: 8730
Epoch: [17]  [ 130/2001]  eta: 0:20:37  lr: 0.000254  loss: 3.0952 (3.1216)  time: 0.6335  data: 0.0002  max mem: 8730
Epoch: [17]  [ 140/2001]  eta: 0:20:27  lr: 0.000254  loss: 2.9915 (3.0993)  time: 0.6367  data: 0.0001  max mem: 8730
Epoch: [17]  [ 150/2001]  eta: 0:20:19  lr: 0.000254  loss: 2.7968 (3.0894)  time: 0.6400  data: 0.0002  max mem: 8730
Epoch: [17]  [ 160/2001]  eta: 0:20:10  lr: 0.000254  loss: 3.0218 (3.0919)  time: 0.6417  data: 0.0002  max mem: 8730
Epoch: [17]  [ 170/2001]  eta: 0:20:01  lr: 0.000254  loss: 3.0312 (3.0937)  time: 0.6360  data: 0.0002  max mem: 8730
Epoch: [17]  [ 180/2001]  eta: 0:19:52  lr: 0.000254  loss: 3.1315 (3.0813)  time: 0.6328  data: 0.0001  max mem: 8730
Epoch: [17]  [ 190/2001]  eta: 0:19:43  lr: 0.000254  loss: 3.2468 (3.0931)  time: 0.6315  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9579, ratio_loss=0.0460, cls_kl=0.0644, token_kl=0.0941
Epoch: [17]  [ 200/2001]  eta: 0:19:34  lr: 0.000254  loss: 3.3096 (3.1016)  time: 0.6301  data: 0.0001  max mem: 8730
Epoch: [17]  [ 210/2001]  eta: 0:19:27  lr: 0.000254  loss: 3.1709 (3.0984)  time: 0.6371  data: 0.0001  max mem: 8730
Epoch: [17]  [ 220/2001]  eta: 0:19:20  lr: 0.000254  loss: 3.0118 (3.0861)  time: 0.6414  data: 0.0002  max mem: 8730
Epoch: [17]  [ 230/2001]  eta: 0:19:11  lr: 0.000254  loss: 2.7693 (3.0786)  time: 0.6333  data: 0.0002  max mem: 8730
Epoch: [17]  [ 240/2001]  eta: 0:19:03  lr: 0.000254  loss: 3.0436 (3.0766)  time: 0.6283  data: 0.0002  max mem: 8730
Epoch: [17]  [ 250/2001]  eta: 0:18:55  lr: 0.000254  loss: 3.3331 (3.0872)  time: 0.6286  data: 0.0002  max mem: 8730
Epoch: [17]  [ 260/2001]  eta: 0:18:48  lr: 0.000254  loss: 3.3569 (3.0945)  time: 0.6331  data: 0.0002  max mem: 8730
Epoch: [17]  [ 270/2001]  eta: 0:18:41  lr: 0.000254  loss: 3.2074 (3.0834)  time: 0.6388  data: 0.0002  max mem: 8730
Epoch: [17]  [ 280/2001]  eta: 0:18:34  lr: 0.000254  loss: 3.1901 (3.0891)  time: 0.6389  data: 0.0002  max mem: 8730
Epoch: [17]  [ 290/2001]  eta: 0:18:27  lr: 0.000254  loss: 3.2291 (3.0872)  time: 0.6364  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9600, ratio_loss=0.0493, cls_kl=0.0654, token_kl=0.0942
Epoch: [17]  [ 300/2001]  eta: 0:18:19  lr: 0.000254  loss: 3.1745 (3.0932)  time: 0.6310  data: 0.0002  max mem: 8730
Epoch: [17]  [ 310/2001]  eta: 0:18:11  lr: 0.000254  loss: 2.9964 (3.0853)  time: 0.6249  data: 0.0002  max mem: 8730
Epoch: [17]  [ 320/2001]  eta: 0:18:04  lr: 0.000254  loss: 2.8856 (3.0830)  time: 0.6242  data: 0.0002  max mem: 8730
Epoch: [17]  [ 330/2001]  eta: 0:17:57  lr: 0.000254  loss: 3.0766 (3.0856)  time: 0.6295  data: 0.0002  max mem: 8730
Epoch: [17]  [ 340/2001]  eta: 0:17:50  lr: 0.000254  loss: 3.1734 (3.0904)  time: 0.6349  data: 0.0002  max mem: 8730
Epoch: [17]  [ 350/2001]  eta: 0:17:43  lr: 0.000254  loss: 3.2563 (3.0922)  time: 0.6383  data: 0.0002  max mem: 8730
Epoch: [17]  [ 360/2001]  eta: 0:17:36  lr: 0.000254  loss: 3.1342 (3.0909)  time: 0.6336  data: 0.0002  max mem: 8730
Epoch: [17]  [ 370/2001]  eta: 0:17:29  lr: 0.000254  loss: 3.1342 (3.0863)  time: 0.6251  data: 0.0002  max mem: 8730
Epoch: [17]  [ 380/2001]  eta: 0:17:22  lr: 0.000254  loss: 2.9121 (3.0792)  time: 0.6279  data: 0.0002  max mem: 8730
Epoch: [17]  [ 390/2001]  eta: 0:17:15  lr: 0.000254  loss: 2.9121 (3.0779)  time: 0.6330  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9261, ratio_loss=0.0457, cls_kl=0.0644, token_kl=0.0932
Epoch: [17]  [ 400/2001]  eta: 0:17:08  lr: 0.000254  loss: 2.8831 (3.0708)  time: 0.6267  data: 0.0002  max mem: 8730
Epoch: [17]  [ 410/2001]  eta: 0:17:01  lr: 0.000254  loss: 3.0463 (3.0737)  time: 0.6242  data: 0.0002  max mem: 8730
Epoch: [17]  [ 420/2001]  eta: 0:16:54  lr: 0.000254  loss: 3.0611 (3.0700)  time: 0.6303  data: 0.0002  max mem: 8730
Epoch: [17]  [ 430/2001]  eta: 0:16:47  lr: 0.000254  loss: 2.9673 (3.0684)  time: 0.6358  data: 0.0001  max mem: 8730
Epoch: [17]  [ 440/2001]  eta: 0:16:40  lr: 0.000254  loss: 3.0358 (3.0643)  time: 0.6332  data: 0.0001  max mem: 8730
Epoch: [17]  [ 450/2001]  eta: 0:16:34  lr: 0.000254  loss: 2.9731 (3.0637)  time: 0.6307  data: 0.0001  max mem: 8730
Epoch: [17]  [ 460/2001]  eta: 0:16:27  lr: 0.000254  loss: 2.9197 (3.0555)  time: 0.6327  data: 0.0001  max mem: 8730
Epoch: [17]  [ 470/2001]  eta: 0:16:20  lr: 0.000254  loss: 3.0405 (3.0603)  time: 0.6294  data: 0.0001  max mem: 8730
Epoch: [17]  [ 480/2001]  eta: 0:16:13  lr: 0.000254  loss: 3.3616 (3.0623)  time: 0.6268  data: 0.0001  max mem: 8730
Epoch: [17]  [ 490/2001]  eta: 0:16:06  lr: 0.000254  loss: 3.1174 (3.0603)  time: 0.6248  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9024, ratio_loss=0.0472, cls_kl=0.0633, token_kl=0.0929
Epoch: [17]  [ 500/2001]  eta: 0:16:00  lr: 0.000254  loss: 3.1174 (3.0644)  time: 0.6249  data: 0.0001  max mem: 8730
Epoch: [17]  [ 510/2001]  eta: 0:15:53  lr: 0.000254  loss: 3.4209 (3.0682)  time: 0.6335  data: 0.0001  max mem: 8730
Epoch: [17]  [ 520/2001]  eta: 0:15:46  lr: 0.000254  loss: 3.1942 (3.0676)  time: 0.6311  data: 0.0001  max mem: 8730
Epoch: [17]  [ 530/2001]  eta: 0:15:40  lr: 0.000254  loss: 2.7861 (3.0639)  time: 0.6235  data: 0.0001  max mem: 8730
Epoch: [17]  [ 540/2001]  eta: 0:15:33  lr: 0.000254  loss: 2.7127 (3.0624)  time: 0.6220  data: 0.0001  max mem: 8730
Epoch: [17]  [ 550/2001]  eta: 0:15:26  lr: 0.000254  loss: 3.2360 (3.0617)  time: 0.6228  data: 0.0001  max mem: 8730
Epoch: [17]  [ 560/2001]  eta: 0:15:19  lr: 0.000254  loss: 2.7055 (3.0554)  time: 0.6243  data: 0.0002  max mem: 8730
Epoch: [17]  [ 570/2001]  eta: 0:15:12  lr: 0.000254  loss: 2.8536 (3.0540)  time: 0.6225  data: 0.0002  max mem: 8730
Epoch: [17]  [ 580/2001]  eta: 0:15:06  lr: 0.000254  loss: 3.1582 (3.0545)  time: 0.6241  data: 0.0001  max mem: 8730
Epoch: [17]  [ 590/2001]  eta: 0:14:59  lr: 0.000254  loss: 3.0438 (3.0509)  time: 0.6302  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8914, ratio_loss=0.0451, cls_kl=0.0625, token_kl=0.0926
Epoch: [17]  [ 600/2001]  eta: 0:14:53  lr: 0.000254  loss: 3.0371 (3.0500)  time: 0.6326  data: 0.0001  max mem: 8730
Epoch: [17]  [ 610/2001]  eta: 0:14:46  lr: 0.000254  loss: 3.1092 (3.0523)  time: 0.6298  data: 0.0001  max mem: 8730
Epoch: [17]  [ 620/2001]  eta: 0:14:39  lr: 0.000254  loss: 3.1081 (3.0513)  time: 0.6271  data: 0.0001  max mem: 8730
Epoch: [17]  [ 630/2001]  eta: 0:14:33  lr: 0.000254  loss: 3.2263 (3.0574)  time: 0.6283  data: 0.0001  max mem: 8730
Epoch: [17]  [ 640/2001]  eta: 0:14:26  lr: 0.000254  loss: 3.2506 (3.0550)  time: 0.6310  data: 0.0001  max mem: 8730
Epoch: [17]  [ 650/2001]  eta: 0:14:20  lr: 0.000254  loss: 2.9856 (3.0544)  time: 0.6332  data: 0.0001  max mem: 8730
| distributed init (rank 3): env://
| distributed init (rank 7): env://
| distributed init (rank 5): env://
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 4): env://
| distributed init (rank 6): env://
| distributed init (rank 2): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp-3keep/checkpoint.pth', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0002536 for PREDICTOR
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Epoch: [17]  [   0/2001]  eta: 3:40:32  lr: 0.000254  loss: 3.6579 (3.6579)  time: 6.6132  data: 3.0160  max mem: 8647
Epoch: [17]  [  10/2001]  eta: 0:38:16  lr: 0.000254  loss: 3.4930 (3.3380)  time: 1.1532  data: 0.2743  max mem: 8728
Epoch: [17]  [  20/2001]  eta: 0:29:12  lr: 0.000254  loss: 3.4378 (3.2931)  time: 0.5983  data: 0.0001  max mem: 8728
Epoch: [17]  [  30/2001]  eta: 0:26:00  lr: 0.000254  loss: 3.3678 (3.3056)  time: 0.5931  data: 0.0001  max mem: 8728
Epoch: [17]  [  40/2001]  eta: 0:24:16  lr: 0.000254  loss: 3.1800 (3.2427)  time: 0.5936  data: 0.0001  max mem: 8728
Epoch: [17]  [  50/2001]  eta: 0:23:09  lr: 0.000254  loss: 3.0856 (3.2230)  time: 0.5884  data: 0.0001  max mem: 8728
Epoch: [17]  [  60/2001]  eta: 0:22:23  lr: 0.000254  loss: 3.0795 (3.1876)  time: 0.5879  data: 0.0001  max mem: 8728
Epoch: [17]  [  70/2001]  eta: 0:21:50  lr: 0.000254  loss: 3.1224 (3.1492)  time: 0.5929  data: 0.0001  max mem: 8728
Epoch: [17]  [  80/2001]  eta: 0:21:25  lr: 0.000254  loss: 3.1346 (3.1517)  time: 0.6008  data: 0.0001  max mem: 8728
Epoch: [17]  [  90/2001]  eta: 0:21:05  lr: 0.000254  loss: 3.2111 (3.1435)  time: 0.6034  data: 0.0001  max mem: 8728
loss info: cls_loss=3.0376, ratio_loss=0.0490, cls_kl=0.0658, token_kl=0.0939
Epoch: [17]  [ 100/2001]  eta: 0:20:48  lr: 0.000254  loss: 3.2470 (3.1515)  time: 0.6053  data: 0.0001  max mem: 8728
Traceback (most recent call last):
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 253, in main
    process.wait()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/subprocess.py", line 1477, in wait
    (pid, sts) = self._try_wait(0)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/subprocess.py", line 1424, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 7): env://
| distributed init (rank 0): env://
| distributed init (rank 5): env://
| distributed init (rank 6): env://
| distributed init (rank 4): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp-3keep/checkpoint.pth', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0002536 for PREDICTOR
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Epoch: [17]  [   0/2001]  eta: 3:38:01  lr: 0.000254  loss: 3.6579 (3.6579)  time: 6.5374  data: 2.9111  max mem: 8647
Epoch: [17]  [  10/2001]  eta: 0:38:09  lr: 0.000254  loss: 3.4930 (3.3380)  time: 1.1500  data: 0.2648  max mem: 8728
Epoch: [17]  [  20/2001]  eta: 0:29:18  lr: 0.000254  loss: 3.4378 (3.2931)  time: 0.6053  data: 0.0001  max mem: 8728
Epoch: [17]  [  30/2001]  eta: 0:26:15  lr: 0.000254  loss: 3.3656 (3.3055)  time: 0.6065  data: 0.0002  max mem: 8728
Epoch: [17]  [  40/2001]  eta: 0:24:34  lr: 0.000254  loss: 3.1799 (3.2425)  time: 0.6096  data: 0.0002  max mem: 8728
Epoch: [17]  [  50/2001]  eta: 0:23:25  lr: 0.000254  loss: 3.0856 (3.2228)  time: 0.5984  data: 0.0002  max mem: 8728
Epoch: [17]  [  60/2001]  eta: 0:22:39  lr: 0.000254  loss: 3.0799 (3.1875)  time: 0.5953  data: 0.0002  max mem: 8728
Epoch: [17]  [  70/2001]  eta: 0:22:07  lr: 0.000254  loss: 3.1227 (3.1491)  time: 0.6039  data: 0.0001  max mem: 8728
Epoch: [17]  [  80/2001]  eta: 0:21:41  lr: 0.000254  loss: 3.1352 (3.1515)  time: 0.6077  data: 0.0001  max mem: 8728
Epoch: [17]  [  90/2001]  eta: 0:21:20  lr: 0.000254  loss: 3.2106 (3.1433)  time: 0.6078  data: 0.0001  max mem: 8728
loss info: cls_loss=3.0373, ratio_loss=0.0490, cls_kl=0.0658, token_kl=0.0939
Epoch: [17]  [ 100/2001]  eta: 0:21:02  lr: 0.000254  loss: 3.2483 (3.1512)  time: 0.6095  data: 0.0001  max mem: 8728
Epoch: [17]  [ 110/2001]  eta: 0:20:47  lr: 0.000254  loss: 3.2006 (3.1514)  time: 0.6117  data: 0.0001  max mem: 8728
Epoch: [17]  [ 120/2001]  eta: 0:20:34  lr: 0.000254  loss: 3.1348 (3.1500)  time: 0.6151  data: 0.0001  max mem: 8728
Epoch: [17]  [ 130/2001]  eta: 0:20:22  lr: 0.000254  loss: 3.1348 (3.1427)  time: 0.6181  data: 0.0001  max mem: 8728
Epoch: [17]  [ 140/2001]  eta: 0:20:11  lr: 0.000254  loss: 3.0461 (3.1289)  time: 0.6188  data: 0.0002  max mem: 8728
Epoch: [17]  [ 150/2001]  eta: 0:20:02  lr: 0.000254  loss: 3.2184 (3.1274)  time: 0.6240  data: 0.0001  max mem: 8728
Epoch: [17]  [ 160/2001]  eta: 0:19:52  lr: 0.000254  loss: 3.2184 (3.1345)  time: 0.6273  data: 0.0002  max mem: 8728
Epoch: [17]  [ 170/2001]  eta: 0:19:44  lr: 0.000254  loss: 3.0924 (3.1268)  time: 0.6279  data: 0.0002  max mem: 8728
Epoch: [17]  [ 180/2001]  eta: 0:19:37  lr: 0.000254  loss: 2.9523 (3.1094)  time: 0.6341  data: 0.0002  max mem: 8728
Epoch: [17]  [ 190/2001]  eta: 0:19:31  lr: 0.000254  loss: 2.8792 (3.1064)  time: 0.6444  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9339, ratio_loss=0.0437, cls_kl=0.0632, token_kl=0.0924
Epoch: [17]  [ 200/2001]  eta: 0:19:23  lr: 0.000254  loss: 2.8803 (3.0931)  time: 0.6455  data: 0.0001  max mem: 8728
Epoch: [17]  [ 210/2001]  eta: 0:19:16  lr: 0.000254  loss: 3.0119 (3.0870)  time: 0.6352  data: 0.0001  max mem: 8728
Epoch: [17]  [ 220/2001]  eta: 0:19:08  lr: 0.000254  loss: 3.0434 (3.0841)  time: 0.6332  data: 0.0001  max mem: 8728
Epoch: [17]  [ 230/2001]  eta: 0:19:01  lr: 0.000254  loss: 3.1257 (3.0790)  time: 0.6343  data: 0.0002  max mem: 8728
Epoch: [17]  [ 240/2001]  eta: 0:18:54  lr: 0.000254  loss: 3.1321 (3.0773)  time: 0.6332  data: 0.0002  max mem: 8728
Epoch: [17]  [ 250/2001]  eta: 0:18:47  lr: 0.000254  loss: 3.0343 (3.0702)  time: 0.6338  data: 0.0001  max mem: 8728
Epoch: [17]  [ 260/2001]  eta: 0:18:40  lr: 0.000254  loss: 2.8476 (3.0612)  time: 0.6361  data: 0.0002  max mem: 8728
Epoch: [17]  [ 270/2001]  eta: 0:18:33  lr: 0.000254  loss: 2.8476 (3.0567)  time: 0.6358  data: 0.0002  max mem: 8728
Epoch: [17]  [ 280/2001]  eta: 0:18:26  lr: 0.000254  loss: 3.2003 (3.0621)  time: 0.6351  data: 0.0002  max mem: 8728
Epoch: [17]  [ 290/2001]  eta: 0:18:19  lr: 0.000254  loss: 3.1209 (3.0538)  time: 0.6378  data: 0.0002  max mem: 8728
loss info: cls_loss=2.8349, ratio_loss=0.0433, cls_kl=0.0607, token_kl=0.0919
Epoch: [17]  [ 300/2001]  eta: 0:18:12  lr: 0.000254  loss: 2.6830 (3.0434)  time: 0.6354  data: 0.0002  max mem: 8728
Epoch: [17]  [ 310/2001]  eta: 0:18:05  lr: 0.000254  loss: 2.7674 (3.0429)  time: 0.6344  data: 0.0002  max mem: 8728
Epoch: [17]  [ 320/2001]  eta: 0:17:59  lr: 0.000254  loss: 3.2142 (3.0511)  time: 0.6347  data: 0.0002  max mem: 8728
Epoch: [17]  [ 330/2001]  eta: 0:17:52  lr: 0.000254  loss: 3.3688 (3.0503)  time: 0.6341  data: 0.0002  max mem: 8728
Epoch: [17]  [ 340/2001]  eta: 0:17:45  lr: 0.000254  loss: 3.2347 (3.0536)  time: 0.6385  data: 0.0001  max mem: 8728
Epoch: [17]  [ 350/2001]  eta: 0:17:38  lr: 0.000254  loss: 3.1028 (3.0565)  time: 0.6361  data: 0.0001  max mem: 8728
Epoch: [17]  [ 360/2001]  eta: 0:17:32  lr: 0.000254  loss: 3.1028 (3.0564)  time: 0.6316  data: 0.0002  max mem: 8728
Epoch: [17]  [ 370/2001]  eta: 0:17:25  lr: 0.000254  loss: 3.1942 (3.0537)  time: 0.6320  data: 0.0001  max mem: 8728
Epoch: [17]  [ 380/2001]  eta: 0:17:18  lr: 0.000254  loss: 3.1168 (3.0519)  time: 0.6347  data: 0.0001  max mem: 8728
Epoch: [17]  [ 390/2001]  eta: 0:17:12  lr: 0.000254  loss: 3.0851 (3.0470)  time: 0.6374  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9736, ratio_loss=0.0467, cls_kl=0.0644, token_kl=0.0940
Epoch: [17]  [ 400/2001]  eta: 0:17:05  lr: 0.000254  loss: 3.1461 (3.0550)  time: 0.6353  data: 0.0002  max mem: 8728
Epoch: [17]  [ 410/2001]  eta: 0:16:58  lr: 0.000254  loss: 3.2509 (3.0609)  time: 0.6319  data: 0.0002  max mem: 8728
Epoch: [17]  [ 420/2001]  eta: 0:16:52  lr: 0.000254  loss: 3.2395 (3.0568)  time: 0.6334  data: 0.0001  max mem: 8728
Epoch: [17]  [ 430/2001]  eta: 0:16:45  lr: 0.000254  loss: 3.3068 (3.0612)  time: 0.6339  data: 0.0001  max mem: 8728
Epoch: [17]  [ 440/2001]  eta: 0:16:38  lr: 0.000254  loss: 3.1522 (3.0614)  time: 0.6348  data: 0.0002  max mem: 8728
Epoch: [17]  [ 450/2001]  eta: 0:16:32  lr: 0.000254  loss: 3.0673 (3.0586)  time: 0.6372  data: 0.0002  max mem: 8728
Epoch: [17]  [ 460/2001]  eta: 0:16:26  lr: 0.000254  loss: 2.8889 (3.0550)  time: 0.6394  data: 0.0001  max mem: 8728
Epoch: [17]  [ 470/2001]  eta: 0:16:19  lr: 0.000254  loss: 2.7976 (3.0479)  time: 0.6353  data: 0.0001  max mem: 8728
Epoch: [17]  [ 480/2001]  eta: 0:16:12  lr: 0.000254  loss: 2.8181 (3.0476)  time: 0.6323  data: 0.0001  max mem: 8728
Epoch: [17]  [ 490/2001]  eta: 0:16:06  lr: 0.000254  loss: 3.1471 (3.0523)  time: 0.6407  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9377, ratio_loss=0.0476, cls_kl=0.0641, token_kl=0.0946
Epoch: [17]  [ 500/2001]  eta: 0:15:59  lr: 0.000254  loss: 3.2484 (3.0533)  time: 0.6386  data: 0.0002  max mem: 8728
Epoch: [17]  [ 510/2001]  eta: 0:15:53  lr: 0.000254  loss: 3.2437 (3.0585)  time: 0.6290  data: 0.0001  max mem: 8728
Epoch: [17]  [ 520/2001]  eta: 0:15:46  lr: 0.000254  loss: 3.2110 (3.0570)  time: 0.6271  data: 0.0001  max mem: 8728
Epoch: [17]  [ 530/2001]  eta: 0:15:39  lr: 0.000254  loss: 3.1067 (3.0522)  time: 0.6295  data: 0.0001  max mem: 8728
Epoch: [17]  [ 540/2001]  eta: 0:15:33  lr: 0.000254  loss: 3.1307 (3.0517)  time: 0.6289  data: 0.0001  max mem: 8728
Epoch: [17]  [ 550/2001]  eta: 0:15:26  lr: 0.000254  loss: 3.1754 (3.0501)  time: 0.6286  data: 0.0001  max mem: 8728
Epoch: [17]  [ 560/2001]  eta: 0:15:19  lr: 0.000254  loss: 3.2883 (3.0543)  time: 0.6277  data: 0.0001  max mem: 8728
Epoch: [17]  [ 570/2001]  eta: 0:15:13  lr: 0.000254  loss: 3.3411 (3.0581)  time: 0.6244  data: 0.0001  max mem: 8728
Epoch: [17]  [ 580/2001]  eta: 0:15:06  lr: 0.000254  loss: 3.2151 (3.0601)  time: 0.6245  data: 0.0002  max mem: 8728
Epoch: [17]  [ 590/2001]  eta: 0:14:59  lr: 0.000254  loss: 3.3174 (3.0623)  time: 0.6243  data: 0.0001  max mem: 8728
loss info: cls_loss=3.0097, ratio_loss=0.0475, cls_kl=0.0676, token_kl=0.0941
Epoch: [17]  [ 600/2001]  eta: 0:14:53  lr: 0.000254  loss: 3.3174 (3.0627)  time: 0.6257  data: 0.0001  max mem: 8728
Epoch: [17]  [ 610/2001]  eta: 0:14:46  lr: 0.000254  loss: 3.1144 (3.0633)  time: 0.6279  data: 0.0001  max mem: 8728
Epoch: [17]  [ 620/2001]  eta: 0:14:40  lr: 0.000254  loss: 3.1453 (3.0648)  time: 0.6341  data: 0.0001  max mem: 8728
Epoch: [17]  [ 630/2001]  eta: 0:14:33  lr: 0.000254  loss: 3.2770 (3.0674)  time: 0.6354  data: 0.0001  max mem: 8728
Epoch: [17]  [ 640/2001]  eta: 0:14:27  lr: 0.000254  loss: 2.9638 (3.0655)  time: 0.6331  data: 0.0002  max mem: 8728
Epoch: [17]  [ 650/2001]  eta: 0:14:20  lr: 0.000254  loss: 2.8917 (3.0647)  time: 0.6345  data: 0.0001  max mem: 8728
Epoch: [17]  [ 660/2001]  eta: 0:14:14  lr: 0.000254  loss: 2.7843 (3.0587)  time: 0.6356  data: 0.0002  max mem: 8728
Epoch: [17]  [ 670/2001]  eta: 0:14:07  lr: 0.000254  loss: 2.9664 (3.0615)  time: 0.6314  data: 0.0002  max mem: 8728
Epoch: [17]  [ 680/2001]  eta: 0:14:01  lr: 0.000254  loss: 3.0853 (3.0618)  time: 0.6275  data: 0.0001  max mem: 8728
Epoch: [17]  [ 690/2001]  eta: 0:13:54  lr: 0.000254  loss: 2.8320 (3.0578)  time: 0.6268  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8954, ratio_loss=0.0459, cls_kl=0.0651, token_kl=0.0949
Epoch: [17]  [ 700/2001]  eta: 0:13:48  lr: 0.000254  loss: 2.7447 (3.0563)  time: 0.6246  data: 0.0002  max mem: 8728
Epoch: [17]  [ 710/2001]  eta: 0:13:41  lr: 0.000254  loss: 2.9060 (3.0545)  time: 0.6286  data: 0.0002  max mem: 8728
Epoch: [17]  [ 720/2001]  eta: 0:13:35  lr: 0.000254  loss: 2.9060 (3.0518)  time: 0.6282  data: 0.0002  max mem: 8728
Epoch: [17]  [ 730/2001]  eta: 0:13:28  lr: 0.000254  loss: 3.0594 (3.0523)  time: 0.6268  data: 0.0002  max mem: 8728
Epoch: [17]  [ 740/2001]  eta: 0:13:22  lr: 0.000254  loss: 3.2505 (3.0567)  time: 0.6298  data: 0.0002  max mem: 8728
Epoch: [17]  [ 750/2001]  eta: 0:13:15  lr: 0.000254  loss: 3.2665 (3.0553)  time: 0.6259  data: 0.0002  max mem: 8728
Epoch: [17]  [ 760/2001]  eta: 0:13:09  lr: 0.000254  loss: 3.2432 (3.0558)  time: 0.6312  data: 0.0002  max mem: 8728
Epoch: [17]  [ 770/2001]  eta: 0:13:02  lr: 0.000254  loss: 3.1821 (3.0564)  time: 0.6342  data: 0.0002  max mem: 8728
Epoch: [17]  [ 780/2001]  eta: 0:12:56  lr: 0.000254  loss: 3.1821 (3.0577)  time: 0.6261  data: 0.0001  max mem: 8728
Epoch: [17]  [ 790/2001]  eta: 0:12:49  lr: 0.000254  loss: 3.1932 (3.0571)  time: 0.6270  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9573, ratio_loss=0.0452, cls_kl=0.0650, token_kl=0.0933
Epoch: [17]  [ 800/2001]  eta: 0:12:43  lr: 0.000254  loss: 3.1678 (3.0584)  time: 0.6286  data: 0.0002  max mem: 8728
Epoch: [17]  [ 810/2001]  eta: 0:12:36  lr: 0.000254  loss: 2.8271 (3.0518)  time: 0.6294  data: 0.0002  max mem: 8728
Epoch: [17]  [ 820/2001]  eta: 0:12:30  lr: 0.000254  loss: 3.0778 (3.0547)  time: 0.6298  data: 0.0002  max mem: 8728
Epoch: [17]  [ 830/2001]  eta: 0:12:23  lr: 0.000254  loss: 3.2364 (3.0512)  time: 0.6280  data: 0.0002  max mem: 8728
Epoch: [17]  [ 840/2001]  eta: 0:12:17  lr: 0.000254  loss: 2.9774 (3.0506)  time: 0.6265  data: 0.0002  max mem: 8728
Epoch: [17]  [ 850/2001]  eta: 0:12:10  lr: 0.000254  loss: 3.0139 (3.0487)  time: 0.6242  data: 0.0001  max mem: 8728
Epoch: [17]  [ 860/2001]  eta: 0:12:04  lr: 0.000254  loss: 3.1017 (3.0499)  time: 0.6246  data: 0.0001  max mem: 8728
Epoch: [17]  [ 870/2001]  eta: 0:11:58  lr: 0.000254  loss: 3.1790 (3.0500)  time: 0.6320  data: 0.0001  max mem: 8728
Epoch: [17]  [ 880/2001]  eta: 0:11:51  lr: 0.000254  loss: 2.9733 (3.0482)  time: 0.6321  data: 0.0001  max mem: 8728
Epoch: [17]  [ 890/2001]  eta: 0:11:45  lr: 0.000254  loss: 2.9706 (3.0459)  time: 0.6354  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8524, ratio_loss=0.0447, cls_kl=0.0632, token_kl=0.0937
Epoch: [17]  [ 900/2001]  eta: 0:11:39  lr: 0.000254  loss: 3.1993 (3.0470)  time: 0.6357  data: 0.0001  max mem: 8728
Epoch: [17]  [ 910/2001]  eta: 0:11:32  lr: 0.000254  loss: 3.2431 (3.0474)  time: 0.6281  data: 0.0001  max mem: 8728
Epoch: [17]  [ 920/2001]  eta: 0:11:26  lr: 0.000254  loss: 3.2546 (3.0478)  time: 0.6275  data: 0.0001  max mem: 8728
Epoch: [17]  [ 930/2001]  eta: 0:11:19  lr: 0.000254  loss: 3.2546 (3.0504)  time: 0.6287  data: 0.0001  max mem: 8728
Epoch: [17]  [ 940/2001]  eta: 0:11:13  lr: 0.000254  loss: 3.2073 (3.0498)  time: 0.6269  data: 0.0001  max mem: 8728
Epoch: [17]  [ 950/2001]  eta: 0:11:06  lr: 0.000254  loss: 2.7128 (3.0445)  time: 0.6268  data: 0.0001  max mem: 8728
Epoch: [17]  [ 960/2001]  eta: 0:11:00  lr: 0.000254  loss: 2.8109 (3.0451)  time: 0.6293  data: 0.0001  max mem: 8728
Epoch: [17]  [ 970/2001]  eta: 0:10:54  lr: 0.000254  loss: 3.0652 (3.0454)  time: 0.6312  data: 0.0001  max mem: 8728
Epoch: [17]  [ 980/2001]  eta: 0:10:47  lr: 0.000254  loss: 3.1623 (3.0456)  time: 0.6307  data: 0.0001  max mem: 8728
Epoch: [17]  [ 990/2001]  eta: 0:10:41  lr: 0.000254  loss: 3.3507 (3.0454)  time: 0.6282  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9286, ratio_loss=0.0452, cls_kl=0.0640, token_kl=0.0917
Epoch: [17]  [1000/2001]  eta: 0:10:34  lr: 0.000254  loss: 3.1231 (3.0453)  time: 0.6290  data: 0.0001  max mem: 8728
Epoch: [17]  [1010/2001]  eta: 0:10:28  lr: 0.000254  loss: 3.0569 (3.0475)  time: 0.6276  data: 0.0001  max mem: 8728
Epoch: [17]  [1020/2001]  eta: 0:10:22  lr: 0.000254  loss: 3.1604 (3.0476)  time: 0.6287  data: 0.0001  max mem: 8728
Epoch: [17]  [1030/2001]  eta: 0:10:15  lr: 0.000254  loss: 3.1357 (3.0454)  time: 0.6312  data: 0.0001  max mem: 8728
Epoch: [17]  [1040/2001]  eta: 0:10:09  lr: 0.000254  loss: 3.1382 (3.0470)  time: 0.6333  data: 0.0001  max mem: 8728
Epoch: [17]  [1050/2001]  eta: 0:10:03  lr: 0.000254  loss: 3.1100 (3.0461)  time: 0.6429  data: 0.0001  max mem: 8728
Epoch: [17]  [1060/2001]  eta: 0:09:56  lr: 0.000254  loss: 3.1068 (3.0477)  time: 0.6476  data: 0.0001  max mem: 8728
Epoch: [17]  [1070/2001]  eta: 0:09:50  lr: 0.000254  loss: 3.1447 (3.0470)  time: 0.6451  data: 0.0001  max mem: 8728
Epoch: [17]  [1080/2001]  eta: 0:09:44  lr: 0.000254  loss: 3.2857 (3.0476)  time: 0.6364  data: 0.0002  max mem: 8728
Epoch: [17]  [1090/2001]  eta: 0:09:37  lr: 0.000254  loss: 3.1291 (3.0474)  time: 0.6285  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9472, ratio_loss=0.0460, cls_kl=0.0629, token_kl=0.0925
Epoch: [17]  [1100/2001]  eta: 0:09:31  lr: 0.000254  loss: 3.1023 (3.0468)  time: 0.6287  data: 0.0001  max mem: 8728
Epoch: [17]  [1110/2001]  eta: 0:09:25  lr: 0.000254  loss: 3.0752 (3.0473)  time: 0.6292  data: 0.0001  max mem: 8728
Epoch: [17]  [1120/2001]  eta: 0:09:18  lr: 0.000254  loss: 3.0950 (3.0488)  time: 0.6291  data: 0.0001  max mem: 8728
Epoch: [17]  [1130/2001]  eta: 0:09:12  lr: 0.000254  loss: 3.2076 (3.0501)  time: 0.6287  data: 0.0002  max mem: 8728
Epoch: [17]  [1140/2001]  eta: 0:09:06  lr: 0.000254  loss: 3.0069 (3.0491)  time: 0.6324  data: 0.0002  max mem: 8728
Epoch: [17]  [1150/2001]  eta: 0:08:59  lr: 0.000254  loss: 3.0069 (3.0496)  time: 0.6349  data: 0.0001  max mem: 8728
Epoch: [17]  [1160/2001]  eta: 0:08:53  lr: 0.000254  loss: 3.0924 (3.0496)  time: 0.6369  data: 0.0002  max mem: 8728
Epoch: [17]  [1170/2001]  eta: 0:08:47  lr: 0.000254  loss: 3.2999 (3.0494)  time: 0.6362  data: 0.0001  max mem: 8728
Epoch: [17]  [1180/2001]  eta: 0:08:40  lr: 0.000254  loss: 3.3824 (3.0517)  time: 0.6324  data: 0.0001  max mem: 8728
Epoch: [17]  [1190/2001]  eta: 0:08:34  lr: 0.000254  loss: 3.3501 (3.0527)  time: 0.6356  data: 0.0001  max mem: 8728
loss info: cls_loss=3.0146, ratio_loss=0.0495, cls_kl=0.0658, token_kl=0.0931
Epoch: [17]  [1200/2001]  eta: 0:08:28  lr: 0.000254  loss: 3.2639 (3.0532)  time: 0.6363  data: 0.0002  max mem: 8728
Epoch: [17]  [1210/2001]  eta: 0:08:21  lr: 0.000254  loss: 3.1403 (3.0524)  time: 0.6345  data: 0.0002  max mem: 8728
Epoch: [17]  [1220/2001]  eta: 0:08:15  lr: 0.000254  loss: 3.1337 (3.0520)  time: 0.6359  data: 0.0001  max mem: 8728
Epoch: [17]  [1230/2001]  eta: 0:08:09  lr: 0.000254  loss: 3.1974 (3.0529)  time: 0.6374  data: 0.0001  max mem: 8728
Epoch: [17]  [1240/2001]  eta: 0:08:02  lr: 0.000254  loss: 3.2911 (3.0534)  time: 0.6372  data: 0.0001  max mem: 8728
Epoch: [17]  [1250/2001]  eta: 0:07:56  lr: 0.000254  loss: 3.1220 (3.0517)  time: 0.6346  data: 0.0002  max mem: 8728
Epoch: [17]  [1260/2001]  eta: 0:07:50  lr: 0.000254  loss: 3.1444 (3.0524)  time: 0.6333  data: 0.0002  max mem: 8728
Epoch: [17]  [1270/2001]  eta: 0:07:43  lr: 0.000254  loss: 3.1996 (3.0529)  time: 0.6318  data: 0.0001  max mem: 8728
Epoch: [17]  [1280/2001]  eta: 0:07:37  lr: 0.000254  loss: 3.1411 (3.0545)  time: 0.6312  data: 0.0001  max mem: 8728
Epoch: [17]  [1290/2001]  eta: 0:07:30  lr: 0.000254  loss: 3.2220 (3.0561)  time: 0.6343  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9868, ratio_loss=0.0464, cls_kl=0.0651, token_kl=0.0941
Epoch: [17]  [1300/2001]  eta: 0:07:24  lr: 0.000254  loss: 3.2445 (3.0567)  time: 0.6342  data: 0.0001  max mem: 8728
Epoch: [17]  [1310/2001]  eta: 0:07:18  lr: 0.000254  loss: 2.9100 (3.0546)  time: 0.6382  data: 0.0002  max mem: 8728
Epoch: [17]  [1320/2001]  eta: 0:07:11  lr: 0.000254  loss: 2.8999 (3.0526)  time: 0.6391  data: 0.0001  max mem: 8728
Epoch: [17]  [1330/2001]  eta: 0:07:05  lr: 0.000254  loss: 2.9554 (3.0537)  time: 0.6380  data: 0.0001  max mem: 8728
Epoch: [17]  [1340/2001]  eta: 0:06:59  lr: 0.000254  loss: 3.2485 (3.0540)  time: 0.6435  data: 0.0001  max mem: 8728
Epoch: [17]  [1350/2001]  eta: 0:06:53  lr: 0.000254  loss: 3.2485 (3.0545)  time: 0.6414  data: 0.0002  max mem: 8728
Epoch: [17]  [1360/2001]  eta: 0:06:46  lr: 0.000254  loss: 3.3480 (3.0566)  time: 0.6373  data: 0.0002  max mem: 8728
Epoch: [17]  [1370/2001]  eta: 0:06:40  lr: 0.000254  loss: 3.3772 (3.0585)  time: 0.6359  data: 0.0001  max mem: 8728
Epoch: [17]  [1380/2001]  eta: 0:06:34  lr: 0.000254  loss: 3.3270 (3.0597)  time: 0.6356  data: 0.0001  max mem: 8728
Epoch: [17]  [1390/2001]  eta: 0:06:27  lr: 0.000254  loss: 3.0966 (3.0594)  time: 0.6385  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9916, ratio_loss=0.0469, cls_kl=0.0633, token_kl=0.0915
Epoch: [17]  [1400/2001]  eta: 0:06:21  lr: 0.000254  loss: 3.0881 (3.0597)  time: 0.6376  data: 0.0001  max mem: 8728
Epoch: [17]  [1410/2001]  eta: 0:06:15  lr: 0.000254  loss: 3.2519 (3.0619)  time: 0.6337  data: 0.0002  max mem: 8728
Epoch: [17]  [1420/2001]  eta: 0:06:08  lr: 0.000254  loss: 3.2338 (3.0619)  time: 0.6378  data: 0.0002  max mem: 8728
Epoch: [17]  [1430/2001]  eta: 0:06:02  lr: 0.000254  loss: 3.1464 (3.0626)  time: 0.6425  data: 0.0002  max mem: 8728
Epoch: [17]  [1440/2001]  eta: 0:05:56  lr: 0.000254  loss: 3.1176 (3.0620)  time: 0.6378  data: 0.0002  max mem: 8728
Epoch: [17]  [1450/2001]  eta: 0:05:49  lr: 0.000254  loss: 3.1176 (3.0627)  time: 0.6384  data: 0.0002  max mem: 8728
Epoch: [17]  [1460/2001]  eta: 0:05:43  lr: 0.000254  loss: 3.2788 (3.0637)  time: 0.6422  data: 0.0002  max mem: 8728
Epoch: [17]  [1470/2001]  eta: 0:05:37  lr: 0.000254  loss: 3.2254 (3.0631)  time: 0.6476  data: 0.0002  max mem: 8728
Epoch: [17]  [1480/2001]  eta: 0:05:30  lr: 0.000254  loss: 2.8720 (3.0620)  time: 0.6448  data: 0.0002  max mem: 8728
Epoch: [17]  [1490/2001]  eta: 0:05:24  lr: 0.000254  loss: 2.7182 (3.0591)  time: 0.6348  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9367, ratio_loss=0.0460, cls_kl=0.0634, token_kl=0.0935
Epoch: [17]  [1500/2001]  eta: 0:05:18  lr: 0.000254  loss: 2.8730 (3.0587)  time: 0.6346  data: 0.0002  max mem: 8728
Epoch: [17]  [1510/2001]  eta: 0:05:11  lr: 0.000254  loss: 3.0818 (3.0598)  time: 0.6381  data: 0.0002  max mem: 8728
Epoch: [17]  [1520/2001]  eta: 0:05:05  lr: 0.000254  loss: 3.3085 (3.0613)  time: 0.6451  data: 0.0001  max mem: 8728
Epoch: [17]  [1530/2001]  eta: 0:04:59  lr: 0.000254  loss: 3.1873 (3.0602)  time: 0.6467  data: 0.0002  max mem: 8728
Epoch: [17]  [1540/2001]  eta: 0:04:52  lr: 0.000254  loss: 3.0363 (3.0610)  time: 0.6414  data: 0.0002  max mem: 8728
Epoch: [17]  [1550/2001]  eta: 0:04:46  lr: 0.000254  loss: 3.0095 (3.0602)  time: 0.6404  data: 0.0002  max mem: 8728
Epoch: [17]  [1560/2001]  eta: 0:04:40  lr: 0.000254  loss: 2.9716 (3.0602)  time: 0.6400  data: 0.0002  max mem: 8728
Epoch: [17]  [1570/2001]  eta: 0:04:33  lr: 0.000254  loss: 2.8440 (3.0586)  time: 0.6359  data: 0.0002  max mem: 8728
Epoch: [17]  [1580/2001]  eta: 0:04:27  lr: 0.000254  loss: 2.8249 (3.0580)  time: 0.6362  data: 0.0001  max mem: 8728
Epoch: [17]  [1590/2001]  eta: 0:04:21  lr: 0.000254  loss: 3.2355 (3.0594)  time: 0.6370  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9891, ratio_loss=0.0456, cls_kl=0.0647, token_kl=0.0926
Epoch: [17]  [1600/2001]  eta: 0:04:14  lr: 0.000254  loss: 3.3786 (3.0615)  time: 0.6374  data: 0.0002  max mem: 8728
Epoch: [17]  [1610/2001]  eta: 0:04:08  lr: 0.000254  loss: 3.3786 (3.0627)  time: 0.6350  data: 0.0002  max mem: 8728
Epoch: [17]  [1620/2001]  eta: 0:04:02  lr: 0.000254  loss: 3.1347 (3.0622)  time: 0.6353  data: 0.0001  max mem: 8728
Epoch: [17]  [1630/2001]  eta: 0:03:55  lr: 0.000254  loss: 3.2182 (3.0637)  time: 0.6373  data: 0.0002  max mem: 8728
Epoch: [17]  [1640/2001]  eta: 0:03:49  lr: 0.000254  loss: 3.3012 (3.0639)  time: 0.6337  data: 0.0002  max mem: 8728
Epoch: [17]  [1650/2001]  eta: 0:03:42  lr: 0.000254  loss: 3.0036 (3.0610)  time: 0.6367  data: 0.0002  max mem: 8728
Epoch: [17]  [1660/2001]  eta: 0:03:36  lr: 0.000254  loss: 2.6763 (3.0595)  time: 0.6393  data: 0.0002  max mem: 8728
Epoch: [17]  [1670/2001]  eta: 0:03:30  lr: 0.000254  loss: 3.0220 (3.0600)  time: 0.6359  data: 0.0001  max mem: 8728
Epoch: [17]  [1680/2001]  eta: 0:03:23  lr: 0.000254  loss: 3.3666 (3.0599)  time: 0.6371  data: 0.0002  max mem: 8728
Epoch: [17]  [1690/2001]  eta: 0:03:17  lr: 0.000254  loss: 3.3004 (3.0603)  time: 0.6383  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9575, ratio_loss=0.0461, cls_kl=0.0654, token_kl=0.0945
Epoch: [17]  [1700/2001]  eta: 0:03:11  lr: 0.000254  loss: 3.3253 (3.0621)  time: 0.6346  data: 0.0002  max mem: 8728
Epoch: [17]  [1710/2001]  eta: 0:03:04  lr: 0.000254  loss: 3.2691 (3.0619)  time: 0.6328  data: 0.0002  max mem: 8728
Epoch: [17]  [1720/2001]  eta: 0:02:58  lr: 0.000254  loss: 2.9832 (3.0608)  time: 0.6321  data: 0.0002  max mem: 8728
Epoch: [17]  [1730/2001]  eta: 0:02:52  lr: 0.000254  loss: 3.1762 (3.0624)  time: 0.6310  data: 0.0002  max mem: 8728
Epoch: [17]  [1740/2001]  eta: 0:02:45  lr: 0.000254  loss: 3.1762 (3.0616)  time: 0.6395  data: 0.0002  max mem: 8728
Epoch: [17]  [1750/2001]  eta: 0:02:39  lr: 0.000254  loss: 2.6955 (3.0601)  time: 0.6410  data: 0.0002  max mem: 8728
Epoch: [17]  [1760/2001]  eta: 0:02:33  lr: 0.000254  loss: 2.9004 (3.0603)  time: 0.6321  data: 0.0002  max mem: 8728
Epoch: [17]  [1770/2001]  eta: 0:02:26  lr: 0.000254  loss: 3.1777 (3.0606)  time: 0.6311  data: 0.0002  max mem: 8728
Epoch: [17]  [1780/2001]  eta: 0:02:20  lr: 0.000254  loss: 3.2757 (3.0608)  time: 0.6335  data: 0.0002  max mem: 8728
Epoch: [17]  [1790/2001]  eta: 0:02:14  lr: 0.000254  loss: 3.0977 (3.0603)  time: 0.6329  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9465, ratio_loss=0.0461, cls_kl=0.0641, token_kl=0.0929
Epoch: [17]  [1800/2001]  eta: 0:02:07  lr: 0.000254  loss: 3.2077 (3.0611)  time: 0.6334  data: 0.0002  max mem: 8728
Epoch: [17]  [1810/2001]  eta: 0:02:01  lr: 0.000254  loss: 3.1425 (3.0602)  time: 0.6314  data: 0.0002  max mem: 8728
Epoch: [17]  [1820/2001]  eta: 0:01:54  lr: 0.000254  loss: 3.0764 (3.0608)  time: 0.6289  data: 0.0002  max mem: 8728
Epoch: [17]  [1830/2001]  eta: 0:01:48  lr: 0.000254  loss: 3.1864 (3.0619)  time: 0.6296  data: 0.0002  max mem: 8728
Epoch: [17]  [1840/2001]  eta: 0:01:42  lr: 0.000254  loss: 3.1864 (3.0617)  time: 0.6335  data: 0.0002  max mem: 8728
Epoch: [17]  [1850/2001]  eta: 0:01:35  lr: 0.000254  loss: 3.0572 (3.0610)  time: 0.6368  data: 0.0001  max mem: 8728
Epoch: [17]  [1860/2001]  eta: 0:01:29  lr: 0.000254  loss: 3.0572 (3.0608)  time: 0.6323  data: 0.0001  max mem: 8728
Epoch: [17]  [1870/2001]  eta: 0:01:23  lr: 0.000254  loss: 3.1175 (3.0595)  time: 0.6280  data: 0.0001  max mem: 8728
Epoch: [17]  [1880/2001]  eta: 0:01:16  lr: 0.000254  loss: 3.2103 (3.0603)  time: 0.6263  data: 0.0002  max mem: 8728
Epoch: [17]  [1890/2001]  eta: 0:01:10  lr: 0.000254  loss: 3.2103 (3.0598)  time: 0.6237  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9099, ratio_loss=0.0443, cls_kl=0.0629, token_kl=0.0929
Epoch: [17]  [1900/2001]  eta: 0:01:04  lr: 0.000254  loss: 3.0233 (3.0592)  time: 0.6290  data: 0.0001  max mem: 8728
Epoch: [17]  [1910/2001]  eta: 0:00:57  lr: 0.000254  loss: 3.1392 (3.0595)  time: 0.6363  data: 0.0001  max mem: 8728
Epoch: [17]  [1920/2001]  eta: 0:00:51  lr: 0.000254  loss: 3.0157 (3.0573)  time: 0.6315  data: 0.0001  max mem: 8728
Epoch: [17]  [1930/2001]  eta: 0:00:45  lr: 0.000254  loss: 2.7232 (3.0568)  time: 0.6282  data: 0.0001  max mem: 8728
Epoch: [17]  [1940/2001]  eta: 0:00:38  lr: 0.000254  loss: 2.8009 (3.0558)  time: 0.6268  data: 0.0001  max mem: 8728
Epoch: [17]  [1950/2001]  eta: 0:00:32  lr: 0.000254  loss: 2.8455 (3.0550)  time: 0.6266  data: 0.0003  max mem: 8728
Epoch: [17]  [1960/2001]  eta: 0:00:26  lr: 0.000254  loss: 3.0452 (3.0539)  time: 0.6286  data: 0.0003  max mem: 8728
Epoch: [17]  [1970/2001]  eta: 0:00:19  lr: 0.000254  loss: 3.0409 (3.0519)  time: 0.6242  data: 0.0002  max mem: 8728
Epoch: [17]  [1980/2001]  eta: 0:00:13  lr: 0.000254  loss: 3.0139 (3.0517)  time: 0.6182  data: 0.0001  max mem: 8728
Epoch: [17]  [1990/2001]  eta: 0:00:06  lr: 0.000254  loss: 3.1131 (3.0513)  time: 0.6207  data: 0.0004  max mem: 8728
loss info: cls_loss=2.7900, ratio_loss=0.0409, cls_kl=0.0584, token_kl=0.0900
Epoch: [17]  [2000/2001]  eta: 0:00:00  lr: 0.000254  loss: 2.9426 (3.0505)  time: 0.6214  data: 0.0004  max mem: 8728
Epoch: [17] Total time: 0:21:10 (0.6348 s / it)
Averaged stats: lr: 0.000254  loss: 2.9426 (3.0501)
Test:  [ 0/53]  eta: 0:05:48  loss: 0.3621 (0.3621)  acc1: 93.3333 (93.3333)  acc5: 99.1667 (99.1667)  time: 6.5766  data: 5.5104  max mem: 8728
Test:  [10/53]  eta: 0:00:39  loss: 0.7754 (0.7810)  acc1: 83.3333 (83.2576)  acc5: 96.6667 (96.4394)  time: 0.9296  data: 0.5012  max mem: 8728
Test:  [20/53]  eta: 0:00:21  loss: 0.7562 (0.7760)  acc1: 83.3333 (83.0556)  acc5: 96.6667 (96.5079)  time: 0.3573  data: 0.0003  max mem: 8728
Test:  [30/53]  eta: 0:00:12  loss: 0.8948 (0.8604)  acc1: 79.1667 (80.8602)  acc5: 95.0000 (95.2151)  time: 0.3409  data: 0.0003  max mem: 8728
Test:  [40/53]  eta: 0:00:06  loss: 1.1090 (0.9254)  acc1: 76.6667 (79.4715)  acc5: 92.5000 (94.4309)  time: 0.2982  data: 0.0002  max mem: 8728
Test:  [50/53]  eta: 0:00:01  loss: 1.0993 (0.9547)  acc1: 77.5000 (78.7418)  acc5: 92.5000 (94.2811)  time: 0.2581  data: 0.0001  max mem: 8728
Test:  [52/53]  eta: 0:00:00  loss: 1.0966 (0.9404)  acc1: 77.5000 (78.9440)  acc5: 92.5000 (94.3680)  time: 0.2437  data: 0.0000  max mem: 8728
Test: Total time: 0:00:22 (0.4276 s / it)
Sparsity0:0.2956662626262626,Sparsity1:0.5647027135678392,Sparsity2:0.786776,
* Acc@1 79.090 Acc@5 94.496 loss 0.942
Accuracy of the network on the 50000 test images: 79.1%
Max accuracy: 79.09%
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0002225 for PREDICTOR
Epoch: [18]  [   0/2001]  eta: 2:25:39  lr: 0.000222  loss: 2.6098 (2.6098)  time: 4.3675  data: 3.7113  max mem: 8728
Epoch: [18]  [  10/2001]  eta: 0:31:46  lr: 0.000222  loss: 3.3306 (3.2820)  time: 0.9576  data: 0.3375  max mem: 8730
Epoch: [18]  [  20/2001]  eta: 0:26:18  lr: 0.000222  loss: 3.1796 (3.1773)  time: 0.6182  data: 0.0001  max mem: 8730
Epoch: [18]  [  30/2001]  eta: 0:24:14  lr: 0.000222  loss: 3.2768 (3.2181)  time: 0.6175  data: 0.0001  max mem: 8730
Epoch: [18]  [  40/2001]  eta: 0:23:11  lr: 0.000222  loss: 3.1832 (3.1696)  time: 0.6176  data: 0.0002  max mem: 8730
Epoch: [18]  [  50/2001]  eta: 0:22:30  lr: 0.000222  loss: 3.0395 (3.1330)  time: 0.6207  data: 0.0002  max mem: 8730
Epoch: [18]  [  60/2001]  eta: 0:21:59  lr: 0.000222  loss: 2.8408 (3.0797)  time: 0.6194  data: 0.0001  max mem: 8730
Epoch: [18]  [  70/2001]  eta: 0:21:35  lr: 0.000222  loss: 2.9114 (3.0866)  time: 0.6177  data: 0.0001  max mem: 8730
Epoch: [18]  [  80/2001]  eta: 0:21:18  lr: 0.000222  loss: 2.9992 (3.0569)  time: 0.6216  data: 0.0001  max mem: 8730
Epoch: [18]  [  90/2001]  eta: 0:21:02  lr: 0.000222  loss: 3.0342 (3.0755)  time: 0.6238  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9517, ratio_loss=0.0463, cls_kl=0.0645, token_kl=0.0941
Epoch: [18]  [ 100/2001]  eta: 0:20:51  lr: 0.000222  loss: 3.1190 (3.0630)  time: 0.6282  data: 0.0001  max mem: 8730
Epoch: [18]  [ 110/2001]  eta: 0:20:38  lr: 0.000222  loss: 3.1993 (3.0703)  time: 0.6277  data: 0.0001  max mem: 8730
Epoch: [18]  [ 120/2001]  eta: 0:20:26  lr: 0.000222  loss: 3.2069 (3.0694)  time: 0.6229  data: 0.0001  max mem: 8730
Epoch: [18]  [ 130/2001]  eta: 0:20:16  lr: 0.000222  loss: 3.1861 (3.0753)  time: 0.6244  data: 0.0001  max mem: 8730
Epoch: [18]  [ 140/2001]  eta: 0:20:09  lr: 0.000222  loss: 3.2802 (3.0939)  time: 0.6338  data: 0.0001  max mem: 8730
Epoch: [18]  [ 150/2001]  eta: 0:20:01  lr: 0.000222  loss: 3.2291 (3.0829)  time: 0.6427  data: 0.0001  max mem: 8730
Epoch: [18]  [ 160/2001]  eta: 0:19:53  lr: 0.000222  loss: 3.1424 (3.0789)  time: 0.6379  data: 0.0001  max mem: 8730
Epoch: [18]  [ 170/2001]  eta: 0:19:44  lr: 0.000222  loss: 3.2569 (3.0878)  time: 0.6303  data: 0.0001  max mem: 8730
Epoch: [18]  [ 180/2001]  eta: 0:19:36  lr: 0.000222  loss: 3.2471 (3.0804)  time: 0.6287  data: 0.0001  max mem: 8730
Epoch: [18]  [ 190/2001]  eta: 0:19:28  lr: 0.000222  loss: 3.1365 (3.0837)  time: 0.6306  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9570, ratio_loss=0.0472, cls_kl=0.0640, token_kl=0.0931
Epoch: [18]  [ 200/2001]  eta: 0:19:20  lr: 0.000222  loss: 3.0550 (3.0680)  time: 0.6286  data: 0.0001  max mem: 8730
Epoch: [18]  [ 210/2001]  eta: 0:19:13  lr: 0.000222  loss: 2.9312 (3.0672)  time: 0.6330  data: 0.0001  max mem: 8730
Epoch: [18]  [ 220/2001]  eta: 0:19:05  lr: 0.000222  loss: 2.9295 (3.0593)  time: 0.6328  data: 0.0001  max mem: 8730
Epoch: [18]  [ 230/2001]  eta: 0:18:59  lr: 0.000222  loss: 2.8988 (3.0492)  time: 0.6344  data: 0.0002  max mem: 8730
Epoch: [18]  [ 240/2001]  eta: 0:18:52  lr: 0.000222  loss: 2.9108 (3.0474)  time: 0.6392  data: 0.0001  max mem: 8730
Epoch: [18]  [ 250/2001]  eta: 0:18:44  lr: 0.000222  loss: 2.9153 (3.0434)  time: 0.6322  data: 0.0001  max mem: 8730
Epoch: [18]  [ 260/2001]  eta: 0:18:36  lr: 0.000222  loss: 2.8771 (3.0433)  time: 0.6253  data: 0.0001  max mem: 8730
Epoch: [18]  [ 270/2001]  eta: 0:18:29  lr: 0.000222  loss: 3.0620 (3.0454)  time: 0.6255  data: 0.0001  max mem: 8730
Epoch: [18]  [ 280/2001]  eta: 0:18:22  lr: 0.000222  loss: 3.2889 (3.0531)  time: 0.6275  data: 0.0001  max mem: 8730
Epoch: [18]  [ 290/2001]  eta: 0:18:15  lr: 0.000222  loss: 3.0898 (3.0496)  time: 0.6256  data: 0.0002  max mem: 8730
loss info: cls_loss=2.8922, ratio_loss=0.0438, cls_kl=0.0615, token_kl=0.0913
Epoch: [18]  [ 300/2001]  eta: 0:18:07  lr: 0.000222  loss: 2.9644 (3.0409)  time: 0.6257  data: 0.0002  max mem: 8730
Epoch: [18]  [ 310/2001]  eta: 0:18:00  lr: 0.000222  loss: 3.0097 (3.0388)  time: 0.6254  data: 0.0001  max mem: 8730
Epoch: [18]  [ 320/2001]  eta: 0:17:53  lr: 0.000222  loss: 3.1708 (3.0440)  time: 0.6270  data: 0.0001  max mem: 8730
Epoch: [18]  [ 330/2001]  eta: 0:17:46  lr: 0.000222  loss: 3.2959 (3.0536)  time: 0.6262  data: 0.0001  max mem: 8730
Epoch: [18]  [ 340/2001]  eta: 0:17:39  lr: 0.000222  loss: 3.2913 (3.0505)  time: 0.6261  data: 0.0001  max mem: 8730
Epoch: [18]  [ 350/2001]  eta: 0:17:33  lr: 0.000222  loss: 3.1352 (3.0528)  time: 0.6332  data: 0.0002  max mem: 8730
Epoch: [18]  [ 360/2001]  eta: 0:17:26  lr: 0.000222  loss: 3.0109 (3.0485)  time: 0.6334  data: 0.0001  max mem: 8730
Epoch: [18]  [ 370/2001]  eta: 0:17:19  lr: 0.000222  loss: 2.8880 (3.0452)  time: 0.6270  data: 0.0001  max mem: 8730
Epoch: [18]  [ 380/2001]  eta: 0:17:13  lr: 0.000222  loss: 3.0977 (3.0464)  time: 0.6312  data: 0.0001  max mem: 8730
Epoch: [18]  [ 390/2001]  eta: 0:17:06  lr: 0.000222  loss: 3.1011 (3.0425)  time: 0.6320  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9227, ratio_loss=0.0451, cls_kl=0.0637, token_kl=0.0929
Epoch: [18]  [ 400/2001]  eta: 0:17:00  lr: 0.000222  loss: 3.0390 (3.0409)  time: 0.6352  data: 0.0001  max mem: 8730
Epoch: [18]  [ 410/2001]  eta: 0:16:53  lr: 0.000222  loss: 3.0807 (3.0440)  time: 0.6391  data: 0.0002  max mem: 8730
Epoch: [18]  [ 420/2001]  eta: 0:16:47  lr: 0.000222  loss: 3.0793 (3.0379)  time: 0.6321  data: 0.0002  max mem: 8730
Epoch: [18]  [ 430/2001]  eta: 0:16:40  lr: 0.000222  loss: 3.1423 (3.0421)  time: 0.6300  data: 0.0001  max mem: 8730
Epoch: [18]  [ 440/2001]  eta: 0:16:33  lr: 0.000222  loss: 3.2555 (3.0445)  time: 0.6291  data: 0.0001  max mem: 8730
Epoch: [18]  [ 450/2001]  eta: 0:16:27  lr: 0.000222  loss: 3.1948 (3.0477)  time: 0.6279  data: 0.0001  max mem: 8730
Epoch: [18]  [ 460/2001]  eta: 0:16:20  lr: 0.000222  loss: 3.1238 (3.0465)  time: 0.6283  data: 0.0001  max mem: 8730
Epoch: [18]  [ 470/2001]  eta: 0:16:14  lr: 0.000222  loss: 2.9872 (3.0440)  time: 0.6306  data: 0.0001  max mem: 8730
Epoch: [18]  [ 480/2001]  eta: 0:16:08  lr: 0.000222  loss: 2.6948 (3.0419)  time: 0.6405  data: 0.0001  max mem: 8730
Epoch: [18]  [ 490/2001]  eta: 0:16:01  lr: 0.000222  loss: 3.1647 (3.0476)  time: 0.6378  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9534, ratio_loss=0.0451, cls_kl=0.0646, token_kl=0.0943
Epoch: [18]  [ 500/2001]  eta: 0:15:55  lr: 0.000222  loss: 3.1185 (3.0439)  time: 0.6337  data: 0.0001  max mem: 8730
Epoch: [18]  [ 510/2001]  eta: 0:15:49  lr: 0.000222  loss: 2.8646 (3.0427)  time: 0.6436  data: 0.0001  max mem: 8730
Epoch: [18]  [ 520/2001]  eta: 0:15:42  lr: 0.000222  loss: 3.0448 (3.0447)  time: 0.6403  data: 0.0001  max mem: 8730
Epoch: [18]  [ 530/2001]  eta: 0:15:36  lr: 0.000222  loss: 3.1800 (3.0462)  time: 0.6340  data: 0.0001  max mem: 8730
Epoch: [18]  [ 540/2001]  eta: 0:15:29  lr: 0.000222  loss: 3.0762 (3.0430)  time: 0.6350  data: 0.0001  max mem: 8730
Epoch: [18]  [ 550/2001]  eta: 0:15:23  lr: 0.000222  loss: 2.9706 (3.0461)  time: 0.6384  data: 0.0001  max mem: 8730
Epoch: [18]  [ 560/2001]  eta: 0:15:17  lr: 0.000222  loss: 3.3302 (3.0532)  time: 0.6442  data: 0.0001  max mem: 8730
Epoch: [18]  [ 570/2001]  eta: 0:15:11  lr: 0.000222  loss: 3.3651 (3.0582)  time: 0.6398  data: 0.0002  max mem: 8730
Epoch: [18]  [ 580/2001]  eta: 0:15:04  lr: 0.000222  loss: 3.2747 (3.0606)  time: 0.6292  data: 0.0002  max mem: 8730
Epoch: [18]  [ 590/2001]  eta: 0:14:57  lr: 0.000222  loss: 3.1510 (3.0586)  time: 0.6265  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0239, ratio_loss=0.0461, cls_kl=0.0648, token_kl=0.0929
Epoch: [18]  [ 600/2001]  eta: 0:14:51  lr: 0.000222  loss: 3.0854 (3.0590)  time: 0.6308  data: 0.0001  max mem: 8730
Epoch: [18]  [ 610/2001]  eta: 0:14:45  lr: 0.000222  loss: 3.0646 (3.0550)  time: 0.6335  data: 0.0001  max mem: 8730
Epoch: [18]  [ 620/2001]  eta: 0:14:38  lr: 0.000222  loss: 3.0646 (3.0562)  time: 0.6320  data: 0.0001  max mem: 8730
Epoch: [18]  [ 630/2001]  eta: 0:14:32  lr: 0.000222  loss: 3.1145 (3.0553)  time: 0.6327  data: 0.0001  max mem: 8730
Epoch: [18]  [ 640/2001]  eta: 0:14:25  lr: 0.000222  loss: 3.2462 (3.0592)  time: 0.6349  data: 0.0001  max mem: 8730
Epoch: [18]  [ 650/2001]  eta: 0:14:19  lr: 0.000222  loss: 3.3660 (3.0568)  time: 0.6362  data: 0.0002  max mem: 8730
Epoch: [18]  [ 660/2001]  eta: 0:14:13  lr: 0.000222  loss: 3.1794 (3.0584)  time: 0.6381  data: 0.0001  max mem: 8730
Epoch: [18]  [ 670/2001]  eta: 0:14:06  lr: 0.000222  loss: 3.2476 (3.0597)  time: 0.6396  data: 0.0001  max mem: 8730
Epoch: [18]  [ 680/2001]  eta: 0:14:00  lr: 0.000222  loss: 3.2484 (3.0608)  time: 0.6363  data: 0.0001  max mem: 8730
Epoch: [18]  [ 690/2001]  eta: 0:13:54  lr: 0.000222  loss: 3.2695 (3.0633)  time: 0.6368  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9831, ratio_loss=0.0467, cls_kl=0.0637, token_kl=0.0922
Epoch: [18]  [ 700/2001]  eta: 0:13:47  lr: 0.000222  loss: 3.3214 (3.0650)  time: 0.6426  data: 0.0001  max mem: 8730
Epoch: [18]  [ 710/2001]  eta: 0:13:41  lr: 0.000222  loss: 3.3214 (3.0686)  time: 0.6469  data: 0.0001  max mem: 8730
Epoch: [18]  [ 720/2001]  eta: 0:13:35  lr: 0.000222  loss: 3.2439 (3.0663)  time: 0.6479  data: 0.0001  max mem: 8730
Epoch: [18]  [ 730/2001]  eta: 0:13:29  lr: 0.000222  loss: 3.2439 (3.0688)  time: 0.6490  data: 0.0002  max mem: 8730
Epoch: [18]  [ 740/2001]  eta: 0:13:23  lr: 0.000222  loss: 3.1575 (3.0644)  time: 0.6453  data: 0.0002  max mem: 8730
Epoch: [18]  [ 750/2001]  eta: 0:13:16  lr: 0.000222  loss: 2.9193 (3.0645)  time: 0.6421  data: 0.0001  max mem: 8730
Epoch: [18]  [ 760/2001]  eta: 0:13:10  lr: 0.000222  loss: 3.0316 (3.0618)  time: 0.6394  data: 0.0001  max mem: 8730
Epoch: [18]  [ 770/2001]  eta: 0:13:04  lr: 0.000222  loss: 3.3119 (3.0646)  time: 0.6332  data: 0.0001  max mem: 8730
Epoch: [18]  [ 780/2001]  eta: 0:12:57  lr: 0.000222  loss: 3.2438 (3.0642)  time: 0.6365  data: 0.0001  max mem: 8730
Epoch: [18]  [ 790/2001]  eta: 0:12:51  lr: 0.000222  loss: 2.9528 (3.0621)  time: 0.6379  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9421, ratio_loss=0.0439, cls_kl=0.0619, token_kl=0.0913
Epoch: [18]  [ 800/2001]  eta: 0:12:44  lr: 0.000222  loss: 2.8999 (3.0617)  time: 0.6348  data: 0.0002  max mem: 8730
Epoch: [18]  [ 810/2001]  eta: 0:12:38  lr: 0.000222  loss: 3.1953 (3.0613)  time: 0.6380  data: 0.0001  max mem: 8730
Epoch: [18]  [ 820/2001]  eta: 0:12:32  lr: 0.000222  loss: 3.1953 (3.0621)  time: 0.6412  data: 0.0002  max mem: 8730
Epoch: [18]  [ 830/2001]  eta: 0:12:26  lr: 0.000222  loss: 3.2131 (3.0611)  time: 0.6446  data: 0.0002  max mem: 8730
Epoch: [18]  [ 840/2001]  eta: 0:12:19  lr: 0.000222  loss: 3.1634 (3.0624)  time: 0.6456  data: 0.0002  max mem: 8730
Epoch: [18]  [ 850/2001]  eta: 0:12:13  lr: 0.000222  loss: 3.0314 (3.0600)  time: 0.6450  data: 0.0002  max mem: 8730
Epoch: [18]  [ 860/2001]  eta: 0:12:07  lr: 0.000222  loss: 2.5774 (3.0531)  time: 0.6469  data: 0.0002  max mem: 8730
Epoch: [18]  [ 870/2001]  eta: 0:12:00  lr: 0.000222  loss: 2.4488 (3.0503)  time: 0.6415  data: 0.0002  max mem: 8730
Epoch: [18]  [ 880/2001]  eta: 0:11:54  lr: 0.000222  loss: 3.1672 (3.0516)  time: 0.6334  data: 0.0001  max mem: 8730
Epoch: [18]  [ 890/2001]  eta: 0:11:48  lr: 0.000222  loss: 3.1293 (3.0498)  time: 0.6331  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8704, ratio_loss=0.0417, cls_kl=0.0611, token_kl=0.0909
Epoch: [18]  [ 900/2001]  eta: 0:11:41  lr: 0.000222  loss: 3.1220 (3.0524)  time: 0.6397  data: 0.0001  max mem: 8730
Epoch: [18]  [ 910/2001]  eta: 0:11:35  lr: 0.000222  loss: 3.1578 (3.0492)  time: 0.6405  data: 0.0001  max mem: 8730
Epoch: [18]  [ 920/2001]  eta: 0:11:29  lr: 0.000222  loss: 3.0884 (3.0507)  time: 0.6383  data: 0.0001  max mem: 8730
Epoch: [18]  [ 930/2001]  eta: 0:11:22  lr: 0.000222  loss: 3.3080 (3.0524)  time: 0.6426  data: 0.0001  max mem: 8730
Epoch: [18]  [ 940/2001]  eta: 0:11:16  lr: 0.000222  loss: 3.3478 (3.0556)  time: 0.6450  data: 0.0001  max mem: 8730
Epoch: [18]  [ 950/2001]  eta: 0:11:10  lr: 0.000222  loss: 3.1352 (3.0519)  time: 0.6371  data: 0.0001  max mem: 8730
Epoch: [18]  [ 960/2001]  eta: 0:11:03  lr: 0.000222  loss: 2.9317 (3.0522)  time: 0.6320  data: 0.0001  max mem: 8730
Epoch: [18]  [ 970/2001]  eta: 0:10:57  lr: 0.000222  loss: 3.1305 (3.0533)  time: 0.6374  data: 0.0001  max mem: 8730
Epoch: [18]  [ 980/2001]  eta: 0:10:50  lr: 0.000222  loss: 3.0922 (3.0510)  time: 0.6415  data: 0.0001  max mem: 8730
Epoch: [18]  [ 990/2001]  eta: 0:10:44  lr: 0.000222  loss: 3.2250 (3.0528)  time: 0.6403  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9557, ratio_loss=0.0456, cls_kl=0.0632, token_kl=0.0926
Epoch: [18]  [1000/2001]  eta: 0:10:38  lr: 0.000222  loss: 3.3437 (3.0535)  time: 0.6366  data: 0.0001  max mem: 8730
Epoch: [18]  [1010/2001]  eta: 0:10:31  lr: 0.000222  loss: 3.1857 (3.0536)  time: 0.6409  data: 0.0001  max mem: 8730
Epoch: [18]  [1020/2001]  eta: 0:10:25  lr: 0.000222  loss: 3.1857 (3.0541)  time: 0.6450  data: 0.0001  max mem: 8730
Epoch: [18]  [1030/2001]  eta: 0:10:19  lr: 0.000222  loss: 3.2122 (3.0529)  time: 0.6414  data: 0.0001  max mem: 8730
Epoch: [18]  [1040/2001]  eta: 0:10:12  lr: 0.000222  loss: 3.1581 (3.0528)  time: 0.6371  data: 0.0001  max mem: 8730
Epoch: [18]  [1050/2001]  eta: 0:10:06  lr: 0.000222  loss: 3.1892 (3.0540)  time: 0.6338  data: 0.0001  max mem: 8730
Epoch: [18]  [1060/2001]  eta: 0:10:00  lr: 0.000222  loss: 3.1892 (3.0528)  time: 0.6391  data: 0.0001  max mem: 8730
Epoch: [18]  [1070/2001]  eta: 0:09:53  lr: 0.000222  loss: 3.1046 (3.0522)  time: 0.6404  data: 0.0001  max mem: 8730
Epoch: [18]  [1080/2001]  eta: 0:09:47  lr: 0.000222  loss: 2.9330 (3.0502)  time: 0.6394  data: 0.0002  max mem: 8730
Epoch: [18]  [1090/2001]  eta: 0:09:41  lr: 0.000222  loss: 2.9330 (3.0496)  time: 0.6500  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9196, ratio_loss=0.0427, cls_kl=0.0608, token_kl=0.0909
Epoch: [18]  [1100/2001]  eta: 0:09:34  lr: 0.000222  loss: 3.2532 (3.0506)  time: 0.6467  data: 0.0001  max mem: 8730
Epoch: [18]  [1110/2001]  eta: 0:09:28  lr: 0.000222  loss: 3.2532 (3.0515)  time: 0.6353  data: 0.0001  max mem: 8730
Epoch: [18]  [1120/2001]  eta: 0:09:21  lr: 0.000222  loss: 3.1490 (3.0515)  time: 0.6353  data: 0.0001  max mem: 8730
Epoch: [18]  [1130/2001]  eta: 0:09:15  lr: 0.000222  loss: 3.1250 (3.0510)  time: 0.6425  data: 0.0001  max mem: 8730
Epoch: [18]  [1140/2001]  eta: 0:09:09  lr: 0.000222  loss: 2.8769 (3.0475)  time: 0.6424  data: 0.0001  max mem: 8730
Epoch: [18]  [1150/2001]  eta: 0:09:02  lr: 0.000222  loss: 2.8769 (3.0479)  time: 0.6389  data: 0.0001  max mem: 8730
Epoch: [18]  [1160/2001]  eta: 0:08:56  lr: 0.000222  loss: 3.0726 (3.0466)  time: 0.6385  data: 0.0001  max mem: 8730
Epoch: [18]  [1170/2001]  eta: 0:08:50  lr: 0.000222  loss: 2.9469 (3.0472)  time: 0.6337  data: 0.0001  max mem: 8730
Epoch: [18]  [1180/2001]  eta: 0:08:43  lr: 0.000222  loss: 3.2099 (3.0481)  time: 0.6301  data: 0.0001  max mem: 8730
Epoch: [18]  [1190/2001]  eta: 0:08:37  lr: 0.000222  loss: 3.1451 (3.0460)  time: 0.6291  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8962, ratio_loss=0.0420, cls_kl=0.0615, token_kl=0.0914
Epoch: [18]  [1200/2001]  eta: 0:08:30  lr: 0.000222  loss: 3.0389 (3.0466)  time: 0.6340  data: 0.0001  max mem: 8730
Epoch: [18]  [1210/2001]  eta: 0:08:24  lr: 0.000222  loss: 3.2260 (3.0470)  time: 0.6368  data: 0.0001  max mem: 8730
Epoch: [18]  [1220/2001]  eta: 0:08:18  lr: 0.000222  loss: 3.1124 (3.0469)  time: 0.6345  data: 0.0001  max mem: 8730
Epoch: [18]  [1230/2001]  eta: 0:08:11  lr: 0.000222  loss: 3.2190 (3.0483)  time: 0.6320  data: 0.0001  max mem: 8730
Epoch: [18]  [1240/2001]  eta: 0:08:05  lr: 0.000222  loss: 3.3979 (3.0520)  time: 0.6357  data: 0.0001  max mem: 8730
Epoch: [18]  [1250/2001]  eta: 0:07:58  lr: 0.000222  loss: 3.3540 (3.0514)  time: 0.6398  data: 0.0001  max mem: 8730
Epoch: [18]  [1260/2001]  eta: 0:07:52  lr: 0.000222  loss: 2.9563 (3.0502)  time: 0.6329  data: 0.0001  max mem: 8730
Epoch: [18]  [1270/2001]  eta: 0:07:46  lr: 0.000222  loss: 2.9387 (3.0492)  time: 0.6313  data: 0.0002  max mem: 8730
Epoch: [18]  [1280/2001]  eta: 0:07:39  lr: 0.000222  loss: 2.8977 (3.0491)  time: 0.6378  data: 0.0001  max mem: 8730
Epoch: [18]  [1290/2001]  eta: 0:07:33  lr: 0.000222  loss: 3.1823 (3.0505)  time: 0.6353  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9958, ratio_loss=0.0484, cls_kl=0.0680, token_kl=0.0978
Epoch: [18]  [1300/2001]  eta: 0:07:26  lr: 0.000222  loss: 3.2341 (3.0508)  time: 0.6346  data: 0.0001  max mem: 8730
Epoch: [18]  [1310/2001]  eta: 0:07:20  lr: 0.000222  loss: 3.2180 (3.0521)  time: 0.6369  data: 0.0001  max mem: 8730
Epoch: [18]  [1320/2001]  eta: 0:07:14  lr: 0.000222  loss: 3.1968 (3.0525)  time: 0.6317  data: 0.0001  max mem: 8730
Epoch: [18]  [1330/2001]  eta: 0:07:07  lr: 0.000222  loss: 3.1355 (3.0505)  time: 0.6306  data: 0.0002  max mem: 8730
Epoch: [18]  [1340/2001]  eta: 0:07:01  lr: 0.000222  loss: 2.7705 (3.0490)  time: 0.6336  data: 0.0001  max mem: 8730
Epoch: [18]  [1350/2001]  eta: 0:06:54  lr: 0.000222  loss: 3.0695 (3.0496)  time: 0.6308  data: 0.0001  max mem: 8730
Epoch: [18]  [1360/2001]  eta: 0:06:48  lr: 0.000222  loss: 3.0695 (3.0485)  time: 0.6402  data: 0.0001  max mem: 8730
Epoch: [18]  [1370/2001]  eta: 0:06:42  lr: 0.000222  loss: 2.8850 (3.0478)  time: 0.6397  data: 0.0001  max mem: 8730
Epoch: [18]  [1380/2001]  eta: 0:06:35  lr: 0.000222  loss: 3.0834 (3.0473)  time: 0.6228  data: 0.0001  max mem: 8730
Epoch: [18]  [1390/2001]  eta: 0:06:29  lr: 0.000222  loss: 3.1863 (3.0485)  time: 0.6217  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8853, ratio_loss=0.0465, cls_kl=0.0634, token_kl=0.0940
Epoch: [18]  [1400/2001]  eta: 0:06:22  lr: 0.000222  loss: 3.1151 (3.0471)  time: 0.6287  data: 0.0001  max mem: 8730
Epoch: [18]  [1410/2001]  eta: 0:06:16  lr: 0.000222  loss: 3.1151 (3.0480)  time: 0.6310  data: 0.0001  max mem: 8730
Loss is nan, stopping training
Traceback (most recent call last):
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 256, in main
    cmd=cmd)
subprocess.CalledProcessError: Command '['/home/zlkong/anaconda3/envs/DynamicVit/bin/python3', '-u', 'main_l2_vit_3keep.py', '--output_dir', 'logs/no-amp-3keep', '--arch', 'deit_small', '--input-size', '224', '--batch-size', '80', '--data-path', '/data/ImageNet_new/', '--epochs', '30', '--dist-eval', '--distill', '--base_rate', '0.7', '--resume', 'logs/no-amp-3keep/checkpoint.pth']' returned non-zero exit status 1.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 5): env://
| distributed init (rank 2): env://
| distributed init (rank 6): env://
| distributed init (rank 4): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 7): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp-3keep/checkpoint.pth', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0002225 for PREDICTOR
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Epoch: [18]  [   0/2001]  eta: 3:42:30  lr: 0.000222  loss: 3.5853 (3.5853)  time: 6.6717  data: 2.9955  max mem: 8647
Epoch: [18]  [  10/2001]  eta: 0:38:35  lr: 0.000222  loss: 3.4940 (3.3357)  time: 1.1630  data: 0.2724  max mem: 8728
Epoch: [18]  [  20/2001]  eta: 0:29:21  lr: 0.000222  loss: 3.3400 (3.2793)  time: 0.6000  data: 0.0001  max mem: 8728
Epoch: [18]  [  30/2001]  eta: 0:26:11  lr: 0.000222  loss: 3.3082 (3.2880)  time: 0.5961  data: 0.0001  max mem: 8728
Epoch: [18]  [  40/2001]  eta: 0:24:25  lr: 0.000222  loss: 3.2459 (3.2294)  time: 0.5982  data: 0.0002  max mem: 8728
Epoch: [18]  [  50/2001]  eta: 0:23:16  lr: 0.000222  loss: 3.1890 (3.2241)  time: 0.5899  data: 0.0002  max mem: 8728
Epoch: [18]  [  60/2001]  eta: 0:22:30  lr: 0.000222  loss: 3.1890 (3.1871)  time: 0.5899  data: 0.0002  max mem: 8728
Epoch: [18]  [  70/2001]  eta: 0:21:57  lr: 0.000222  loss: 3.1431 (3.1503)  time: 0.5956  data: 0.0002  max mem: 8728
Epoch: [18]  [  80/2001]  eta: 0:21:30  lr: 0.000222  loss: 3.1431 (3.1327)  time: 0.5997  data: 0.0002  max mem: 8728
Epoch: [18]  [  90/2001]  eta: 0:21:08  lr: 0.000222  loss: 3.0521 (3.1157)  time: 0.5999  data: 0.0002  max mem: 8728
loss info: cls_loss=3.0119, ratio_loss=0.0497, cls_kl=0.0649, token_kl=0.0932
Epoch: [18]  [ 100/2001]  eta: 0:20:51  lr: 0.000222  loss: 3.2197 (3.1280)  time: 0.6045  data: 0.0002  max mem: 8728
Epoch: [18]  [ 110/2001]  eta: 0:20:37  lr: 0.000222  loss: 3.1990 (3.1188)  time: 0.6121  data: 0.0002  max mem: 8728
Epoch: [18]  [ 120/2001]  eta: 0:20:25  lr: 0.000222  loss: 3.1581 (3.1202)  time: 0.6156  data: 0.0002  max mem: 8728
Epoch: [18]  [ 130/2001]  eta: 0:20:12  lr: 0.000222  loss: 3.2022 (3.1173)  time: 0.6124  data: 0.0002  max mem: 8728
Epoch: [18]  [ 140/2001]  eta: 0:20:01  lr: 0.000222  loss: 3.0714 (3.1096)  time: 0.6084  data: 0.0002  max mem: 8728
Epoch: [18]  [ 150/2001]  eta: 0:19:49  lr: 0.000222  loss: 3.0069 (3.1005)  time: 0.6079  data: 0.0002  max mem: 8728
Epoch: [18]  [ 160/2001]  eta: 0:19:39  lr: 0.000222  loss: 3.0573 (3.1030)  time: 0.6078  data: 0.0002  max mem: 8728
Epoch: [18]  [ 170/2001]  eta: 0:19:30  lr: 0.000222  loss: 3.1251 (3.1009)  time: 0.6114  data: 0.0001  max mem: 8728
Epoch: [18]  [ 180/2001]  eta: 0:19:21  lr: 0.000222  loss: 3.0140 (3.0880)  time: 0.6147  data: 0.0001  max mem: 8728
Epoch: [18]  [ 190/2001]  eta: 0:19:13  lr: 0.000222  loss: 2.8454 (3.0807)  time: 0.6200  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9067, ratio_loss=0.0441, cls_kl=0.0626, token_kl=0.0912
Epoch: [18]  [ 200/2001]  eta: 0:19:05  lr: 0.000222  loss: 2.8336 (3.0686)  time: 0.6219  data: 0.0001  max mem: 8728
Epoch: [18]  [ 210/2001]  eta: 0:18:58  lr: 0.000222  loss: 3.0805 (3.0661)  time: 0.6196  data: 0.0001  max mem: 8728
Epoch: [18]  [ 220/2001]  eta: 0:18:50  lr: 0.000222  loss: 3.1122 (3.0630)  time: 0.6179  data: 0.0001  max mem: 8728
Epoch: [18]  [ 230/2001]  eta: 0:18:42  lr: 0.000222  loss: 3.1293 (3.0631)  time: 0.6144  data: 0.0002  max mem: 8728
Epoch: [18]  [ 240/2001]  eta: 0:18:34  lr: 0.000222  loss: 3.1590 (3.0634)  time: 0.6148  data: 0.0002  max mem: 8728
Epoch: [18]  [ 250/2001]  eta: 0:18:28  lr: 0.000222  loss: 3.1234 (3.0541)  time: 0.6234  data: 0.0002  max mem: 8728
Epoch: [18]  [ 260/2001]  eta: 0:18:21  lr: 0.000222  loss: 2.8470 (3.0469)  time: 0.6297  data: 0.0002  max mem: 8728
Epoch: [18]  [ 270/2001]  eta: 0:18:14  lr: 0.000222  loss: 2.8470 (3.0378)  time: 0.6285  data: 0.0002  max mem: 8728
Epoch: [18]  [ 280/2001]  eta: 0:18:08  lr: 0.000222  loss: 3.1591 (3.0441)  time: 0.6280  data: 0.0002  max mem: 8728
Epoch: [18]  [ 290/2001]  eta: 0:18:01  lr: 0.000222  loss: 3.1591 (3.0395)  time: 0.6267  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8536, ratio_loss=0.0416, cls_kl=0.0603, token_kl=0.0918
Epoch: [18]  [ 300/2001]  eta: 0:17:55  lr: 0.000222  loss: 2.7721 (3.0313)  time: 0.6269  data: 0.0001  max mem: 8728
Epoch: [18]  [ 310/2001]  eta: 0:17:48  lr: 0.000222  loss: 2.7727 (3.0302)  time: 0.6274  data: 0.0001  max mem: 8728
Epoch: [18]  [ 320/2001]  eta: 0:17:41  lr: 0.000222  loss: 3.2452 (3.0412)  time: 0.6263  data: 0.0001  max mem: 8728
Epoch: [18]  [ 330/2001]  eta: 0:17:35  lr: 0.000222  loss: 3.3702 (3.0435)  time: 0.6271  data: 0.0001  max mem: 8728
Epoch: [18]  [ 340/2001]  eta: 0:17:28  lr: 0.000222  loss: 3.1947 (3.0471)  time: 0.6296  data: 0.0001  max mem: 8728
Epoch: [18]  [ 350/2001]  eta: 0:17:22  lr: 0.000222  loss: 3.1320 (3.0486)  time: 0.6275  data: 0.0001  max mem: 8728
Epoch: [18]  [ 360/2001]  eta: 0:17:15  lr: 0.000222  loss: 3.0596 (3.0482)  time: 0.6273  data: 0.0001  max mem: 8728
Epoch: [18]  [ 370/2001]  eta: 0:17:09  lr: 0.000222  loss: 3.0440 (3.0465)  time: 0.6281  data: 0.0002  max mem: 8728
Epoch: [18]  [ 380/2001]  eta: 0:17:02  lr: 0.000222  loss: 3.0440 (3.0447)  time: 0.6273  data: 0.0002  max mem: 8728
Epoch: [18]  [ 390/2001]  eta: 0:16:56  lr: 0.000222  loss: 2.9396 (3.0420)  time: 0.6310  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9749, ratio_loss=0.0463, cls_kl=0.0661, token_kl=0.0941
Epoch: [18]  [ 400/2001]  eta: 0:16:50  lr: 0.000222  loss: 3.0531 (3.0457)  time: 0.6340  data: 0.0001  max mem: 8728
Epoch: [18]  [ 410/2001]  eta: 0:16:44  lr: 0.000222  loss: 3.2546 (3.0522)  time: 0.6341  data: 0.0001  max mem: 8728
Epoch: [18]  [ 420/2001]  eta: 0:16:38  lr: 0.000222  loss: 3.1655 (3.0497)  time: 0.6349  data: 0.0001  max mem: 8728
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 5): env://
| distributed init (rank 3): env://
| distributed init (rank 7): env://
| distributed init (rank 4): env://
| distributed init (rank 1): env://
| distributed init (rank 6): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp-3keep/checkpoint.pth', sched='cosine', seed=42, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0002225 for PREDICTOR
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Epoch: [18]  [   0/2001]  eta: 3:44:37  lr: 0.000222  loss: 3.7870 (3.7870)  time: 6.7353  data: 3.2204  max mem: 8647
Epoch: [18]  [  10/2001]  eta: 0:38:41  lr: 0.000222  loss: 3.0633 (2.9708)  time: 1.1659  data: 0.2929  max mem: 8728
Epoch: [18]  [  20/2001]  eta: 0:29:20  lr: 0.000222  loss: 3.1557 (3.1599)  time: 0.5962  data: 0.0001  max mem: 8728
Epoch: [18]  [  30/2001]  eta: 0:26:07  lr: 0.000222  loss: 3.1728 (3.1341)  time: 0.5911  data: 0.0002  max mem: 8728
Epoch: [18]  [  40/2001]  eta: 0:24:17  lr: 0.000222  loss: 3.1615 (3.1425)  time: 0.5903  data: 0.0001  max mem: 8728
Epoch: [18]  [  50/2001]  eta: 0:23:09  lr: 0.000222  loss: 3.1615 (3.1624)  time: 0.5842  data: 0.0002  max mem: 8728
Epoch: [18]  [  60/2001]  eta: 0:22:21  lr: 0.000222  loss: 3.2092 (3.1532)  time: 0.5850  data: 0.0002  max mem: 8728
Epoch: [18]  [  70/2001]  eta: 0:21:47  lr: 0.000222  loss: 3.1205 (3.1065)  time: 0.5867  data: 0.0002  max mem: 8728
Epoch: [18]  [  80/2001]  eta: 0:21:20  lr: 0.000222  loss: 3.0990 (3.1075)  time: 0.5908  data: 0.0002  max mem: 8728
Epoch: [18]  [  90/2001]  eta: 0:20:57  lr: 0.000222  loss: 3.2082 (3.1119)  time: 0.5913  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9994, ratio_loss=0.0468, cls_kl=0.0641, token_kl=0.0925
Epoch: [18]  [ 100/2001]  eta: 0:20:38  lr: 0.000222  loss: 3.1700 (3.1043)  time: 0.5918  data: 0.0002  max mem: 8728
Epoch: [18]  [ 110/2001]  eta: 0:20:21  lr: 0.000222  loss: 3.0287 (3.0933)  time: 0.5916  data: 0.0001  max mem: 8728
Epoch: [18]  [ 120/2001]  eta: 0:20:06  lr: 0.000222  loss: 3.1183 (3.0964)  time: 0.5903  data: 0.0002  max mem: 8728
Epoch: [18]  [ 130/2001]  eta: 0:19:53  lr: 0.000222  loss: 3.0639 (3.0769)  time: 0.5917  data: 0.0002  max mem: 8728
Epoch: [18]  [ 140/2001]  eta: 0:19:41  lr: 0.000222  loss: 2.7464 (3.0644)  time: 0.5959  data: 0.0002  max mem: 8728
Epoch: [18]  [ 150/2001]  eta: 0:19:30  lr: 0.000222  loss: 3.0974 (3.0695)  time: 0.5970  data: 0.0002  max mem: 8728
Epoch: [18]  [ 160/2001]  eta: 0:19:20  lr: 0.000222  loss: 3.1570 (3.0571)  time: 0.5977  data: 0.0002  max mem: 8728
Epoch: [18]  [ 170/2001]  eta: 0:19:10  lr: 0.000222  loss: 3.1450 (3.0585)  time: 0.5989  data: 0.0002  max mem: 8728
Epoch: [18]  [ 180/2001]  eta: 0:19:02  lr: 0.000222  loss: 3.0392 (3.0582)  time: 0.6022  data: 0.0002  max mem: 8728
Epoch: [18]  [ 190/2001]  eta: 0:18:54  lr: 0.000222  loss: 3.0224 (3.0409)  time: 0.6107  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8806, ratio_loss=0.0460, cls_kl=0.0628, token_kl=0.0932
Epoch: [18]  [ 200/2001]  eta: 0:18:47  lr: 0.000222  loss: 3.1321 (3.0522)  time: 0.6121  data: 0.0001  max mem: 8728
Epoch: [18]  [ 210/2001]  eta: 0:18:39  lr: 0.000222  loss: 3.2282 (3.0582)  time: 0.6084  data: 0.0002  max mem: 8728
Epoch: [18]  [ 220/2001]  eta: 0:18:32  lr: 0.000222  loss: 3.2811 (3.0710)  time: 0.6102  data: 0.0002  max mem: 8728
Epoch: [18]  [ 230/2001]  eta: 0:18:24  lr: 0.000222  loss: 3.2834 (3.0716)  time: 0.6111  data: 0.0002  max mem: 8728
Epoch: [18]  [ 240/2001]  eta: 0:18:17  lr: 0.000222  loss: 3.2851 (3.0749)  time: 0.6108  data: 0.0001  max mem: 8728
Epoch: [18]  [ 250/2001]  eta: 0:18:10  lr: 0.000222  loss: 2.9259 (3.0638)  time: 0.6108  data: 0.0001  max mem: 8728
Epoch: [18]  [ 260/2001]  eta: 0:18:03  lr: 0.000222  loss: 2.9259 (3.0638)  time: 0.6101  data: 0.0001  max mem: 8728
Epoch: [18]  [ 270/2001]  eta: 0:17:56  lr: 0.000222  loss: 2.9965 (3.0551)  time: 0.6110  data: 0.0002  max mem: 8728
Epoch: [18]  [ 280/2001]  eta: 0:17:49  lr: 0.000222  loss: 3.1495 (3.0619)  time: 0.6132  data: 0.0002  max mem: 8728
Epoch: [18]  [ 290/2001]  eta: 0:17:43  lr: 0.000222  loss: 3.2126 (3.0561)  time: 0.6148  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9626, ratio_loss=0.0456, cls_kl=0.0642, token_kl=0.0930
Epoch: [18]  [ 300/2001]  eta: 0:17:36  lr: 0.000222  loss: 3.0196 (3.0568)  time: 0.6144  data: 0.0002  max mem: 8728
Epoch: [18]  [ 310/2001]  eta: 0:17:30  lr: 0.000222  loss: 3.1845 (3.0638)  time: 0.6161  data: 0.0001  max mem: 8728
Epoch: [18]  [ 320/2001]  eta: 0:17:23  lr: 0.000222  loss: 3.2065 (3.0612)  time: 0.6165  data: 0.0001  max mem: 8728
Epoch: [18]  [ 330/2001]  eta: 0:17:17  lr: 0.000222  loss: 3.1330 (3.0580)  time: 0.6157  data: 0.0001  max mem: 8728
Epoch: [18]  [ 340/2001]  eta: 0:17:10  lr: 0.000222  loss: 3.1330 (3.0601)  time: 0.6185  data: 0.0001  max mem: 8728
Epoch: [18]  [ 350/2001]  eta: 0:17:04  lr: 0.000222  loss: 2.9787 (3.0601)  time: 0.6210  data: 0.0001  max mem: 8728
Epoch: [18]  [ 360/2001]  eta: 0:16:58  lr: 0.000222  loss: 2.7866 (3.0518)  time: 0.6203  data: 0.0002  max mem: 8728
Epoch: [18]  [ 370/2001]  eta: 0:16:52  lr: 0.000222  loss: 2.7566 (3.0489)  time: 0.6208  data: 0.0002  max mem: 8728
Epoch: [18]  [ 380/2001]  eta: 0:16:46  lr: 0.000222  loss: 2.8021 (3.0425)  time: 0.6253  data: 0.0002  max mem: 8728
Epoch: [18]  [ 390/2001]  eta: 0:16:40  lr: 0.000222  loss: 2.8565 (3.0420)  time: 0.6226  data: 0.0002  max mem: 8728
loss info: cls_loss=2.8974, ratio_loss=0.0471, cls_kl=0.0628, token_kl=0.0939
Epoch: [18]  [ 400/2001]  eta: 0:16:34  lr: 0.000222  loss: 3.1277 (3.0420)  time: 0.6235  data: 0.0002  max mem: 8728
Epoch: [18]  [ 410/2001]  eta: 0:16:28  lr: 0.000222  loss: 3.0153 (3.0368)  time: 0.6285  data: 0.0001  max mem: 8728
Epoch: [18]  [ 420/2001]  eta: 0:16:22  lr: 0.000222  loss: 2.9668 (3.0341)  time: 0.6264  data: 0.0001  max mem: 8728
Epoch: [18]  [ 430/2001]  eta: 0:16:16  lr: 0.000222  loss: 3.1741 (3.0308)  time: 0.6234  data: 0.0001  max mem: 8728
Epoch: [18]  [ 440/2001]  eta: 0:16:10  lr: 0.000222  loss: 2.7465 (3.0256)  time: 0.6245  data: 0.0001  max mem: 8728
Epoch: [18]  [ 450/2001]  eta: 0:16:04  lr: 0.000222  loss: 2.9335 (3.0249)  time: 0.6305  data: 0.0001  max mem: 8728
Epoch: [18]  [ 460/2001]  eta: 0:15:58  lr: 0.000222  loss: 3.1505 (3.0266)  time: 0.6347  data: 0.0001  max mem: 8728
Epoch: [18]  [ 470/2001]  eta: 0:15:52  lr: 0.000222  loss: 3.0429 (3.0215)  time: 0.6357  data: 0.0001  max mem: 8728
Epoch: [18]  [ 480/2001]  eta: 0:15:46  lr: 0.000222  loss: 3.0786 (3.0230)  time: 0.6317  data: 0.0001  max mem: 8728
Epoch: [18]  [ 490/2001]  eta: 0:15:40  lr: 0.000222  loss: 3.0786 (3.0187)  time: 0.6307  data: 0.0002  max mem: 8728
loss info: cls_loss=2.8027, ratio_loss=0.0451, cls_kl=0.0606, token_kl=0.0934
Epoch: [18]  [ 500/2001]  eta: 0:15:34  lr: 0.000222  loss: 2.9416 (3.0195)  time: 0.6333  data: 0.0002  max mem: 8728
Epoch: [18]  [ 510/2001]  eta: 0:15:28  lr: 0.000222  loss: 3.3030 (3.0241)  time: 0.6313  data: 0.0002  max mem: 8728
Epoch: [18]  [ 520/2001]  eta: 0:15:22  lr: 0.000222  loss: 3.1593 (3.0234)  time: 0.6309  data: 0.0002  max mem: 8728
Epoch: [18]  [ 530/2001]  eta: 0:15:17  lr: 0.000222  loss: 2.9783 (3.0202)  time: 0.6343  data: 0.0002  max mem: 8728
Epoch: [18]  [ 540/2001]  eta: 0:15:11  lr: 0.000222  loss: 3.0904 (3.0215)  time: 0.6347  data: 0.0002  max mem: 8728
Epoch: [18]  [ 550/2001]  eta: 0:15:05  lr: 0.000222  loss: 3.1877 (3.0230)  time: 0.6338  data: 0.0001  max mem: 8728
Epoch: [18]  [ 560/2001]  eta: 0:14:59  lr: 0.000222  loss: 3.2395 (3.0237)  time: 0.6325  data: 0.0002  max mem: 8728
Epoch: [18]  [ 570/2001]  eta: 0:14:53  lr: 0.000222  loss: 2.9138 (3.0241)  time: 0.6321  data: 0.0002  max mem: 8728
Epoch: [18]  [ 580/2001]  eta: 0:14:47  lr: 0.000222  loss: 2.8537 (3.0208)  time: 0.6355  data: 0.0002  max mem: 8728
Epoch: [18]  [ 590/2001]  eta: 0:14:41  lr: 0.000222  loss: 3.1412 (3.0265)  time: 0.6361  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9680, ratio_loss=0.0492, cls_kl=0.0658, token_kl=0.0955
Epoch: [18]  [ 600/2001]  eta: 0:14:35  lr: 0.000222  loss: 3.3940 (3.0286)  time: 0.6332  data: 0.0002  max mem: 8728
Epoch: [18]  [ 610/2001]  eta: 0:14:29  lr: 0.000222  loss: 3.3152 (3.0324)  time: 0.6352  data: 0.0002  max mem: 8728
Epoch: [18]  [ 620/2001]  eta: 0:14:23  lr: 0.000222  loss: 3.2447 (3.0335)  time: 0.6401  data: 0.0001  max mem: 8728
Epoch: [18]  [ 630/2001]  eta: 0:14:17  lr: 0.000222  loss: 3.1127 (3.0346)  time: 0.6362  data: 0.0001  max mem: 8728
Epoch: [18]  [ 640/2001]  eta: 0:14:11  lr: 0.000222  loss: 3.1127 (3.0346)  time: 0.6341  data: 0.0001  max mem: 8728
Epoch: [18]  [ 650/2001]  eta: 0:14:05  lr: 0.000222  loss: 3.1422 (3.0380)  time: 0.6360  data: 0.0001  max mem: 8728
Epoch: [18]  [ 660/2001]  eta: 0:13:58  lr: 0.000222  loss: 3.1435 (3.0363)  time: 0.6335  data: 0.0002  max mem: 8728
Epoch: [18]  [ 670/2001]  eta: 0:13:52  lr: 0.000222  loss: 3.2855 (3.0405)  time: 0.6360  data: 0.0002  max mem: 8728
Epoch: [18]  [ 680/2001]  eta: 0:13:46  lr: 0.000222  loss: 3.0924 (3.0389)  time: 0.6385  data: 0.0002  max mem: 8728
Epoch: [18]  [ 690/2001]  eta: 0:13:40  lr: 0.000222  loss: 2.9212 (3.0374)  time: 0.6377  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9849, ratio_loss=0.0472, cls_kl=0.0658, token_kl=0.0955
Epoch: [18]  [ 700/2001]  eta: 0:13:34  lr: 0.000222  loss: 3.0039 (3.0381)  time: 0.6382  data: 0.0002  max mem: 8728
Epoch: [18]  [ 710/2001]  eta: 0:13:28  lr: 0.000222  loss: 3.0471 (3.0369)  time: 0.6393  data: 0.0002  max mem: 8728
Epoch: [18]  [ 720/2001]  eta: 0:13:22  lr: 0.000222  loss: 2.9033 (3.0344)  time: 0.6391  data: 0.0001  max mem: 8728
Epoch: [18]  [ 730/2001]  eta: 0:13:16  lr: 0.000222  loss: 3.0429 (3.0349)  time: 0.6359  data: 0.0002  max mem: 8728
Epoch: [18]  [ 740/2001]  eta: 0:13:10  lr: 0.000222  loss: 3.2113 (3.0363)  time: 0.6341  data: 0.0002  max mem: 8728
Epoch: [18]  [ 750/2001]  eta: 0:13:04  lr: 0.000222  loss: 3.1301 (3.0377)  time: 0.6363  data: 0.0002  max mem: 8728
Epoch: [18]  [ 760/2001]  eta: 0:12:58  lr: 0.000222  loss: 3.1116 (3.0359)  time: 0.6353  data: 0.0002  max mem: 8728
Epoch: [18]  [ 770/2001]  eta: 0:12:52  lr: 0.000222  loss: 3.1790 (3.0372)  time: 0.6350  data: 0.0002  max mem: 8728
Epoch: [18]  [ 780/2001]  eta: 0:12:45  lr: 0.000222  loss: 3.3816 (3.0420)  time: 0.6351  data: 0.0001  max mem: 8728
Epoch: [18]  [ 790/2001]  eta: 0:12:39  lr: 0.000222  loss: 3.2978 (3.0421)  time: 0.6345  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9857, ratio_loss=0.0467, cls_kl=0.0667, token_kl=0.0933
Epoch: [18]  [ 800/2001]  eta: 0:12:33  lr: 0.000222  loss: 3.2745 (3.0462)  time: 0.6341  data: 0.0001  max mem: 8728
Epoch: [18]  [ 810/2001]  eta: 0:12:27  lr: 0.000222  loss: 3.2147 (3.0467)  time: 0.6342  data: 0.0001  max mem: 8728
Epoch: [18]  [ 820/2001]  eta: 0:12:21  lr: 0.000222  loss: 3.1378 (3.0477)  time: 0.6343  data: 0.0001  max mem: 8728
Epoch: [18]  [ 830/2001]  eta: 0:12:15  lr: 0.000222  loss: 3.1378 (3.0475)  time: 0.6340  data: 0.0002  max mem: 8728
Epoch: [18]  [ 840/2001]  eta: 0:12:08  lr: 0.000222  loss: 3.1989 (3.0488)  time: 0.6375  data: 0.0001  max mem: 8728
Epoch: [18]  [ 850/2001]  eta: 0:12:02  lr: 0.000222  loss: 3.1729 (3.0491)  time: 0.6384  data: 0.0001  max mem: 8728
Epoch: [18]  [ 860/2001]  eta: 0:11:56  lr: 0.000222  loss: 3.1219 (3.0503)  time: 0.6392  data: 0.0002  max mem: 8728
Epoch: [18]  [ 870/2001]  eta: 0:11:50  lr: 0.000222  loss: 3.0894 (3.0504)  time: 0.6394  data: 0.0001  max mem: 8728
Epoch: [18]  [ 880/2001]  eta: 0:11:44  lr: 0.000222  loss: 3.1522 (3.0510)  time: 0.6388  data: 0.0002  max mem: 8728
Epoch: [18]  [ 890/2001]  eta: 0:11:38  lr: 0.000222  loss: 3.2774 (3.0545)  time: 0.6431  data: 0.0002  max mem: 8728
loss info: cls_loss=3.0383, ratio_loss=0.0453, cls_kl=0.0644, token_kl=0.0906
Epoch: [18]  [ 900/2001]  eta: 0:11:32  lr: 0.000222  loss: 3.3025 (3.0554)  time: 0.6406  data: 0.0002  max mem: 8728
Epoch: [18]  [ 910/2001]  eta: 0:11:26  lr: 0.000222  loss: 3.2580 (3.0550)  time: 0.6376  data: 0.0002  max mem: 8728
Epoch: [18]  [ 920/2001]  eta: 0:11:19  lr: 0.000222  loss: 3.2184 (3.0570)  time: 0.6377  data: 0.0002  max mem: 8728
Epoch: [18]  [ 930/2001]  eta: 0:11:13  lr: 0.000222  loss: 2.8904 (3.0524)  time: 0.6350  data: 0.0002  max mem: 8728
Epoch: [18]  [ 940/2001]  eta: 0:11:07  lr: 0.000222  loss: 2.9686 (3.0554)  time: 0.6392  data: 0.0002  max mem: 8728
Epoch: [18]  [ 950/2001]  eta: 0:11:01  lr: 0.000222  loss: 3.2328 (3.0563)  time: 0.6418  data: 0.0002  max mem: 8728
Epoch: [18]  [ 960/2001]  eta: 0:10:55  lr: 0.000222  loss: 3.0997 (3.0532)  time: 0.6407  data: 0.0002  max mem: 8728
Epoch: [18]  [ 970/2001]  eta: 0:10:48  lr: 0.000222  loss: 2.9462 (3.0526)  time: 0.6399  data: 0.0002  max mem: 8728
Epoch: [18]  [ 980/2001]  eta: 0:10:42  lr: 0.000222  loss: 2.9741 (3.0515)  time: 0.6424  data: 0.0002  max mem: 8728
Epoch: [18]  [ 990/2001]  eta: 0:10:36  lr: 0.000222  loss: 3.0413 (3.0511)  time: 0.6417  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9111, ratio_loss=0.0454, cls_kl=0.0625, token_kl=0.0908
Epoch: [18]  [1000/2001]  eta: 0:10:30  lr: 0.000222  loss: 3.2327 (3.0529)  time: 0.6373  data: 0.0002  max mem: 8728
Epoch: [18]  [1010/2001]  eta: 0:10:24  lr: 0.000222  loss: 3.3733 (3.0538)  time: 0.6382  data: 0.0002  max mem: 8728
Epoch: [18]  [1020/2001]  eta: 0:10:18  lr: 0.000222  loss: 3.4204 (3.0552)  time: 0.6434  data: 0.0002  max mem: 8728
Epoch: [18]  [1030/2001]  eta: 0:10:11  lr: 0.000222  loss: 3.1376 (3.0538)  time: 0.6416  data: 0.0002  max mem: 8728
Epoch: [18]  [1040/2001]  eta: 0:10:05  lr: 0.000222  loss: 2.9857 (3.0529)  time: 0.6442  data: 0.0002  max mem: 8728
Epoch: [18]  [1050/2001]  eta: 0:09:59  lr: 0.000222  loss: 2.9911 (3.0511)  time: 0.6497  data: 0.0002  max mem: 8728
Epoch: [18]  [1060/2001]  eta: 0:09:53  lr: 0.000222  loss: 3.0927 (3.0509)  time: 0.6470  data: 0.0002  max mem: 8728
Epoch: [18]  [1070/2001]  eta: 0:09:47  lr: 0.000222  loss: 3.0303 (3.0498)  time: 0.6443  data: 0.0001  max mem: 8728
Epoch: [18]  [1080/2001]  eta: 0:09:40  lr: 0.000222  loss: 2.9768 (3.0484)  time: 0.6402  data: 0.0002  max mem: 8728
Epoch: [18]  [1090/2001]  eta: 0:09:34  lr: 0.000222  loss: 2.9817 (3.0460)  time: 0.6404  data: 0.0002  max mem: 8728
loss info: cls_loss=2.8959, ratio_loss=0.0462, cls_kl=0.0638, token_kl=0.0933
Epoch: [18]  [1100/2001]  eta: 0:09:28  lr: 0.000222  loss: 3.1791 (3.0487)  time: 0.6450  data: 0.0002  max mem: 8728
Epoch: [18]  [1110/2001]  eta: 0:09:22  lr: 0.000222  loss: 3.2087 (3.0481)  time: 0.6436  data: 0.0002  max mem: 8728
Epoch: [18]  [1120/2001]  eta: 0:09:16  lr: 0.000222  loss: 3.2000 (3.0499)  time: 0.6407  data: 0.0002  max mem: 8728
Epoch: [18]  [1130/2001]  eta: 0:09:09  lr: 0.000222  loss: 3.0775 (3.0453)  time: 0.6427  data: 0.0002  max mem: 8728
Epoch: [18]  [1140/2001]  eta: 0:09:03  lr: 0.000222  loss: 2.5469 (3.0427)  time: 0.6406  data: 0.0002  max mem: 8728
Epoch: [18]  [1150/2001]  eta: 0:08:57  lr: 0.000222  loss: 2.9645 (3.0418)  time: 0.6389  data: 0.0002  max mem: 8728
Epoch: [18]  [1160/2001]  eta: 0:08:51  lr: 0.000222  loss: 3.1167 (3.0421)  time: 0.6427  data: 0.0002  max mem: 8728
Epoch: [18]  [1170/2001]  eta: 0:08:44  lr: 0.000222  loss: 3.1891 (3.0437)  time: 0.6464  data: 0.0002  max mem: 8728
Epoch: [18]  [1180/2001]  eta: 0:08:38  lr: 0.000222  loss: 3.2162 (3.0448)  time: 0.6443  data: 0.0002  max mem: 8728
Epoch: [18]  [1190/2001]  eta: 0:08:32  lr: 0.000222  loss: 3.0147 (3.0440)  time: 0.6416  data: 0.0002  max mem: 8728
loss info: cls_loss=2.8870, ratio_loss=0.0433, cls_kl=0.0616, token_kl=0.0932
Epoch: [18]  [1200/2001]  eta: 0:08:26  lr: 0.000222  loss: 2.9872 (3.0429)  time: 0.6390  data: 0.0002  max mem: 8728
Epoch: [18]  [1210/2001]  eta: 0:08:19  lr: 0.000222  loss: 2.9407 (3.0417)  time: 0.6371  data: 0.0002  max mem: 8728
Epoch: [18]  [1220/2001]  eta: 0:08:13  lr: 0.000222  loss: 3.0499 (3.0420)  time: 0.6402  data: 0.0002  max mem: 8728
Epoch: [18]  [1230/2001]  eta: 0:08:07  lr: 0.000222  loss: 3.2221 (3.0424)  time: 0.6464  data: 0.0002  max mem: 8728
Epoch: [18]  [1240/2001]  eta: 0:08:01  lr: 0.000222  loss: 3.2221 (3.0437)  time: 0.6445  data: 0.0002  max mem: 8728
Epoch: [18]  [1250/2001]  eta: 0:07:54  lr: 0.000222  loss: 3.1621 (3.0445)  time: 0.6390  data: 0.0001  max mem: 8728
Epoch: [18]  [1260/2001]  eta: 0:07:48  lr: 0.000222  loss: 3.0365 (3.0448)  time: 0.6389  data: 0.0002  max mem: 8728
Epoch: [18]  [1270/2001]  eta: 0:07:42  lr: 0.000222  loss: 3.2217 (3.0459)  time: 0.6384  data: 0.0002  max mem: 8728
Epoch: [18]  [1280/2001]  eta: 0:07:35  lr: 0.000222  loss: 3.3881 (3.0484)  time: 0.6378  data: 0.0002  max mem: 8728
Epoch: [18]  [1290/2001]  eta: 0:07:29  lr: 0.000222  loss: 3.1500 (3.0463)  time: 0.6443  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9468, ratio_loss=0.0448, cls_kl=0.0637, token_kl=0.0930
Epoch: [18]  [1300/2001]  eta: 0:07:23  lr: 0.000222  loss: 2.7732 (3.0450)  time: 0.6460  data: 0.0002  max mem: 8728
Epoch: [18]  [1310/2001]  eta: 0:07:17  lr: 0.000222  loss: 2.7137 (3.0444)  time: 0.6487  data: 0.0002  max mem: 8728
Epoch: [18]  [1320/2001]  eta: 0:07:10  lr: 0.000222  loss: 3.2247 (3.0463)  time: 0.6481  data: 0.0002  max mem: 8728
Epoch: [18]  [1330/2001]  eta: 0:07:04  lr: 0.000222  loss: 3.2317 (3.0468)  time: 0.6386  data: 0.0001  max mem: 8728
Epoch: [18]  [1340/2001]  eta: 0:06:58  lr: 0.000222  loss: 2.9093 (3.0433)  time: 0.6396  data: 0.0001  max mem: 8728
Epoch: [18]  [1350/2001]  eta: 0:06:52  lr: 0.000222  loss: 2.6899 (3.0426)  time: 0.6445  data: 0.0002  max mem: 8728
Epoch: [18]  [1360/2001]  eta: 0:06:45  lr: 0.000222  loss: 3.0939 (3.0426)  time: 0.6443  data: 0.0002  max mem: 8728
Epoch: [18]  [1370/2001]  eta: 0:06:39  lr: 0.000222  loss: 3.2008 (3.0430)  time: 0.6407  data: 0.0001  max mem: 8728
Epoch: [18]  [1380/2001]  eta: 0:06:33  lr: 0.000222  loss: 3.1822 (3.0430)  time: 0.6373  data: 0.0001  max mem: 8728
Epoch: [18]  [1390/2001]  eta: 0:06:26  lr: 0.000222  loss: 3.1392 (3.0426)  time: 0.6352  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9060, ratio_loss=0.0420, cls_kl=0.0611, token_kl=0.0898
Epoch: [18]  [1400/2001]  eta: 0:06:20  lr: 0.000222  loss: 3.1722 (3.0424)  time: 0.6353  data: 0.0001  max mem: 8728
Epoch: [18]  [1410/2001]  eta: 0:06:14  lr: 0.000222  loss: 3.1722 (3.0428)  time: 0.6349  data: 0.0001  max mem: 8728
Epoch: [18]  [1420/2001]  eta: 0:06:07  lr: 0.000222  loss: 3.1364 (3.0428)  time: 0.6346  data: 0.0002  max mem: 8728
Epoch: [18]  [1430/2001]  eta: 0:06:01  lr: 0.000222  loss: 3.1413 (3.0432)  time: 0.6339  data: 0.0002  max mem: 8728
Epoch: [18]  [1440/2001]  eta: 0:05:55  lr: 0.000222  loss: 3.0578 (3.0428)  time: 0.6325  data: 0.0001  max mem: 8728
Epoch: [18]  [1450/2001]  eta: 0:05:48  lr: 0.000222  loss: 3.0108 (3.0427)  time: 0.6318  data: 0.0001  max mem: 8728
Epoch: [18]  [1460/2001]  eta: 0:05:42  lr: 0.000222  loss: 3.2561 (3.0437)  time: 0.6308  data: 0.0001  max mem: 8728
Epoch: [18]  [1470/2001]  eta: 0:05:36  lr: 0.000222  loss: 3.2848 (3.0441)  time: 0.6372  data: 0.0001  max mem: 8728
Epoch: [18]  [1480/2001]  eta: 0:05:29  lr: 0.000222  loss: 3.2099 (3.0451)  time: 0.6372  data: 0.0002  max mem: 8728
Epoch: [18]  [1490/2001]  eta: 0:05:23  lr: 0.000222  loss: 3.2099 (3.0462)  time: 0.6307  data: 0.0002  max mem: 8728
loss info: cls_loss=3.0125, ratio_loss=0.0478, cls_kl=0.0655, token_kl=0.0950
Epoch: [18]  [1500/2001]  eta: 0:05:17  lr: 0.000222  loss: 3.3319 (3.0476)  time: 0.6288  data: 0.0001  max mem: 8728
Epoch: [18]  [1510/2001]  eta: 0:05:10  lr: 0.000222  loss: 3.2359 (3.0476)  time: 0.6285  data: 0.0001  max mem: 8728
Epoch: [18]  [1520/2001]  eta: 0:05:04  lr: 0.000222  loss: 3.0704 (3.0479)  time: 0.6306  data: 0.0001  max mem: 8728
Epoch: [18]  [1530/2001]  eta: 0:04:58  lr: 0.000222  loss: 3.0704 (3.0471)  time: 0.6292  data: 0.0001  max mem: 8728
Epoch: [18]  [1540/2001]  eta: 0:04:51  lr: 0.000222  loss: 3.2046 (3.0472)  time: 0.6348  data: 0.0001  max mem: 8728
Epoch: [18]  [1550/2001]  eta: 0:04:45  lr: 0.000222  loss: 2.9154 (3.0457)  time: 0.6393  data: 0.0002  max mem: 8728
Epoch: [18]  [1560/2001]  eta: 0:04:39  lr: 0.000222  loss: 3.0835 (3.0465)  time: 0.6330  data: 0.0002  max mem: 8728
Epoch: [18]  [1570/2001]  eta: 0:04:32  lr: 0.000222  loss: 3.2524 (3.0477)  time: 0.6260  data: 0.0001  max mem: 8728
Epoch: [18]  [1580/2001]  eta: 0:04:26  lr: 0.000222  loss: 3.1895 (3.0480)  time: 0.6282  data: 0.0001  max mem: 8728
Epoch: [18]  [1590/2001]  eta: 0:04:20  lr: 0.000222  loss: 3.2378 (3.0494)  time: 0.6304  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9854, ratio_loss=0.0485, cls_kl=0.0655, token_kl=0.0947
Epoch: [18]  [1600/2001]  eta: 0:04:13  lr: 0.000222  loss: 3.3482 (3.0504)  time: 0.6265  data: 0.0001  max mem: 8728
Epoch: [18]  [1610/2001]  eta: 0:04:07  lr: 0.000222  loss: 3.3684 (3.0521)  time: 0.6275  data: 0.0001  max mem: 8728
Epoch: [18]  [1620/2001]  eta: 0:04:01  lr: 0.000222  loss: 3.3684 (3.0522)  time: 0.6288  data: 0.0002  max mem: 8728
Epoch: [18]  [1630/2001]  eta: 0:03:54  lr: 0.000222  loss: 3.3042 (3.0533)  time: 0.6292  data: 0.0002  max mem: 8728
Epoch: [18]  [1640/2001]  eta: 0:03:48  lr: 0.000222  loss: 3.3042 (3.0537)  time: 0.6289  data: 0.0001  max mem: 8728
Epoch: [18]  [1650/2001]  eta: 0:03:42  lr: 0.000222  loss: 2.9767 (3.0516)  time: 0.6291  data: 0.0001  max mem: 8728
Epoch: [18]  [1660/2001]  eta: 0:03:35  lr: 0.000222  loss: 2.9495 (3.0508)  time: 0.6268  data: 0.0001  max mem: 8728
Epoch: [18]  [1670/2001]  eta: 0:03:29  lr: 0.000222  loss: 3.0582 (3.0507)  time: 0.6253  data: 0.0001  max mem: 8728
Epoch: [18]  [1680/2001]  eta: 0:03:23  lr: 0.000222  loss: 3.2981 (3.0514)  time: 0.6276  data: 0.0001  max mem: 8728
Epoch: [18]  [1690/2001]  eta: 0:03:16  lr: 0.000222  loss: 3.2755 (3.0506)  time: 0.6244  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9396, ratio_loss=0.0461, cls_kl=0.0639, token_kl=0.0929
Epoch: [18]  [1700/2001]  eta: 0:03:10  lr: 0.000222  loss: 3.1165 (3.0508)  time: 0.6260  data: 0.0001  max mem: 8728
Epoch: [18]  [1710/2001]  eta: 0:03:04  lr: 0.000222  loss: 3.1165 (3.0516)  time: 0.6287  data: 0.0001  max mem: 8728
Epoch: [18]  [1720/2001]  eta: 0:02:57  lr: 0.000222  loss: 3.0842 (3.0515)  time: 0.6272  data: 0.0001  max mem: 8728
Epoch: [18]  [1730/2001]  eta: 0:02:51  lr: 0.000222  loss: 3.2693 (3.0531)  time: 0.6290  data: 0.0001  max mem: 8728
Epoch: [18]  [1740/2001]  eta: 0:02:45  lr: 0.000222  loss: 3.3149 (3.0528)  time: 0.6357  data: 0.0002  max mem: 8728
Epoch: [18]  [1750/2001]  eta: 0:02:38  lr: 0.000222  loss: 3.2932 (3.0536)  time: 0.6333  data: 0.0002  max mem: 8728
Epoch: [18]  [1760/2001]  eta: 0:02:32  lr: 0.000222  loss: 3.0341 (3.0534)  time: 0.6318  data: 0.0002  max mem: 8728
Epoch: [18]  [1770/2001]  eta: 0:02:26  lr: 0.000222  loss: 2.8312 (3.0520)  time: 0.6317  data: 0.0002  max mem: 8728
Epoch: [18]  [1780/2001]  eta: 0:02:19  lr: 0.000222  loss: 2.8075 (3.0519)  time: 0.6260  data: 0.0002  max mem: 8728
Epoch: [18]  [1790/2001]  eta: 0:02:13  lr: 0.000222  loss: 3.1754 (3.0522)  time: 0.6251  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9544, ratio_loss=0.0438, cls_kl=0.0643, token_kl=0.0925
Epoch: [18]  [1800/2001]  eta: 0:02:07  lr: 0.000222  loss: 3.1705 (3.0508)  time: 0.6243  data: 0.0002  max mem: 8728
Epoch: [18]  [1810/2001]  eta: 0:02:00  lr: 0.000222  loss: 3.0889 (3.0505)  time: 0.6270  data: 0.0002  max mem: 8728
Epoch: [18]  [1820/2001]  eta: 0:01:54  lr: 0.000222  loss: 3.1244 (3.0493)  time: 0.6269  data: 0.0002  max mem: 8728
Epoch: [18]  [1830/2001]  eta: 0:01:48  lr: 0.000222  loss: 3.1244 (3.0498)  time: 0.6289  data: 0.0002  max mem: 8728
Epoch: [18]  [1840/2001]  eta: 0:01:41  lr: 0.000222  loss: 3.2195 (3.0493)  time: 0.6312  data: 0.0002  max mem: 8728
Epoch: [18]  [1850/2001]  eta: 0:01:35  lr: 0.000222  loss: 3.2107 (3.0494)  time: 0.6308  data: 0.0002  max mem: 8728
Epoch: [18]  [1860/2001]  eta: 0:01:29  lr: 0.000222  loss: 2.9811 (3.0486)  time: 0.6281  data: 0.0002  max mem: 8728
Epoch: [18]  [1870/2001]  eta: 0:01:22  lr: 0.000222  loss: 3.0882 (3.0500)  time: 0.6269  data: 0.0001  max mem: 8728
Epoch: [18]  [1880/2001]  eta: 0:01:16  lr: 0.000222  loss: 3.2244 (3.0491)  time: 0.6295  data: 0.0001  max mem: 8728
Epoch: [18]  [1890/2001]  eta: 0:01:10  lr: 0.000222  loss: 3.0888 (3.0497)  time: 0.6299  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9033, ratio_loss=0.0451, cls_kl=0.0619, token_kl=0.0927
Epoch: [18]  [1900/2001]  eta: 0:01:03  lr: 0.000222  loss: 3.0502 (3.0493)  time: 0.6360  data: 0.0001  max mem: 8728
Epoch: [18]  [1910/2001]  eta: 0:00:57  lr: 0.000222  loss: 2.7772 (3.0476)  time: 0.6366  data: 0.0001  max mem: 8728
Epoch: [18]  [1920/2001]  eta: 0:00:51  lr: 0.000222  loss: 2.8496 (3.0474)  time: 0.6280  data: 0.0002  max mem: 8728
Epoch: [18]  [1930/2001]  eta: 0:00:44  lr: 0.000222  loss: 3.0705 (3.0476)  time: 0.6284  data: 0.0002  max mem: 8728
Epoch: [18]  [1940/2001]  eta: 0:00:38  lr: 0.000222  loss: 3.0937 (3.0477)  time: 0.6311  data: 0.0001  max mem: 8728
Epoch: [18]  [1950/2001]  eta: 0:00:32  lr: 0.000222  loss: 3.0686 (3.0472)  time: 0.6263  data: 0.0002  max mem: 8728
Epoch: [18]  [1960/2001]  eta: 0:00:25  lr: 0.000222  loss: 2.9999 (3.0472)  time: 0.6307  data: 0.0002  max mem: 8728
Epoch: [18]  [1970/2001]  eta: 0:00:19  lr: 0.000222  loss: 3.1094 (3.0478)  time: 0.6336  data: 0.0001  max mem: 8728
Epoch: [18]  [1980/2001]  eta: 0:00:13  lr: 0.000222  loss: 3.3071 (3.0489)  time: 0.6307  data: 0.0001  max mem: 8728
Epoch: [18]  [1990/2001]  eta: 0:00:06  lr: 0.000222  loss: 3.3271 (3.0482)  time: 0.6271  data: 0.0004  max mem: 8728
loss info: cls_loss=2.9348, ratio_loss=0.0462, cls_kl=0.0624, token_kl=0.0958
Epoch: [18]  [2000/2001]  eta: 0:00:00  lr: 0.000222  loss: 3.1011 (3.0485)  time: 0.6244  data: 0.0004  max mem: 8728
Epoch: [18] Total time: 0:21:05 (0.6325 s / it)
Averaged stats: lr: 0.000222  loss: 3.1011 (3.0542)
Test:  [ 0/53]  eta: 0:05:28  loss: 0.3746 (0.3746)  acc1: 94.1667 (94.1667)  acc5: 98.3333 (98.3333)  time: 6.1996  data: 4.8685  max mem: 8728
Test:  [10/53]  eta: 0:00:40  loss: 0.7695 (0.7663)  acc1: 83.3333 (83.5606)  acc5: 96.6667 (96.7424)  time: 0.9369  data: 0.4712  max mem: 8728
Test:  [20/53]  eta: 0:00:21  loss: 0.7390 (0.7754)  acc1: 82.5000 (83.1746)  acc5: 96.6667 (96.5476)  time: 0.3703  data: 0.0159  max mem: 8728
Test:  [30/53]  eta: 0:00:12  loss: 0.8935 (0.8579)  acc1: 79.1667 (81.1290)  acc5: 94.1667 (95.2688)  time: 0.3465  data: 0.0003  max mem: 8728
Test:  [40/53]  eta: 0:00:06  loss: 1.1328 (0.9263)  acc1: 75.8333 (79.3902)  acc5: 91.6667 (94.3699)  time: 0.3114  data: 0.0002  max mem: 8728
Test:  [50/53]  eta: 0:00:01  loss: 1.1110 (0.9564)  acc1: 75.0000 (78.5621)  acc5: 92.5000 (94.1994)  time: 0.2583  data: 0.0001  max mem: 8728
Test:  [52/53]  eta: 0:00:00  loss: 1.0936 (0.9429)  acc1: 75.8333 (78.7520)  acc5: 92.5000 (94.2720)  time: 0.2484  data: 0.0001  max mem: 8728
Test: Total time: 0:00:22 (0.4312 s / it)
Sparsity0:0.2919878787878788,Sparsity1:0.544955175879397,Sparsity2:0.776416,
* Acc@1 79.046 Acc@5 94.514 loss 0.938
Accuracy of the network on the 50000 test images: 79.0%
Max accuracy: 79.05%
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0001924 for PREDICTOR
Epoch: [19]  [   0/2001]  eta: 2:28:11  lr: 0.000192  loss: 3.4042 (3.4042)  time: 4.4436  data: 3.7628  max mem: 8728
Epoch: [19]  [  10/2001]  eta: 0:31:53  lr: 0.000192  loss: 2.9506 (3.0138)  time: 0.9611  data: 0.3422  max mem: 8730
Epoch: [19]  [  20/2001]  eta: 0:26:18  lr: 0.000192  loss: 3.0741 (3.0578)  time: 0.6146  data: 0.0002  max mem: 8730
Epoch: [19]  [  30/2001]  eta: 0:24:13  lr: 0.000192  loss: 3.3300 (3.1223)  time: 0.6142  data: 0.0002  max mem: 8730
Epoch: [19]  [  40/2001]  eta: 0:23:10  lr: 0.000192  loss: 3.3337 (3.1843)  time: 0.6166  data: 0.0002  max mem: 8730
Epoch: [19]  [  50/2001]  eta: 0:22:31  lr: 0.000192  loss: 3.1287 (3.1566)  time: 0.6233  data: 0.0002  max mem: 8730
Epoch: [19]  [  60/2001]  eta: 0:22:03  lr: 0.000192  loss: 2.9448 (3.1257)  time: 0.6259  data: 0.0002  max mem: 8730
Epoch: [19]  [  70/2001]  eta: 0:21:43  lr: 0.000192  loss: 2.9695 (3.1102)  time: 0.6301  data: 0.0002  max mem: 8730
| distributed init (rank 5): env://
| distributed init (rank 4): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 7): env://
| distributed init (rank 3): env://
| distributed init (rank 6): env://
| distributed init (rank 2): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp-3keep/checkpoint.pth', sched='cosine', seed=42, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0001924 for PREDICTOR
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Epoch: [19]  [   0/2001]  eta: 3:42:31  lr: 0.000192  loss: 3.7855 (3.7855)  time: 6.6725  data: 2.5284  max mem: 8647
Epoch: [19]  [  10/2001]  eta: 0:38:26  lr: 0.000192  loss: 2.9563 (2.9784)  time: 1.1584  data: 0.2300  max mem: 8728
Epoch: [19]  [  20/2001]  eta: 0:29:15  lr: 0.000192  loss: 3.1332 (3.1296)  time: 0.5969  data: 0.0001  max mem: 8728
Epoch: [19]  [  30/2001]  eta: 0:26:09  lr: 0.000192  loss: 3.2022 (3.1028)  time: 0.5968  data: 0.0002  max mem: 8728
Epoch: [19]  [  40/2001]  eta: 0:24:21  lr: 0.000192  loss: 3.0995 (3.1368)  time: 0.5978  data: 0.0002  max mem: 8728
Epoch: [19]  [  50/2001]  eta: 0:23:18  lr: 0.000192  loss: 3.2373 (3.1566)  time: 0.5937  data: 0.0002  max mem: 8728
Epoch: [19]  [  60/2001]  eta: 0:22:32  lr: 0.000192  loss: 3.2834 (3.1590)  time: 0.5964  data: 0.0002  max mem: 8728
Epoch: [19]  [  70/2001]  eta: 0:21:57  lr: 0.000192  loss: 3.1677 (3.1256)  time: 0.5941  data: 0.0001  max mem: 8728
Epoch: [19]  [  80/2001]  eta: 0:21:30  lr: 0.000192  loss: 3.1677 (3.1201)  time: 0.5968  data: 0.0001  max mem: 8728
Epoch: [19]  [  90/2001]  eta: 0:21:09  lr: 0.000192  loss: 3.2250 (3.1278)  time: 0.5998  data: 0.0001  max mem: 8728
loss info: cls_loss=3.0087, ratio_loss=0.0458, cls_kl=0.0649, token_kl=0.0934
Epoch: [19]  [ 100/2001]  eta: 0:20:52  lr: 0.000192  loss: 3.1032 (3.1148)  time: 0.6066  data: 0.0001  max mem: 8728
Epoch: [19]  [ 110/2001]  eta: 0:20:38  lr: 0.000192  loss: 2.9482 (3.1098)  time: 0.6130  data: 0.0001  max mem: 8728
Epoch: [19]  [ 120/2001]  eta: 0:20:24  lr: 0.000192  loss: 2.9798 (3.1128)  time: 0.6117  data: 0.0001  max mem: 8728
Epoch: [19]  [ 130/2001]  eta: 0:20:13  lr: 0.000192  loss: 2.9798 (3.1064)  time: 0.6127  data: 0.0001  max mem: 8728
Epoch: [19]  [ 140/2001]  eta: 0:20:02  lr: 0.000192  loss: 2.9728 (3.0926)  time: 0.6142  data: 0.0001  max mem: 8728
Epoch: [19]  [ 150/2001]  eta: 0:19:51  lr: 0.000192  loss: 3.0906 (3.0996)  time: 0.6128  data: 0.0001  max mem: 8728
Epoch: [19]  [ 160/2001]  eta: 0:19:41  lr: 0.000192  loss: 3.2779 (3.0913)  time: 0.6122  data: 0.0001  max mem: 8728
Epoch: [19]  [ 170/2001]  eta: 0:19:32  lr: 0.000192  loss: 2.9196 (3.0812)  time: 0.6138  data: 0.0001  max mem: 8728
Epoch: [19]  [ 180/2001]  eta: 0:19:24  lr: 0.000192  loss: 3.2798 (3.0892)  time: 0.6201  data: 0.0001  max mem: 8728
Epoch: [19]  [ 190/2001]  eta: 0:19:16  lr: 0.000192  loss: 3.3038 (3.0744)  time: 0.6274  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9377, ratio_loss=0.0455, cls_kl=0.0641, token_kl=0.0930
Epoch: [19]  [ 200/2001]  eta: 0:19:09  lr: 0.000192  loss: 3.2537 (3.0836)  time: 0.6263  data: 0.0001  max mem: 8728
Epoch: [19]  [ 210/2001]  eta: 0:19:01  lr: 0.000192  loss: 3.2537 (3.0861)  time: 0.6220  data: 0.0001  max mem: 8728
Epoch: [19]  [ 220/2001]  eta: 0:18:53  lr: 0.000192  loss: 3.2688 (3.0980)  time: 0.6225  data: 0.0001  max mem: 8728
Epoch: [19]  [ 230/2001]  eta: 0:18:46  lr: 0.000192  loss: 3.2612 (3.1006)  time: 0.6262  data: 0.0001  max mem: 8728
Epoch: [19]  [ 240/2001]  eta: 0:18:39  lr: 0.000192  loss: 3.2553 (3.0986)  time: 0.6273  data: 0.0001  max mem: 8728
Epoch: [19]  [ 250/2001]  eta: 0:18:33  lr: 0.000192  loss: 3.0798 (3.0894)  time: 0.6280  data: 0.0001  max mem: 8728
Epoch: [19]  [ 260/2001]  eta: 0:18:25  lr: 0.000192  loss: 3.0449 (3.0841)  time: 0.6269  data: 0.0001  max mem: 8728
Epoch: [19]  [ 270/2001]  eta: 0:18:19  lr: 0.000192  loss: 2.9764 (3.0781)  time: 0.6266  data: 0.0001  max mem: 8728
Epoch: [19]  [ 280/2001]  eta: 0:18:12  lr: 0.000192  loss: 3.0824 (3.0805)  time: 0.6288  data: 0.0001  max mem: 8728
Epoch: [19]  [ 290/2001]  eta: 0:18:06  lr: 0.000192  loss: 3.1899 (3.0788)  time: 0.6320  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9485, ratio_loss=0.0452, cls_kl=0.0643, token_kl=0.0933
Epoch: [19]  [ 300/2001]  eta: 0:17:59  lr: 0.000192  loss: 2.9555 (3.0745)  time: 0.6351  data: 0.0001  max mem: 8728
Epoch: [19]  [ 310/2001]  eta: 0:17:53  lr: 0.000192  loss: 3.1711 (3.0806)  time: 0.6354  data: 0.0001  max mem: 8728
Epoch: [19]  [ 320/2001]  eta: 0:17:47  lr: 0.000192  loss: 3.1575 (3.0761)  time: 0.6363  data: 0.0001  max mem: 8728
Epoch: [19]  [ 330/2001]  eta: 0:17:40  lr: 0.000192  loss: 3.0070 (3.0723)  time: 0.6363  data: 0.0001  max mem: 8728
Epoch: [19]  [ 340/2001]  eta: 0:17:34  lr: 0.000192  loss: 3.1194 (3.0694)  time: 0.6372  data: 0.0001  max mem: 8728
Epoch: [19]  [ 350/2001]  eta: 0:17:28  lr: 0.000192  loss: 3.1194 (3.0697)  time: 0.6382  data: 0.0001  max mem: 8728
Epoch: [19]  [ 360/2001]  eta: 0:17:22  lr: 0.000192  loss: 2.8982 (3.0614)  time: 0.6386  data: 0.0001  max mem: 8728
Epoch: [19]  [ 370/2001]  eta: 0:17:16  lr: 0.000192  loss: 3.0525 (3.0599)  time: 0.6385  data: 0.0001  max mem: 8728
Epoch: [19]  [ 380/2001]  eta: 0:17:09  lr: 0.000192  loss: 3.0525 (3.0520)  time: 0.6390  data: 0.0001  max mem: 8728
Epoch: [19]  [ 390/2001]  eta: 0:17:03  lr: 0.000192  loss: 2.8157 (3.0486)  time: 0.6384  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8692, ratio_loss=0.0448, cls_kl=0.0622, token_kl=0.0938
Epoch: [19]  [ 400/2001]  eta: 0:16:57  lr: 0.000192  loss: 3.0211 (3.0469)  time: 0.6367  data: 0.0001  max mem: 8728
Epoch: [19]  [ 410/2001]  eta: 0:16:51  lr: 0.000192  loss: 2.7434 (3.0399)  time: 0.6381  data: 0.0001  max mem: 8728
Epoch: [19]  [ 420/2001]  eta: 0:16:44  lr: 0.000192  loss: 2.6963 (3.0391)  time: 0.6398  data: 0.0001  max mem: 8728
Epoch: [19]  [ 430/2001]  eta: 0:16:38  lr: 0.000192  loss: 3.1134 (3.0332)  time: 0.6399  data: 0.0001  max mem: 8728
Epoch: [19]  [ 440/2001]  eta: 0:16:32  lr: 0.000192  loss: 2.7081 (3.0265)  time: 0.6405  data: 0.0001  max mem: 8728
Epoch: [19]  [ 450/2001]  eta: 0:16:26  lr: 0.000192  loss: 2.8459 (3.0253)  time: 0.6430  data: 0.0001  max mem: 8728
Epoch: [19]  [ 460/2001]  eta: 0:16:20  lr: 0.000192  loss: 3.2694 (3.0300)  time: 0.6476  data: 0.0001  max mem: 8728
Epoch: [19]  [ 470/2001]  eta: 0:16:14  lr: 0.000192  loss: 3.2762 (3.0281)  time: 0.6468  data: 0.0001  max mem: 8728
Epoch: [19]  [ 480/2001]  eta: 0:16:08  lr: 0.000192  loss: 3.2127 (3.0310)  time: 0.6437  data: 0.0001  max mem: 8728
Epoch: [19]  [ 490/2001]  eta: 0:16:02  lr: 0.000192  loss: 3.0562 (3.0261)  time: 0.6428  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8243, ratio_loss=0.0435, cls_kl=0.0620, token_kl=0.0937
Epoch: [19]  [ 500/2001]  eta: 0:15:55  lr: 0.000192  loss: 2.9408 (3.0272)  time: 0.6403  data: 0.0001  max mem: 8728
Epoch: [19]  [ 510/2001]  eta: 0:15:49  lr: 0.000192  loss: 3.3765 (3.0330)  time: 0.6402  data: 0.0001  max mem: 8728
Epoch: [19]  [ 520/2001]  eta: 0:15:43  lr: 0.000192  loss: 3.2512 (3.0325)  time: 0.6421  data: 0.0001  max mem: 8728
Epoch: [19]  [ 530/2001]  eta: 0:15:37  lr: 0.000192  loss: 2.9831 (3.0295)  time: 0.6410  data: 0.0001  max mem: 8728
Epoch: [19]  [ 540/2001]  eta: 0:15:30  lr: 0.000192  loss: 3.0117 (3.0304)  time: 0.6391  data: 0.0001  max mem: 8728
Epoch: [19]  [ 550/2001]  eta: 0:15:24  lr: 0.000192  loss: 3.1477 (3.0300)  time: 0.6424  data: 0.0001  max mem: 8728
Epoch: [19]  [ 560/2001]  eta: 0:15:18  lr: 0.000192  loss: 3.1389 (3.0305)  time: 0.6460  data: 0.0001  max mem: 8728
Epoch: [19]  [ 570/2001]  eta: 0:15:12  lr: 0.000192  loss: 3.0712 (3.0281)  time: 0.6435  data: 0.0001  max mem: 8728
Epoch: [19]  [ 580/2001]  eta: 0:15:05  lr: 0.000192  loss: 2.7978 (3.0235)  time: 0.6398  data: 0.0001  max mem: 8728
Epoch: [19]  [ 590/2001]  eta: 0:14:59  lr: 0.000192  loss: 3.0267 (3.0279)  time: 0.6390  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9449, ratio_loss=0.0493, cls_kl=0.0660, token_kl=0.0965
Epoch: [19]  [ 600/2001]  eta: 0:14:53  lr: 0.000192  loss: 3.3743 (3.0332)  time: 0.6394  data: 0.0001  max mem: 8728
Epoch: [19]  [ 610/2001]  eta: 0:14:47  lr: 0.000192  loss: 3.3743 (3.0364)  time: 0.6445  data: 0.0001  max mem: 8728
Epoch: [19]  [ 620/2001]  eta: 0:14:41  lr: 0.000192  loss: 3.1624 (3.0360)  time: 0.6595  data: 0.0001  max mem: 8728
Epoch: [19]  [ 630/2001]  eta: 0:14:35  lr: 0.000192  loss: 3.1532 (3.0384)  time: 0.6590  data: 0.0001  max mem: 8728
Epoch: [19]  [ 640/2001]  eta: 0:14:29  lr: 0.000192  loss: 3.1532 (3.0388)  time: 0.6456  data: 0.0001  max mem: 8728
Epoch: [19]  [ 650/2001]  eta: 0:14:22  lr: 0.000192  loss: 3.0609 (3.0412)  time: 0.6412  data: 0.0001  max mem: 8728
Epoch: [19]  [ 660/2001]  eta: 0:14:16  lr: 0.000192  loss: 3.0609 (3.0383)  time: 0.6401  data: 0.0001  max mem: 8728
Epoch: [19]  [ 670/2001]  eta: 0:14:10  lr: 0.000192  loss: 3.1137 (3.0432)  time: 0.6423  data: 0.0001  max mem: 8728
Epoch: [19]  [ 680/2001]  eta: 0:14:03  lr: 0.000192  loss: 3.0950 (3.0397)  time: 0.6439  data: 0.0001  max mem: 8728
Epoch: [19]  [ 690/2001]  eta: 0:13:57  lr: 0.000192  loss: 2.8636 (3.0383)  time: 0.6430  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9905, ratio_loss=0.0491, cls_kl=0.0668, token_kl=0.0959
Epoch: [19]  [ 700/2001]  eta: 0:13:51  lr: 0.000192  loss: 3.1851 (3.0423)  time: 0.6425  data: 0.0001  max mem: 8728
Epoch: [19]  [ 710/2001]  eta: 0:13:44  lr: 0.000192  loss: 3.2427 (3.0408)  time: 0.6408  data: 0.0001  max mem: 8728
Epoch: [19]  [ 720/2001]  eta: 0:13:38  lr: 0.000192  loss: 3.0368 (3.0391)  time: 0.6401  data: 0.0001  max mem: 8728
Epoch: [19]  [ 730/2001]  eta: 0:13:32  lr: 0.000192  loss: 3.1972 (3.0391)  time: 0.6415  data: 0.0001  max mem: 8728
Epoch: [19]  [ 740/2001]  eta: 0:13:25  lr: 0.000192  loss: 3.2331 (3.0409)  time: 0.6414  data: 0.0001  max mem: 8728
Epoch: [19]  [ 750/2001]  eta: 0:13:19  lr: 0.000192  loss: 3.2331 (3.0414)  time: 0.6397  data: 0.0001  max mem: 8728
Epoch: [19]  [ 760/2001]  eta: 0:13:12  lr: 0.000192  loss: 3.2061 (3.0410)  time: 0.6385  data: 0.0001  max mem: 8728
Epoch: [19]  [ 770/2001]  eta: 0:13:06  lr: 0.000192  loss: 3.0833 (3.0416)  time: 0.6386  data: 0.0001  max mem: 8728
Epoch: [19]  [ 780/2001]  eta: 0:13:00  lr: 0.000192  loss: 3.1784 (3.0451)  time: 0.6374  data: 0.0001  max mem: 8728
Epoch: [19]  [ 790/2001]  eta: 0:12:53  lr: 0.000192  loss: 3.3419 (3.0464)  time: 0.6377  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9845, ratio_loss=0.0471, cls_kl=0.0636, token_kl=0.0937
Epoch: [19]  [ 800/2001]  eta: 0:12:47  lr: 0.000192  loss: 3.1478 (3.0493)  time: 0.6419  data: 0.0001  max mem: 8728
Epoch: [19]  [ 810/2001]  eta: 0:12:41  lr: 0.000192  loss: 3.1861 (3.0508)  time: 0.6422  data: 0.0001  max mem: 8728
Epoch: [19]  [ 820/2001]  eta: 0:12:34  lr: 0.000192  loss: 3.1914 (3.0511)  time: 0.6388  data: 0.0001  max mem: 8728
Epoch: [19]  [ 830/2001]  eta: 0:12:28  lr: 0.000192  loss: 3.1103 (3.0507)  time: 0.6375  data: 0.0001  max mem: 8728
Epoch: [19]  [ 840/2001]  eta: 0:12:21  lr: 0.000192  loss: 3.1562 (3.0506)  time: 0.6372  data: 0.0001  max mem: 8728
Epoch: [19]  [ 850/2001]  eta: 0:12:15  lr: 0.000192  loss: 3.1901 (3.0509)  time: 0.6361  data: 0.0001  max mem: 8728
Epoch: [19]  [ 860/2001]  eta: 0:12:08  lr: 0.000192  loss: 3.0619 (3.0509)  time: 0.6347  data: 0.0001  max mem: 8728
Epoch: [19]  [ 870/2001]  eta: 0:12:02  lr: 0.000192  loss: 3.0619 (3.0511)  time: 0.6338  data: 0.0001  max mem: 8728
Epoch: [19]  [ 880/2001]  eta: 0:11:55  lr: 0.000192  loss: 3.1470 (3.0507)  time: 0.6327  data: 0.0001  max mem: 8728
Epoch: [19]  [ 890/2001]  eta: 0:11:49  lr: 0.000192  loss: 3.2011 (3.0532)  time: 0.6355  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9901, ratio_loss=0.0445, cls_kl=0.0636, token_kl=0.0908
Epoch: [19]  [ 900/2001]  eta: 0:11:43  lr: 0.000192  loss: 3.2091 (3.0527)  time: 0.6363  data: 0.0001  max mem: 8728
Epoch: [19]  [ 910/2001]  eta: 0:11:36  lr: 0.000192  loss: 3.1797 (3.0533)  time: 0.6341  data: 0.0001  max mem: 8728
Epoch: [19]  [ 920/2001]  eta: 0:11:30  lr: 0.000192  loss: 3.3422 (3.0553)  time: 0.6338  data: 0.0001  max mem: 8728
Epoch: [19]  [ 930/2001]  eta: 0:11:23  lr: 0.000192  loss: 2.9051 (3.0519)  time: 0.6329  data: 0.0001  max mem: 8728
Epoch: [19]  [ 940/2001]  eta: 0:11:17  lr: 0.000192  loss: 3.1087 (3.0542)  time: 0.6337  data: 0.0001  max mem: 8728
Epoch: [19]  [ 950/2001]  eta: 0:11:10  lr: 0.000192  loss: 3.2787 (3.0558)  time: 0.6321  data: 0.0001  max mem: 8728
Epoch: [19]  [ 960/2001]  eta: 0:11:04  lr: 0.000192  loss: 3.0379 (3.0527)  time: 0.6302  data: 0.0001  max mem: 8728
Epoch: [19]  [ 970/2001]  eta: 0:10:57  lr: 0.000192  loss: 2.7210 (3.0528)  time: 0.6290  data: 0.0001  max mem: 8728
Epoch: [19]  [ 980/2001]  eta: 0:10:51  lr: 0.000192  loss: 2.9116 (3.0519)  time: 0.6296  data: 0.0001  max mem: 8728
Epoch: [19]  [ 990/2001]  eta: 0:10:45  lr: 0.000192  loss: 2.9703 (3.0514)  time: 0.6315  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9361, ratio_loss=0.0438, cls_kl=0.0627, token_kl=0.0914
Epoch: [19]  [1000/2001]  eta: 0:10:38  lr: 0.000192  loss: 3.2352 (3.0532)  time: 0.6322  data: 0.0001  max mem: 8728
Epoch: [19]  [1010/2001]  eta: 0:10:32  lr: 0.000192  loss: 3.4572 (3.0550)  time: 0.6331  data: 0.0001  max mem: 8728
Epoch: [19]  [1020/2001]  eta: 0:10:25  lr: 0.000192  loss: 3.1828 (3.0545)  time: 0.6304  data: 0.0001  max mem: 8728
Epoch: [19]  [1030/2001]  eta: 0:10:19  lr: 0.000192  loss: 3.1368 (3.0542)  time: 0.6288  data: 0.0001  max mem: 8728
Epoch: [19]  [1040/2001]  eta: 0:10:12  lr: 0.000192  loss: 3.0502 (3.0535)  time: 0.6367  data: 0.0001  max mem: 8728
Epoch: [19]  [1050/2001]  eta: 0:10:06  lr: 0.000192  loss: 2.9979 (3.0520)  time: 0.6356  data: 0.0001  max mem: 8728
Epoch: [19]  [1060/2001]  eta: 0:09:59  lr: 0.000192  loss: 3.0357 (3.0522)  time: 0.6280  data: 0.0001  max mem: 8728
Epoch: [19]  [1070/2001]  eta: 0:09:53  lr: 0.000192  loss: 3.0447 (3.0527)  time: 0.6297  data: 0.0001  max mem: 8728
Epoch: [19]  [1080/2001]  eta: 0:09:47  lr: 0.000192  loss: 3.0447 (3.0523)  time: 0.6280  data: 0.0001  max mem: 8728
Epoch: [19]  [1090/2001]  eta: 0:09:40  lr: 0.000192  loss: 2.9477 (3.0494)  time: 0.6257  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9360, ratio_loss=0.0450, cls_kl=0.0640, token_kl=0.0948
Epoch: [19]  [1100/2001]  eta: 0:09:34  lr: 0.000192  loss: 3.1422 (3.0526)  time: 0.6260  data: 0.0001  max mem: 8728
Epoch: [19]  [1110/2001]  eta: 0:09:27  lr: 0.000192  loss: 3.2654 (3.0519)  time: 0.6258  data: 0.0001  max mem: 8728
Epoch: [19]  [1120/2001]  eta: 0:09:21  lr: 0.000192  loss: 3.2348 (3.0541)  time: 0.6290  data: 0.0001  max mem: 8728
Epoch: [19]  [1130/2001]  eta: 0:09:14  lr: 0.000192  loss: 3.1511 (3.0506)  time: 0.6314  data: 0.0001  max mem: 8728
Epoch: [19]  [1140/2001]  eta: 0:09:08  lr: 0.000192  loss: 2.6150 (3.0483)  time: 0.6299  data: 0.0001  max mem: 8728
Epoch: [19]  [1150/2001]  eta: 0:09:01  lr: 0.000192  loss: 3.0510 (3.0471)  time: 0.6287  data: 0.0001  max mem: 8728
Epoch: [19]  [1160/2001]  eta: 0:08:55  lr: 0.000192  loss: 3.1413 (3.0480)  time: 0.6278  data: 0.0001  max mem: 8728
Epoch: [19]  [1170/2001]  eta: 0:08:49  lr: 0.000192  loss: 3.1413 (3.0491)  time: 0.6262  data: 0.0001  max mem: 8728
Epoch: [19]  [1180/2001]  eta: 0:08:42  lr: 0.000192  loss: 3.1488 (3.0498)  time: 0.6273  data: 0.0001  max mem: 8728
Epoch: [19]  [1190/2001]  eta: 0:08:36  lr: 0.000192  loss: 3.0024 (3.0479)  time: 0.6309  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8902, ratio_loss=0.0449, cls_kl=0.0634, token_kl=0.0938
Epoch: [19]  [1200/2001]  eta: 0:08:29  lr: 0.000192  loss: 2.8517 (3.0469)  time: 0.6311  data: 0.0001  max mem: 8728
Epoch: [19]  [1210/2001]  eta: 0:08:23  lr: 0.000192  loss: 2.9185 (3.0458)  time: 0.6288  data: 0.0001  max mem: 8728
Epoch: [19]  [1220/2001]  eta: 0:08:17  lr: 0.000192  loss: 2.9800 (3.0454)  time: 0.6268  data: 0.0001  max mem: 8728
Epoch: [19]  [1230/2001]  eta: 0:08:10  lr: 0.000192  loss: 3.2132 (3.0469)  time: 0.6275  data: 0.0001  max mem: 8728
Epoch: [19]  [1240/2001]  eta: 0:08:04  lr: 0.000192  loss: 3.2435 (3.0480)  time: 0.6266  data: 0.0001  max mem: 8728
Epoch: [19]  [1250/2001]  eta: 0:07:57  lr: 0.000192  loss: 3.1911 (3.0485)  time: 0.6265  data: 0.0002  max mem: 8728
Epoch: [19]  [1260/2001]  eta: 0:07:51  lr: 0.000192  loss: 3.1348 (3.0495)  time: 0.6252  data: 0.0002  max mem: 8728
Epoch: [19]  [1270/2001]  eta: 0:07:44  lr: 0.000192  loss: 3.1528 (3.0505)  time: 0.6249  data: 0.0001  max mem: 8728
Epoch: [19]  [1280/2001]  eta: 0:07:38  lr: 0.000192  loss: 3.3333 (3.0527)  time: 0.6254  data: 0.0001  max mem: 8728
Epoch: [19]  [1290/2001]  eta: 0:07:32  lr: 0.000192  loss: 3.0481 (3.0503)  time: 0.6259  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9513, ratio_loss=0.0453, cls_kl=0.0616, token_kl=0.0924
Epoch: [19]  [1300/2001]  eta: 0:07:25  lr: 0.000192  loss: 2.8579 (3.0491)  time: 0.6273  data: 0.0001  max mem: 8728
Epoch: [19]  [1310/2001]  eta: 0:07:19  lr: 0.000192  loss: 3.0394 (3.0484)  time: 0.6302  data: 0.0001  max mem: 8728
Epoch: [19]  [1320/2001]  eta: 0:07:12  lr: 0.000192  loss: 3.1907 (3.0507)  time: 0.6313  data: 0.0001  max mem: 8728
Epoch: [19]  [1330/2001]  eta: 0:07:06  lr: 0.000192  loss: 3.4019 (3.0523)  time: 0.6275  data: 0.0001  max mem: 8728
Epoch: [19]  [1340/2001]  eta: 0:07:00  lr: 0.000192  loss: 3.0423 (3.0496)  time: 0.6261  data: 0.0001  max mem: 8728
Epoch: [19]  [1350/2001]  eta: 0:06:53  lr: 0.000192  loss: 2.6887 (3.0489)  time: 0.6258  data: 0.0001  max mem: 8728
Epoch: [19]  [1360/2001]  eta: 0:06:47  lr: 0.000192  loss: 3.2554 (3.0480)  time: 0.6251  data: 0.0001  max mem: 8728
Epoch: [19]  [1370/2001]  eta: 0:06:40  lr: 0.000192  loss: 3.2412 (3.0487)  time: 0.6254  data: 0.0001  max mem: 8728
Epoch: [19]  [1380/2001]  eta: 0:06:34  lr: 0.000192  loss: 3.1844 (3.0488)  time: 0.6264  data: 0.0001  max mem: 8728
Epoch: [19]  [1390/2001]  eta: 0:06:28  lr: 0.000192  loss: 3.1219 (3.0486)  time: 0.6251  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9303, ratio_loss=0.0425, cls_kl=0.0612, token_kl=0.0902
Epoch: [19]  [1400/2001]  eta: 0:06:21  lr: 0.000192  loss: 3.1219 (3.0477)  time: 0.6272  data: 0.0001  max mem: 8728
Epoch: [19]  [1410/2001]  eta: 0:06:15  lr: 0.000192  loss: 3.1349 (3.0477)  time: 0.6280  data: 0.0001  max mem: 8728
Epoch: [19]  [1420/2001]  eta: 0:06:08  lr: 0.000192  loss: 3.0728 (3.0479)  time: 0.6285  data: 0.0001  max mem: 8728
Epoch: [19]  [1430/2001]  eta: 0:06:02  lr: 0.000192  loss: 3.0728 (3.0470)  time: 0.6303  data: 0.0001  max mem: 8728
Epoch: [19]  [1440/2001]  eta: 0:05:56  lr: 0.000192  loss: 3.0075 (3.0460)  time: 0.6288  data: 0.0001  max mem: 8728
Epoch: [19]  [1450/2001]  eta: 0:05:49  lr: 0.000192  loss: 2.9896 (3.0455)  time: 0.6294  data: 0.0001  max mem: 8728
Epoch: [19]  [1460/2001]  eta: 0:05:43  lr: 0.000192  loss: 3.2030 (3.0467)  time: 0.6296  data: 0.0001  max mem: 8728
Epoch: [19]  [1470/2001]  eta: 0:05:37  lr: 0.000192  loss: 3.2030 (3.0473)  time: 0.6350  data: 0.0001  max mem: 8728
Epoch: [19]  [1480/2001]  eta: 0:05:30  lr: 0.000192  loss: 3.2834 (3.0484)  time: 0.6346  data: 0.0001  max mem: 8728
Epoch: [19]  [1490/2001]  eta: 0:05:24  lr: 0.000192  loss: 3.2924 (3.0490)  time: 0.6283  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9696, ratio_loss=0.0468, cls_kl=0.0641, token_kl=0.0945
Epoch: [19]  [1500/2001]  eta: 0:05:18  lr: 0.000192  loss: 3.2672 (3.0498)  time: 0.6292  data: 0.0001  max mem: 8728
Epoch: [19]  [1510/2001]  eta: 0:05:11  lr: 0.000192  loss: 3.3777 (3.0512)  time: 0.6288  data: 0.0001  max mem: 8728
Epoch: [19]  [1520/2001]  eta: 0:05:05  lr: 0.000192  loss: 3.3858 (3.0516)  time: 0.6296  data: 0.0001  max mem: 8728
Epoch: [19]  [1530/2001]  eta: 0:04:58  lr: 0.000192  loss: 3.0208 (3.0514)  time: 0.6336  data: 0.0001  max mem: 8728
Epoch: [19]  [1540/2001]  eta: 0:04:52  lr: 0.000192  loss: 3.1214 (3.0518)  time: 0.6379  data: 0.0001  max mem: 8728
Epoch: [19]  [1550/2001]  eta: 0:04:46  lr: 0.000192  loss: 3.0085 (3.0509)  time: 0.6348  data: 0.0001  max mem: 8728
Epoch: [19]  [1560/2001]  eta: 0:04:39  lr: 0.000192  loss: 3.0085 (3.0522)  time: 0.6307  data: 0.0001  max mem: 8728
Epoch: [19]  [1570/2001]  eta: 0:04:33  lr: 0.000192  loss: 3.3770 (3.0538)  time: 0.6313  data: 0.0001  max mem: 8728
Epoch: [19]  [1580/2001]  eta: 0:04:27  lr: 0.000192  loss: 3.3238 (3.0542)  time: 0.6303  data: 0.0001  max mem: 8728
Epoch: [19]  [1590/2001]  eta: 0:04:20  lr: 0.000192  loss: 3.3585 (3.0556)  time: 0.6304  data: 0.0001  max mem: 8728
loss info: cls_loss=3.0436, ratio_loss=0.0485, cls_kl=0.0673, token_kl=0.0952
Epoch: [19]  [1600/2001]  eta: 0:04:14  lr: 0.000192  loss: 3.3085 (3.0558)  time: 0.6316  data: 0.0001  max mem: 8728
Epoch: [19]  [1610/2001]  eta: 0:04:08  lr: 0.000192  loss: 3.2706 (3.0567)  time: 0.6314  data: 0.0001  max mem: 8728
Epoch: [19]  [1620/2001]  eta: 0:04:01  lr: 0.000192  loss: 3.3360 (3.0575)  time: 0.6310  data: 0.0001  max mem: 8728
Epoch: [19]  [1630/2001]  eta: 0:03:55  lr: 0.000192  loss: 3.3323 (3.0587)  time: 0.6317  data: 0.0001  max mem: 8728
Epoch: [19]  [1640/2001]  eta: 0:03:49  lr: 0.000192  loss: 3.1624 (3.0594)  time: 0.6328  data: 0.0001  max mem: 8728
Epoch: [19]  [1650/2001]  eta: 0:03:42  lr: 0.000192  loss: 3.1062 (3.0577)  time: 0.6337  data: 0.0001  max mem: 8728
Epoch: [19]  [1660/2001]  eta: 0:03:36  lr: 0.000192  loss: 2.9516 (3.0573)  time: 0.6364  data: 0.0001  max mem: 8728
Epoch: [19]  [1670/2001]  eta: 0:03:30  lr: 0.000192  loss: 3.1485 (3.0574)  time: 0.6355  data: 0.0001  max mem: 8728
Epoch: [19]  [1680/2001]  eta: 0:03:23  lr: 0.000192  loss: 3.2955 (3.0583)  time: 0.6321  data: 0.0001  max mem: 8728
Epoch: [19]  [1690/2001]  eta: 0:03:17  lr: 0.000192  loss: 3.2881 (3.0574)  time: 0.6309  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9614, ratio_loss=0.0443, cls_kl=0.0651, token_kl=0.0938
Epoch: [19]  [1700/2001]  eta: 0:03:10  lr: 0.000192  loss: 3.1664 (3.0574)  time: 0.6314  data: 0.0001  max mem: 8728
Epoch: [19]  [1710/2001]  eta: 0:03:04  lr: 0.000192  loss: 3.3751 (3.0594)  time: 0.6330  data: 0.0001  max mem: 8728
Epoch: [19]  [1720/2001]  eta: 0:02:58  lr: 0.000192  loss: 3.3780 (3.0598)  time: 0.6336  data: 0.0001  max mem: 8728
Epoch: [19]  [1730/2001]  eta: 0:02:51  lr: 0.000192  loss: 3.3396 (3.0615)  time: 0.6356  data: 0.0001  max mem: 8728
Epoch: [19]  [1740/2001]  eta: 0:02:45  lr: 0.000192  loss: 3.3396 (3.0614)  time: 0.6407  data: 0.0001  max mem: 8728
Epoch: [19]  [1750/2001]  eta: 0:02:39  lr: 0.000192  loss: 3.1838 (3.0615)  time: 0.6390  data: 0.0001  max mem: 8728
Epoch: [19]  [1760/2001]  eta: 0:02:32  lr: 0.000192  loss: 3.1838 (3.0610)  time: 0.6342  data: 0.0001  max mem: 8728
Epoch: [19]  [1770/2001]  eta: 0:02:26  lr: 0.000192  loss: 2.7740 (3.0599)  time: 0.6336  data: 0.0001  max mem: 8728
Epoch: [19]  [1780/2001]  eta: 0:02:20  lr: 0.000192  loss: 2.8538 (3.0596)  time: 0.6340  data: 0.0001  max mem: 8728
Epoch: [19]  [1790/2001]  eta: 0:02:13  lr: 0.000192  loss: 3.0252 (3.0600)  time: 0.6368  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9812, ratio_loss=0.0437, cls_kl=0.0643, token_kl=0.0932
Epoch: [19]  [1800/2001]  eta: 0:02:07  lr: 0.000192  loss: 3.0252 (3.0588)  time: 0.6361  data: 0.0001  max mem: 8728
Epoch: [19]  [1810/2001]  eta: 0:02:01  lr: 0.000192  loss: 3.0906 (3.0583)  time: 0.6338  data: 0.0001  max mem: 8728
Epoch: [19]  [1820/2001]  eta: 0:01:54  lr: 0.000192  loss: 3.0597 (3.0569)  time: 0.6356  data: 0.0001  max mem: 8728
Epoch: [19]  [1830/2001]  eta: 0:01:48  lr: 0.000192  loss: 3.2170 (3.0574)  time: 0.6360  data: 0.0001  max mem: 8728
Epoch: [19]  [1840/2001]  eta: 0:01:42  lr: 0.000192  loss: 3.1375 (3.0565)  time: 0.6337  data: 0.0001  max mem: 8728
Epoch: [19]  [1850/2001]  eta: 0:01:35  lr: 0.000192  loss: 2.9408 (3.0564)  time: 0.6351  data: 0.0001  max mem: 8728
Epoch: [19]  [1860/2001]  eta: 0:01:29  lr: 0.000192  loss: 2.9146 (3.0552)  time: 0.6367  data: 0.0001  max mem: 8728
Epoch: [19]  [1870/2001]  eta: 0:01:23  lr: 0.000192  loss: 3.1552 (3.0564)  time: 0.6363  data: 0.0001  max mem: 8728
Epoch: [19]  [1880/2001]  eta: 0:01:16  lr: 0.000192  loss: 3.2579 (3.0552)  time: 0.6359  data: 0.0001  max mem: 8728
Epoch: [19]  [1890/2001]  eta: 0:01:10  lr: 0.000192  loss: 3.0936 (3.0563)  time: 0.6374  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8922, ratio_loss=0.0445, cls_kl=0.0610, token_kl=0.0921
Epoch: [19]  [1900/2001]  eta: 0:01:04  lr: 0.000192  loss: 3.0936 (3.0559)  time: 0.6419  data: 0.0001  max mem: 8728
Epoch: [19]  [1910/2001]  eta: 0:00:57  lr: 0.000192  loss: 2.8339 (3.0543)  time: 0.6413  data: 0.0001  max mem: 8728
Epoch: [19]  [1920/2001]  eta: 0:00:51  lr: 0.000192  loss: 2.9048 (3.0537)  time: 0.6372  data: 0.0001  max mem: 8728
Epoch: [19]  [1930/2001]  eta: 0:00:45  lr: 0.000192  loss: 3.1626 (3.0539)  time: 0.6351  data: 0.0001  max mem: 8728
Epoch: [19]  [1940/2001]  eta: 0:00:38  lr: 0.000192  loss: 3.2248 (3.0546)  time: 0.6347  data: 0.0001  max mem: 8728
Epoch: [19]  [1950/2001]  eta: 0:00:32  lr: 0.000192  loss: 3.2144 (3.0537)  time: 0.6364  data: 0.0001  max mem: 8728
Epoch: [19]  [1960/2001]  eta: 0:00:26  lr: 0.000192  loss: 3.0915 (3.0537)  time: 0.6376  data: 0.0001  max mem: 8728
Epoch: [19]  [1970/2001]  eta: 0:00:19  lr: 0.000192  loss: 3.0915 (3.0536)  time: 0.6388  data: 0.0001  max mem: 8728
Epoch: [19]  [1980/2001]  eta: 0:00:13  lr: 0.000192  loss: 3.2119 (3.0543)  time: 0.6396  data: 0.0001  max mem: 8728
Epoch: [19]  [1990/2001]  eta: 0:00:06  lr: 0.000192  loss: 3.2886 (3.0537)  time: 0.6336  data: 0.0004  max mem: 8728
loss info: cls_loss=2.9100, ratio_loss=0.0470, cls_kl=0.0638, token_kl=0.0958
Epoch: [19]  [2000/2001]  eta: 0:00:00  lr: 0.000192  loss: 3.1834 (3.0537)  time: 0.6280  data: 0.0004  max mem: 8728
Epoch: [19] Total time: 0:21:10 (0.6350 s / it)
Averaged stats: lr: 0.000192  loss: 3.1834 (3.0517)
Test:  [ 0/53]  eta: 0:05:29  loss: 0.3784 (0.3784)  acc1: 94.1667 (94.1667)  acc5: 98.3333 (98.3333)  time: 6.2229  data: 5.2641  max mem: 8728
Test:  [10/53]  eta: 0:00:39  loss: 0.7775 (0.7716)  acc1: 83.3333 (82.8788)  acc5: 97.5000 (96.7424)  time: 0.9117  data: 0.4788  max mem: 8728
Test:  [20/53]  eta: 0:00:21  loss: 0.7377 (0.7761)  acc1: 82.5000 (82.7381)  acc5: 97.5000 (96.5873)  time: 0.3715  data: 0.0005  max mem: 8728
Test:  [30/53]  eta: 0:00:12  loss: 0.8770 (0.8597)  acc1: 80.0000 (80.6183)  acc5: 94.1667 (95.2688)  time: 0.3405  data: 0.0005  max mem: 8728
Test:  [40/53]  eta: 0:00:06  loss: 1.1094 (0.9279)  acc1: 75.0000 (79.1057)  acc5: 91.6667 (94.4512)  time: 0.2920  data: 0.0002  max mem: 8728
Test:  [50/53]  eta: 0:00:01  loss: 1.1185 (0.9578)  acc1: 75.8333 (78.4641)  acc5: 91.6667 (94.2484)  time: 0.2598  data: 0.0001  max mem: 8728
Test:  [52/53]  eta: 0:00:00  loss: 1.0829 (0.9443)  acc1: 75.8333 (78.6560)  acc5: 92.5000 (94.3200)  time: 0.2458  data: 0.0001  max mem: 8728
Test: Total time: 0:00:22 (0.4242 s / it)
Sparsity0:0.29662707070707073,Sparsity1:0.5645362814070352,Sparsity2:0.7895096,
* Acc@1 79.004 Acc@5 94.570 loss 0.941
Accuracy of the network on the 50000 test images: 79.0%
Max accuracy: 79.00%
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0001638 for PREDICTOR
Epoch: [20]  [   0/2001]  eta: 2:31:31  lr: 0.000164  loss: 3.2169 (3.2169)  time: 4.5436  data: 3.9293  max mem: 8728
Epoch: [20]  [  10/2001]  eta: 0:32:16  lr: 0.000164  loss: 3.1886 (3.0821)  time: 0.9728  data: 0.3573  max mem: 8730
Epoch: [20]  [  20/2001]  eta: 0:26:30  lr: 0.000164  loss: 3.1886 (3.1044)  time: 0.6158  data: 0.0001  max mem: 8730
Epoch: [20]  [  30/2001]  eta: 0:24:32  lr: 0.000164  loss: 3.4061 (3.1835)  time: 0.6230  data: 0.0001  max mem: 8730
Epoch: [20]  [  40/2001]  eta: 0:23:29  lr: 0.000164  loss: 3.3843 (3.2168)  time: 0.6304  data: 0.0001  max mem: 8730
Epoch: [20]  [  50/2001]  eta: 0:22:50  lr: 0.000164  loss: 3.1285 (3.1729)  time: 0.6338  data: 0.0001  max mem: 8730
Epoch: [20]  [  60/2001]  eta: 0:22:22  lr: 0.000164  loss: 2.9094 (3.1313)  time: 0.6366  data: 0.0002  max mem: 8730
Epoch: [20]  [  70/2001]  eta: 0:22:00  lr: 0.000164  loss: 3.0084 (3.1238)  time: 0.6361  data: 0.0001  max mem: 8730
Epoch: [20]  [  80/2001]  eta: 0:21:43  lr: 0.000164  loss: 3.1579 (3.1363)  time: 0.6379  data: 0.0001  max mem: 8730
Epoch: [20]  [  90/2001]  eta: 0:21:30  lr: 0.000164  loss: 3.1918 (3.1304)  time: 0.6439  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9927, ratio_loss=0.0460, cls_kl=0.0652, token_kl=0.0941
Epoch: [20]  [ 100/2001]  eta: 0:21:17  lr: 0.000164  loss: 2.9633 (3.1029)  time: 0.6455  data: 0.0002  max mem: 8730
Epoch: [20]  [ 110/2001]  eta: 0:21:05  lr: 0.000164  loss: 2.9633 (3.1040)  time: 0.6425  data: 0.0002  max mem: 8730
Epoch: [20]  [ 120/2001]  eta: 0:20:54  lr: 0.000164  loss: 3.2093 (3.1093)  time: 0.6411  data: 0.0002  max mem: 8730
Epoch: [20]  [ 130/2001]  eta: 0:20:43  lr: 0.000164  loss: 3.1646 (3.0995)  time: 0.6393  data: 0.0002  max mem: 8730
Epoch: [20]  [ 140/2001]  eta: 0:20:33  lr: 0.000164  loss: 3.1262 (3.0807)  time: 0.6381  data: 0.0002  max mem: 8730
Epoch: [20]  [ 150/2001]  eta: 0:20:24  lr: 0.000164  loss: 3.0726 (3.0817)  time: 0.6405  data: 0.0001  max mem: 8730
Epoch: [20]  [ 160/2001]  eta: 0:20:15  lr: 0.000164  loss: 2.9730 (3.0702)  time: 0.6425  data: 0.0002  max mem: 8730
Epoch: [20]  [ 170/2001]  eta: 0:20:07  lr: 0.000164  loss: 3.1775 (3.0905)  time: 0.6432  data: 0.0002  max mem: 8730
Epoch: [20]  [ 180/2001]  eta: 0:19:58  lr: 0.000164  loss: 3.2759 (3.0932)  time: 0.6417  data: 0.0002  max mem: 8730
Epoch: [20]  [ 190/2001]  eta: 0:19:50  lr: 0.000164  loss: 3.1054 (3.0946)  time: 0.6389  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9649, ratio_loss=0.0461, cls_kl=0.0634, token_kl=0.0942
Epoch: [20]  [ 200/2001]  eta: 0:19:41  lr: 0.000164  loss: 3.2403 (3.0970)  time: 0.6389  data: 0.0001  max mem: 8730
Epoch: [20]  [ 210/2001]  eta: 0:19:34  lr: 0.000164  loss: 3.2680 (3.0960)  time: 0.6397  data: 0.0001  max mem: 8730
Epoch: [20]  [ 220/2001]  eta: 0:19:26  lr: 0.000164  loss: 3.2618 (3.0975)  time: 0.6427  data: 0.0001  max mem: 8730
Epoch: [20]  [ 230/2001]  eta: 0:19:19  lr: 0.000164  loss: 3.1629 (3.0901)  time: 0.6455  data: 0.0001  max mem: 8730
Epoch: [20]  [ 240/2001]  eta: 0:19:12  lr: 0.000164  loss: 3.1449 (3.0944)  time: 0.6452  data: 0.0001  max mem: 8730
Epoch: [20]  [ 250/2001]  eta: 0:19:04  lr: 0.000164  loss: 2.9538 (3.0827)  time: 0.6400  data: 0.0001  max mem: 8730
Epoch: [20]  [ 260/2001]  eta: 0:18:56  lr: 0.000164  loss: 2.9473 (3.0827)  time: 0.6352  data: 0.0001  max mem: 8730
Epoch: [20]  [ 270/2001]  eta: 0:18:48  lr: 0.000164  loss: 3.0502 (3.0792)  time: 0.6342  data: 0.0001  max mem: 8730
Epoch: [20]  [ 280/2001]  eta: 0:18:41  lr: 0.000164  loss: 3.0677 (3.0774)  time: 0.6351  data: 0.0001  max mem: 8730
Epoch: [20]  [ 290/2001]  eta: 0:18:34  lr: 0.000164  loss: 3.0893 (3.0740)  time: 0.6380  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9198, ratio_loss=0.0459, cls_kl=0.0631, token_kl=0.0931
Epoch: [20]  [ 300/2001]  eta: 0:18:26  lr: 0.000164  loss: 3.0462 (3.0716)  time: 0.6361  data: 0.0002  max mem: 8730
Epoch: [20]  [ 310/2001]  eta: 0:18:19  lr: 0.000164  loss: 3.1772 (3.0753)  time: 0.6328  data: 0.0001  max mem: 8730
Epoch: [20]  [ 320/2001]  eta: 0:18:11  lr: 0.000164  loss: 3.1936 (3.0739)  time: 0.6342  data: 0.0001  max mem: 8730
Epoch: [20]  [ 330/2001]  eta: 0:18:04  lr: 0.000164  loss: 3.2397 (3.0787)  time: 0.6360  data: 0.0001  max mem: 8730
Epoch: [20]  [ 340/2001]  eta: 0:17:57  lr: 0.000164  loss: 3.3477 (3.0820)  time: 0.6353  data: 0.0001  max mem: 8730
Epoch: [20]  [ 350/2001]  eta: 0:17:50  lr: 0.000164  loss: 3.3016 (3.0844)  time: 0.6322  data: 0.0001  max mem: 8730
Epoch: [20]  [ 360/2001]  eta: 0:17:42  lr: 0.000164  loss: 3.3102 (3.0907)  time: 0.6314  data: 0.0001  max mem: 8730
Epoch: [20]  [ 370/2001]  eta: 0:17:35  lr: 0.000164  loss: 3.2356 (3.0874)  time: 0.6309  data: 0.0001  max mem: 8730
Epoch: [20]  [ 380/2001]  eta: 0:17:28  lr: 0.000164  loss: 3.1232 (3.0888)  time: 0.6299  data: 0.0001  max mem: 8730
Epoch: [20]  [ 390/2001]  eta: 0:17:21  lr: 0.000164  loss: 3.2361 (3.0958)  time: 0.6307  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0632, ratio_loss=0.0490, cls_kl=0.0670, token_kl=0.0936
Epoch: [20]  [ 400/2001]  eta: 0:17:14  lr: 0.000164  loss: 3.2853 (3.0977)  time: 0.6357  data: 0.0001  max mem: 8730
Epoch: [20]  [ 410/2001]  eta: 0:17:07  lr: 0.000164  loss: 3.0431 (3.0923)  time: 0.6345  data: 0.0001  max mem: 8730
Epoch: [20]  [ 420/2001]  eta: 0:17:00  lr: 0.000164  loss: 3.1207 (3.0926)  time: 0.6302  data: 0.0002  max mem: 8730
Epoch: [20]  [ 430/2001]  eta: 0:16:53  lr: 0.000164  loss: 3.1882 (3.0922)  time: 0.6296  data: 0.0001  max mem: 8730
Epoch: [20]  [ 440/2001]  eta: 0:16:46  lr: 0.000164  loss: 2.7045 (3.0786)  time: 0.6290  data: 0.0001  max mem: 8730
Epoch: [20]  [ 450/2001]  eta: 0:16:39  lr: 0.000164  loss: 2.5887 (3.0754)  time: 0.6299  data: 0.0001  max mem: 8730
Epoch: [20]  [ 460/2001]  eta: 0:16:32  lr: 0.000164  loss: 2.9999 (3.0735)  time: 0.6312  data: 0.0001  max mem: 8730
Epoch: [20]  [ 470/2001]  eta: 0:16:25  lr: 0.000164  loss: 3.1231 (3.0776)  time: 0.6318  data: 0.0001  max mem: 8730
Epoch: [20]  [ 480/2001]  eta: 0:16:19  lr: 0.000164  loss: 3.1380 (3.0754)  time: 0.6363  data: 0.0001  max mem: 8730
Epoch: [20]  [ 490/2001]  eta: 0:16:12  lr: 0.000164  loss: 3.0528 (3.0735)  time: 0.6374  data: 0.0002  max mem: 8730
loss info: cls_loss=2.8647, ratio_loss=0.0431, cls_kl=0.0598, token_kl=0.0908
Epoch: [20]  [ 500/2001]  eta: 0:16:05  lr: 0.000164  loss: 3.0215 (3.0724)  time: 0.6365  data: 0.0002  max mem: 8730
Epoch: [20]  [ 510/2001]  eta: 0:15:59  lr: 0.000164  loss: 3.0215 (3.0712)  time: 0.6367  data: 0.0002  max mem: 8730
Epoch: [20]  [ 520/2001]  eta: 0:15:52  lr: 0.000164  loss: 2.8250 (3.0676)  time: 0.6339  data: 0.0002  max mem: 8730
Epoch: [20]  [ 530/2001]  eta: 0:15:45  lr: 0.000164  loss: 2.8814 (3.0645)  time: 0.6321  data: 0.0001  max mem: 8730
Epoch: [20]  [ 540/2001]  eta: 0:15:38  lr: 0.000164  loss: 2.8814 (3.0588)  time: 0.6315  data: 0.0002  max mem: 8730
Epoch: [20]  [ 550/2001]  eta: 0:15:32  lr: 0.000164  loss: 2.9543 (3.0585)  time: 0.6297  data: 0.0002  max mem: 8730
Epoch: [20]  [ 560/2001]  eta: 0:15:25  lr: 0.000164  loss: 3.1053 (3.0620)  time: 0.6305  data: 0.0002  max mem: 8730
Epoch: [20]  [ 570/2001]  eta: 0:15:18  lr: 0.000164  loss: 3.3042 (3.0635)  time: 0.6327  data: 0.0002  max mem: 8730
Epoch: [20]  [ 580/2001]  eta: 0:15:12  lr: 0.000164  loss: 3.3315 (3.0681)  time: 0.6298  data: 0.0002  max mem: 8730
Epoch: [20]  [ 590/2001]  eta: 0:15:05  lr: 0.000164  loss: 3.2971 (3.0664)  time: 0.6284  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9282, ratio_loss=0.0427, cls_kl=0.0629, token_kl=0.0928
Epoch: [20]  [ 600/2001]  eta: 0:14:58  lr: 0.000164  loss: 2.9845 (3.0660)  time: 0.6283  data: 0.0002  max mem: 8730
Epoch: [20]  [ 610/2001]  eta: 0:14:51  lr: 0.000164  loss: 3.0653 (3.0651)  time: 0.6275  data: 0.0001  max mem: 8730
Epoch: [20]  [ 620/2001]  eta: 0:14:45  lr: 0.000164  loss: 3.1389 (3.0682)  time: 0.6263  data: 0.0002  max mem: 8730
Epoch: [20]  [ 630/2001]  eta: 0:14:38  lr: 0.000164  loss: 3.1281 (3.0645)  time: 0.6276  data: 0.0002  max mem: 8730
Epoch: [20]  [ 640/2001]  eta: 0:14:31  lr: 0.000164  loss: 2.9866 (3.0615)  time: 0.6287  data: 0.0002  max mem: 8730
Epoch: [20]  [ 650/2001]  eta: 0:14:25  lr: 0.000164  loss: 2.7704 (3.0581)  time: 0.6329  data: 0.0001  max mem: 8730
Epoch: [20]  [ 660/2001]  eta: 0:14:18  lr: 0.000164  loss: 2.8376 (3.0598)  time: 0.6383  data: 0.0001  max mem: 8730
Epoch: [20]  [ 670/2001]  eta: 0:14:12  lr: 0.000164  loss: 3.0883 (3.0589)  time: 0.6374  data: 0.0002  max mem: 8730
Epoch: [20]  [ 680/2001]  eta: 0:14:05  lr: 0.000164  loss: 2.8174 (3.0542)  time: 0.6312  data: 0.0002  max mem: 8730
Epoch: [20]  [ 690/2001]  eta: 0:13:59  lr: 0.000164  loss: 3.1481 (3.0558)  time: 0.6314  data: 0.0002  max mem: 8730
loss info: cls_loss=2.8991, ratio_loss=0.0459, cls_kl=0.0626, token_kl=0.0942
Epoch: [20]  [ 700/2001]  eta: 0:13:52  lr: 0.000164  loss: 3.2960 (3.0577)  time: 0.6315  data: 0.0002  max mem: 8730
Epoch: [20]  [ 710/2001]  eta: 0:13:46  lr: 0.000164  loss: 3.3078 (3.0571)  time: 0.6294  data: 0.0001  max mem: 8730
Epoch: [20]  [ 720/2001]  eta: 0:13:39  lr: 0.000164  loss: 3.2407 (3.0595)  time: 0.6344  data: 0.0001  max mem: 8730
Epoch: [20]  [ 730/2001]  eta: 0:13:32  lr: 0.000164  loss: 2.9311 (3.0540)  time: 0.6327  data: 0.0002  max mem: 8730
Epoch: [20]  [ 740/2001]  eta: 0:13:26  lr: 0.000164  loss: 2.6674 (3.0523)  time: 0.6293  data: 0.0002  max mem: 8730
Epoch: [20]  [ 750/2001]  eta: 0:13:19  lr: 0.000164  loss: 3.0589 (3.0537)  time: 0.6296  data: 0.0002  max mem: 8730
Epoch: [20]  [ 760/2001]  eta: 0:13:13  lr: 0.000164  loss: 3.3119 (3.0551)  time: 0.6274  data: 0.0002  max mem: 8730
Epoch: [20]  [ 770/2001]  eta: 0:13:06  lr: 0.000164  loss: 3.3119 (3.0569)  time: 0.6252  data: 0.0002  max mem: 8730
Epoch: [20]  [ 780/2001]  eta: 0:13:00  lr: 0.000164  loss: 3.2691 (3.0557)  time: 0.6255  data: 0.0002  max mem: 8730
Epoch: [20]  [ 790/2001]  eta: 0:12:53  lr: 0.000164  loss: 3.1575 (3.0573)  time: 0.6276  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9358, ratio_loss=0.0440, cls_kl=0.0616, token_kl=0.0918
Epoch: [20]  [ 800/2001]  eta: 0:12:46  lr: 0.000164  loss: 3.0695 (3.0554)  time: 0.6274  data: 0.0002  max mem: 8730
Epoch: [20]  [ 810/2001]  eta: 0:12:40  lr: 0.000164  loss: 2.9268 (3.0554)  time: 0.6271  data: 0.0002  max mem: 8730
Epoch: [20]  [ 820/2001]  eta: 0:12:33  lr: 0.000164  loss: 3.1265 (3.0573)  time: 0.6283  data: 0.0002  max mem: 8730
Epoch: [20]  [ 830/2001]  eta: 0:12:27  lr: 0.000164  loss: 3.3579 (3.0618)  time: 0.6326  data: 0.0002  max mem: 8730
Epoch: [20]  [ 840/2001]  eta: 0:12:20  lr: 0.000164  loss: 3.3463 (3.0621)  time: 0.6306  data: 0.0002  max mem: 8730
Epoch: [20]  [ 850/2001]  eta: 0:12:14  lr: 0.000164  loss: 3.2198 (3.0615)  time: 0.6273  data: 0.0002  max mem: 8730
Epoch: [20]  [ 860/2001]  eta: 0:12:07  lr: 0.000164  loss: 3.1098 (3.0604)  time: 0.6299  data: 0.0001  max mem: 8730
Epoch: [20]  [ 870/2001]  eta: 0:12:01  lr: 0.000164  loss: 3.3349 (3.0635)  time: 0.6308  data: 0.0002  max mem: 8730
Epoch: [20]  [ 880/2001]  eta: 0:11:54  lr: 0.000164  loss: 3.1989 (3.0609)  time: 0.6298  data: 0.0002  max mem: 8730
Epoch: [20]  [ 890/2001]  eta: 0:11:48  lr: 0.000164  loss: 3.1978 (3.0647)  time: 0.6283  data: 0.0002  max mem: 8730
loss info: cls_loss=3.0326, ratio_loss=0.0478, cls_kl=0.0637, token_kl=0.0941
Epoch: [20]  [ 900/2001]  eta: 0:11:41  lr: 0.000164  loss: 3.3105 (3.0662)  time: 0.6313  data: 0.0002  max mem: 8730
Epoch: [20]  [ 910/2001]  eta: 0:11:35  lr: 0.000164  loss: 3.2725 (3.0675)  time: 0.6333  data: 0.0001  max mem: 8730
Epoch: [20]  [ 920/2001]  eta: 0:11:29  lr: 0.000164  loss: 3.1423 (3.0658)  time: 0.6361  data: 0.0001  max mem: 8730
Epoch: [20]  [ 930/2001]  eta: 0:11:22  lr: 0.000164  loss: 3.1423 (3.0680)  time: 0.6392  data: 0.0001  max mem: 8730
Epoch: [20]  [ 940/2001]  eta: 0:11:16  lr: 0.000164  loss: 3.1194 (3.0685)  time: 0.6376  data: 0.0001  max mem: 8730
Epoch: [20]  [ 950/2001]  eta: 0:11:09  lr: 0.000164  loss: 3.0614 (3.0684)  time: 0.6324  data: 0.0001  max mem: 8730
Epoch: [20]  [ 960/2001]  eta: 0:11:03  lr: 0.000164  loss: 3.2531 (3.0704)  time: 0.6290  data: 0.0001  max mem: 8730
Epoch: [20]  [ 970/2001]  eta: 0:10:57  lr: 0.000164  loss: 3.1524 (3.0670)  time: 0.6294  data: 0.0001  max mem: 8730
Epoch: [20]  [ 980/2001]  eta: 0:10:50  lr: 0.000164  loss: 2.7070 (3.0648)  time: 0.6346  data: 0.0001  max mem: 8730
Epoch: [20]  [ 990/2001]  eta: 0:10:44  lr: 0.000164  loss: 3.0496 (3.0651)  time: 0.6364  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9582, ratio_loss=0.0417, cls_kl=0.0620, token_kl=0.0893
Epoch: [20]  [1000/2001]  eta: 0:10:37  lr: 0.000164  loss: 3.1665 (3.0656)  time: 0.6326  data: 0.0001  max mem: 8730
Epoch: [20]  [1010/2001]  eta: 0:10:31  lr: 0.000164  loss: 3.1632 (3.0662)  time: 0.6307  data: 0.0001  max mem: 8730
Epoch: [20]  [1020/2001]  eta: 0:10:24  lr: 0.000164  loss: 3.1748 (3.0669)  time: 0.6302  data: 0.0001  max mem: 8730
Epoch: [20]  [1030/2001]  eta: 0:10:18  lr: 0.000164  loss: 3.0772 (3.0657)  time: 0.6310  data: 0.0001  max mem: 8730
Epoch: [20]  [1040/2001]  eta: 0:10:12  lr: 0.000164  loss: 3.0772 (3.0665)  time: 0.6351  data: 0.0001  max mem: 8730
Epoch: [20]  [1050/2001]  eta: 0:10:05  lr: 0.000164  loss: 3.2982 (3.0690)  time: 0.6367  data: 0.0001  max mem: 8730
Epoch: [20]  [1060/2001]  eta: 0:09:59  lr: 0.000164  loss: 3.2951 (3.0679)  time: 0.6344  data: 0.0001  max mem: 8730
Epoch: [20]  [1070/2001]  eta: 0:09:53  lr: 0.000164  loss: 3.0008 (3.0671)  time: 0.6359  data: 0.0001  max mem: 8730
Epoch: [20]  [1080/2001]  eta: 0:09:46  lr: 0.000164  loss: 3.1990 (3.0689)  time: 0.6392  data: 0.0001  max mem: 8730
Epoch: [20]  [1090/2001]  eta: 0:09:40  lr: 0.000164  loss: 3.1993 (3.0687)  time: 0.6461  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9983, ratio_loss=0.0441, cls_kl=0.0633, token_kl=0.0918
Epoch: [20]  [1100/2001]  eta: 0:09:34  lr: 0.000164  loss: 3.1993 (3.0690)  time: 0.6413  data: 0.0001  max mem: 8730
Epoch: [20]  [1110/2001]  eta: 0:09:27  lr: 0.000164  loss: 3.1731 (3.0670)  time: 0.6338  data: 0.0001  max mem: 8730
Epoch: [20]  [1120/2001]  eta: 0:09:21  lr: 0.000164  loss: 3.1723 (3.0682)  time: 0.6382  data: 0.0001  max mem: 8730
Epoch: [20]  [1130/2001]  eta: 0:09:14  lr: 0.000164  loss: 3.2894 (3.0702)  time: 0.6354  data: 0.0001  max mem: 8730
Epoch: [20]  [1140/2001]  eta: 0:09:08  lr: 0.000164  loss: 3.2733 (3.0703)  time: 0.6333  data: 0.0001  max mem: 8730
Epoch: [20]  [1150/2001]  eta: 0:09:02  lr: 0.000164  loss: 3.1171 (3.0689)  time: 0.6343  data: 0.0001  max mem: 8730
Epoch: [20]  [1160/2001]  eta: 0:08:55  lr: 0.000164  loss: 3.1121 (3.0694)  time: 0.6390  data: 0.0002  max mem: 8730
Epoch: [20]  [1170/2001]  eta: 0:08:49  lr: 0.000164  loss: 3.1138 (3.0693)  time: 0.6415  data: 0.0002  max mem: 8730
| distributed init (rank 1): env://
| distributed init (rank 4): env://
| distributed init (rank 7): env://
| distributed init (rank 2): env://
| distributed init (rank 6): env://
| distributed init (rank 3): env://
| distributed init (rank 0): env://
| distributed init (rank 5): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp-3keep/checkpoint.pth', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0001638 for PREDICTOR
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Epoch: [20]  [   0/2001]  eta: 3:38:06  lr: 0.000164  loss: 3.2999 (3.2999)  time: 6.5398  data: 2.4527  max mem: 8647
Epoch: [20]  [  10/2001]  eta: 0:38:05  lr: 0.000164  loss: 3.4867 (3.4070)  time: 1.1477  data: 0.2231  max mem: 8728
Epoch: [20]  [  20/2001]  eta: 0:29:01  lr: 0.000164  loss: 3.3793 (3.3331)  time: 0.5960  data: 0.0001  max mem: 8728
Epoch: [20]  [  30/2001]  eta: 0:25:56  lr: 0.000164  loss: 3.3793 (3.3348)  time: 0.5928  data: 0.0001  max mem: 8728
Epoch: [20]  [  40/2001]  eta: 0:24:12  lr: 0.000164  loss: 3.2917 (3.2718)  time: 0.5955  data: 0.0001  max mem: 8728
Epoch: [20]  [  50/2001]  eta: 0:23:06  lr: 0.000164  loss: 3.2139 (3.2525)  time: 0.5886  data: 0.0001  max mem: 8728
Epoch: [20]  [  60/2001]  eta: 0:22:21  lr: 0.000164  loss: 3.2114 (3.2175)  time: 0.5891  data: 0.0001  max mem: 8728
Epoch: [20]  [  70/2001]  eta: 0:21:48  lr: 0.000164  loss: 3.1576 (3.1886)  time: 0.5929  data: 0.0001  max mem: 8728
Epoch: [20]  [  80/2001]  eta: 0:21:25  lr: 0.000164  loss: 3.1805 (3.1835)  time: 0.6020  data: 0.0001  max mem: 8728
Epoch: [20]  [  90/2001]  eta: 0:21:05  lr: 0.000164  loss: 3.2582 (3.1744)  time: 0.6079  data: 0.0001  max mem: 8728
loss info: cls_loss=3.0676, ratio_loss=0.0468, cls_kl=0.0670, token_kl=0.0954
Epoch: [20]  [ 100/2001]  eta: 0:20:49  lr: 0.000164  loss: 3.2786 (3.1794)  time: 0.6084  data: 0.0001  max mem: 8728
Epoch: [20]  [ 110/2001]  eta: 0:20:35  lr: 0.000164  loss: 3.2180 (3.1721)  time: 0.6115  data: 0.0001  max mem: 8728
Epoch: [20]  [ 120/2001]  eta: 0:20:22  lr: 0.000164  loss: 3.2180 (3.1685)  time: 0.6132  data: 0.0001  max mem: 8728
Epoch: [20]  [ 130/2001]  eta: 0:20:10  lr: 0.000164  loss: 3.1531 (3.1535)  time: 0.6138  data: 0.0001  max mem: 8728
Epoch: [20]  [ 140/2001]  eta: 0:20:00  lr: 0.000164  loss: 3.0861 (3.1446)  time: 0.6152  data: 0.0001  max mem: 8728
Epoch: [20]  [ 150/2001]  eta: 0:19:50  lr: 0.000164  loss: 3.0387 (3.1303)  time: 0.6154  data: 0.0001  max mem: 8728
Epoch: [20]  [ 160/2001]  eta: 0:19:40  lr: 0.000164  loss: 3.1054 (3.1369)  time: 0.6165  data: 0.0001  max mem: 8728
Epoch: [20]  [ 170/2001]  eta: 0:19:31  lr: 0.000164  loss: 3.1775 (3.1335)  time: 0.6171  data: 0.0001  max mem: 8728
Epoch: [20]  [ 180/2001]  eta: 0:19:23  lr: 0.000164  loss: 3.0916 (3.1257)  time: 0.6188  data: 0.0002  max mem: 8728
Epoch: [20]  [ 190/2001]  eta: 0:19:16  lr: 0.000164  loss: 2.9728 (3.1154)  time: 0.6270  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9171, ratio_loss=0.0433, cls_kl=0.0618, token_kl=0.0918
Epoch: [20]  [ 200/2001]  eta: 0:19:09  lr: 0.000164  loss: 2.8479 (3.1001)  time: 0.6307  data: 0.0001  max mem: 8728
Epoch: [20]  [ 210/2001]  eta: 0:19:01  lr: 0.000164  loss: 3.0833 (3.0974)  time: 0.6266  data: 0.0001  max mem: 8728
Epoch: [20]  [ 220/2001]  eta: 0:18:54  lr: 0.000164  loss: 3.0833 (3.0915)  time: 0.6248  data: 0.0001  max mem: 8728
Epoch: [20]  [ 230/2001]  eta: 0:18:46  lr: 0.000164  loss: 3.0202 (3.0890)  time: 0.6232  data: 0.0001  max mem: 8728
Epoch: [20]  [ 240/2001]  eta: 0:18:39  lr: 0.000164  loss: 3.1603 (3.0837)  time: 0.6230  data: 0.0001  max mem: 8728
Epoch: [20]  [ 250/2001]  eta: 0:18:32  lr: 0.000164  loss: 3.0368 (3.0705)  time: 0.6244  data: 0.0001  max mem: 8728
Epoch: [20]  [ 260/2001]  eta: 0:18:25  lr: 0.000164  loss: 2.8183 (3.0586)  time: 0.6277  data: 0.0002  max mem: 8728
Epoch: [20]  [ 270/2001]  eta: 0:18:18  lr: 0.000164  loss: 2.8508 (3.0525)  time: 0.6278  data: 0.0002  max mem: 8728
Epoch: [20]  [ 280/2001]  eta: 0:18:11  lr: 0.000164  loss: 3.0918 (3.0565)  time: 0.6261  data: 0.0001  max mem: 8728
Epoch: [20]  [ 290/2001]  eta: 0:18:05  lr: 0.000164  loss: 3.0918 (3.0504)  time: 0.6329  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8201, ratio_loss=0.0419, cls_kl=0.0605, token_kl=0.0910
Epoch: [20]  [ 300/2001]  eta: 0:17:59  lr: 0.000164  loss: 2.7912 (3.0411)  time: 0.6359  data: 0.0001  max mem: 8728
Epoch: [20]  [ 310/2001]  eta: 0:17:52  lr: 0.000164  loss: 2.9339 (3.0410)  time: 0.6316  data: 0.0001  max mem: 8728
Epoch: [20]  [ 320/2001]  eta: 0:17:46  lr: 0.000164  loss: 3.3010 (3.0510)  time: 0.6294  data: 0.0001  max mem: 8728
Epoch: [20]  [ 330/2001]  eta: 0:17:39  lr: 0.000164  loss: 3.3181 (3.0479)  time: 0.6292  data: 0.0001  max mem: 8728
Epoch: [20]  [ 340/2001]  eta: 0:17:33  lr: 0.000164  loss: 3.1935 (3.0525)  time: 0.6303  data: 0.0001  max mem: 8728
Epoch: [20]  [ 350/2001]  eta: 0:17:26  lr: 0.000164  loss: 3.2352 (3.0546)  time: 0.6293  data: 0.0001  max mem: 8728
Epoch: [20]  [ 360/2001]  eta: 0:17:19  lr: 0.000164  loss: 3.2066 (3.0534)  time: 0.6277  data: 0.0001  max mem: 8728
Epoch: [20]  [ 370/2001]  eta: 0:17:13  lr: 0.000164  loss: 3.0634 (3.0510)  time: 0.6278  data: 0.0001  max mem: 8728
Epoch: [20]  [ 380/2001]  eta: 0:17:06  lr: 0.000164  loss: 3.0634 (3.0493)  time: 0.6293  data: 0.0001  max mem: 8728
Epoch: [20]  [ 390/2001]  eta: 0:17:00  lr: 0.000164  loss: 3.0501 (3.0448)  time: 0.6301  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9649, ratio_loss=0.0452, cls_kl=0.0645, token_kl=0.0943
Epoch: [20]  [ 400/2001]  eta: 0:16:53  lr: 0.000164  loss: 3.1901 (3.0509)  time: 0.6291  data: 0.0001  max mem: 8728
Epoch: [20]  [ 410/2001]  eta: 0:16:47  lr: 0.000164  loss: 3.2518 (3.0552)  time: 0.6298  data: 0.0001  max mem: 8728
Epoch: [20]  [ 420/2001]  eta: 0:16:41  lr: 0.000164  loss: 3.1338 (3.0522)  time: 0.6322  data: 0.0001  max mem: 8728
Epoch: [20]  [ 430/2001]  eta: 0:16:34  lr: 0.000164  loss: 3.2571 (3.0584)  time: 0.6332  data: 0.0001  max mem: 8728
Epoch: [20]  [ 440/2001]  eta: 0:16:28  lr: 0.000164  loss: 3.2880 (3.0585)  time: 0.6300  data: 0.0001  max mem: 8728
Epoch: [20]  [ 450/2001]  eta: 0:16:21  lr: 0.000164  loss: 3.0911 (3.0572)  time: 0.6265  data: 0.0001  max mem: 8728
Epoch: [20]  [ 460/2001]  eta: 0:16:15  lr: 0.000164  loss: 2.9503 (3.0525)  time: 0.6303  data: 0.0001  max mem: 8728
Epoch: [20]  [ 470/2001]  eta: 0:16:08  lr: 0.000164  loss: 2.7819 (3.0468)  time: 0.6314  data: 0.0001  max mem: 8728
Epoch: [20]  [ 480/2001]  eta: 0:16:02  lr: 0.000164  loss: 2.8139 (3.0456)  time: 0.6277  data: 0.0001  max mem: 8728
Epoch: [20]  [ 490/2001]  eta: 0:15:56  lr: 0.000164  loss: 3.1083 (3.0507)  time: 0.6313  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9308, ratio_loss=0.0454, cls_kl=0.0655, token_kl=0.0951
Epoch: [20]  [ 500/2001]  eta: 0:15:49  lr: 0.000164  loss: 3.0612 (3.0483)  time: 0.6357  data: 0.0001  max mem: 8728
Epoch: [20]  [ 510/2001]  eta: 0:15:43  lr: 0.000164  loss: 3.0584 (3.0506)  time: 0.6318  data: 0.0001  max mem: 8728
Epoch: [20]  [ 520/2001]  eta: 0:15:37  lr: 0.000164  loss: 3.1645 (3.0512)  time: 0.6301  data: 0.0001  max mem: 8728
Epoch: [20]  [ 530/2001]  eta: 0:15:30  lr: 0.000164  loss: 3.1285 (3.0469)  time: 0.6323  data: 0.0001  max mem: 8728
Epoch: [20]  [ 540/2001]  eta: 0:15:24  lr: 0.000164  loss: 3.1285 (3.0454)  time: 0.6300  data: 0.0001  max mem: 8728
Epoch: [20]  [ 550/2001]  eta: 0:15:17  lr: 0.000164  loss: 3.1508 (3.0445)  time: 0.6280  data: 0.0001  max mem: 8728
Epoch: [20]  [ 560/2001]  eta: 0:15:11  lr: 0.000164  loss: 3.3500 (3.0496)  time: 0.6264  data: 0.0001  max mem: 8728
Epoch: [20]  [ 570/2001]  eta: 0:15:04  lr: 0.000164  loss: 3.3592 (3.0528)  time: 0.6278  data: 0.0001  max mem: 8728
Epoch: [20]  [ 580/2001]  eta: 0:14:58  lr: 0.000164  loss: 3.1084 (3.0546)  time: 0.6267  data: 0.0001  max mem: 8728
Epoch: [20]  [ 590/2001]  eta: 0:14:51  lr: 0.000164  loss: 3.2340 (3.0569)  time: 0.6264  data: 0.0001  max mem: 8728
loss info: cls_loss=3.0018, ratio_loss=0.0460, cls_kl=0.0643, token_kl=0.0931
Epoch: [20]  [ 600/2001]  eta: 0:14:45  lr: 0.000164  loss: 3.2154 (3.0568)  time: 0.6312  data: 0.0001  max mem: 8728
Epoch: [20]  [ 610/2001]  eta: 0:14:39  lr: 0.000164  loss: 3.1321 (3.0564)  time: 0.6303  data: 0.0001  max mem: 8728
Epoch: [20]  [ 620/2001]  eta: 0:14:32  lr: 0.000164  loss: 3.2284 (3.0590)  time: 0.6311  data: 0.0001  max mem: 8728
Epoch: [20]  [ 630/2001]  eta: 0:14:26  lr: 0.000164  loss: 3.3206 (3.0604)  time: 0.6313  data: 0.0001  max mem: 8728
Epoch: [20]  [ 640/2001]  eta: 0:14:20  lr: 0.000164  loss: 3.1096 (3.0589)  time: 0.6299  data: 0.0001  max mem: 8728
Epoch: [20]  [ 650/2001]  eta: 0:14:13  lr: 0.000164  loss: 2.9780 (3.0571)  time: 0.6307  data: 0.0001  max mem: 8728
Epoch: [20]  [ 660/2001]  eta: 0:14:07  lr: 0.000164  loss: 2.8599 (3.0513)  time: 0.6310  data: 0.0001  max mem: 8728
Epoch: [20]  [ 670/2001]  eta: 0:14:01  lr: 0.000164  loss: 3.0594 (3.0535)  time: 0.6326  data: 0.0001  max mem: 8728
Epoch: [20]  [ 680/2001]  eta: 0:13:54  lr: 0.000164  loss: 3.2857 (3.0544)  time: 0.6304  data: 0.0001  max mem: 8728
Epoch: [20]  [ 690/2001]  eta: 0:13:48  lr: 0.000164  loss: 2.9417 (3.0521)  time: 0.6309  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8873, ratio_loss=0.0463, cls_kl=0.0630, token_kl=0.0943
Epoch: [20]  [ 700/2001]  eta: 0:13:42  lr: 0.000164  loss: 2.8244 (3.0510)  time: 0.6335  data: 0.0001  max mem: 8728
Epoch: [20]  [ 710/2001]  eta: 0:13:35  lr: 0.000164  loss: 3.0363 (3.0488)  time: 0.6345  data: 0.0001  max mem: 8728
Epoch: [20]  [ 720/2001]  eta: 0:13:29  lr: 0.000164  loss: 3.0363 (3.0463)  time: 0.6328  data: 0.0001  max mem: 8728
Epoch: [20]  [ 730/2001]  eta: 0:13:23  lr: 0.000164  loss: 3.0843 (3.0477)  time: 0.6324  data: 0.0001  max mem: 8728
Epoch: [20]  [ 740/2001]  eta: 0:13:17  lr: 0.000164  loss: 3.3307 (3.0509)  time: 0.6339  data: 0.0001  max mem: 8728
Epoch: [20]  [ 750/2001]  eta: 0:13:10  lr: 0.000164  loss: 3.3307 (3.0492)  time: 0.6334  data: 0.0001  max mem: 8728
Epoch: [20]  [ 760/2001]  eta: 0:13:04  lr: 0.000164  loss: 3.3946 (3.0495)  time: 0.6324  data: 0.0001  max mem: 8728
Epoch: [20]  [ 770/2001]  eta: 0:12:58  lr: 0.000164  loss: 3.2531 (3.0505)  time: 0.6312  data: 0.0001  max mem: 8728
Epoch: [20]  [ 780/2001]  eta: 0:12:51  lr: 0.000164  loss: 3.1685 (3.0511)  time: 0.6316  data: 0.0001  max mem: 8728
Epoch: [20]  [ 790/2001]  eta: 0:12:45  lr: 0.000164  loss: 3.0090 (3.0498)  time: 0.6322  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9431, ratio_loss=0.0437, cls_kl=0.0642, token_kl=0.0926
Epoch: [20]  [ 800/2001]  eta: 0:12:39  lr: 0.000164  loss: 2.9726 (3.0505)  time: 0.6317  data: 0.0001  max mem: 8728
Epoch: [20]  [ 810/2001]  eta: 0:12:32  lr: 0.000164  loss: 2.7870 (3.0446)  time: 0.6320  data: 0.0001  max mem: 8728
Epoch: [20]  [ 820/2001]  eta: 0:12:26  lr: 0.000164  loss: 2.7870 (3.0461)  time: 0.6295  data: 0.0001  max mem: 8728
Epoch: [20]  [ 830/2001]  eta: 0:12:20  lr: 0.000164  loss: 3.1925 (3.0427)  time: 0.6281  data: 0.0001  max mem: 8728
Epoch: [20]  [ 840/2001]  eta: 0:12:13  lr: 0.000164  loss: 2.7690 (3.0416)  time: 0.6323  data: 0.0001  max mem: 8728
Epoch: [20]  [ 850/2001]  eta: 0:12:07  lr: 0.000164  loss: 3.1174 (3.0414)  time: 0.6332  data: 0.0001  max mem: 8728
Epoch: [20]  [ 860/2001]  eta: 0:12:01  lr: 0.000164  loss: 2.9817 (3.0406)  time: 0.6332  data: 0.0001  max mem: 8728
Epoch: [20]  [ 870/2001]  eta: 0:11:54  lr: 0.000164  loss: 2.9817 (3.0412)  time: 0.6333  data: 0.0001  max mem: 8728
Epoch: [20]  [ 880/2001]  eta: 0:11:48  lr: 0.000164  loss: 3.0417 (3.0387)  time: 0.6312  data: 0.0001  max mem: 8728
Epoch: [20]  [ 890/2001]  eta: 0:11:42  lr: 0.000164  loss: 2.9655 (3.0380)  time: 0.6370  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8306, ratio_loss=0.0443, cls_kl=0.0622, token_kl=0.0953
Epoch: [20]  [ 900/2001]  eta: 0:11:36  lr: 0.000164  loss: 3.1243 (3.0383)  time: 0.6383  data: 0.0001  max mem: 8728
Epoch: [20]  [ 910/2001]  eta: 0:11:29  lr: 0.000164  loss: 3.2179 (3.0387)  time: 0.6355  data: 0.0001  max mem: 8728
Epoch: [20]  [ 920/2001]  eta: 0:11:23  lr: 0.000164  loss: 3.3608 (3.0403)  time: 0.6357  data: 0.0001  max mem: 8728
Epoch: [20]  [ 930/2001]  eta: 0:11:17  lr: 0.000164  loss: 3.2072 (3.0429)  time: 0.6347  data: 0.0001  max mem: 8728
Epoch: [20]  [ 940/2001]  eta: 0:11:10  lr: 0.000164  loss: 3.1710 (3.0422)  time: 0.6366  data: 0.0001  max mem: 8728
Epoch: [20]  [ 950/2001]  eta: 0:11:04  lr: 0.000164  loss: 2.6523 (3.0368)  time: 0.6372  data: 0.0001  max mem: 8728
Epoch: [20]  [ 960/2001]  eta: 0:10:58  lr: 0.000164  loss: 3.0064 (3.0366)  time: 0.6350  data: 0.0001  max mem: 8728
Epoch: [20]  [ 970/2001]  eta: 0:10:52  lr: 0.000164  loss: 3.1674 (3.0373)  time: 0.6333  data: 0.0001  max mem: 8728
Epoch: [20]  [ 980/2001]  eta: 0:10:45  lr: 0.000164  loss: 3.2136 (3.0377)  time: 0.6333  data: 0.0001  max mem: 8728
Epoch: [20]  [ 990/2001]  eta: 0:10:39  lr: 0.000164  loss: 3.2969 (3.0374)  time: 0.6339  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9357, ratio_loss=0.0444, cls_kl=0.0635, token_kl=0.0924
Epoch: [20]  [1000/2001]  eta: 0:10:33  lr: 0.000164  loss: 3.2022 (3.0381)  time: 0.6344  data: 0.0001  max mem: 8728
Epoch: [20]  [1010/2001]  eta: 0:10:26  lr: 0.000164  loss: 3.2174 (3.0400)  time: 0.6332  data: 0.0001  max mem: 8728
Epoch: [20]  [1020/2001]  eta: 0:10:20  lr: 0.000164  loss: 3.2261 (3.0400)  time: 0.6319  data: 0.0001  max mem: 8728
Epoch: [20]  [1030/2001]  eta: 0:10:14  lr: 0.000164  loss: 3.0251 (3.0379)  time: 0.6317  data: 0.0001  max mem: 8728
Epoch: [20]  [1040/2001]  eta: 0:10:07  lr: 0.000164  loss: 3.2549 (3.0396)  time: 0.6354  data: 0.0001  max mem: 8728
Epoch: [20]  [1050/2001]  eta: 0:10:01  lr: 0.000164  loss: 3.2549 (3.0393)  time: 0.6363  data: 0.0001  max mem: 8728
Epoch: [20]  [1060/2001]  eta: 0:09:55  lr: 0.000164  loss: 3.1904 (3.0408)  time: 0.6383  data: 0.0001  max mem: 8728
Epoch: [20]  [1070/2001]  eta: 0:09:48  lr: 0.000164  loss: 3.1392 (3.0397)  time: 0.6382  data: 0.0001  max mem: 8728
Epoch: [20]  [1080/2001]  eta: 0:09:42  lr: 0.000164  loss: 2.9882 (3.0395)  time: 0.6343  data: 0.0001  max mem: 8728
Epoch: [20]  [1090/2001]  eta: 0:09:36  lr: 0.000164  loss: 3.2678 (3.0395)  time: 0.6367  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9320, ratio_loss=0.0450, cls_kl=0.0638, token_kl=0.0937
Epoch: [20]  [1100/2001]  eta: 0:09:30  lr: 0.000164  loss: 3.1999 (3.0389)  time: 0.6365  data: 0.0001  max mem: 8728
Epoch: [20]  [1110/2001]  eta: 0:09:23  lr: 0.000164  loss: 3.1382 (3.0400)  time: 0.6352  data: 0.0001  max mem: 8728
Epoch: [20]  [1120/2001]  eta: 0:09:17  lr: 0.000164  loss: 3.2028 (3.0411)  time: 0.6339  data: 0.0001  max mem: 8728
Epoch: [20]  [1130/2001]  eta: 0:09:11  lr: 0.000164  loss: 3.1911 (3.0423)  time: 0.6323  data: 0.0001  max mem: 8728
Epoch: [20]  [1140/2001]  eta: 0:09:04  lr: 0.000164  loss: 3.1130 (3.0407)  time: 0.6318  data: 0.0001  max mem: 8728
Epoch: [20]  [1150/2001]  eta: 0:08:58  lr: 0.000164  loss: 3.0418 (3.0410)  time: 0.6328  data: 0.0001  max mem: 8728
Epoch: [20]  [1160/2001]  eta: 0:08:52  lr: 0.000164  loss: 3.1587 (3.0403)  time: 0.6341  data: 0.0001  max mem: 8728
Epoch: [20]  [1170/2001]  eta: 0:08:45  lr: 0.000164  loss: 3.1637 (3.0409)  time: 0.6331  data: 0.0001  max mem: 8728
Epoch: [20]  [1180/2001]  eta: 0:08:39  lr: 0.000164  loss: 3.4584 (3.0441)  time: 0.6352  data: 0.0001  max mem: 8728
Epoch: [20]  [1190/2001]  eta: 0:08:33  lr: 0.000164  loss: 3.4584 (3.0462)  time: 0.6376  data: 0.0001  max mem: 8728
loss info: cls_loss=3.0243, ratio_loss=0.0444, cls_kl=0.0657, token_kl=0.0931
Epoch: [20]  [1200/2001]  eta: 0:08:26  lr: 0.000164  loss: 3.1977 (3.0465)  time: 0.6364  data: 0.0001  max mem: 8728
Epoch: [20]  [1210/2001]  eta: 0:08:20  lr: 0.000164  loss: 3.0892 (3.0458)  time: 0.6357  data: 0.0001  max mem: 8728
Epoch: [20]  [1220/2001]  eta: 0:08:14  lr: 0.000164  loss: 2.9623 (3.0446)  time: 0.6355  data: 0.0001  max mem: 8728
Epoch: [20]  [1230/2001]  eta: 0:08:07  lr: 0.000164  loss: 3.0561 (3.0453)  time: 0.6346  data: 0.0001  max mem: 8728
Epoch: [20]  [1240/2001]  eta: 0:08:01  lr: 0.000164  loss: 3.0811 (3.0452)  time: 0.6369  data: 0.0001  max mem: 8728
Epoch: [20]  [1250/2001]  eta: 0:07:55  lr: 0.000164  loss: 2.8998 (3.0436)  time: 0.6385  data: 0.0001  max mem: 8728
Epoch: [20]  [1260/2001]  eta: 0:07:49  lr: 0.000164  loss: 3.1612 (3.0453)  time: 0.6381  data: 0.0001  max mem: 8728
Epoch: [20]  [1270/2001]  eta: 0:07:42  lr: 0.000164  loss: 3.1988 (3.0461)  time: 0.6391  data: 0.0001  max mem: 8728
Epoch: [20]  [1280/2001]  eta: 0:07:36  lr: 0.000164  loss: 3.3386 (3.0492)  time: 0.6384  data: 0.0001  max mem: 8728
Epoch: [20]  [1290/2001]  eta: 0:07:30  lr: 0.000164  loss: 3.3669 (3.0507)  time: 0.6373  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9964, ratio_loss=0.0456, cls_kl=0.0665, token_kl=0.0932
Epoch: [20]  [1300/2001]  eta: 0:07:23  lr: 0.000164  loss: 3.1451 (3.0515)  time: 0.6362  data: 0.0001  max mem: 8728
Epoch: [20]  [1310/2001]  eta: 0:07:17  lr: 0.000164  loss: 3.0880 (3.0497)  time: 0.6411  data: 0.0001  max mem: 8728
Epoch: [20]  [1320/2001]  eta: 0:07:11  lr: 0.000164  loss: 2.9376 (3.0482)  time: 0.6415  data: 0.0001  max mem: 8728
Epoch: [20]  [1330/2001]  eta: 0:07:04  lr: 0.000164  loss: 3.1090 (3.0496)  time: 0.6349  data: 0.0001  max mem: 8728
Epoch: [20]  [1340/2001]  eta: 0:06:58  lr: 0.000164  loss: 3.2778 (3.0496)  time: 0.6353  data: 0.0001  max mem: 8728
Epoch: [20]  [1350/2001]  eta: 0:06:52  lr: 0.000164  loss: 3.2057 (3.0500)  time: 0.6359  data: 0.0001  max mem: 8728
Epoch: [20]  [1360/2001]  eta: 0:06:45  lr: 0.000164  loss: 3.1267 (3.0516)  time: 0.6355  data: 0.0001  max mem: 8728
Epoch: [20]  [1370/2001]  eta: 0:06:39  lr: 0.000164  loss: 3.2787 (3.0529)  time: 0.6377  data: 0.0001  max mem: 8728
Epoch: [20]  [1380/2001]  eta: 0:06:33  lr: 0.000164  loss: 3.2621 (3.0545)  time: 0.6396  data: 0.0001  max mem: 8728
Epoch: [20]  [1390/2001]  eta: 0:06:27  lr: 0.000164  loss: 3.1845 (3.0541)  time: 0.6379  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9774, ratio_loss=0.0457, cls_kl=0.0627, token_kl=0.0910
Epoch: [20]  [1400/2001]  eta: 0:06:20  lr: 0.000164  loss: 3.1172 (3.0536)  time: 0.6395  data: 0.0001  max mem: 8728
Epoch: [20]  [1410/2001]  eta: 0:06:14  lr: 0.000164  loss: 3.2334 (3.0564)  time: 0.6408  data: 0.0001  max mem: 8728
Epoch: [20]  [1420/2001]  eta: 0:06:08  lr: 0.000164  loss: 3.2334 (3.0559)  time: 0.6407  data: 0.0001  max mem: 8728
Epoch: [20]  [1430/2001]  eta: 0:06:01  lr: 0.000164  loss: 3.0900 (3.0558)  time: 0.6415  data: 0.0001  max mem: 8728
Epoch: [20]  [1440/2001]  eta: 0:05:55  lr: 0.000164  loss: 3.1624 (3.0560)  time: 0.6396  data: 0.0001  max mem: 8728
Epoch: [20]  [1450/2001]  eta: 0:05:49  lr: 0.000164  loss: 3.2531 (3.0564)  time: 0.6368  data: 0.0001  max mem: 8728
Epoch: [20]  [1460/2001]  eta: 0:05:42  lr: 0.000164  loss: 3.2554 (3.0576)  time: 0.6371  data: 0.0001  max mem: 8728
Epoch: [20]  [1470/2001]  eta: 0:05:36  lr: 0.000164  loss: 3.2175 (3.0572)  time: 0.6407  data: 0.0001  max mem: 8728
Epoch: [20]  [1480/2001]  eta: 0:05:30  lr: 0.000164  loss: 3.1363 (3.0557)  time: 0.6387  data: 0.0001  max mem: 8728
Epoch: [20]  [1490/2001]  eta: 0:05:23  lr: 0.000164  loss: 2.7774 (3.0527)  time: 0.6325  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9271, ratio_loss=0.0451, cls_kl=0.0634, token_kl=0.0942
Epoch: [20]  [1500/2001]  eta: 0:05:17  lr: 0.000164  loss: 2.7774 (3.0521)  time: 0.6327  data: 0.0001  max mem: 8728
Epoch: [20]  [1510/2001]  eta: 0:05:11  lr: 0.000164  loss: 3.2296 (3.0530)  time: 0.6353  data: 0.0001  max mem: 8728
Epoch: [20]  [1520/2001]  eta: 0:05:04  lr: 0.000164  loss: 3.2588 (3.0539)  time: 0.6344  data: 0.0001  max mem: 8728
Epoch: [20]  [1530/2001]  eta: 0:04:58  lr: 0.000164  loss: 3.0970 (3.0525)  time: 0.6322  data: 0.0001  max mem: 8728
Epoch: [20]  [1540/2001]  eta: 0:04:52  lr: 0.000164  loss: 3.0556 (3.0526)  time: 0.6312  data: 0.0001  max mem: 8728
Epoch: [20]  [1550/2001]  eta: 0:04:45  lr: 0.000164  loss: 3.0556 (3.0510)  time: 0.6305  data: 0.0001  max mem: 8728
Epoch: [20]  [1560/2001]  eta: 0:04:39  lr: 0.000164  loss: 2.9311 (3.0505)  time: 0.6317  data: 0.0001  max mem: 8728
Epoch: [20]  [1570/2001]  eta: 0:04:33  lr: 0.000164  loss: 3.0706 (3.0494)  time: 0.6344  data: 0.0001  max mem: 8728
Epoch: [20]  [1580/2001]  eta: 0:04:26  lr: 0.000164  loss: 3.0706 (3.0495)  time: 0.6324  data: 0.0001  max mem: 8728
Epoch: [20]  [1590/2001]  eta: 0:04:20  lr: 0.000164  loss: 3.1864 (3.0505)  time: 0.6308  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9362, ratio_loss=0.0437, cls_kl=0.0640, token_kl=0.0921
Epoch: [20]  [1600/2001]  eta: 0:04:14  lr: 0.000164  loss: 3.2374 (3.0520)  time: 0.6328  data: 0.0001  max mem: 8728
Epoch: [20]  [1610/2001]  eta: 0:04:07  lr: 0.000164  loss: 3.2478 (3.0530)  time: 0.6339  data: 0.0001  max mem: 8728
Epoch: [20]  [1620/2001]  eta: 0:04:01  lr: 0.000164  loss: 3.0683 (3.0531)  time: 0.6339  data: 0.0001  max mem: 8728
Epoch: [20]  [1630/2001]  eta: 0:03:55  lr: 0.000164  loss: 3.0595 (3.0537)  time: 0.6338  data: 0.0001  max mem: 8728
Epoch: [20]  [1640/2001]  eta: 0:03:48  lr: 0.000164  loss: 3.1626 (3.0538)  time: 0.6330  data: 0.0001  max mem: 8728
Epoch: [20]  [1650/2001]  eta: 0:03:42  lr: 0.000164  loss: 3.0696 (3.0508)  time: 0.6325  data: 0.0001  max mem: 8728
Epoch: [20]  [1660/2001]  eta: 0:03:36  lr: 0.000164  loss: 2.5633 (3.0478)  time: 0.6304  data: 0.0001  max mem: 8728
Epoch: [20]  [1670/2001]  eta: 0:03:29  lr: 0.000164  loss: 2.6616 (3.0476)  time: 0.6285  data: 0.0001  max mem: 8728
Epoch: [20]  [1680/2001]  eta: 0:03:23  lr: 0.000164  loss: 3.2720 (3.0472)  time: 0.6282  data: 0.0001  max mem: 8728
Epoch: [20]  [1690/2001]  eta: 0:03:17  lr: 0.000164  loss: 3.1781 (3.0468)  time: 0.6264  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8910, ratio_loss=0.0433, cls_kl=0.0619, token_kl=0.0939
Epoch: [20]  [1700/2001]  eta: 0:03:10  lr: 0.000164  loss: 3.3452 (3.0488)  time: 0.6261  data: 0.0001  max mem: 8728
Epoch: [20]  [1710/2001]  eta: 0:03:04  lr: 0.000164  loss: 3.3985 (3.0494)  time: 0.6267  data: 0.0001  max mem: 8728
Epoch: [20]  [1720/2001]  eta: 0:02:57  lr: 0.000164  loss: 3.1663 (3.0487)  time: 0.6265  data: 0.0001  max mem: 8728
Epoch: [20]  [1730/2001]  eta: 0:02:51  lr: 0.000164  loss: 3.2341 (3.0501)  time: 0.6280  data: 0.0001  max mem: 8728
Epoch: [20]  [1740/2001]  eta: 0:02:45  lr: 0.000164  loss: 3.1876 (3.0495)  time: 0.6305  data: 0.0001  max mem: 8728
Epoch: [20]  [1750/2001]  eta: 0:02:38  lr: 0.000164  loss: 2.9091 (3.0490)  time: 0.6280  data: 0.0001  max mem: 8728
Epoch: [20]  [1760/2001]  eta: 0:02:32  lr: 0.000164  loss: 2.9230 (3.0493)  time: 0.6271  data: 0.0001  max mem: 8728
Epoch: [20]  [1770/2001]  eta: 0:02:26  lr: 0.000164  loss: 3.3092 (3.0500)  time: 0.6308  data: 0.0001  max mem: 8728
Epoch: [20]  [1780/2001]  eta: 0:02:19  lr: 0.000164  loss: 3.2661 (3.0502)  time: 0.6291  data: 0.0001  max mem: 8728
Epoch: [20]  [1790/2001]  eta: 0:02:13  lr: 0.000164  loss: 3.0484 (3.0491)  time: 0.6259  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9746, ratio_loss=0.0447, cls_kl=0.0626, token_kl=0.0917
Epoch: [20]  [1800/2001]  eta: 0:02:07  lr: 0.000164  loss: 3.2009 (3.0502)  time: 0.6255  data: 0.0001  max mem: 8728
Epoch: [20]  [1810/2001]  eta: 0:02:00  lr: 0.000164  loss: 3.2223 (3.0497)  time: 0.6237  data: 0.0001  max mem: 8728
Epoch: [20]  [1820/2001]  eta: 0:01:54  lr: 0.000164  loss: 3.0813 (3.0504)  time: 0.6239  data: 0.0001  max mem: 8728
Epoch: [20]  [1830/2001]  eta: 0:01:48  lr: 0.000164  loss: 3.2516 (3.0515)  time: 0.6247  data: 0.0001  max mem: 8728
Epoch: [20]  [1840/2001]  eta: 0:01:41  lr: 0.000164  loss: 3.2516 (3.0509)  time: 0.6233  data: 0.0001  max mem: 8728
Epoch: [20]  [1850/2001]  eta: 0:01:35  lr: 0.000164  loss: 2.8345 (3.0495)  time: 0.6238  data: 0.0001  max mem: 8728
Epoch: [20]  [1860/2001]  eta: 0:01:29  lr: 0.000164  loss: 2.9310 (3.0493)  time: 0.6223  data: 0.0001  max mem: 8728
Epoch: [20]  [1870/2001]  eta: 0:01:22  lr: 0.000164  loss: 2.9547 (3.0478)  time: 0.6237  data: 0.0001  max mem: 8728
Epoch: [20]  [1880/2001]  eta: 0:01:16  lr: 0.000164  loss: 3.1829 (3.0488)  time: 0.6258  data: 0.0001  max mem: 8728
Epoch: [20]  [1890/2001]  eta: 0:01:10  lr: 0.000164  loss: 3.1829 (3.0478)  time: 0.6265  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8737, ratio_loss=0.0448, cls_kl=0.0619, token_kl=0.0925
Epoch: [20]  [1900/2001]  eta: 0:01:03  lr: 0.000164  loss: 2.9921 (3.0471)  time: 0.6301  data: 0.0001  max mem: 8728
Epoch: [20]  [1910/2001]  eta: 0:00:57  lr: 0.000164  loss: 3.0558 (3.0472)  time: 0.6257  data: 0.0001  max mem: 8728
Epoch: [20]  [1920/2001]  eta: 0:00:51  lr: 0.000164  loss: 2.8882 (3.0449)  time: 0.6249  data: 0.0001  max mem: 8728
Epoch: [20]  [1930/2001]  eta: 0:00:44  lr: 0.000164  loss: 2.7341 (3.0441)  time: 0.6277  data: 0.0001  max mem: 8728
Epoch: [20]  [1940/2001]  eta: 0:00:38  lr: 0.000164  loss: 2.9033 (3.0430)  time: 0.6252  data: 0.0001  max mem: 8728
Epoch: [20]  [1950/2001]  eta: 0:00:32  lr: 0.000164  loss: 2.9007 (3.0418)  time: 0.6250  data: 0.0001  max mem: 8728
Epoch: [20]  [1960/2001]  eta: 0:00:25  lr: 0.000164  loss: 3.0051 (3.0409)  time: 0.6244  data: 0.0001  max mem: 8728
Epoch: [20]  [1970/2001]  eta: 0:00:19  lr: 0.000164  loss: 2.9995 (3.0392)  time: 0.6239  data: 0.0001  max mem: 8728
Epoch: [20]  [1980/2001]  eta: 0:00:13  lr: 0.000164  loss: 2.9445 (3.0390)  time: 0.6247  data: 0.0001  max mem: 8728
Epoch: [20]  [1990/2001]  eta: 0:00:06  lr: 0.000164  loss: 3.0976 (3.0382)  time: 0.6210  data: 0.0002  max mem: 8728
loss info: cls_loss=2.7543, ratio_loss=0.0397, cls_kl=0.0607, token_kl=0.0911
Epoch: [20]  [2000/2001]  eta: 0:00:00  lr: 0.000164  loss: 3.0437 (3.0374)  time: 0.6164  data: 0.0002  max mem: 8728
Epoch: [20] Total time: 0:21:05 (0.6326 s / it)
Averaged stats: lr: 0.000164  loss: 3.0437 (3.0468)
Test:  [ 0/53]  eta: 0:05:36  loss: 0.3419 (0.3419)  acc1: 94.1667 (94.1667)  acc5: 99.1667 (99.1667)  time: 6.3507  data: 5.4638  max mem: 8728
Test:  [10/53]  eta: 0:00:38  loss: 0.7706 (0.7720)  acc1: 83.3333 (83.5606)  acc5: 96.6667 (96.6667)  time: 0.8935  data: 0.4969  max mem: 8728
Test:  [20/53]  eta: 0:00:20  loss: 0.7586 (0.7714)  acc1: 83.3333 (83.2540)  acc5: 96.6667 (96.6270)  time: 0.3470  data: 0.0003  max mem: 8728
Test:  [30/53]  eta: 0:00:12  loss: 0.8792 (0.8573)  acc1: 79.1667 (81.0215)  acc5: 94.1667 (95.3763)  time: 0.3436  data: 0.0003  max mem: 8728
Test:  [40/53]  eta: 0:00:06  loss: 1.0998 (0.9223)  acc1: 77.5000 (79.5935)  acc5: 91.6667 (94.4919)  time: 0.3029  data: 0.0002  max mem: 8728
Test:  [50/53]  eta: 0:00:01  loss: 1.0998 (0.9512)  acc1: 76.6667 (78.8235)  acc5: 91.6667 (94.2484)  time: 0.2585  data: 0.0001  max mem: 8728
Test:  [52/53]  eta: 0:00:00  loss: 1.0725 (0.9374)  acc1: 77.5000 (79.0080)  acc5: 91.6667 (94.3360)  time: 0.2464  data: 0.0000  max mem: 8728
Test: Total time: 0:00:22 (0.4213 s / it)
Sparsity0:0.30198545454545456,Sparsity1:0.5616562814070352,Sparsity2:0.7847808,
* Acc@1 79.110 Acc@5 94.456 loss 0.939
Accuracy of the network on the 50000 test images: 79.1%
Max accuracy: 79.11%
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0001368 for PREDICTOR
Epoch: [21]  [   0/2001]  eta: 2:34:52  lr: 0.000137  loss: 3.2652 (3.2652)  time: 4.6437  data: 3.9741  max mem: 8728
Epoch: [21]  [  10/2001]  eta: 0:32:16  lr: 0.000137  loss: 3.3460 (3.3100)  time: 0.9724  data: 0.3614  max mem: 8730
Epoch: [21]  [  20/2001]  eta: 0:26:23  lr: 0.000137  loss: 3.2467 (3.1535)  time: 0.6072  data: 0.0001  max mem: 8730
Epoch: [21]  [  30/2001]  eta: 0:24:16  lr: 0.000137  loss: 3.1980 (3.1826)  time: 0.6105  data: 0.0001  max mem: 8730
Epoch: [21]  [  40/2001]  eta: 0:23:11  lr: 0.000137  loss: 3.1980 (3.1658)  time: 0.6149  data: 0.0001  max mem: 8730
Epoch: [21]  [  50/2001]  eta: 0:22:29  lr: 0.000137  loss: 3.0631 (3.1237)  time: 0.6179  data: 0.0001  max mem: 8730
Epoch: [21]  [  60/2001]  eta: 0:22:01  lr: 0.000137  loss: 2.8932 (3.0747)  time: 0.6218  data: 0.0001  max mem: 8730
Epoch: [21]  [  70/2001]  eta: 0:21:39  lr: 0.000137  loss: 3.1664 (3.0891)  time: 0.6266  data: 0.0001  max mem: 8730
Epoch: [21]  [  80/2001]  eta: 0:21:21  lr: 0.000137  loss: 3.1853 (3.0668)  time: 0.6261  data: 0.0001  max mem: 8730
Epoch: [21]  [  90/2001]  eta: 0:21:06  lr: 0.000137  loss: 3.1726 (3.0886)  time: 0.6250  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9716, ratio_loss=0.0456, cls_kl=0.0640, token_kl=0.0946
Epoch: [21]  [ 100/2001]  eta: 0:20:53  lr: 0.000137  loss: 3.1726 (3.0768)  time: 0.6265  data: 0.0001  max mem: 8730
Epoch: [21]  [ 110/2001]  eta: 0:20:40  lr: 0.000137  loss: 3.1047 (3.0787)  time: 0.6267  data: 0.0001  max mem: 8730
Epoch: [21]  [ 120/2001]  eta: 0:20:29  lr: 0.000137  loss: 3.1895 (3.0868)  time: 0.6266  data: 0.0001  max mem: 8730
Epoch: [21]  [ 130/2001]  eta: 0:20:19  lr: 0.000137  loss: 3.3243 (3.1030)  time: 0.6276  data: 0.0001  max mem: 8730
Epoch: [21]  [ 140/2001]  eta: 0:20:09  lr: 0.000137  loss: 3.3457 (3.1087)  time: 0.6280  data: 0.0001  max mem: 8730
Epoch: [21]  [ 150/2001]  eta: 0:20:00  lr: 0.000137  loss: 3.2391 (3.0982)  time: 0.6276  data: 0.0001  max mem: 8730
Epoch: [21]  [ 160/2001]  eta: 0:19:51  lr: 0.000137  loss: 3.1317 (3.0996)  time: 0.6280  data: 0.0001  max mem: 8730
Epoch: [21]  [ 170/2001]  eta: 0:19:43  lr: 0.000137  loss: 3.2077 (3.1033)  time: 0.6289  data: 0.0001  max mem: 8730
Epoch: [21]  [ 180/2001]  eta: 0:19:35  lr: 0.000137  loss: 3.1937 (3.0969)  time: 0.6306  data: 0.0001  max mem: 8730
Epoch: [21]  [ 190/2001]  eta: 0:19:27  lr: 0.000137  loss: 3.2495 (3.0995)  time: 0.6313  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9825, ratio_loss=0.0462, cls_kl=0.0655, token_kl=0.0927
Epoch: [21]  [ 200/2001]  eta: 0:19:19  lr: 0.000137  loss: 3.1055 (3.0873)  time: 0.6305  data: 0.0001  max mem: 8730
Epoch: [21]  [ 210/2001]  eta: 0:19:12  lr: 0.000137  loss: 2.9342 (3.0840)  time: 0.6321  data: 0.0001  max mem: 8730
Epoch: [21]  [ 220/2001]  eta: 0:19:05  lr: 0.000137  loss: 3.0214 (3.0798)  time: 0.6356  data: 0.0001  max mem: 8730
Epoch: [21]  [ 230/2001]  eta: 0:18:57  lr: 0.000137  loss: 2.9807 (3.0679)  time: 0.6326  data: 0.0001  max mem: 8730
Epoch: [21]  [ 240/2001]  eta: 0:18:50  lr: 0.000137  loss: 2.9460 (3.0640)  time: 0.6300  data: 0.0001  max mem: 8730
Epoch: [21]  [ 250/2001]  eta: 0:18:43  lr: 0.000137  loss: 2.8255 (3.0569)  time: 0.6310  data: 0.0001  max mem: 8730
Epoch: [21]  [ 260/2001]  eta: 0:18:36  lr: 0.000137  loss: 2.8722 (3.0543)  time: 0.6285  data: 0.0001  max mem: 8730
Epoch: [21]  [ 270/2001]  eta: 0:18:29  lr: 0.000137  loss: 3.0992 (3.0619)  time: 0.6286  data: 0.0001  max mem: 8730
Epoch: [21]  [ 280/2001]  eta: 0:18:21  lr: 0.000137  loss: 3.3162 (3.0701)  time: 0.6291  data: 0.0001  max mem: 8730
Epoch: [21]  [ 290/2001]  eta: 0:18:14  lr: 0.000137  loss: 3.2868 (3.0639)  time: 0.6297  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8957, ratio_loss=0.0413, cls_kl=0.0621, token_kl=0.0922
Epoch: [21]  [ 300/2001]  eta: 0:18:08  lr: 0.000137  loss: 2.8257 (3.0525)  time: 0.6316  data: 0.0001  max mem: 8730
Epoch: [21]  [ 310/2001]  eta: 0:18:01  lr: 0.000137  loss: 2.8730 (3.0505)  time: 0.6323  data: 0.0001  max mem: 8730
Epoch: [21]  [ 320/2001]  eta: 0:17:54  lr: 0.000137  loss: 2.9931 (3.0547)  time: 0.6340  data: 0.0001  max mem: 8730
Epoch: [21]  [ 330/2001]  eta: 0:17:47  lr: 0.000137  loss: 3.1765 (3.0589)  time: 0.6336  data: 0.0001  max mem: 8730
Epoch: [21]  [ 340/2001]  eta: 0:17:41  lr: 0.000137  loss: 3.1084 (3.0557)  time: 0.6322  data: 0.0001  max mem: 8730
Epoch: [21]  [ 350/2001]  eta: 0:17:34  lr: 0.000137  loss: 3.0871 (3.0572)  time: 0.6368  data: 0.0001  max mem: 8730
Epoch: [21]  [ 360/2001]  eta: 0:17:28  lr: 0.000137  loss: 3.0648 (3.0537)  time: 0.6374  data: 0.0001  max mem: 8730
Epoch: [21]  [ 370/2001]  eta: 0:17:21  lr: 0.000137  loss: 2.9657 (3.0479)  time: 0.6336  data: 0.0001  max mem: 8730
Epoch: [21]  [ 380/2001]  eta: 0:17:15  lr: 0.000137  loss: 3.0563 (3.0472)  time: 0.6361  data: 0.0001  max mem: 8730
Epoch: [21]  [ 390/2001]  eta: 0:17:08  lr: 0.000137  loss: 3.0985 (3.0409)  time: 0.6397  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8751, ratio_loss=0.0442, cls_kl=0.0624, token_kl=0.0928
Epoch: [21]  [ 400/2001]  eta: 0:17:02  lr: 0.000137  loss: 2.7397 (3.0391)  time: 0.6387  data: 0.0001  max mem: 8730
Epoch: [21]  [ 410/2001]  eta: 0:16:56  lr: 0.000137  loss: 3.0753 (3.0392)  time: 0.6370  data: 0.0001  max mem: 8730
Epoch: [21]  [ 420/2001]  eta: 0:16:49  lr: 0.000137  loss: 2.9381 (3.0344)  time: 0.6348  data: 0.0001  max mem: 8730
Epoch: [21]  [ 430/2001]  eta: 0:16:42  lr: 0.000137  loss: 3.1182 (3.0399)  time: 0.6318  data: 0.0001  max mem: 8730
Epoch: [21]  [ 440/2001]  eta: 0:16:36  lr: 0.000137  loss: 3.2696 (3.0427)  time: 0.6309  data: 0.0001  max mem: 8730
Epoch: [21]  [ 450/2001]  eta: 0:16:29  lr: 0.000137  loss: 3.2696 (3.0476)  time: 0.6313  data: 0.0001  max mem: 8730
Epoch: [21]  [ 460/2001]  eta: 0:16:22  lr: 0.000137  loss: 3.2175 (3.0451)  time: 0.6312  data: 0.0001  max mem: 8730
Epoch: [21]  [ 470/2001]  eta: 0:16:16  lr: 0.000137  loss: 3.0851 (3.0439)  time: 0.6307  data: 0.0001  max mem: 8730
Epoch: [21]  [ 480/2001]  eta: 0:16:10  lr: 0.000137  loss: 2.9847 (3.0415)  time: 0.6363  data: 0.0001  max mem: 8730
Epoch: [21]  [ 490/2001]  eta: 0:16:03  lr: 0.000137  loss: 3.0792 (3.0463)  time: 0.6386  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9551, ratio_loss=0.0434, cls_kl=0.0641, token_kl=0.0937
Epoch: [21]  [ 500/2001]  eta: 0:15:57  lr: 0.000137  loss: 3.0792 (3.0424)  time: 0.6348  data: 0.0001  max mem: 8730
Epoch: [21]  [ 510/2001]  eta: 0:15:50  lr: 0.000137  loss: 2.9252 (3.0412)  time: 0.6377  data: 0.0001  max mem: 8730
Epoch: [21]  [ 520/2001]  eta: 0:15:44  lr: 0.000137  loss: 3.0410 (3.0445)  time: 0.6366  data: 0.0001  max mem: 8730
Epoch: [21]  [ 530/2001]  eta: 0:15:37  lr: 0.000137  loss: 3.1814 (3.0454)  time: 0.6330  data: 0.0001  max mem: 8730
Epoch: [21]  [ 540/2001]  eta: 0:15:31  lr: 0.000137  loss: 3.0968 (3.0444)  time: 0.6349  data: 0.0001  max mem: 8730
Epoch: [21]  [ 550/2001]  eta: 0:15:25  lr: 0.000137  loss: 2.9539 (3.0465)  time: 0.6383  data: 0.0001  max mem: 8730
Epoch: [21]  [ 560/2001]  eta: 0:15:18  lr: 0.000137  loss: 3.3799 (3.0521)  time: 0.6431  data: 0.0001  max mem: 8730
Epoch: [21]  [ 570/2001]  eta: 0:15:12  lr: 0.000137  loss: 3.2872 (3.0535)  time: 0.6377  data: 0.0001  max mem: 8730
Epoch: [21]  [ 580/2001]  eta: 0:15:05  lr: 0.000137  loss: 3.0939 (3.0563)  time: 0.6307  data: 0.0001  max mem: 8730
Epoch: [21]  [ 590/2001]  eta: 0:14:59  lr: 0.000137  loss: 3.0820 (3.0553)  time: 0.6337  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0195, ratio_loss=0.0458, cls_kl=0.0650, token_kl=0.0930
Epoch: [21]  [ 600/2001]  eta: 0:14:52  lr: 0.000137  loss: 3.1817 (3.0575)  time: 0.6343  data: 0.0001  max mem: 8730
Epoch: [21]  [ 610/2001]  eta: 0:14:46  lr: 0.000137  loss: 3.0848 (3.0531)  time: 0.6332  data: 0.0001  max mem: 8730
Epoch: [21]  [ 620/2001]  eta: 0:14:40  lr: 0.000137  loss: 2.8658 (3.0545)  time: 0.6327  data: 0.0001  max mem: 8730
Epoch: [21]  [ 630/2001]  eta: 0:14:33  lr: 0.000137  loss: 3.1759 (3.0551)  time: 0.6362  data: 0.0001  max mem: 8730
Epoch: [21]  [ 640/2001]  eta: 0:14:27  lr: 0.000137  loss: 3.2059 (3.0594)  time: 0.6374  data: 0.0001  max mem: 8730
Epoch: [21]  [ 650/2001]  eta: 0:14:21  lr: 0.000137  loss: 3.3242 (3.0566)  time: 0.6403  data: 0.0001  max mem: 8730
Epoch: [21]  [ 660/2001]  eta: 0:14:14  lr: 0.000137  loss: 3.3747 (3.0601)  time: 0.6403  data: 0.0001  max mem: 8730
Epoch: [21]  [ 670/2001]  eta: 0:14:08  lr: 0.000137  loss: 3.2604 (3.0605)  time: 0.6386  data: 0.0001  max mem: 8730
Epoch: [21]  [ 680/2001]  eta: 0:14:02  lr: 0.000137  loss: 3.2034 (3.0630)  time: 0.6399  data: 0.0001  max mem: 8730
Epoch: [21]  [ 690/2001]  eta: 0:13:55  lr: 0.000137  loss: 3.3378 (3.0648)  time: 0.6355  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0154, ratio_loss=0.0451, cls_kl=0.0635, token_kl=0.0921
Epoch: [21]  [ 700/2001]  eta: 0:13:49  lr: 0.000137  loss: 3.2606 (3.0673)  time: 0.6357  data: 0.0001  max mem: 8730
Epoch: [21]  [ 710/2001]  eta: 0:13:42  lr: 0.000137  loss: 3.2606 (3.0718)  time: 0.6369  data: 0.0001  max mem: 8730
Epoch: [21]  [ 720/2001]  eta: 0:13:36  lr: 0.000137  loss: 3.2425 (3.0707)  time: 0.6357  data: 0.0001  max mem: 8730
Epoch: [21]  [ 730/2001]  eta: 0:13:30  lr: 0.000137  loss: 3.2380 (3.0734)  time: 0.6364  data: 0.0001  max mem: 8730
Epoch: [21]  [ 740/2001]  eta: 0:13:23  lr: 0.000137  loss: 3.0004 (3.0683)  time: 0.6372  data: 0.0001  max mem: 8730
Epoch: [21]  [ 750/2001]  eta: 0:13:17  lr: 0.000137  loss: 3.1510 (3.0691)  time: 0.6359  data: 0.0001  max mem: 8730
Epoch: [21]  [ 760/2001]  eta: 0:13:10  lr: 0.000137  loss: 3.1510 (3.0653)  time: 0.6357  data: 0.0001  max mem: 8730
Epoch: [21]  [ 770/2001]  eta: 0:13:04  lr: 0.000137  loss: 3.1697 (3.0683)  time: 0.6358  data: 0.0001  max mem: 8730
Epoch: [21]  [ 780/2001]  eta: 0:12:58  lr: 0.000137  loss: 3.2593 (3.0664)  time: 0.6434  data: 0.0001  max mem: 8730
Epoch: [21]  [ 790/2001]  eta: 0:12:51  lr: 0.000137  loss: 2.9002 (3.0631)  time: 0.6428  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9248, ratio_loss=0.0439, cls_kl=0.0623, token_kl=0.0918
Epoch: [21]  [ 800/2001]  eta: 0:12:45  lr: 0.000137  loss: 2.8395 (3.0614)  time: 0.6345  data: 0.0001  max mem: 8730
Epoch: [21]  [ 810/2001]  eta: 0:12:39  lr: 0.000137  loss: 3.1508 (3.0622)  time: 0.6433  data: 0.0001  max mem: 8730
Epoch: [21]  [ 820/2001]  eta: 0:12:33  lr: 0.000137  loss: 3.2519 (3.0617)  time: 0.6488  data: 0.0001  max mem: 8730
Epoch: [21]  [ 830/2001]  eta: 0:12:26  lr: 0.000137  loss: 3.0629 (3.0607)  time: 0.6457  data: 0.0001  max mem: 8730
Epoch: [21]  [ 840/2001]  eta: 0:12:20  lr: 0.000137  loss: 3.0629 (3.0613)  time: 0.6428  data: 0.0001  max mem: 8730
Epoch: [21]  [ 850/2001]  eta: 0:12:14  lr: 0.000137  loss: 3.0420 (3.0598)  time: 0.6393  data: 0.0001  max mem: 8730
Epoch: [21]  [ 860/2001]  eta: 0:12:07  lr: 0.000137  loss: 2.7706 (3.0550)  time: 0.6354  data: 0.0001  max mem: 8730
Epoch: [21]  [ 870/2001]  eta: 0:12:01  lr: 0.000137  loss: 2.7399 (3.0533)  time: 0.6328  data: 0.0001  max mem: 8730
Epoch: [21]  [ 880/2001]  eta: 0:11:54  lr: 0.000137  loss: 3.2615 (3.0548)  time: 0.6327  data: 0.0001  max mem: 8730
Epoch: [21]  [ 890/2001]  eta: 0:11:48  lr: 0.000137  loss: 3.0799 (3.0525)  time: 0.6331  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8818, ratio_loss=0.0413, cls_kl=0.0603, token_kl=0.0921
Epoch: [21]  [ 900/2001]  eta: 0:11:41  lr: 0.000137  loss: 3.0630 (3.0538)  time: 0.6351  data: 0.0001  max mem: 8730
Epoch: [21]  [ 910/2001]  eta: 0:11:35  lr: 0.000137  loss: 3.1506 (3.0521)  time: 0.6362  data: 0.0001  max mem: 8730
Epoch: [21]  [ 920/2001]  eta: 0:11:29  lr: 0.000137  loss: 3.0252 (3.0526)  time: 0.6354  data: 0.0001  max mem: 8730
Epoch: [21]  [ 930/2001]  eta: 0:11:22  lr: 0.000137  loss: 3.2628 (3.0553)  time: 0.6326  data: 0.0001  max mem: 8730
Epoch: [21]  [ 940/2001]  eta: 0:11:16  lr: 0.000137  loss: 3.3245 (3.0578)  time: 0.6413  data: 0.0001  max mem: 8730
Epoch: [21]  [ 950/2001]  eta: 0:11:10  lr: 0.000137  loss: 3.0239 (3.0538)  time: 0.6427  data: 0.0001  max mem: 8730
Epoch: [21]  [ 960/2001]  eta: 0:11:03  lr: 0.000137  loss: 2.9012 (3.0535)  time: 0.6319  data: 0.0001  max mem: 8730
Epoch: [21]  [ 970/2001]  eta: 0:10:57  lr: 0.000137  loss: 3.1824 (3.0547)  time: 0.6299  data: 0.0001  max mem: 8730
Epoch: [21]  [ 980/2001]  eta: 0:10:50  lr: 0.000137  loss: 3.1766 (3.0535)  time: 0.6357  data: 0.0001  max mem: 8730
Epoch: [21]  [ 990/2001]  eta: 0:10:44  lr: 0.000137  loss: 3.1766 (3.0546)  time: 0.6383  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9675, ratio_loss=0.0454, cls_kl=0.0636, token_kl=0.0935
Epoch: [21]  [1000/2001]  eta: 0:10:37  lr: 0.000137  loss: 3.3679 (3.0562)  time: 0.6310  data: 0.0001  max mem: 8730
Epoch: [21]  [1010/2001]  eta: 0:10:31  lr: 0.000137  loss: 3.1562 (3.0562)  time: 0.6277  data: 0.0001  max mem: 8730
Epoch: [21]  [1020/2001]  eta: 0:10:24  lr: 0.000137  loss: 3.0670 (3.0562)  time: 0.6281  data: 0.0001  max mem: 8730
Epoch: [21]  [1030/2001]  eta: 0:10:18  lr: 0.000137  loss: 3.1164 (3.0555)  time: 0.6280  data: 0.0001  max mem: 8730
Epoch: [21]  [1040/2001]  eta: 0:10:12  lr: 0.000137  loss: 3.1449 (3.0553)  time: 0.6304  data: 0.0001  max mem: 8730
Epoch: [21]  [1050/2001]  eta: 0:10:05  lr: 0.000137  loss: 3.2039 (3.0565)  time: 0.6309  data: 0.0001  max mem: 8730
Epoch: [21]  [1060/2001]  eta: 0:09:59  lr: 0.000137  loss: 3.2059 (3.0568)  time: 0.6313  data: 0.0001  max mem: 8730
Epoch: [21]  [1070/2001]  eta: 0:09:52  lr: 0.000137  loss: 3.0229 (3.0561)  time: 0.6315  data: 0.0001  max mem: 8730
Epoch: [21]  [1080/2001]  eta: 0:09:46  lr: 0.000137  loss: 2.7926 (3.0546)  time: 0.6329  data: 0.0001  max mem: 8730
Epoch: [21]  [1090/2001]  eta: 0:09:40  lr: 0.000137  loss: 2.7926 (3.0538)  time: 0.6321  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9452, ratio_loss=0.0415, cls_kl=0.0617, token_kl=0.0912
Epoch: [21]  [1100/2001]  eta: 0:09:33  lr: 0.000137  loss: 3.1902 (3.0548)  time: 0.6272  data: 0.0001  max mem: 8730
Epoch: [21]  [1110/2001]  eta: 0:09:27  lr: 0.000137  loss: 3.1751 (3.0551)  time: 0.6259  data: 0.0001  max mem: 8730
Epoch: [21]  [1120/2001]  eta: 0:09:20  lr: 0.000137  loss: 3.0883 (3.0550)  time: 0.6279  data: 0.0001  max mem: 8730
Epoch: [21]  [1130/2001]  eta: 0:09:14  lr: 0.000137  loss: 3.0485 (3.0552)  time: 0.6302  data: 0.0001  max mem: 8730
Epoch: [21]  [1140/2001]  eta: 0:09:07  lr: 0.000137  loss: 2.8294 (3.0524)  time: 0.6263  data: 0.0001  max mem: 8730
Epoch: [21]  [1150/2001]  eta: 0:09:01  lr: 0.000137  loss: 3.0105 (3.0524)  time: 0.6241  data: 0.0001  max mem: 8730
Epoch: [21]  [1160/2001]  eta: 0:08:54  lr: 0.000137  loss: 3.0105 (3.0516)  time: 0.6234  data: 0.0001  max mem: 8730
Epoch: [21]  [1170/2001]  eta: 0:08:48  lr: 0.000137  loss: 2.9449 (3.0518)  time: 0.6227  data: 0.0001  max mem: 8730
Epoch: [21]  [1180/2001]  eta: 0:08:42  lr: 0.000137  loss: 3.1275 (3.0530)  time: 0.6269  data: 0.0001  max mem: 8730
Epoch: [21]  [1190/2001]  eta: 0:08:35  lr: 0.000137  loss: 3.0490 (3.0504)  time: 0.6278  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9047, ratio_loss=0.0427, cls_kl=0.0623, token_kl=0.0924
Epoch: [21]  [1200/2001]  eta: 0:08:29  lr: 0.000137  loss: 3.1037 (3.0514)  time: 0.6242  data: 0.0001  max mem: 8730
Epoch: [21]  [1210/2001]  eta: 0:08:22  lr: 0.000137  loss: 3.3400 (3.0525)  time: 0.6265  data: 0.0001  max mem: 8730
Epoch: [21]  [1220/2001]  eta: 0:08:16  lr: 0.000137  loss: 3.1478 (3.0520)  time: 0.6297  data: 0.0001  max mem: 8730
Epoch: [21]  [1230/2001]  eta: 0:08:10  lr: 0.000137  loss: 3.1243 (3.0539)  time: 0.6304  data: 0.0001  max mem: 8730
Epoch: [21]  [1240/2001]  eta: 0:08:03  lr: 0.000137  loss: 3.4636 (3.0581)  time: 0.6265  data: 0.0001  max mem: 8730
Epoch: [21]  [1250/2001]  eta: 0:07:57  lr: 0.000137  loss: 3.4111 (3.0577)  time: 0.6280  data: 0.0001  max mem: 8730
Epoch: [21]  [1260/2001]  eta: 0:07:50  lr: 0.000137  loss: 2.9776 (3.0566)  time: 0.6320  data: 0.0001  max mem: 8730
Epoch: [21]  [1270/2001]  eta: 0:07:44  lr: 0.000137  loss: 2.9009 (3.0565)  time: 0.6248  data: 0.0001  max mem: 8730
Epoch: [21]  [1280/2001]  eta: 0:07:37  lr: 0.000137  loss: 2.7719 (3.0557)  time: 0.6188  data: 0.0001  max mem: 8730
Epoch: [21]  [1290/2001]  eta: 0:07:31  lr: 0.000137  loss: 3.1714 (3.0559)  time: 0.6213  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0060, ratio_loss=0.0491, cls_kl=0.0670, token_kl=0.0976
Epoch: [21]  [1300/2001]  eta: 0:07:25  lr: 0.000137  loss: 3.2780 (3.0565)  time: 0.6245  data: 0.0001  max mem: 8730
Epoch: [21]  [1310/2001]  eta: 0:07:18  lr: 0.000137  loss: 3.3400 (3.0578)  time: 0.6238  data: 0.0001  max mem: 8730
Epoch: [21]  [1320/2001]  eta: 0:07:12  lr: 0.000137  loss: 3.2917 (3.0585)  time: 0.6252  data: 0.0002  max mem: 8730
Epoch: [21]  [1330/2001]  eta: 0:07:05  lr: 0.000137  loss: 3.1809 (3.0562)  time: 0.6264  data: 0.0001  max mem: 8730
Epoch: [21]  [1340/2001]  eta: 0:06:59  lr: 0.000137  loss: 2.8013 (3.0540)  time: 0.6243  data: 0.0001  max mem: 8730
Epoch: [21]  [1350/2001]  eta: 0:06:53  lr: 0.000137  loss: 3.0557 (3.0537)  time: 0.6218  data: 0.0001  max mem: 8730
Epoch: [21]  [1360/2001]  eta: 0:06:46  lr: 0.000137  loss: 3.1479 (3.0536)  time: 0.6295  data: 0.0001  max mem: 8730
Epoch: [21]  [1370/2001]  eta: 0:06:40  lr: 0.000137  loss: 3.1691 (3.0531)  time: 0.6298  data: 0.0001  max mem: 8730
Epoch: [21]  [1380/2001]  eta: 0:06:33  lr: 0.000137  loss: 3.2414 (3.0533)  time: 0.6217  data: 0.0001  max mem: 8730
Epoch: [21]  [1390/2001]  eta: 0:06:27  lr: 0.000137  loss: 3.2634 (3.0550)  time: 0.6221  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9048, ratio_loss=0.0439, cls_kl=0.0624, token_kl=0.0942
Epoch: [21]  [1400/2001]  eta: 0:06:21  lr: 0.000137  loss: 3.1455 (3.0536)  time: 0.6209  data: 0.0001  max mem: 8730
Epoch: [21]  [1410/2001]  eta: 0:06:14  lr: 0.000137  loss: 3.1455 (3.0536)  time: 0.6258  data: 0.0001  max mem: 8730
Epoch: [21]  [1420/2001]  eta: 0:06:08  lr: 0.000137  loss: 3.2263 (3.0536)  time: 0.6307  data: 0.0001  max mem: 8730
Epoch: [21]  [1430/2001]  eta: 0:06:02  lr: 0.000137  loss: 3.1385 (3.0539)  time: 0.6268  data: 0.0001  max mem: 8730
Epoch: [21]  [1440/2001]  eta: 0:05:55  lr: 0.000137  loss: 2.8905 (3.0526)  time: 0.6343  data: 0.0001  max mem: 8730
Epoch: [21]  [1450/2001]  eta: 0:05:49  lr: 0.000137  loss: 2.9813 (3.0529)  time: 0.6422  data: 0.0001  max mem: 8730
Epoch: [21]  [1460/2001]  eta: 0:05:43  lr: 0.000137  loss: 3.1733 (3.0528)  time: 0.6334  data: 0.0001  max mem: 8730
Epoch: [21]  [1470/2001]  eta: 0:05:36  lr: 0.000137  loss: 2.8508 (3.0510)  time: 0.6270  data: 0.0001  max mem: 8730
Epoch: [21]  [1480/2001]  eta: 0:05:30  lr: 0.000137  loss: 3.0324 (3.0506)  time: 0.6275  data: 0.0001  max mem: 8730
Epoch: [21]  [1490/2001]  eta: 0:05:24  lr: 0.000137  loss: 3.0324 (3.0498)  time: 0.6298  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8700, ratio_loss=0.0420, cls_kl=0.0603, token_kl=0.0914
Epoch: [21]  [1500/2001]  eta: 0:05:17  lr: 0.000137  loss: 2.9459 (3.0490)  time: 0.6315  data: 0.0001  max mem: 8730
Epoch: [21]  [1510/2001]  eta: 0:05:11  lr: 0.000137  loss: 3.1328 (3.0491)  time: 0.6276  data: 0.0001  max mem: 8730
Epoch: [21]  [1520/2001]  eta: 0:05:04  lr: 0.000137  loss: 3.0271 (3.0482)  time: 0.6244  data: 0.0001  max mem: 8730
Epoch: [21]  [1530/2001]  eta: 0:04:58  lr: 0.000137  loss: 3.0271 (3.0478)  time: 0.6247  data: 0.0001  max mem: 8730
Epoch: [21]  [1540/2001]  eta: 0:04:52  lr: 0.000137  loss: 3.1574 (3.0480)  time: 0.6254  data: 0.0001  max mem: 8730
Epoch: [21]  [1550/2001]  eta: 0:04:45  lr: 0.000137  loss: 2.9615 (3.0467)  time: 0.6270  data: 0.0001  max mem: 8730
Epoch: [21]  [1560/2001]  eta: 0:04:39  lr: 0.000137  loss: 3.2045 (3.0479)  time: 0.6279  data: 0.0001  max mem: 8730
Epoch: [21]  [1570/2001]  eta: 0:04:33  lr: 0.000137  loss: 3.3996 (3.0480)  time: 0.6268  data: 0.0001  max mem: 8730
Epoch: [21]  [1580/2001]  eta: 0:04:26  lr: 0.000137  loss: 3.1784 (3.0487)  time: 0.6259  data: 0.0001  max mem: 8730
Epoch: [21]  [1590/2001]  eta: 0:04:20  lr: 0.000137  loss: 3.1784 (3.0495)  time: 0.6236  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9553, ratio_loss=0.0465, cls_kl=0.0641, token_kl=0.0943
Epoch: [21]  [1600/2001]  eta: 0:04:14  lr: 0.000137  loss: 3.2153 (3.0491)  time: 0.6245  data: 0.0001  max mem: 8730
Epoch: [21]  [1610/2001]  eta: 0:04:07  lr: 0.000137  loss: 3.2296 (3.0494)  time: 0.6293  data: 0.0001  max mem: 8730
Epoch: [21]  [1620/2001]  eta: 0:04:01  lr: 0.000137  loss: 3.2898 (3.0515)  time: 0.6329  data: 0.0001  max mem: 8730
Epoch: [21]  [1630/2001]  eta: 0:03:55  lr: 0.000137  loss: 3.3689 (3.0531)  time: 0.6371  data: 0.0001  max mem: 8730
Epoch: [21]  [1640/2001]  eta: 0:03:48  lr: 0.000137  loss: 3.2903 (3.0526)  time: 0.6358  data: 0.0001  max mem: 8730
Epoch: [21]  [1650/2001]  eta: 0:03:42  lr: 0.000137  loss: 3.2108 (3.0538)  time: 0.6330  data: 0.0001  max mem: 8730
Epoch: [21]  [1660/2001]  eta: 0:03:36  lr: 0.000137  loss: 3.2108 (3.0536)  time: 0.6341  data: 0.0001  max mem: 8730
Epoch: [21]  [1670/2001]  eta: 0:03:29  lr: 0.000137  loss: 3.1811 (3.0538)  time: 0.6306  data: 0.0001  max mem: 8730
Epoch: [21]  [1680/2001]  eta: 0:03:23  lr: 0.000137  loss: 3.1811 (3.0540)  time: 0.6324  data: 0.0001  max mem: 8730
Epoch: [21]  [1690/2001]  eta: 0:03:17  lr: 0.000137  loss: 3.2586 (3.0547)  time: 0.6361  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0131, ratio_loss=0.0439, cls_kl=0.0623, token_kl=0.0913
Epoch: [21]  [1700/2001]  eta: 0:03:10  lr: 0.000137  loss: 3.1049 (3.0538)  time: 0.6301  data: 0.0001  max mem: 8730
Epoch: [21]  [1710/2001]  eta: 0:03:04  lr: 0.000137  loss: 3.0193 (3.0531)  time: 0.6288  data: 0.0001  max mem: 8730
Epoch: [21]  [1720/2001]  eta: 0:02:58  lr: 0.000137  loss: 3.0871 (3.0546)  time: 0.6305  data: 0.0001  max mem: 8730
Epoch: [21]  [1730/2001]  eta: 0:02:51  lr: 0.000137  loss: 3.2751 (3.0559)  time: 0.6277  data: 0.0001  max mem: 8730
Epoch: [21]  [1740/2001]  eta: 0:02:45  lr: 0.000137  loss: 3.3179 (3.0564)  time: 0.6279  data: 0.0001  max mem: 8730
Epoch: [21]  [1750/2001]  eta: 0:02:38  lr: 0.000137  loss: 3.2374 (3.0557)  time: 0.6293  data: 0.0001  max mem: 8730
Epoch: [21]  [1760/2001]  eta: 0:02:32  lr: 0.000137  loss: 3.1610 (3.0561)  time: 0.6317  data: 0.0001  max mem: 8730
Epoch: [21]  [1770/2001]  eta: 0:02:26  lr: 0.000137  loss: 3.1893 (3.0565)  time: 0.6329  data: 0.0001  max mem: 8730
Epoch: [21]  [1780/2001]  eta: 0:02:19  lr: 0.000137  loss: 2.9813 (3.0554)  time: 0.6292  data: 0.0001  max mem: 8730
Epoch: [21]  [1790/2001]  eta: 0:02:13  lr: 0.000137  loss: 3.0782 (3.0567)  time: 0.6380  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0030, ratio_loss=0.0466, cls_kl=0.0643, token_kl=0.0942
Epoch: [21]  [1800/2001]  eta: 0:02:07  lr: 0.000137  loss: 3.1480 (3.0570)  time: 0.6396  data: 0.0001  max mem: 8730
Epoch: [21]  [1810/2001]  eta: 0:02:00  lr: 0.000137  loss: 3.1403 (3.0567)  time: 0.6286  data: 0.0001  max mem: 8730
Epoch: [21]  [1820/2001]  eta: 0:01:54  lr: 0.000137  loss: 3.0521 (3.0558)  time: 0.6264  data: 0.0001  max mem: 8730
Epoch: [21]  [1830/2001]  eta: 0:01:48  lr: 0.000137  loss: 3.2870 (3.0568)  time: 0.6295  data: 0.0001  max mem: 8730
Epoch: [21]  [1840/2001]  eta: 0:01:41  lr: 0.000137  loss: 3.2870 (3.0554)  time: 0.6334  data: 0.0001  max mem: 8730
Epoch: [21]  [1850/2001]  eta: 0:01:35  lr: 0.000137  loss: 3.1673 (3.0562)  time: 0.6336  data: 0.0001  max mem: 8730
Epoch: [21]  [1860/2001]  eta: 0:01:29  lr: 0.000137  loss: 3.1022 (3.0549)  time: 0.6307  data: 0.0001  max mem: 8730
Epoch: [21]  [1870/2001]  eta: 0:01:22  lr: 0.000137  loss: 3.0135 (3.0550)  time: 0.6289  data: 0.0001  max mem: 8730
Epoch: [21]  [1880/2001]  eta: 0:01:16  lr: 0.000137  loss: 3.1396 (3.0544)  time: 0.6302  data: 0.0001  max mem: 8730
Epoch: [21]  [1890/2001]  eta: 0:01:10  lr: 0.000137  loss: 3.1386 (3.0540)  time: 0.6300  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8806, ratio_loss=0.0430, cls_kl=0.0609, token_kl=0.0920
Epoch: [21]  [1900/2001]  eta: 0:01:03  lr: 0.000137  loss: 2.9902 (3.0534)  time: 0.6308  data: 0.0001  max mem: 8730
Epoch: [21]  [1910/2001]  eta: 0:00:57  lr: 0.000137  loss: 3.0138 (3.0535)  time: 0.6346  data: 0.0001  max mem: 8730
Epoch: [21]  [1920/2001]  eta: 0:00:51  lr: 0.000137  loss: 3.1563 (3.0537)  time: 0.6372  data: 0.0001  max mem: 8730
Epoch: [21]  [1930/2001]  eta: 0:00:44  lr: 0.000137  loss: 3.0717 (3.0529)  time: 0.6413  data: 0.0001  max mem: 8730
Epoch: [21]  [1940/2001]  eta: 0:00:38  lr: 0.000137  loss: 2.8640 (3.0527)  time: 0.6421  data: 0.0001  max mem: 8730
Epoch: [21]  [1950/2001]  eta: 0:00:32  lr: 0.000137  loss: 2.9116 (3.0518)  time: 0.6382  data: 0.0001  max mem: 8730
Epoch: [21]  [1960/2001]  eta: 0:00:25  lr: 0.000137  loss: 3.0777 (3.0528)  time: 0.6363  data: 0.0001  max mem: 8730
Epoch: [21]  [1970/2001]  eta: 0:00:19  lr: 0.000137  loss: 3.2356 (3.0540)  time: 0.6354  data: 0.0001  max mem: 8730
Epoch: [21]  [1980/2001]  eta: 0:00:13  lr: 0.000137  loss: 3.2118 (3.0539)  time: 0.6329  data: 0.0001  max mem: 8730
Epoch: [21]  [1990/2001]  eta: 0:00:06  lr: 0.000137  loss: 3.0255 (3.0537)  time: 0.6284  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9331, ratio_loss=0.0465, cls_kl=0.0637, token_kl=0.0956
Epoch: [21]  [2000/2001]  eta: 0:00:00  lr: 0.000137  loss: 3.1801 (3.0533)  time: 0.6255  data: 0.0002  max mem: 8730
Epoch: [21] Total time: 0:21:07 (0.6336 s / it)
Averaged stats: lr: 0.000137  loss: 3.1801 (3.0436)
Test:  [ 0/53]  eta: 0:04:30  loss: 0.3593 (0.3593)  acc1: 92.5000 (92.5000)  acc5: 100.0000 (100.0000)  time: 5.0997  data: 4.2241  max mem: 8730
Test:  [10/53]  eta: 0:00:35  loss: 0.7071 (0.7635)  acc1: 84.1667 (83.3333)  acc5: 96.6667 (96.7424)  time: 0.8336  data: 0.4203  max mem: 8730
Test:  [20/53]  eta: 0:00:19  loss: 0.7071 (0.7711)  acc1: 82.5000 (82.8571)  acc5: 96.6667 (96.5873)  time: 0.3738  data: 0.0203  max mem: 8730
Test:  [30/53]  eta: 0:00:11  loss: 0.8960 (0.8508)  acc1: 79.1667 (81.0484)  acc5: 94.1667 (95.2419)  time: 0.3418  data: 0.0020  max mem: 8730
Test:  [40/53]  eta: 0:00:05  loss: 1.1104 (0.9194)  acc1: 75.0000 (79.2683)  acc5: 91.6667 (94.6138)  time: 0.3020  data: 0.0016  max mem: 8730
Test:  [50/53]  eta: 0:00:01  loss: 1.1179 (0.9491)  acc1: 75.0000 (78.5131)  acc5: 92.5000 (94.4935)  time: 0.2575  data: 0.0001  max mem: 8730
Test:  [52/53]  eta: 0:00:00  loss: 1.1104 (0.9336)  acc1: 75.0000 (78.6880)  acc5: 93.3333 (94.5600)  time: 0.2463  data: 0.0000  max mem: 8730
Test: Total time: 0:00:21 (0.4068 s / it)
Sparsity0:0.2918682828282828,Sparsity1:0.5531610050251257,Sparsity2:0.7820808,
* Acc@1 78.988 Acc@5 94.614 loss 0.935
Accuracy of the network on the 50000 test images: 79.0%
Max accuracy: 79.11%
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0001117 for PREDICTOR
Epoch: [22]  [   0/2001]  eta: 2:27:08  lr: 0.000112  loss: 2.0374 (2.0374)  time: 4.4122  data: 3.1649  max mem: 8730
Epoch: [22]  [  10/2001]  eta: 0:32:08  lr: 0.000112  loss: 2.7521 (2.8694)  time: 0.9685  data: 0.2879  max mem: 8730
Epoch: [22]  [  20/2001]  eta: 0:26:28  lr: 0.000112  loss: 3.0748 (3.0108)  time: 0.6215  data: 0.0002  max mem: 8730
Epoch: [22]  [  30/2001]  eta: 0:24:27  lr: 0.000112  loss: 3.0507 (2.9921)  time: 0.6211  data: 0.0001  max mem: 8730
Epoch: [22]  [  40/2001]  eta: 0:23:23  lr: 0.000112  loss: 3.0576 (3.0622)  time: 0.6250  data: 0.0001  max mem: 8730
Epoch: [22]  [  50/2001]  eta: 0:22:42  lr: 0.000112  loss: 3.2709 (3.1083)  time: 0.6271  data: 0.0001  max mem: 8730
Epoch: [22]  [  60/2001]  eta: 0:22:14  lr: 0.000112  loss: 3.1960 (3.0968)  time: 0.6293  data: 0.0001  max mem: 8730
Epoch: [22]  [  70/2001]  eta: 0:21:51  lr: 0.000112  loss: 2.6061 (3.0361)  time: 0.6310  data: 0.0001  max mem: 8730
Epoch: [22]  [  80/2001]  eta: 0:21:33  lr: 0.000112  loss: 2.5644 (3.0028)  time: 0.6316  data: 0.0001  max mem: 8730
Epoch: [22]  [  90/2001]  eta: 0:21:19  lr: 0.000112  loss: 2.8579 (3.0042)  time: 0.6353  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9042, ratio_loss=0.0441, cls_kl=0.0625, token_kl=0.0931
Epoch: [22]  [ 100/2001]  eta: 0:21:06  lr: 0.000112  loss: 2.9601 (2.9813)  time: 0.6363  data: 0.0001  max mem: 8730
Epoch: [22]  [ 110/2001]  eta: 0:20:54  lr: 0.000112  loss: 3.1526 (2.9997)  time: 0.6357  data: 0.0001  max mem: 8730
Epoch: [22]  [ 120/2001]  eta: 0:20:44  lr: 0.000112  loss: 3.1428 (2.9904)  time: 0.6369  data: 0.0002  max mem: 8730
Epoch: [22]  [ 130/2001]  eta: 0:20:33  lr: 0.000112  loss: 2.9773 (2.9996)  time: 0.6366  data: 0.0001  max mem: 8730
Epoch: [22]  [ 140/2001]  eta: 0:20:23  lr: 0.000112  loss: 3.1897 (3.0032)  time: 0.6356  data: 0.0001  max mem: 8730
Epoch: [22]  [ 150/2001]  eta: 0:20:14  lr: 0.000112  loss: 3.1138 (3.0053)  time: 0.6343  data: 0.0001  max mem: 8730
Epoch: [22]  [ 160/2001]  eta: 0:20:07  lr: 0.000112  loss: 3.0250 (2.9947)  time: 0.6432  data: 0.0001  max mem: 8730
Epoch: [22]  [ 170/2001]  eta: 0:19:58  lr: 0.000112  loss: 3.2425 (3.0154)  time: 0.6436  data: 0.0001  max mem: 8730
Epoch: [22]  [ 180/2001]  eta: 0:19:50  lr: 0.000112  loss: 3.4532 (3.0290)  time: 0.6359  data: 0.0002  max mem: 8730
Epoch: [22]  [ 190/2001]  eta: 0:19:42  lr: 0.000112  loss: 3.2149 (3.0219)  time: 0.6380  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9316, ratio_loss=0.0455, cls_kl=0.0617, token_kl=0.0939
Epoch: [22]  [ 200/2001]  eta: 0:19:34  lr: 0.000112  loss: 3.0820 (3.0239)  time: 0.6379  data: 0.0001  max mem: 8730
Epoch: [22]  [ 210/2001]  eta: 0:19:28  lr: 0.000112  loss: 3.1556 (3.0223)  time: 0.6457  data: 0.0001  max mem: 8730
Epoch: [22]  [ 220/2001]  eta: 0:19:20  lr: 0.000112  loss: 3.2435 (3.0291)  time: 0.6433  data: 0.0002  max mem: 8730
Epoch: [22]  [ 230/2001]  eta: 0:19:12  lr: 0.000112  loss: 2.9962 (3.0163)  time: 0.6339  data: 0.0002  max mem: 8730
Epoch: [22]  [ 240/2001]  eta: 0:19:04  lr: 0.000112  loss: 2.9302 (3.0191)  time: 0.6354  data: 0.0001  max mem: 8730
Epoch: [22]  [ 250/2001]  eta: 0:18:57  lr: 0.000112  loss: 3.2533 (3.0217)  time: 0.6360  data: 0.0001  max mem: 8730
Epoch: [22]  [ 260/2001]  eta: 0:18:49  lr: 0.000112  loss: 3.1615 (3.0228)  time: 0.6360  data: 0.0001  max mem: 8730
Epoch: [22]  [ 270/2001]  eta: 0:18:43  lr: 0.000112  loss: 3.0707 (3.0193)  time: 0.6411  data: 0.0001  max mem: 8730
Epoch: [22]  [ 280/2001]  eta: 0:18:35  lr: 0.000112  loss: 3.1016 (3.0201)  time: 0.6420  data: 0.0002  max mem: 8730
Epoch: [22]  [ 290/2001]  eta: 0:18:28  lr: 0.000112  loss: 3.1704 (3.0184)  time: 0.6353  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9144, ratio_loss=0.0413, cls_kl=0.0605, token_kl=0.0908
Epoch: [22]  [ 300/2001]  eta: 0:18:21  lr: 0.000112  loss: 2.9619 (3.0134)  time: 0.6352  data: 0.0002  max mem: 8730
Epoch: [22]  [ 310/2001]  eta: 0:18:14  lr: 0.000112  loss: 3.1069 (3.0204)  time: 0.6361  data: 0.0002  max mem: 8730
Epoch: [22]  [ 320/2001]  eta: 0:18:07  lr: 0.000112  loss: 3.1621 (3.0231)  time: 0.6353  data: 0.0002  max mem: 8730
Epoch: [22]  [ 330/2001]  eta: 0:18:00  lr: 0.000112  loss: 3.1573 (3.0225)  time: 0.6360  data: 0.0002  max mem: 8730
Epoch: [22]  [ 340/2001]  eta: 0:17:53  lr: 0.000112  loss: 3.1333 (3.0176)  time: 0.6362  data: 0.0002  max mem: 8730
Epoch: [22]  [ 350/2001]  eta: 0:17:46  lr: 0.000112  loss: 3.0742 (3.0155)  time: 0.6354  data: 0.0002  max mem: 8730
Epoch: [22]  [ 360/2001]  eta: 0:17:39  lr: 0.000112  loss: 3.2006 (3.0187)  time: 0.6331  data: 0.0002  max mem: 8730
Epoch: [22]  [ 370/2001]  eta: 0:17:32  lr: 0.000112  loss: 3.2359 (3.0237)  time: 0.6366  data: 0.0002  max mem: 8730
Epoch: [22]  [ 380/2001]  eta: 0:17:25  lr: 0.000112  loss: 3.2161 (3.0193)  time: 0.6373  data: 0.0002  max mem: 8730
Epoch: [22]  [ 390/2001]  eta: 0:17:18  lr: 0.000112  loss: 3.1138 (3.0232)  time: 0.6325  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9455, ratio_loss=0.0424, cls_kl=0.0606, token_kl=0.0916
Epoch: [22]  [ 400/2001]  eta: 0:17:11  lr: 0.000112  loss: 3.2865 (3.0302)  time: 0.6344  data: 0.0002  max mem: 8730
Epoch: [22]  [ 410/2001]  eta: 0:17:04  lr: 0.000112  loss: 3.2638 (3.0320)  time: 0.6329  data: 0.0002  max mem: 8730
Epoch: [22]  [ 420/2001]  eta: 0:16:57  lr: 0.000112  loss: 3.0726 (3.0305)  time: 0.6294  data: 0.0001  max mem: 8730
Epoch: [22]  [ 430/2001]  eta: 0:16:51  lr: 0.000112  loss: 2.9405 (3.0275)  time: 0.6418  data: 0.0001  max mem: 8730
Epoch: [22]  [ 440/2001]  eta: 0:16:44  lr: 0.000112  loss: 3.2060 (3.0295)  time: 0.6407  data: 0.0001  max mem: 8730
Epoch: [22]  [ 450/2001]  eta: 0:16:37  lr: 0.000112  loss: 3.2060 (3.0293)  time: 0.6291  data: 0.0001  max mem: 8730
Epoch: [22]  [ 460/2001]  eta: 0:16:30  lr: 0.000112  loss: 3.0749 (3.0280)  time: 0.6303  data: 0.0002  max mem: 8730
Epoch: [22]  [ 470/2001]  eta: 0:16:24  lr: 0.000112  loss: 3.3106 (3.0370)  time: 0.6292  data: 0.0001  max mem: 8730
Epoch: [22]  [ 480/2001]  eta: 0:16:17  lr: 0.000112  loss: 3.2120 (3.0372)  time: 0.6320  data: 0.0002  max mem: 8730
Epoch: [22]  [ 490/2001]  eta: 0:16:10  lr: 0.000112  loss: 3.0715 (3.0327)  time: 0.6334  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9495, ratio_loss=0.0450, cls_kl=0.0603, token_kl=0.0928
Epoch: [22]  [ 500/2001]  eta: 0:16:03  lr: 0.000112  loss: 3.0201 (3.0355)  time: 0.6294  data: 0.0002  max mem: 8730
Epoch: [22]  [ 510/2001]  eta: 0:15:56  lr: 0.000112  loss: 3.5200 (3.0412)  time: 0.6282  data: 0.0002  max mem: 8730
Epoch: [22]  [ 520/2001]  eta: 0:15:50  lr: 0.000112  loss: 3.2898 (3.0388)  time: 0.6281  data: 0.0001  max mem: 8730
Epoch: [22]  [ 530/2001]  eta: 0:15:43  lr: 0.000112  loss: 3.0415 (3.0407)  time: 0.6255  data: 0.0001  max mem: 8730
Epoch: [22]  [ 540/2001]  eta: 0:15:36  lr: 0.000112  loss: 3.1649 (3.0397)  time: 0.6263  data: 0.0001  max mem: 8730
Epoch: [22]  [ 550/2001]  eta: 0:15:29  lr: 0.000112  loss: 3.1337 (3.0429)  time: 0.6282  data: 0.0001  max mem: 8730
Epoch: [22]  [ 560/2001]  eta: 0:15:23  lr: 0.000112  loss: 3.1337 (3.0450)  time: 0.6285  data: 0.0002  max mem: 8730
Epoch: [22]  [ 570/2001]  eta: 0:15:16  lr: 0.000112  loss: 3.2181 (3.0444)  time: 0.6281  data: 0.0002  max mem: 8730
Epoch: [22]  [ 580/2001]  eta: 0:15:09  lr: 0.000112  loss: 3.2404 (3.0493)  time: 0.6355  data: 0.0002  max mem: 8730
Epoch: [22]  [ 590/2001]  eta: 0:15:03  lr: 0.000112  loss: 3.2525 (3.0501)  time: 0.6348  data: 0.0002  max mem: 8730
loss info: cls_loss=3.0267, ratio_loss=0.0457, cls_kl=0.0650, token_kl=0.0930
Epoch: [22]  [ 600/2001]  eta: 0:14:56  lr: 0.000112  loss: 3.1027 (3.0508)  time: 0.6222  data: 0.0002  max mem: 8730
Epoch: [22]  [ 610/2001]  eta: 0:14:49  lr: 0.000112  loss: 3.0010 (3.0477)  time: 0.6210  data: 0.0002  max mem: 8730
Epoch: [22]  [ 620/2001]  eta: 0:14:42  lr: 0.000112  loss: 3.1279 (3.0482)  time: 0.6246  data: 0.0001  max mem: 8730
Epoch: [22]  [ 630/2001]  eta: 0:14:36  lr: 0.000112  loss: 3.1823 (3.0477)  time: 0.6237  data: 0.0001  max mem: 8730
Epoch: [22]  [ 640/2001]  eta: 0:14:29  lr: 0.000112  loss: 3.1823 (3.0511)  time: 0.6322  data: 0.0002  max mem: 8730
Epoch: [22]  [ 650/2001]  eta: 0:14:22  lr: 0.000112  loss: 3.1781 (3.0508)  time: 0.6328  data: 0.0002  max mem: 8730
Epoch: [22]  [ 660/2001]  eta: 0:14:16  lr: 0.000112  loss: 3.1781 (3.0537)  time: 0.6244  data: 0.0001  max mem: 8730
Epoch: [22]  [ 670/2001]  eta: 0:14:09  lr: 0.000112  loss: 3.1574 (3.0535)  time: 0.6240  data: 0.0001  max mem: 8730
Epoch: [22]  [ 680/2001]  eta: 0:14:02  lr: 0.000112  loss: 3.2189 (3.0534)  time: 0.6229  data: 0.0004  max mem: 8730
Epoch: [22]  [ 690/2001]  eta: 0:13:56  lr: 0.000112  loss: 3.2486 (3.0572)  time: 0.6254  data: 0.0004  max mem: 8730
loss info: cls_loss=2.9994, ratio_loss=0.0488, cls_kl=0.0670, token_kl=0.0971
Epoch: [22]  [ 700/2001]  eta: 0:13:49  lr: 0.000112  loss: 3.3191 (3.0605)  time: 0.6287  data: 0.0001  max mem: 8730
Epoch: [22]  [ 710/2001]  eta: 0:13:43  lr: 0.000112  loss: 3.2181 (3.0591)  time: 0.6258  data: 0.0001  max mem: 8730
Epoch: [22]  [ 720/2001]  eta: 0:13:36  lr: 0.000112  loss: 3.1368 (3.0599)  time: 0.6227  data: 0.0001  max mem: 8730
Epoch: [22]  [ 730/2001]  eta: 0:13:29  lr: 0.000112  loss: 3.1049 (3.0584)  time: 0.6242  data: 0.0002  max mem: 8730
Epoch: [22]  [ 740/2001]  eta: 0:13:23  lr: 0.000112  loss: 3.1005 (3.0603)  time: 0.6263  data: 0.0001  max mem: 8730
Epoch: [22]  [ 750/2001]  eta: 0:13:16  lr: 0.000112  loss: 3.1059 (3.0590)  time: 0.6269  data: 0.0001  max mem: 8730
Epoch: [22]  [ 760/2001]  eta: 0:13:10  lr: 0.000112  loss: 3.2422 (3.0585)  time: 0.6242  data: 0.0001  max mem: 8730
Epoch: [22]  [ 770/2001]  eta: 0:13:03  lr: 0.000112  loss: 3.2422 (3.0569)  time: 0.6223  data: 0.0002  max mem: 8730
Epoch: [22]  [ 780/2001]  eta: 0:12:57  lr: 0.000112  loss: 3.0964 (3.0569)  time: 0.6242  data: 0.0002  max mem: 8730
Epoch: [22]  [ 790/2001]  eta: 0:12:50  lr: 0.000112  loss: 3.1511 (3.0570)  time: 0.6254  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9353, ratio_loss=0.0426, cls_kl=0.0619, token_kl=0.0911
Epoch: [22]  [ 800/2001]  eta: 0:12:44  lr: 0.000112  loss: 3.1511 (3.0572)  time: 0.6253  data: 0.0001  max mem: 8730
Epoch: [22]  [ 810/2001]  eta: 0:12:37  lr: 0.000112  loss: 3.1372 (3.0596)  time: 0.6270  data: 0.0002  max mem: 8730
Epoch: [22]  [ 820/2001]  eta: 0:12:31  lr: 0.000112  loss: 3.0807 (3.0580)  time: 0.6254  data: 0.0002  max mem: 8730
Epoch: [22]  [ 830/2001]  eta: 0:12:24  lr: 0.000112  loss: 2.9926 (3.0581)  time: 0.6272  data: 0.0001  max mem: 8730
Epoch: [22]  [ 840/2001]  eta: 0:12:18  lr: 0.000112  loss: 3.2372 (3.0593)  time: 0.6252  data: 0.0001  max mem: 8730
| distributed init (rank 7): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
| distributed init (rank 5): env://
| distributed init (rank 4): env://
| distributed init (rank 6): env://
| distributed init (rank 0): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp-3keep/checkpoint.pth', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0001117 for PREDICTOR
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Epoch: [22]  [   0/2001]  eta: 3:38:12  lr: 0.000112  loss: 3.4528 (3.4528)  time: 6.5430  data: 2.8265  max mem: 8647
Epoch: [22]  [  10/2001]  eta: 0:38:19  lr: 0.000112  loss: 3.4528 (3.3511)  time: 1.1548  data: 0.2571  max mem: 8728
Epoch: [22]  [  20/2001]  eta: 0:29:09  lr: 0.000112  loss: 3.3490 (3.3071)  time: 0.6003  data: 0.0001  max mem: 8728
Epoch: [22]  [  30/2001]  eta: 0:25:55  lr: 0.000112  loss: 3.3490 (3.3015)  time: 0.5881  data: 0.0001  max mem: 8728
Epoch: [22]  [  40/2001]  eta: 0:24:12  lr: 0.000112  loss: 3.3020 (3.2485)  time: 0.5909  data: 0.0001  max mem: 8728
Epoch: [22]  [  50/2001]  eta: 0:23:07  lr: 0.000112  loss: 3.1179 (3.2433)  time: 0.5903  data: 0.0001  max mem: 8728
Epoch: [22]  [  60/2001]  eta: 0:22:21  lr: 0.000112  loss: 3.1179 (3.1944)  time: 0.5899  data: 0.0001  max mem: 8728
Epoch: [22]  [  70/2001]  eta: 0:21:47  lr: 0.000112  loss: 3.0904 (3.1625)  time: 0.5897  data: 0.0001  max mem: 8728
Epoch: [22]  [  80/2001]  eta: 0:21:20  lr: 0.000112  loss: 3.0904 (3.1563)  time: 0.5908  data: 0.0001  max mem: 8728
Epoch: [22]  [  90/2001]  eta: 0:20:59  lr: 0.000112  loss: 2.9474 (3.1456)  time: 0.5967  data: 0.0001  max mem: 8728
loss info: cls_loss=3.0380, ratio_loss=0.0469, cls_kl=0.0646, token_kl=0.0949
Epoch: [22]  [ 100/2001]  eta: 0:20:42  lr: 0.000112  loss: 3.1816 (3.1526)  time: 0.6013  data: 0.0001  max mem: 8728
Epoch: [22]  [ 110/2001]  eta: 0:20:27  lr: 0.000112  loss: 3.1816 (3.1461)  time: 0.6028  data: 0.0001  max mem: 8728
Epoch: [22]  [ 120/2001]  eta: 0:20:14  lr: 0.000112  loss: 3.2311 (3.1370)  time: 0.6049  data: 0.0001  max mem: 8728
Epoch: [22]  [ 130/2001]  eta: 0:20:02  lr: 0.000112  loss: 3.1213 (3.1316)  time: 0.6053  data: 0.0001  max mem: 8728
Epoch: [22]  [ 140/2001]  eta: 0:19:50  lr: 0.000112  loss: 3.0464 (3.1223)  time: 0.6064  data: 0.0001  max mem: 8728
Epoch: [22]  [ 150/2001]  eta: 0:19:41  lr: 0.000112  loss: 3.0290 (3.1134)  time: 0.6092  data: 0.0001  max mem: 8728
Epoch: [22]  [ 160/2001]  eta: 0:19:31  lr: 0.000112  loss: 3.1090 (3.1178)  time: 0.6120  data: 0.0001  max mem: 8728
Epoch: [22]  [ 170/2001]  eta: 0:19:23  lr: 0.000112  loss: 3.1971 (3.1183)  time: 0.6177  data: 0.0001  max mem: 8728
Epoch: [22]  [ 180/2001]  eta: 0:19:15  lr: 0.000112  loss: 3.0400 (3.1016)  time: 0.6187  data: 0.0001  max mem: 8728
Epoch: [22]  [ 190/2001]  eta: 0:19:09  lr: 0.000112  loss: 2.9004 (3.0963)  time: 0.6286  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9069, ratio_loss=0.0431, cls_kl=0.0617, token_kl=0.0920
Epoch: [22]  [ 200/2001]  eta: 0:19:01  lr: 0.000112  loss: 2.9004 (3.0791)  time: 0.6283  data: 0.0001  max mem: 8728
Traceback (most recent call last):
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 253, in main
    process.wait()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/subprocess.py", line 1477, in wait
    (pid, sts) = self._try_wait(0)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/subprocess.py", line 1424, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 4): env://
| distributed init (rank 3): env://
| distributed init (rank 1): env://
| distributed init (rank 6): env://
| distributed init (rank 0): env://
| distributed init (rank 7): env://
| distributed init (rank 2): env://
| distributed init (rank 5): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp-3keep/checkpoint.pth', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0001117 for PREDICTOR
Epoch: [22]  [   0/2001]  eta: 3:36:16  lr: 0.000112  loss: 3.4528 (3.4528)  time: 6.4851  data: 2.9161  max mem: 8647
Epoch: [22]  [  10/2001]  eta: 0:38:09  lr: 0.000112  loss: 3.4528 (3.3511)  time: 1.1501  data: 0.2652  max mem: 8728
Epoch: [22]  [  20/2001]  eta: 0:29:12  lr: 0.000112  loss: 3.3490 (3.3071)  time: 0.6044  data: 0.0001  max mem: 8728
Epoch: [22]  [  30/2001]  eta: 0:26:05  lr: 0.000112  loss: 3.3490 (3.3015)  time: 0.5988  data: 0.0002  max mem: 8728
Epoch: [22]  [  40/2001]  eta: 0:24:21  lr: 0.000112  loss: 3.3021 (3.2485)  time: 0.5986  data: 0.0002  max mem: 8728
Epoch: [22]  [  50/2001]  eta: 0:23:15  lr: 0.000112  loss: 3.1179 (3.2432)  time: 0.5928  data: 0.0001  max mem: 8728
Epoch: [22]  [  60/2001]  eta: 0:22:27  lr: 0.000112  loss: 3.1179 (3.1944)  time: 0.5907  data: 0.0001  max mem: 8728
Epoch: [22]  [  70/2001]  eta: 0:21:57  lr: 0.000112  loss: 3.0902 (3.1624)  time: 0.5980  data: 0.0001  max mem: 8728
Epoch: [22]  [  80/2001]  eta: 0:21:33  lr: 0.000112  loss: 3.0902 (3.1562)  time: 0.6082  data: 0.0002  max mem: 8728
Epoch: [22]  [  90/2001]  eta: 0:21:12  lr: 0.000112  loss: 2.9463 (3.1455)  time: 0.6078  data: 0.0002  max mem: 8728
loss info: cls_loss=3.0379, ratio_loss=0.0469, cls_kl=0.0646, token_kl=0.0949
Epoch: [22]  [ 100/2001]  eta: 0:20:55  lr: 0.000112  loss: 3.1819 (3.1524)  time: 0.6099  data: 0.0001  max mem: 8728
Epoch: [22]  [ 110/2001]  eta: 0:20:41  lr: 0.000112  loss: 3.1819 (3.1460)  time: 0.6125  data: 0.0001  max mem: 8728
Epoch: [22]  [ 120/2001]  eta: 0:20:27  lr: 0.000112  loss: 3.2302 (3.1369)  time: 0.6130  data: 0.0001  max mem: 8728
Epoch: [22]  [ 130/2001]  eta: 0:20:16  lr: 0.000112  loss: 3.1233 (3.1315)  time: 0.6156  data: 0.0001  max mem: 8728
Epoch: [22]  [ 140/2001]  eta: 0:20:05  lr: 0.000112  loss: 3.0516 (3.1223)  time: 0.6172  data: 0.0001  max mem: 8728
Epoch: [22]  [ 150/2001]  eta: 0:19:55  lr: 0.000112  loss: 3.0292 (3.1134)  time: 0.6185  data: 0.0001  max mem: 8728
Epoch: [22]  [ 160/2001]  eta: 0:19:46  lr: 0.000112  loss: 3.1106 (3.1178)  time: 0.6220  data: 0.0001  max mem: 8728
Epoch: [22]  [ 170/2001]  eta: 0:19:37  lr: 0.000112  loss: 3.2032 (3.1184)  time: 0.6236  data: 0.0001  max mem: 8728
Epoch: [22]  [ 180/2001]  eta: 0:19:29  lr: 0.000112  loss: 3.0377 (3.1017)  time: 0.6252  data: 0.0001  max mem: 8728
Epoch: [22]  [ 190/2001]  eta: 0:19:22  lr: 0.000112  loss: 2.9014 (3.0964)  time: 0.6324  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9071, ratio_loss=0.0430, cls_kl=0.0617, token_kl=0.0920
Epoch: [22]  [ 200/2001]  eta: 0:19:15  lr: 0.000112  loss: 2.9014 (3.0791)  time: 0.6339  data: 0.0001  max mem: 8728
| distributed init (rank 1): env://
| distributed init (rank 5): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
| distributed init (rank 4): env://
| distributed init (rank 0): env://
| distributed init (rank 6): env://
| distributed init (rank 7): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp-3keep/checkpoint.pth', sched='cosine', seed=42, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0001117 for PREDICTOR
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Epoch: [22]  [   0/2001]  eta: 3:39:31  lr: 0.000112  loss: 3.2348 (3.2348)  time: 6.5826  data: 2.9917  max mem: 8647
Epoch: [22]  [  10/2001]  eta: 0:38:16  lr: 0.000112  loss: 2.9872 (2.9554)  time: 1.1535  data: 0.2721  max mem: 8728
Epoch: [22]  [  20/2001]  eta: 0:29:14  lr: 0.000112  loss: 3.1189 (3.0886)  time: 0.6006  data: 0.0001  max mem: 8728
Epoch: [22]  [  30/2001]  eta: 0:26:08  lr: 0.000112  loss: 3.1810 (3.0704)  time: 0.5987  data: 0.0002  max mem: 8728
Epoch: [22]  [  40/2001]  eta: 0:24:23  lr: 0.000112  loss: 3.2260 (3.1218)  time: 0.6000  data: 0.0002  max mem: 8728
Epoch: [22]  [  50/2001]  eta: 0:23:18  lr: 0.000112  loss: 3.3223 (3.1484)  time: 0.5944  data: 0.0001  max mem: 8728
Epoch: [22]  [  60/2001]  eta: 0:22:31  lr: 0.000112  loss: 3.2933 (3.1569)  time: 0.5941  data: 0.0002  max mem: 8728
Epoch: [22]  [  70/2001]  eta: 0:21:57  lr: 0.000112  loss: 3.2164 (3.1300)  time: 0.5949  data: 0.0002  max mem: 8728
Epoch: [22]  [  80/2001]  eta: 0:21:33  lr: 0.000112  loss: 3.1467 (3.1375)  time: 0.6027  data: 0.0001  max mem: 8728
Epoch: [22]  [  90/2001]  eta: 0:21:13  lr: 0.000112  loss: 3.2643 (3.1396)  time: 0.6090  data: 0.0002  max mem: 8728
loss info: cls_loss=3.0182, ratio_loss=0.0447, cls_kl=0.0643, token_kl=0.0928
Epoch: [22]  [ 100/2001]  eta: 0:20:55  lr: 0.000112  loss: 2.9881 (3.1215)  time: 0.6093  data: 0.0001  max mem: 8728
Epoch: [22]  [ 110/2001]  eta: 0:20:40  lr: 0.000112  loss: 2.8684 (3.1131)  time: 0.6090  data: 0.0001  max mem: 8728
Epoch: [22]  [ 120/2001]  eta: 0:20:27  lr: 0.000112  loss: 3.1386 (3.1177)  time: 0.6112  data: 0.0001  max mem: 8728
Epoch: [22]  [ 130/2001]  eta: 0:20:16  lr: 0.000112  loss: 3.1398 (3.1046)  time: 0.6196  data: 0.0001  max mem: 8728
Epoch: [22]  [ 140/2001]  eta: 0:20:06  lr: 0.000112  loss: 2.8237 (3.0892)  time: 0.6223  data: 0.0001  max mem: 8728
Epoch: [22]  [ 150/2001]  eta: 0:19:55  lr: 0.000112  loss: 3.0368 (3.0915)  time: 0.6178  data: 0.0001  max mem: 8728
Epoch: [22]  [ 160/2001]  eta: 0:19:46  lr: 0.000112  loss: 3.1433 (3.0815)  time: 0.6183  data: 0.0001  max mem: 8728
Epoch: [22]  [ 170/2001]  eta: 0:19:37  lr: 0.000112  loss: 3.1207 (3.0772)  time: 0.6192  data: 0.0002  max mem: 8728
Epoch: [22]  [ 180/2001]  eta: 0:19:28  lr: 0.000112  loss: 3.1445 (3.0805)  time: 0.6183  data: 0.0001  max mem: 8728
Epoch: [22]  [ 190/2001]  eta: 0:19:21  lr: 0.000112  loss: 3.0859 (3.0626)  time: 0.6276  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9069, ratio_loss=0.0441, cls_kl=0.0619, token_kl=0.0929
Epoch: [22]  [ 200/2001]  eta: 0:19:14  lr: 0.000112  loss: 3.0730 (3.0698)  time: 0.6345  data: 0.0001  max mem: 8728
Epoch: [22]  [ 210/2001]  eta: 0:19:06  lr: 0.000112  loss: 3.1398 (3.0736)  time: 0.6296  data: 0.0001  max mem: 8728
Epoch: [22]  [ 220/2001]  eta: 0:18:58  lr: 0.000112  loss: 3.1398 (3.0813)  time: 0.6251  data: 0.0001  max mem: 8728
Epoch: [22]  [ 230/2001]  eta: 0:18:51  lr: 0.000112  loss: 3.1362 (3.0827)  time: 0.6251  data: 0.0001  max mem: 8728
Epoch: [22]  [ 240/2001]  eta: 0:18:43  lr: 0.000112  loss: 3.3025 (3.0844)  time: 0.6249  data: 0.0001  max mem: 8728
Epoch: [22]  [ 250/2001]  eta: 0:18:36  lr: 0.000112  loss: 3.1313 (3.0757)  time: 0.6260  data: 0.0001  max mem: 8728
Epoch: [22]  [ 260/2001]  eta: 0:18:29  lr: 0.000112  loss: 3.1481 (3.0786)  time: 0.6286  data: 0.0001  max mem: 8728
Epoch: [22]  [ 270/2001]  eta: 0:18:22  lr: 0.000112  loss: 3.1903 (3.0758)  time: 0.6261  data: 0.0001  max mem: 8728
Epoch: [22]  [ 280/2001]  eta: 0:18:15  lr: 0.000112  loss: 3.3610 (3.0818)  time: 0.6239  data: 0.0001  max mem: 8728
Epoch: [22]  [ 290/2001]  eta: 0:18:08  lr: 0.000112  loss: 3.2218 (3.0768)  time: 0.6243  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9762, ratio_loss=0.0431, cls_kl=0.0633, token_kl=0.0928
Epoch: [22]  [ 300/2001]  eta: 0:18:01  lr: 0.000112  loss: 3.0011 (3.0742)  time: 0.6236  data: 0.0001  max mem: 8728
Epoch: [22]  [ 310/2001]  eta: 0:17:54  lr: 0.000112  loss: 3.0631 (3.0790)  time: 0.6254  data: 0.0001  max mem: 8728
Epoch: [22]  [ 320/2001]  eta: 0:17:48  lr: 0.000112  loss: 3.1597 (3.0768)  time: 0.6305  data: 0.0001  max mem: 8728
Epoch: [22]  [ 330/2001]  eta: 0:17:41  lr: 0.000112  loss: 3.0309 (3.0710)  time: 0.6311  data: 0.0002  max mem: 8728
Epoch: [22]  [ 340/2001]  eta: 0:17:35  lr: 0.000112  loss: 3.0336 (3.0696)  time: 0.6356  data: 0.0002  max mem: 8728
Epoch: [22]  [ 350/2001]  eta: 0:17:28  lr: 0.000112  loss: 3.0336 (3.0675)  time: 0.6325  data: 0.0002  max mem: 8728
Epoch: [22]  [ 360/2001]  eta: 0:17:22  lr: 0.000112  loss: 2.9087 (3.0598)  time: 0.6313  data: 0.0002  max mem: 8728
Epoch: [22]  [ 370/2001]  eta: 0:17:15  lr: 0.000112  loss: 2.9293 (3.0578)  time: 0.6343  data: 0.0002  max mem: 8728
Epoch: [22]  [ 380/2001]  eta: 0:17:09  lr: 0.000112  loss: 2.8275 (3.0499)  time: 0.6312  data: 0.0002  max mem: 8728
Epoch: [22]  [ 390/2001]  eta: 0:17:02  lr: 0.000112  loss: 2.7339 (3.0468)  time: 0.6320  data: 0.0002  max mem: 8728
loss info: cls_loss=2.8651, ratio_loss=0.0439, cls_kl=0.0640, token_kl=0.0945
Epoch: [22]  [ 400/2001]  eta: 0:16:56  lr: 0.000112  loss: 3.0115 (3.0471)  time: 0.6296  data: 0.0001  max mem: 8728
Epoch: [22]  [ 410/2001]  eta: 0:16:49  lr: 0.000112  loss: 3.0115 (3.0412)  time: 0.6285  data: 0.0001  max mem: 8728
Epoch: [22]  [ 420/2001]  eta: 0:16:43  lr: 0.000112  loss: 2.7938 (3.0389)  time: 0.6320  data: 0.0002  max mem: 8728
Epoch: [22]  [ 430/2001]  eta: 0:16:36  lr: 0.000112  loss: 3.1834 (3.0337)  time: 0.6299  data: 0.0002  max mem: 8728
Epoch: [22]  [ 440/2001]  eta: 0:16:29  lr: 0.000112  loss: 2.8825 (3.0264)  time: 0.6251  data: 0.0001  max mem: 8728
Epoch: [22]  [ 450/2001]  eta: 0:16:23  lr: 0.000112  loss: 2.8825 (3.0258)  time: 0.6265  data: 0.0002  max mem: 8728
Epoch: [22]  [ 460/2001]  eta: 0:16:17  lr: 0.000112  loss: 3.3141 (3.0314)  time: 0.6330  data: 0.0002  max mem: 8728
Epoch: [22]  [ 470/2001]  eta: 0:16:10  lr: 0.000112  loss: 3.2292 (3.0288)  time: 0.6338  data: 0.0001  max mem: 8728
Epoch: [22]  [ 480/2001]  eta: 0:16:04  lr: 0.000112  loss: 3.1153 (3.0281)  time: 0.6304  data: 0.0001  max mem: 8728
Epoch: [22]  [ 490/2001]  eta: 0:15:57  lr: 0.000112  loss: 2.9519 (3.0246)  time: 0.6294  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8119, ratio_loss=0.0414, cls_kl=0.0623, token_kl=0.0939
Epoch: [22]  [ 500/2001]  eta: 0:15:51  lr: 0.000112  loss: 2.8858 (3.0242)  time: 0.6288  data: 0.0001  max mem: 8728
Epoch: [22]  [ 510/2001]  eta: 0:15:44  lr: 0.000112  loss: 3.2978 (3.0302)  time: 0.6293  data: 0.0001  max mem: 8728
Epoch: [22]  [ 520/2001]  eta: 0:15:38  lr: 0.000112  loss: 3.2299 (3.0281)  time: 0.6305  data: 0.0001  max mem: 8728
Epoch: [22]  [ 530/2001]  eta: 0:15:32  lr: 0.000112  loss: 3.0373 (3.0241)  time: 0.6346  data: 0.0001  max mem: 8728
Epoch: [22]  [ 540/2001]  eta: 0:15:25  lr: 0.000112  loss: 3.0530 (3.0255)  time: 0.6353  data: 0.0001  max mem: 8728
Epoch: [22]  [ 550/2001]  eta: 0:15:19  lr: 0.000112  loss: 3.1925 (3.0260)  time: 0.6337  data: 0.0001  max mem: 8728
Epoch: [22]  [ 560/2001]  eta: 0:15:12  lr: 0.000112  loss: 3.0826 (3.0271)  time: 0.6317  data: 0.0001  max mem: 8728
Epoch: [22]  [ 570/2001]  eta: 0:15:06  lr: 0.000112  loss: 3.0486 (3.0261)  time: 0.6288  data: 0.0001  max mem: 8728
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 7): env://
| distributed init (rank 4): env://
| distributed init (rank 3): env://
| distributed init (rank 6): env://
| distributed init (rank 5): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp-3keep/checkpoint.pth', sched='cosine', seed=42, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0001117 for PREDICTOR
Failed to find state_dict_ema, starting from loaded model weights
Epoch: [22]  [   0/2001]  eta: 3:36:29  lr: 0.000112  loss: 3.2348 (3.2348)  time: 6.4916  data: 2.6658  max mem: 8647
Epoch: [22]  [  10/2001]  eta: 0:38:07  lr: 0.000112  loss: 2.9872 (2.9554)  time: 1.1487  data: 0.2425  max mem: 8728
Epoch: [22]  [  20/2001]  eta: 0:29:07  lr: 0.000112  loss: 3.1189 (3.0886)  time: 0.6015  data: 0.0001  max mem: 8728
Epoch: [22]  [  30/2001]  eta: 0:26:01  lr: 0.000112  loss: 3.1810 (3.0704)  time: 0.5963  data: 0.0001  max mem: 8728
Epoch: [22]  [  40/2001]  eta: 0:24:15  lr: 0.000112  loss: 3.2260 (3.1218)  time: 0.5959  data: 0.0002  max mem: 8728
Epoch: [22]  [  50/2001]  eta: 0:23:09  lr: 0.000112  loss: 3.3223 (3.1484)  time: 0.5873  data: 0.0001  max mem: 8728
Epoch: [22]  [  60/2001]  eta: 0:22:22  lr: 0.000112  loss: 3.2934 (3.1569)  time: 0.5870  data: 0.0001  max mem: 8728
Epoch: [22]  [  70/2001]  eta: 0:21:48  lr: 0.000112  loss: 3.2172 (3.1300)  time: 0.5909  data: 0.0001  max mem: 8728
Epoch: [22]  [  80/2001]  eta: 0:21:24  lr: 0.000112  loss: 3.1472 (3.1374)  time: 0.5993  data: 0.0001  max mem: 8728
Epoch: [22]  [  90/2001]  eta: 0:21:05  lr: 0.000112  loss: 3.2647 (3.1395)  time: 0.6072  data: 0.0002  max mem: 8728
loss info: cls_loss=3.0182, ratio_loss=0.0447, cls_kl=0.0643, token_kl=0.0928
Epoch: [22]  [ 100/2001]  eta: 0:20:49  lr: 0.000112  loss: 2.9888 (3.1214)  time: 0.6106  data: 0.0001  max mem: 8728
Epoch: [22]  [ 110/2001]  eta: 0:20:34  lr: 0.000112  loss: 2.8663 (3.1129)  time: 0.6101  data: 0.0001  max mem: 8728
Epoch: [22]  [ 120/2001]  eta: 0:20:21  lr: 0.000112  loss: 3.1382 (3.1176)  time: 0.6105  data: 0.0001  max mem: 8728
Epoch: [22]  [ 130/2001]  eta: 0:20:09  lr: 0.000112  loss: 3.1382 (3.1045)  time: 0.6111  data: 0.0001  max mem: 8728
Epoch: [22]  [ 140/2001]  eta: 0:19:59  lr: 0.000112  loss: 2.8221 (3.0892)  time: 0.6149  data: 0.0001  max mem: 8728
Epoch: [22]  [ 150/2001]  eta: 0:19:50  lr: 0.000112  loss: 3.0386 (3.0914)  time: 0.6196  data: 0.0001  max mem: 8728
Epoch: [22]  [ 160/2001]  eta: 0:19:40  lr: 0.000112  loss: 3.1455 (3.0815)  time: 0.6198  data: 0.0001  max mem: 8728
Epoch: [22]  [ 170/2001]  eta: 0:19:32  lr: 0.000112  loss: 3.1201 (3.0773)  time: 0.6209  data: 0.0001  max mem: 8728
Epoch: [22]  [ 180/2001]  eta: 0:19:24  lr: 0.000112  loss: 3.1442 (3.0805)  time: 0.6234  data: 0.0001  max mem: 8728
Epoch: [22]  [ 190/2001]  eta: 0:19:17  lr: 0.000112  loss: 3.0856 (3.0627)  time: 0.6272  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9070, ratio_loss=0.0441, cls_kl=0.0620, token_kl=0.0930
Epoch: [22]  [ 200/2001]  eta: 0:19:09  lr: 0.000112  loss: 3.0730 (3.0698)  time: 0.6273  data: 0.0001  max mem: 8728
Epoch: [22]  [ 210/2001]  eta: 0:19:01  lr: 0.000112  loss: 3.1402 (3.0736)  time: 0.6217  data: 0.0001  max mem: 8728
Epoch: [22]  [ 220/2001]  eta: 0:18:54  lr: 0.000112  loss: 3.1402 (3.0813)  time: 0.6242  data: 0.0001  max mem: 8728
Epoch: [22]  [ 230/2001]  eta: 0:18:47  lr: 0.000112  loss: 3.1354 (3.0827)  time: 0.6287  data: 0.0001  max mem: 8728
Epoch: [22]  [ 240/2001]  eta: 0:18:40  lr: 0.000112  loss: 3.3028 (3.0844)  time: 0.6265  data: 0.0001  max mem: 8728
Epoch: [22]  [ 250/2001]  eta: 0:18:33  lr: 0.000112  loss: 3.1302 (3.0757)  time: 0.6281  data: 0.0001  max mem: 8728
Epoch: [22]  [ 260/2001]  eta: 0:18:26  lr: 0.000112  loss: 3.1516 (3.0787)  time: 0.6298  data: 0.0001  max mem: 8728
Epoch: [22]  [ 270/2001]  eta: 0:18:20  lr: 0.000112  loss: 3.1876 (3.0758)  time: 0.6321  data: 0.0001  max mem: 8728
Epoch: [22]  [ 280/2001]  eta: 0:18:13  lr: 0.000112  loss: 3.3620 (3.0819)  time: 0.6342  data: 0.0001  max mem: 8728
Epoch: [22]  [ 290/2001]  eta: 0:18:07  lr: 0.000112  loss: 3.2246 (3.0769)  time: 0.6321  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9764, ratio_loss=0.0431, cls_kl=0.0632, token_kl=0.0927
Epoch: [22]  [ 300/2001]  eta: 0:18:00  lr: 0.000112  loss: 2.9973 (3.0743)  time: 0.6307  data: 0.0001  max mem: 8728
Epoch: [22]  [ 310/2001]  eta: 0:17:54  lr: 0.000112  loss: 3.0636 (3.0791)  time: 0.6314  data: 0.0001  max mem: 8728
Epoch: [22]  [ 320/2001]  eta: 0:17:47  lr: 0.000112  loss: 3.1625 (3.0769)  time: 0.6339  data: 0.0001  max mem: 8728
Epoch: [22]  [ 330/2001]  eta: 0:17:41  lr: 0.000112  loss: 3.0263 (3.0711)  time: 0.6358  data: 0.0001  max mem: 8728
Epoch: [22]  [ 340/2001]  eta: 0:17:35  lr: 0.000112  loss: 3.0335 (3.0697)  time: 0.6415  data: 0.0001  max mem: 8728
Epoch: [22]  [ 350/2001]  eta: 0:17:29  lr: 0.000112  loss: 3.0335 (3.0676)  time: 0.6468  data: 0.0002  max mem: 8728
Epoch: [22]  [ 360/2001]  eta: 0:17:23  lr: 0.000112  loss: 2.9079 (3.0598)  time: 0.6432  data: 0.0001  max mem: 8728
Epoch: [22]  [ 370/2001]  eta: 0:17:17  lr: 0.000112  loss: 2.9253 (3.0579)  time: 0.6392  data: 0.0001  max mem: 8728
Epoch: [22]  [ 380/2001]  eta: 0:17:11  lr: 0.000112  loss: 2.8276 (3.0500)  time: 0.6443  data: 0.0002  max mem: 8728
Epoch: [22]  [ 390/2001]  eta: 0:17:05  lr: 0.000112  loss: 2.7359 (3.0469)  time: 0.6480  data: 0.0002  max mem: 8728
loss info: cls_loss=2.8651, ratio_loss=0.0440, cls_kl=0.0641, token_kl=0.0946
Epoch: [22]  [ 400/2001]  eta: 0:16:59  lr: 0.000112  loss: 3.0125 (3.0472)  time: 0.6407  data: 0.0001  max mem: 8728
Epoch: [22]  [ 410/2001]  eta: 0:16:52  lr: 0.000112  loss: 3.0125 (3.0414)  time: 0.6347  data: 0.0001  max mem: 8728
Epoch: [22]  [ 420/2001]  eta: 0:16:46  lr: 0.000112  loss: 2.7952 (3.0390)  time: 0.6343  data: 0.0001  max mem: 8728
Epoch: [22]  [ 430/2001]  eta: 0:16:39  lr: 0.000112  loss: 3.1796 (3.0338)  time: 0.6329  data: 0.0001  max mem: 8728
Epoch: [22]  [ 440/2001]  eta: 0:16:33  lr: 0.000112  loss: 2.8785 (3.0265)  time: 0.6337  data: 0.0001  max mem: 8728
Epoch: [22]  [ 450/2001]  eta: 0:16:27  lr: 0.000112  loss: 2.8785 (3.0259)  time: 0.6369  data: 0.0001  max mem: 8728
Epoch: [22]  [ 460/2001]  eta: 0:16:20  lr: 0.000112  loss: 3.3134 (3.0314)  time: 0.6415  data: 0.0001  max mem: 8728
Epoch: [22]  [ 470/2001]  eta: 0:16:14  lr: 0.000112  loss: 3.2313 (3.0288)  time: 0.6464  data: 0.0001  max mem: 8728
Epoch: [22]  [ 480/2001]  eta: 0:16:08  lr: 0.000112  loss: 3.1183 (3.0282)  time: 0.6464  data: 0.0001  max mem: 8728
Epoch: [22]  [ 490/2001]  eta: 0:16:02  lr: 0.000112  loss: 2.9518 (3.0246)  time: 0.6381  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8116, ratio_loss=0.0414, cls_kl=0.0623, token_kl=0.0939
Epoch: [22]  [ 500/2001]  eta: 0:15:55  lr: 0.000112  loss: 2.8823 (3.0243)  time: 0.6314  data: 0.0001  max mem: 8728
Epoch: [22]  [ 510/2001]  eta: 0:15:49  lr: 0.000112  loss: 3.2959 (3.0302)  time: 0.6325  data: 0.0001  max mem: 8728
Epoch: [22]  [ 520/2001]  eta: 0:15:42  lr: 0.000112  loss: 3.2291 (3.0282)  time: 0.6357  data: 0.0001  max mem: 8728
Epoch: [22]  [ 530/2001]  eta: 0:15:36  lr: 0.000112  loss: 3.0386 (3.0242)  time: 0.6366  data: 0.0001  max mem: 8728
Epoch: [22]  [ 540/2001]  eta: 0:15:30  lr: 0.000112  loss: 3.0572 (3.0255)  time: 0.6378  data: 0.0001  max mem: 8728
Epoch: [22]  [ 550/2001]  eta: 0:15:23  lr: 0.000112  loss: 3.1900 (3.0260)  time: 0.6370  data: 0.0001  max mem: 8728
Epoch: [22]  [ 560/2001]  eta: 0:15:17  lr: 0.000112  loss: 3.0834 (3.0272)  time: 0.6327  data: 0.0001  max mem: 8728
Epoch: [22]  [ 570/2001]  eta: 0:15:10  lr: 0.000112  loss: 3.0494 (3.0261)  time: 0.6329  data: 0.0001  max mem: 8728
Epoch: [22]  [ 580/2001]  eta: 0:15:04  lr: 0.000112  loss: 2.8531 (3.0227)  time: 0.6329  data: 0.0001  max mem: 8728
Epoch: [22]  [ 590/2001]  eta: 0:14:57  lr: 0.000112  loss: 3.1473 (3.0280)  time: 0.6308  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9540, ratio_loss=0.0465, cls_kl=0.0644, token_kl=0.0966
Epoch: [22]  [ 600/2001]  eta: 0:14:51  lr: 0.000112  loss: 3.2927 (3.0304)  time: 0.6305  data: 0.0001  max mem: 8728
Epoch: [22]  [ 610/2001]  eta: 0:14:44  lr: 0.000112  loss: 3.2990 (3.0344)  time: 0.6310  data: 0.0001  max mem: 8728
Epoch: [22]  [ 620/2001]  eta: 0:14:38  lr: 0.000112  loss: 3.2320 (3.0349)  time: 0.6342  data: 0.0001  max mem: 8728
Epoch: [22]  [ 630/2001]  eta: 0:14:32  lr: 0.000112  loss: 3.1077 (3.0354)  time: 0.6341  data: 0.0001  max mem: 8728
Epoch: [22]  [ 640/2001]  eta: 0:14:25  lr: 0.000112  loss: 3.1077 (3.0341)  time: 0.6299  data: 0.0001  max mem: 8728
Epoch: [22]  [ 650/2001]  eta: 0:14:19  lr: 0.000112  loss: 2.9985 (3.0357)  time: 0.6281  data: 0.0001  max mem: 8728
Epoch: [22]  [ 660/2001]  eta: 0:14:12  lr: 0.000112  loss: 2.9985 (3.0329)  time: 0.6294  data: 0.0001  max mem: 8728
Epoch: [22]  [ 670/2001]  eta: 0:14:06  lr: 0.000112  loss: 3.1020 (3.0351)  time: 0.6289  data: 0.0001  max mem: 8728
Epoch: [22]  [ 680/2001]  eta: 0:13:59  lr: 0.000112  loss: 3.1020 (3.0327)  time: 0.6264  data: 0.0001  max mem: 8728
Epoch: [22]  [ 690/2001]  eta: 0:13:52  lr: 0.000112  loss: 3.0024 (3.0308)  time: 0.6253  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9361, ratio_loss=0.0482, cls_kl=0.0645, token_kl=0.0953
Epoch: [22]  [ 700/2001]  eta: 0:13:46  lr: 0.000112  loss: 2.8963 (3.0322)  time: 0.6247  data: 0.0001  max mem: 8728
Epoch: [22]  [ 710/2001]  eta: 0:13:39  lr: 0.000112  loss: 2.8850 (3.0307)  time: 0.6234  data: 0.0001  max mem: 8728
Epoch: [22]  [ 720/2001]  eta: 0:13:33  lr: 0.000112  loss: 3.0895 (3.0291)  time: 0.6251  data: 0.0001  max mem: 8728
Epoch: [22]  [ 730/2001]  eta: 0:13:26  lr: 0.000112  loss: 3.1981 (3.0302)  time: 0.6289  data: 0.0001  max mem: 8728
Epoch: [22]  [ 740/2001]  eta: 0:13:20  lr: 0.000112  loss: 3.2416 (3.0317)  time: 0.6244  data: 0.0001  max mem: 8728
Epoch: [22]  [ 750/2001]  eta: 0:13:13  lr: 0.000112  loss: 3.3112 (3.0328)  time: 0.6231  data: 0.0001  max mem: 8728
Epoch: [22]  [ 760/2001]  eta: 0:13:07  lr: 0.000112  loss: 3.1073 (3.0308)  time: 0.6251  data: 0.0001  max mem: 8728
Epoch: [22]  [ 770/2001]  eta: 0:13:00  lr: 0.000112  loss: 3.1224 (3.0316)  time: 0.6244  data: 0.0001  max mem: 8728
Epoch: [22]  [ 780/2001]  eta: 0:12:54  lr: 0.000112  loss: 3.2541 (3.0350)  time: 0.6237  data: 0.0001  max mem: 8728
Epoch: [22]  [ 790/2001]  eta: 0:12:47  lr: 0.000112  loss: 3.2993 (3.0358)  time: 0.6270  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9835, ratio_loss=0.0453, cls_kl=0.0636, token_kl=0.0938
Epoch: [22]  [ 800/2001]  eta: 0:12:41  lr: 0.000112  loss: 3.2993 (3.0409)  time: 0.6245  data: 0.0001  max mem: 8728
Epoch: [22]  [ 810/2001]  eta: 0:12:34  lr: 0.000112  loss: 3.3550 (3.0437)  time: 0.6226  data: 0.0001  max mem: 8728
Epoch: [22]  [ 820/2001]  eta: 0:12:28  lr: 0.000112  loss: 3.2062 (3.0443)  time: 0.6247  data: 0.0001  max mem: 8728
Epoch: [22]  [ 830/2001]  eta: 0:12:21  lr: 0.000112  loss: 3.1574 (3.0445)  time: 0.6237  data: 0.0001  max mem: 8728
Epoch: [22]  [ 840/2001]  eta: 0:12:15  lr: 0.000112  loss: 3.1805 (3.0447)  time: 0.6258  data: 0.0001  max mem: 8728
Epoch: [22]  [ 850/2001]  eta: 0:12:09  lr: 0.000112  loss: 3.1805 (3.0453)  time: 0.6269  data: 0.0001  max mem: 8728
Epoch: [22]  [ 860/2001]  eta: 0:12:02  lr: 0.000112  loss: 3.0853 (3.0459)  time: 0.6233  data: 0.0001  max mem: 8728
Epoch: [22]  [ 870/2001]  eta: 0:11:56  lr: 0.000112  loss: 3.1056 (3.0461)  time: 0.6215  data: 0.0001  max mem: 8728
Epoch: [22]  [ 880/2001]  eta: 0:11:49  lr: 0.000112  loss: 3.0846 (3.0464)  time: 0.6240  data: 0.0001  max mem: 8728
Epoch: [22]  [ 890/2001]  eta: 0:11:43  lr: 0.000112  loss: 3.1777 (3.0491)  time: 0.6292  data: 0.0001  max mem: 8728
loss info: cls_loss=3.0251, ratio_loss=0.0432, cls_kl=0.0633, token_kl=0.0914
Epoch: [22]  [ 900/2001]  eta: 0:11:36  lr: 0.000112  loss: 3.2103 (3.0490)  time: 0.6290  data: 0.0001  max mem: 8728
Epoch: [22]  [ 910/2001]  eta: 0:11:30  lr: 0.000112  loss: 3.2193 (3.0493)  time: 0.6258  data: 0.0001  max mem: 8728
Epoch: [22]  [ 920/2001]  eta: 0:11:24  lr: 0.000112  loss: 3.2323 (3.0521)  time: 0.6310  data: 0.0001  max mem: 8728
Epoch: [22]  [ 930/2001]  eta: 0:11:17  lr: 0.000112  loss: 2.8541 (3.0487)  time: 0.6325  data: 0.0001  max mem: 8728
Epoch: [22]  [ 940/2001]  eta: 0:11:11  lr: 0.000112  loss: 2.8877 (3.0524)  time: 0.6316  data: 0.0001  max mem: 8728
Epoch: [22]  [ 950/2001]  eta: 0:11:05  lr: 0.000112  loss: 3.3101 (3.0541)  time: 0.6257  data: 0.0001  max mem: 8728
Epoch: [22]  [ 960/2001]  eta: 0:10:58  lr: 0.000112  loss: 3.0556 (3.0503)  time: 0.6198  data: 0.0001  max mem: 8728
Epoch: [22]  [ 970/2001]  eta: 0:10:52  lr: 0.000112  loss: 2.7437 (3.0501)  time: 0.6239  data: 0.0001  max mem: 8728
Epoch: [22]  [ 980/2001]  eta: 0:10:45  lr: 0.000112  loss: 2.9466 (3.0484)  time: 0.6234  data: 0.0001  max mem: 8728
Epoch: [22]  [ 990/2001]  eta: 0:10:39  lr: 0.000112  loss: 2.9466 (3.0477)  time: 0.6231  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9357, ratio_loss=0.0420, cls_kl=0.0616, token_kl=0.0914
Epoch: [22]  [1000/2001]  eta: 0:10:32  lr: 0.000112  loss: 3.0760 (3.0496)  time: 0.6236  data: 0.0001  max mem: 8728
Epoch: [22]  [1010/2001]  eta: 0:10:26  lr: 0.000112  loss: 3.3790 (3.0501)  time: 0.6225  data: 0.0001  max mem: 8728
Epoch: [22]  [1020/2001]  eta: 0:10:20  lr: 0.000112  loss: 3.2405 (3.0503)  time: 0.6237  data: 0.0001  max mem: 8728
Epoch: [22]  [1030/2001]  eta: 0:10:13  lr: 0.000112  loss: 3.1568 (3.0496)  time: 0.6187  data: 0.0001  max mem: 8728
Epoch: [22]  [1040/2001]  eta: 0:10:07  lr: 0.000112  loss: 3.1568 (3.0495)  time: 0.6284  data: 0.0001  max mem: 8728
Epoch: [22]  [1050/2001]  eta: 0:10:01  lr: 0.000112  loss: 3.0165 (3.0480)  time: 0.6346  data: 0.0001  max mem: 8728
Epoch: [22]  [1060/2001]  eta: 0:09:54  lr: 0.000112  loss: 3.0834 (3.0487)  time: 0.6275  data: 0.0001  max mem: 8728
Epoch: [22]  [1070/2001]  eta: 0:09:48  lr: 0.000112  loss: 3.0492 (3.0478)  time: 0.6288  data: 0.0001  max mem: 8728
Epoch: [22]  [1080/2001]  eta: 0:09:41  lr: 0.000112  loss: 2.8297 (3.0470)  time: 0.6293  data: 0.0001  max mem: 8728
Epoch: [22]  [1090/2001]  eta: 0:09:35  lr: 0.000112  loss: 3.0312 (3.0456)  time: 0.6286  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9308, ratio_loss=0.0447, cls_kl=0.0640, token_kl=0.0948
Epoch: [22]  [1100/2001]  eta: 0:09:29  lr: 0.000112  loss: 3.2060 (3.0489)  time: 0.6267  data: 0.0001  max mem: 8728
Epoch: [22]  [1110/2001]  eta: 0:09:22  lr: 0.000112  loss: 3.1030 (3.0482)  time: 0.6258  data: 0.0001  max mem: 8728
Epoch: [22]  [1120/2001]  eta: 0:09:16  lr: 0.000112  loss: 3.0574 (3.0500)  time: 0.6215  data: 0.0001  max mem: 8728
Epoch: [22]  [1130/2001]  eta: 0:09:10  lr: 0.000112  loss: 3.0323 (3.0458)  time: 0.6231  data: 0.0001  max mem: 8728
Epoch: [22]  [1140/2001]  eta: 0:09:03  lr: 0.000112  loss: 2.5790 (3.0438)  time: 0.6255  data: 0.0001  max mem: 8728
Epoch: [22]  [1150/2001]  eta: 0:08:57  lr: 0.000112  loss: 2.8629 (3.0423)  time: 0.6264  data: 0.0001  max mem: 8728
Epoch: [22]  [1160/2001]  eta: 0:08:50  lr: 0.000112  loss: 3.0909 (3.0436)  time: 0.6252  data: 0.0001  max mem: 8728
Epoch: [22]  [1170/2001]  eta: 0:08:44  lr: 0.000112  loss: 3.2639 (3.0459)  time: 0.6250  data: 0.0001  max mem: 8728
Epoch: [22]  [1180/2001]  eta: 0:08:38  lr: 0.000112  loss: 3.3113 (3.0468)  time: 0.6319  data: 0.0001  max mem: 8728
Epoch: [22]  [1190/2001]  eta: 0:08:32  lr: 0.000112  loss: 3.0411 (3.0454)  time: 0.6283  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9091, ratio_loss=0.0447, cls_kl=0.0633, token_kl=0.0934
Epoch: [22]  [1200/2001]  eta: 0:08:25  lr: 0.000112  loss: 3.0360 (3.0448)  time: 0.6251  data: 0.0001  max mem: 8728
Epoch: [22]  [1210/2001]  eta: 0:08:19  lr: 0.000112  loss: 3.0313 (3.0443)  time: 0.6244  data: 0.0001  max mem: 8728
Epoch: [22]  [1220/2001]  eta: 0:08:12  lr: 0.000112  loss: 3.0313 (3.0444)  time: 0.6255  data: 0.0001  max mem: 8728
Epoch: [22]  [1230/2001]  eta: 0:08:06  lr: 0.000112  loss: 3.1223 (3.0447)  time: 0.6285  data: 0.0001  max mem: 8728
Epoch: [22]  [1240/2001]  eta: 0:08:00  lr: 0.000112  loss: 3.2441 (3.0458)  time: 0.6270  data: 0.0001  max mem: 8728
Epoch: [22]  [1250/2001]  eta: 0:07:53  lr: 0.000112  loss: 3.1394 (3.0461)  time: 0.6273  data: 0.0001  max mem: 8728
Epoch: [22]  [1260/2001]  eta: 0:07:47  lr: 0.000112  loss: 3.1281 (3.0468)  time: 0.6293  data: 0.0001  max mem: 8728
Epoch: [22]  [1270/2001]  eta: 0:07:41  lr: 0.000112  loss: 3.1515 (3.0476)  time: 0.6296  data: 0.0001  max mem: 8728
Epoch: [22]  [1280/2001]  eta: 0:07:35  lr: 0.000112  loss: 3.2607 (3.0492)  time: 0.6297  data: 0.0001  max mem: 8728
Epoch: [22]  [1290/2001]  eta: 0:07:28  lr: 0.000112  loss: 3.1174 (3.0471)  time: 0.6288  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9318, ratio_loss=0.0445, cls_kl=0.0627, token_kl=0.0925
Epoch: [22]  [1300/2001]  eta: 0:07:22  lr: 0.000112  loss: 2.8750 (3.0455)  time: 0.6289  data: 0.0001  max mem: 8728
Epoch: [22]  [1310/2001]  eta: 0:07:16  lr: 0.000112  loss: 2.9493 (3.0448)  time: 0.6318  data: 0.0001  max mem: 8728
Epoch: [22]  [1320/2001]  eta: 0:07:09  lr: 0.000112  loss: 3.1863 (3.0466)  time: 0.6320  data: 0.0001  max mem: 8728
Epoch: [22]  [1330/2001]  eta: 0:07:03  lr: 0.000112  loss: 3.3352 (3.0481)  time: 0.6315  data: 0.0001  max mem: 8728
Epoch: [22]  [1340/2001]  eta: 0:06:57  lr: 0.000112  loss: 2.8947 (3.0462)  time: 0.6316  data: 0.0001  max mem: 8728
Epoch: [22]  [1350/2001]  eta: 0:06:50  lr: 0.000112  loss: 2.8381 (3.0457)  time: 0.6306  data: 0.0001  max mem: 8728
Epoch: [22]  [1360/2001]  eta: 0:06:44  lr: 0.000112  loss: 3.1834 (3.0458)  time: 0.6281  data: 0.0001  max mem: 8728
Epoch: [22]  [1370/2001]  eta: 0:06:38  lr: 0.000112  loss: 3.0648 (3.0459)  time: 0.6256  data: 0.0001  max mem: 8728
Epoch: [22]  [1380/2001]  eta: 0:06:31  lr: 0.000112  loss: 3.0444 (3.0457)  time: 0.6279  data: 0.0001  max mem: 8728
Epoch: [22]  [1390/2001]  eta: 0:06:25  lr: 0.000112  loss: 3.0997 (3.0461)  time: 0.6288  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9525, ratio_loss=0.0415, cls_kl=0.0613, token_kl=0.0903
Epoch: [22]  [1400/2001]  eta: 0:06:19  lr: 0.000112  loss: 3.1620 (3.0463)  time: 0.6299  data: 0.0001  max mem: 8728
Epoch: [22]  [1410/2001]  eta: 0:06:12  lr: 0.000112  loss: 3.1453 (3.0465)  time: 0.6304  data: 0.0002  max mem: 8728
Epoch: [22]  [1420/2001]  eta: 0:06:06  lr: 0.000112  loss: 3.1223 (3.0463)  time: 0.6330  data: 0.0002  max mem: 8728
Epoch: [22]  [1430/2001]  eta: 0:06:00  lr: 0.000112  loss: 2.9936 (3.0462)  time: 0.6414  data: 0.0002  max mem: 8728
Epoch: [22]  [1440/2001]  eta: 0:05:54  lr: 0.000112  loss: 3.0553 (3.0462)  time: 0.6450  data: 0.0002  max mem: 8728
Epoch: [22]  [1450/2001]  eta: 0:05:47  lr: 0.000112  loss: 3.1679 (3.0461)  time: 0.6380  data: 0.0002  max mem: 8728
Epoch: [22]  [1460/2001]  eta: 0:05:41  lr: 0.000112  loss: 3.1679 (3.0470)  time: 0.6317  data: 0.0001  max mem: 8728
Epoch: [22]  [1470/2001]  eta: 0:05:35  lr: 0.000112  loss: 3.1930 (3.0471)  time: 0.6353  data: 0.0001  max mem: 8728
Epoch: [22]  [1480/2001]  eta: 0:05:28  lr: 0.000112  loss: 3.1930 (3.0482)  time: 0.6334  data: 0.0001  max mem: 8728
Epoch: [22]  [1490/2001]  eta: 0:05:22  lr: 0.000112  loss: 3.2532 (3.0492)  time: 0.6336  data: 0.0001  max mem: 8728
loss info: cls_loss=3.0008, ratio_loss=0.0462, cls_kl=0.0635, token_kl=0.0944
Epoch: [22]  [1500/2001]  eta: 0:05:16  lr: 0.000112  loss: 3.3281 (3.0506)  time: 0.6347  data: 0.0001  max mem: 8728
Epoch: [22]  [1510/2001]  eta: 0:05:09  lr: 0.000112  loss: 3.3056 (3.0514)  time: 0.6339  data: 0.0001  max mem: 8728
Epoch: [22]  [1520/2001]  eta: 0:05:03  lr: 0.000112  loss: 3.3056 (3.0515)  time: 0.6391  data: 0.0001  max mem: 8728
Epoch: [22]  [1530/2001]  eta: 0:04:57  lr: 0.000112  loss: 2.8861 (3.0508)  time: 0.6352  data: 0.0001  max mem: 8728
Epoch: [22]  [1540/2001]  eta: 0:04:51  lr: 0.000112  loss: 2.9871 (3.0507)  time: 0.6285  data: 0.0001  max mem: 8728
Epoch: [22]  [1550/2001]  eta: 0:04:44  lr: 0.000112  loss: 3.0146 (3.0497)  time: 0.6280  data: 0.0001  max mem: 8728
Epoch: [22]  [1560/2001]  eta: 0:04:38  lr: 0.000112  loss: 3.1314 (3.0502)  time: 0.6308  data: 0.0001  max mem: 8728
Epoch: [22]  [1570/2001]  eta: 0:04:32  lr: 0.000112  loss: 3.3177 (3.0517)  time: 0.6320  data: 0.0001  max mem: 8728
Epoch: [22]  [1580/2001]  eta: 0:04:25  lr: 0.000112  loss: 3.1933 (3.0515)  time: 0.6314  data: 0.0001  max mem: 8728
Epoch: [22]  [1590/2001]  eta: 0:04:19  lr: 0.000112  loss: 3.1833 (3.0524)  time: 0.6305  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9986, ratio_loss=0.0467, cls_kl=0.0649, token_kl=0.0946
Epoch: [22]  [1600/2001]  eta: 0:04:13  lr: 0.000112  loss: 3.3177 (3.0535)  time: 0.6290  data: 0.0001  max mem: 8728
Epoch: [22]  [1610/2001]  eta: 0:04:06  lr: 0.000112  loss: 3.3457 (3.0547)  time: 0.6311  data: 0.0001  max mem: 8728
Epoch: [22]  [1620/2001]  eta: 0:04:00  lr: 0.000112  loss: 3.2076 (3.0552)  time: 0.6328  data: 0.0001  max mem: 8728
Epoch: [22]  [1630/2001]  eta: 0:03:54  lr: 0.000112  loss: 3.2847 (3.0559)  time: 0.6327  data: 0.0001  max mem: 8728
Epoch: [22]  [1640/2001]  eta: 0:03:47  lr: 0.000112  loss: 3.2397 (3.0562)  time: 0.6333  data: 0.0001  max mem: 8728
Epoch: [22]  [1650/2001]  eta: 0:03:41  lr: 0.000112  loss: 2.9141 (3.0543)  time: 0.6311  data: 0.0001  max mem: 8728
Epoch: [22]  [1660/2001]  eta: 0:03:35  lr: 0.000112  loss: 2.9784 (3.0533)  time: 0.6320  data: 0.0001  max mem: 8728
Epoch: [22]  [1670/2001]  eta: 0:03:28  lr: 0.000112  loss: 3.0382 (3.0529)  time: 0.6347  data: 0.0001  max mem: 8728
Epoch: [22]  [1680/2001]  eta: 0:03:22  lr: 0.000112  loss: 3.2111 (3.0533)  time: 0.6329  data: 0.0001  max mem: 8728
Epoch: [22]  [1690/2001]  eta: 0:03:16  lr: 0.000112  loss: 3.2967 (3.0529)  time: 0.6310  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9286, ratio_loss=0.0438, cls_kl=0.0639, token_kl=0.0929
Epoch: [22]  [1700/2001]  eta: 0:03:10  lr: 0.000112  loss: 3.1814 (3.0532)  time: 0.6313  data: 0.0001  max mem: 8728
Epoch: [22]  [1710/2001]  eta: 0:03:03  lr: 0.000112  loss: 3.2638 (3.0544)  time: 0.6324  data: 0.0001  max mem: 8728
Epoch: [22]  [1720/2001]  eta: 0:02:57  lr: 0.000112  loss: 3.2638 (3.0545)  time: 0.6338  data: 0.0001  max mem: 8728
Epoch: [22]  [1730/2001]  eta: 0:02:51  lr: 0.000112  loss: 3.3837 (3.0567)  time: 0.6353  data: 0.0001  max mem: 8728
Epoch: [22]  [1740/2001]  eta: 0:02:44  lr: 0.000112  loss: 3.1665 (3.0553)  time: 0.6369  data: 0.0001  max mem: 8728
Epoch: [22]  [1750/2001]  eta: 0:02:38  lr: 0.000112  loss: 3.1556 (3.0557)  time: 0.6358  data: 0.0001  max mem: 8728
Epoch: [22]  [1760/2001]  eta: 0:02:32  lr: 0.000112  loss: 3.0675 (3.0552)  time: 0.6335  data: 0.0001  max mem: 8728
Epoch: [22]  [1770/2001]  eta: 0:02:25  lr: 0.000112  loss: 2.8901 (3.0543)  time: 0.6340  data: 0.0001  max mem: 8728
Epoch: [22]  [1780/2001]  eta: 0:02:19  lr: 0.000112  loss: 3.0698 (3.0540)  time: 0.6394  data: 0.0001  max mem: 8728
Epoch: [22]  [1790/2001]  eta: 0:02:13  lr: 0.000112  loss: 3.0740 (3.0545)  time: 0.6387  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9543, ratio_loss=0.0434, cls_kl=0.0615, token_kl=0.0919
Epoch: [22]  [1800/2001]  eta: 0:02:06  lr: 0.000112  loss: 3.1867 (3.0530)  time: 0.6344  data: 0.0001  max mem: 8728
Epoch: [22]  [1810/2001]  eta: 0:02:00  lr: 0.000112  loss: 3.2160 (3.0532)  time: 0.6338  data: 0.0001  max mem: 8728
Epoch: [22]  [1820/2001]  eta: 0:01:54  lr: 0.000112  loss: 3.0909 (3.0517)  time: 0.6320  data: 0.0001  max mem: 8728
Epoch: [22]  [1830/2001]  eta: 0:01:48  lr: 0.000112  loss: 3.0909 (3.0518)  time: 0.6318  data: 0.0001  max mem: 8728
Epoch: [22]  [1840/2001]  eta: 0:01:41  lr: 0.000112  loss: 3.1457 (3.0509)  time: 0.6315  data: 0.0001  max mem: 8728
Epoch: [22]  [1850/2001]  eta: 0:01:35  lr: 0.000112  loss: 3.0165 (3.0508)  time: 0.6322  data: 0.0001  max mem: 8728
Epoch: [22]  [1860/2001]  eta: 0:01:29  lr: 0.000112  loss: 3.0745 (3.0502)  time: 0.6335  data: 0.0001  max mem: 8728
Epoch: [22]  [1870/2001]  eta: 0:01:22  lr: 0.000112  loss: 3.1896 (3.0513)  time: 0.6320  data: 0.0001  max mem: 8728
Epoch: [22]  [1880/2001]  eta: 0:01:16  lr: 0.000112  loss: 3.2194 (3.0503)  time: 0.6314  data: 0.0001  max mem: 8728
Epoch: [22]  [1890/2001]  eta: 0:01:10  lr: 0.000112  loss: 3.1658 (3.0511)  time: 0.6322  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8958, ratio_loss=0.0423, cls_kl=0.0614, token_kl=0.0931
Epoch: [22]  [1900/2001]  eta: 0:01:03  lr: 0.000112  loss: 3.1658 (3.0508)  time: 0.6370  data: 0.0001  max mem: 8728
Epoch: [22]  [1910/2001]  eta: 0:00:57  lr: 0.000112  loss: 2.8591 (3.0496)  time: 0.6361  data: 0.0001  max mem: 8728
Epoch: [22]  [1920/2001]  eta: 0:00:51  lr: 0.000112  loss: 2.9151 (3.0494)  time: 0.6308  data: 0.0001  max mem: 8728
Epoch: [22]  [1930/2001]  eta: 0:00:44  lr: 0.000112  loss: 3.2124 (3.0501)  time: 0.6323  data: 0.0001  max mem: 8728
Epoch: [22]  [1940/2001]  eta: 0:00:38  lr: 0.000112  loss: 3.1698 (3.0501)  time: 0.6323  data: 0.0001  max mem: 8728
Epoch: [22]  [1950/2001]  eta: 0:00:32  lr: 0.000112  loss: 3.0809 (3.0492)  time: 0.6331  data: 0.0001  max mem: 8728
Epoch: [22]  [1960/2001]  eta: 0:00:25  lr: 0.000112  loss: 2.9149 (3.0490)  time: 0.6370  data: 0.0001  max mem: 8728
Epoch: [22]  [1970/2001]  eta: 0:00:19  lr: 0.000112  loss: 3.1037 (3.0489)  time: 0.6354  data: 0.0001  max mem: 8728
Epoch: [22]  [1980/2001]  eta: 0:00:13  lr: 0.000112  loss: 3.1501 (3.0504)  time: 0.6310  data: 0.0001  max mem: 8728
Epoch: [22]  [1990/2001]  eta: 0:00:06  lr: 0.000112  loss: 3.3163 (3.0493)  time: 0.6250  data: 0.0004  max mem: 8728
loss info: cls_loss=2.9168, ratio_loss=0.0455, cls_kl=0.0622, token_kl=0.0950
Epoch: [22]  [2000/2001]  eta: 0:00:00  lr: 0.000112  loss: 3.1451 (3.0489)  time: 0.6235  data: 0.0004  max mem: 8728
Epoch: [22] Total time: 0:21:04 (0.6319 s / it)
Averaged stats: lr: 0.000112  loss: 3.1451 (3.0466)
Test:  [ 0/53]  eta: 0:05:39  loss: 0.3924 (0.3924)  acc1: 94.1667 (94.1667)  acc5: 99.1667 (99.1667)  time: 6.4139  data: 5.4308  max mem: 8728
Test:  [10/53]  eta: 0:00:40  loss: 0.7672 (0.7665)  acc1: 83.3333 (83.5606)  acc5: 97.5000 (96.8182)  time: 0.9391  data: 0.4944  max mem: 8728
Test:  [20/53]  eta: 0:00:21  loss: 0.7233 (0.7684)  acc1: 83.3333 (83.1746)  acc5: 96.6667 (96.6667)  time: 0.3723  data: 0.0005  max mem: 8728
Test:  [30/53]  eta: 0:00:12  loss: 0.8864 (0.8548)  acc1: 79.1667 (80.9946)  acc5: 94.1667 (95.3763)  time: 0.3418  data: 0.0002  max mem: 8728
Test:  [40/53]  eta: 0:00:06  loss: 1.1193 (0.9232)  acc1: 75.8333 (79.3902)  acc5: 91.6667 (94.4919)  time: 0.2974  data: 0.0002  max mem: 8728
Test:  [50/53]  eta: 0:00:01  loss: 1.1142 (0.9537)  acc1: 75.8333 (78.6765)  acc5: 92.5000 (94.2811)  time: 0.2596  data: 0.0001  max mem: 8728
Test:  [52/53]  eta: 0:00:00  loss: 1.0950 (0.9414)  acc1: 76.6667 (78.8640)  acc5: 92.5000 (94.3520)  time: 0.2460  data: 0.0001  max mem: 8728
Test: Total time: 0:00:22 (0.4304 s / it)
Sparsity0:0.2952460606060606,Sparsity1:0.5508470351758794,Sparsity2:0.7843584,
* Acc@1 79.064 Acc@5 94.490 loss 0.937
Accuracy of the network on the 50000 test images: 79.1%
Max accuracy: 79.06%
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0000890 for PREDICTOR
Epoch: [23]  [   0/2001]  eta: 2:34:17  lr: 0.000089  loss: 3.3155 (3.3155)  time: 4.6263  data: 3.9407  max mem: 8728
Epoch: [23]  [  10/2001]  eta: 0:32:30  lr: 0.000089  loss: 2.9838 (2.9800)  time: 0.9796  data: 0.3584  max mem: 8730
Epoch: [23]  [  20/2001]  eta: 0:26:35  lr: 0.000089  loss: 3.0150 (3.0659)  time: 0.6141  data: 0.0001  max mem: 8730
Epoch: [23]  [  30/2001]  eta: 0:24:24  lr: 0.000089  loss: 3.4029 (3.1535)  time: 0.6125  data: 0.0001  max mem: 8730
Epoch: [23]  [  40/2001]  eta: 0:23:18  lr: 0.000089  loss: 3.3988 (3.2074)  time: 0.6161  data: 0.0002  max mem: 8730
Epoch: [23]  [  50/2001]  eta: 0:22:34  lr: 0.000089  loss: 3.2381 (3.1741)  time: 0.6188  data: 0.0001  max mem: 8730
Epoch: [23]  [  60/2001]  eta: 0:22:07  lr: 0.000089  loss: 3.0219 (3.1446)  time: 0.6250  data: 0.0002  max mem: 8730
Epoch: [23]  [  70/2001]  eta: 0:21:43  lr: 0.000089  loss: 2.9990 (3.1319)  time: 0.6270  data: 0.0002  max mem: 8730
Epoch: [23]  [  80/2001]  eta: 0:21:25  lr: 0.000089  loss: 3.0579 (3.1313)  time: 0.6244  data: 0.0002  max mem: 8730
Epoch: [23]  [  90/2001]  eta: 0:21:09  lr: 0.000089  loss: 3.1245 (3.1335)  time: 0.6256  data: 0.0002  max mem: 8730
loss info: cls_loss=3.0105, ratio_loss=0.0438, cls_kl=0.0657, token_kl=0.0941
Epoch: [23]  [ 100/2001]  eta: 0:20:55  lr: 0.000089  loss: 3.0818 (3.1234)  time: 0.6248  data: 0.0002  max mem: 8730
Epoch: [23]  [ 110/2001]  eta: 0:20:43  lr: 0.000089  loss: 3.1518 (3.1217)  time: 0.6279  data: 0.0002  max mem: 8730
Epoch: [23]  [ 120/2001]  eta: 0:20:32  lr: 0.000089  loss: 3.3042 (3.1272)  time: 0.6284  data: 0.0002  max mem: 8730
Epoch: [23]  [ 130/2001]  eta: 0:20:22  lr: 0.000089  loss: 2.9963 (3.1193)  time: 0.6274  data: 0.0002  max mem: 8730
Epoch: [23]  [ 140/2001]  eta: 0:20:12  lr: 0.000089  loss: 2.9684 (3.0953)  time: 0.6301  data: 0.0002  max mem: 8730
Epoch: [23]  [ 150/2001]  eta: 0:20:03  lr: 0.000089  loss: 3.1027 (3.0954)  time: 0.6294  data: 0.0002  max mem: 8730
Epoch: [23]  [ 160/2001]  eta: 0:19:54  lr: 0.000089  loss: 2.9916 (3.0865)  time: 0.6295  data: 0.0002  max mem: 8730
Epoch: [23]  [ 170/2001]  eta: 0:19:45  lr: 0.000089  loss: 3.2818 (3.1020)  time: 0.6299  data: 0.0002  max mem: 8730
Epoch: [23]  [ 180/2001]  eta: 0:19:37  lr: 0.000089  loss: 3.2725 (3.0968)  time: 0.6264  data: 0.0002  max mem: 8730
Epoch: [23]  [ 190/2001]  eta: 0:19:28  lr: 0.000089  loss: 2.9512 (3.0943)  time: 0.6270  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9603, ratio_loss=0.0450, cls_kl=0.0651, token_kl=0.0936
Epoch: [23]  [ 200/2001]  eta: 0:19:20  lr: 0.000089  loss: 3.3484 (3.1067)  time: 0.6247  data: 0.0002  max mem: 8730
Epoch: [23]  [ 210/2001]  eta: 0:19:12  lr: 0.000089  loss: 3.3052 (3.1022)  time: 0.6245  data: 0.0002  max mem: 8730
Epoch: [23]  [ 220/2001]  eta: 0:19:05  lr: 0.000089  loss: 3.1980 (3.1004)  time: 0.6314  data: 0.0001  max mem: 8730
Epoch: [23]  [ 230/2001]  eta: 0:18:58  lr: 0.000089  loss: 3.1371 (3.0965)  time: 0.6368  data: 0.0002  max mem: 8730
Epoch: [23]  [ 240/2001]  eta: 0:18:51  lr: 0.000089  loss: 3.1371 (3.0980)  time: 0.6350  data: 0.0001  max mem: 8730
Epoch: [23]  [ 250/2001]  eta: 0:18:43  lr: 0.000089  loss: 3.0507 (3.0873)  time: 0.6263  data: 0.0001  max mem: 8730
Epoch: [23]  [ 260/2001]  eta: 0:18:36  lr: 0.000089  loss: 2.9274 (3.0913)  time: 0.6261  data: 0.0001  max mem: 8730
Epoch: [23]  [ 270/2001]  eta: 0:18:29  lr: 0.000089  loss: 3.3699 (3.0971)  time: 0.6290  data: 0.0001  max mem: 8730
Epoch: [23]  [ 280/2001]  eta: 0:18:21  lr: 0.000089  loss: 3.0790 (3.0960)  time: 0.6246  data: 0.0001  max mem: 8730
Epoch: [23]  [ 290/2001]  eta: 0:18:14  lr: 0.000089  loss: 3.0960 (3.0947)  time: 0.6232  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9632, ratio_loss=0.0448, cls_kl=0.0653, token_kl=0.0948
Epoch: [23]  [ 300/2001]  eta: 0:18:06  lr: 0.000089  loss: 3.0618 (3.0915)  time: 0.6252  data: 0.0002  max mem: 8730
Epoch: [23]  [ 310/2001]  eta: 0:17:59  lr: 0.000089  loss: 3.2490 (3.0970)  time: 0.6260  data: 0.0002  max mem: 8730
Epoch: [23]  [ 320/2001]  eta: 0:17:53  lr: 0.000089  loss: 3.3639 (3.0964)  time: 0.6282  data: 0.0002  max mem: 8730
Epoch: [23]  [ 330/2001]  eta: 0:17:45  lr: 0.000089  loss: 3.3235 (3.0989)  time: 0.6270  data: 0.0002  max mem: 8730
Epoch: [23]  [ 340/2001]  eta: 0:17:39  lr: 0.000089  loss: 3.3235 (3.0989)  time: 0.6272  data: 0.0002  max mem: 8730
Epoch: [23]  [ 350/2001]  eta: 0:17:32  lr: 0.000089  loss: 3.1193 (3.0973)  time: 0.6277  data: 0.0001  max mem: 8730
Epoch: [23]  [ 360/2001]  eta: 0:17:25  lr: 0.000089  loss: 3.2591 (3.1047)  time: 0.6271  data: 0.0002  max mem: 8730
Epoch: [23]  [ 370/2001]  eta: 0:17:18  lr: 0.000089  loss: 3.3541 (3.1038)  time: 0.6254  data: 0.0002  max mem: 8730
Epoch: [23]  [ 380/2001]  eta: 0:17:11  lr: 0.000089  loss: 3.1961 (3.1028)  time: 0.6228  data: 0.0002  max mem: 8730
Epoch: [23]  [ 390/2001]  eta: 0:17:04  lr: 0.000089  loss: 3.2816 (3.1103)  time: 0.6210  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0597, ratio_loss=0.0484, cls_kl=0.0656, token_kl=0.0937
Epoch: [23]  [ 400/2001]  eta: 0:16:57  lr: 0.000089  loss: 3.3186 (3.1117)  time: 0.6244  data: 0.0001  max mem: 8730
Epoch: [23]  [ 410/2001]  eta: 0:16:51  lr: 0.000089  loss: 2.9977 (3.1052)  time: 0.6322  data: 0.0001  max mem: 8730
Epoch: [23]  [ 420/2001]  eta: 0:16:44  lr: 0.000089  loss: 3.1170 (3.1072)  time: 0.6267  data: 0.0001  max mem: 8730
Epoch: [23]  [ 430/2001]  eta: 0:16:37  lr: 0.000089  loss: 3.2149 (3.1085)  time: 0.6261  data: 0.0001  max mem: 8730
Epoch: [23]  [ 440/2001]  eta: 0:16:31  lr: 0.000089  loss: 2.8238 (3.0944)  time: 0.6346  data: 0.0001  max mem: 8730
Epoch: [23]  [ 450/2001]  eta: 0:16:25  lr: 0.000089  loss: 2.5653 (3.0923)  time: 0.6342  data: 0.0002  max mem: 8730
Epoch: [23]  [ 460/2001]  eta: 0:16:18  lr: 0.000089  loss: 3.0297 (3.0894)  time: 0.6266  data: 0.0002  max mem: 8730
Epoch: [23]  [ 470/2001]  eta: 0:16:11  lr: 0.000089  loss: 3.0297 (3.0910)  time: 0.6237  data: 0.0002  max mem: 8730
Epoch: [23]  [ 480/2001]  eta: 0:16:04  lr: 0.000089  loss: 3.2354 (3.0905)  time: 0.6234  data: 0.0002  max mem: 8730
Epoch: [23]  [ 490/2001]  eta: 0:15:58  lr: 0.000089  loss: 3.0738 (3.0886)  time: 0.6292  data: 0.0002  max mem: 8730
loss info: cls_loss=2.8953, ratio_loss=0.0416, cls_kl=0.0605, token_kl=0.0902
Epoch: [23]  [ 500/2001]  eta: 0:15:52  lr: 0.000089  loss: 3.0201 (3.0891)  time: 0.6375  data: 0.0002  max mem: 8730
Epoch: [23]  [ 510/2001]  eta: 0:15:46  lr: 0.000089  loss: 3.0201 (3.0868)  time: 0.6388  data: 0.0002  max mem: 8730
Epoch: [23]  [ 520/2001]  eta: 0:15:39  lr: 0.000089  loss: 2.9011 (3.0843)  time: 0.6367  data: 0.0002  max mem: 8730
Epoch: [23]  [ 530/2001]  eta: 0:15:33  lr: 0.000089  loss: 2.8700 (3.0783)  time: 0.6330  data: 0.0002  max mem: 8730
Epoch: [23]  [ 540/2001]  eta: 0:15:27  lr: 0.000089  loss: 2.8374 (3.0729)  time: 0.6314  data: 0.0002  max mem: 8730
Epoch: [23]  [ 550/2001]  eta: 0:15:20  lr: 0.000089  loss: 2.9721 (3.0730)  time: 0.6300  data: 0.0002  max mem: 8730
Epoch: [23]  [ 560/2001]  eta: 0:15:14  lr: 0.000089  loss: 3.1429 (3.0736)  time: 0.6362  data: 0.0001  max mem: 8730
Epoch: [23]  [ 570/2001]  eta: 0:15:07  lr: 0.000089  loss: 3.1429 (3.0739)  time: 0.6337  data: 0.0001  max mem: 8730
Epoch: [23]  [ 580/2001]  eta: 0:15:01  lr: 0.000089  loss: 3.2443 (3.0772)  time: 0.6241  data: 0.0001  max mem: 8730
Epoch: [23]  [ 590/2001]  eta: 0:14:54  lr: 0.000089  loss: 3.1642 (3.0743)  time: 0.6250  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8977, ratio_loss=0.0424, cls_kl=0.0624, token_kl=0.0926
Epoch: [23]  [ 600/2001]  eta: 0:14:48  lr: 0.000089  loss: 3.0879 (3.0751)  time: 0.6249  data: 0.0001  max mem: 8730
Epoch: [23]  [ 610/2001]  eta: 0:14:41  lr: 0.000089  loss: 3.0879 (3.0740)  time: 0.6258  data: 0.0002  max mem: 8730
Epoch: [23]  [ 620/2001]  eta: 0:14:35  lr: 0.000089  loss: 3.2413 (3.0774)  time: 0.6280  data: 0.0001  max mem: 8730
Epoch: [23]  [ 630/2001]  eta: 0:14:28  lr: 0.000089  loss: 3.2413 (3.0754)  time: 0.6256  data: 0.0001  max mem: 8730
Epoch: [23]  [ 640/2001]  eta: 0:14:22  lr: 0.000089  loss: 2.9015 (3.0728)  time: 0.6259  data: 0.0001  max mem: 8730
Epoch: [23]  [ 650/2001]  eta: 0:14:15  lr: 0.000089  loss: 2.8904 (3.0703)  time: 0.6313  data: 0.0001  max mem: 8730
Epoch: [23]  [ 660/2001]  eta: 0:14:09  lr: 0.000089  loss: 3.0413 (3.0730)  time: 0.6331  data: 0.0001  max mem: 8730
Epoch: [23]  [ 670/2001]  eta: 0:14:03  lr: 0.000089  loss: 3.0572 (3.0721)  time: 0.6336  data: 0.0001  max mem: 8730
Epoch: [23]  [ 680/2001]  eta: 0:13:56  lr: 0.000089  loss: 2.7299 (3.0674)  time: 0.6288  data: 0.0001  max mem: 8730
Epoch: [23]  [ 690/2001]  eta: 0:13:50  lr: 0.000089  loss: 2.9529 (3.0690)  time: 0.6250  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9332, ratio_loss=0.0450, cls_kl=0.0639, token_kl=0.0957
Epoch: [23]  [ 700/2001]  eta: 0:13:43  lr: 0.000089  loss: 3.2947 (3.0702)  time: 0.6285  data: 0.0001  max mem: 8730
Epoch: [23]  [ 710/2001]  eta: 0:13:37  lr: 0.000089  loss: 3.1774 (3.0705)  time: 0.6284  data: 0.0001  max mem: 8730
Epoch: [23]  [ 720/2001]  eta: 0:13:30  lr: 0.000089  loss: 3.2213 (3.0715)  time: 0.6282  data: 0.0002  max mem: 8730
Epoch: [23]  [ 730/2001]  eta: 0:13:24  lr: 0.000089  loss: 3.1937 (3.0679)  time: 0.6284  data: 0.0002  max mem: 8730
Epoch: [23]  [ 740/2001]  eta: 0:13:18  lr: 0.000089  loss: 3.0632 (3.0666)  time: 0.6271  data: 0.0001  max mem: 8730
Epoch: [23]  [ 750/2001]  eta: 0:13:11  lr: 0.000089  loss: 3.1802 (3.0693)  time: 0.6293  data: 0.0001  max mem: 8730
Epoch: [23]  [ 760/2001]  eta: 0:13:05  lr: 0.000089  loss: 3.3870 (3.0710)  time: 0.6310  data: 0.0001  max mem: 8730
Epoch: [23]  [ 770/2001]  eta: 0:12:58  lr: 0.000089  loss: 3.3161 (3.0725)  time: 0.6295  data: 0.0001  max mem: 8730
Epoch: [23]  [ 780/2001]  eta: 0:12:52  lr: 0.000089  loss: 3.2457 (3.0707)  time: 0.6311  data: 0.0002  max mem: 8730
Epoch: [23]  [ 790/2001]  eta: 0:12:46  lr: 0.000089  loss: 3.2294 (3.0720)  time: 0.6325  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9670, ratio_loss=0.0437, cls_kl=0.0646, token_kl=0.0928
Epoch: [23]  [ 800/2001]  eta: 0:12:39  lr: 0.000089  loss: 3.0390 (3.0708)  time: 0.6307  data: 0.0001  max mem: 8730
Epoch: [23]  [ 810/2001]  eta: 0:12:33  lr: 0.000089  loss: 2.9624 (3.0702)  time: 0.6289  data: 0.0001  max mem: 8730
Epoch: [23]  [ 820/2001]  eta: 0:12:27  lr: 0.000089  loss: 3.1615 (3.0721)  time: 0.6281  data: 0.0001  max mem: 8730
Epoch: [23]  [ 830/2001]  eta: 0:12:20  lr: 0.000089  loss: 3.3969 (3.0773)  time: 0.6347  data: 0.0001  max mem: 8730
Epoch: [23]  [ 840/2001]  eta: 0:12:14  lr: 0.000089  loss: 3.3742 (3.0764)  time: 0.6374  data: 0.0001  max mem: 8730
Epoch: [23]  [ 850/2001]  eta: 0:12:08  lr: 0.000089  loss: 3.1119 (3.0762)  time: 0.6351  data: 0.0001  max mem: 8730
Epoch: [23]  [ 860/2001]  eta: 0:12:01  lr: 0.000089  loss: 2.9872 (3.0746)  time: 0.6325  data: 0.0001  max mem: 8730
Epoch: [23]  [ 870/2001]  eta: 0:11:55  lr: 0.000089  loss: 3.2340 (3.0782)  time: 0.6335  data: 0.0001  max mem: 8730
Epoch: [23]  [ 880/2001]  eta: 0:11:49  lr: 0.000089  loss: 3.2340 (3.0767)  time: 0.6335  data: 0.0001  max mem: 8730
Epoch: [23]  [ 890/2001]  eta: 0:11:42  lr: 0.000089  loss: 3.1473 (3.0784)  time: 0.6297  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0177, ratio_loss=0.0469, cls_kl=0.0669, token_kl=0.0957
Epoch: [23]  [ 900/2001]  eta: 0:11:36  lr: 0.000089  loss: 3.1473 (3.0776)  time: 0.6321  data: 0.0001  max mem: 8730
Epoch: [23]  [ 910/2001]  eta: 0:11:30  lr: 0.000089  loss: 3.1624 (3.0785)  time: 0.6306  data: 0.0001  max mem: 8730
Epoch: [23]  [ 920/2001]  eta: 0:11:24  lr: 0.000089  loss: 3.1153 (3.0761)  time: 0.6337  data: 0.0001  max mem: 8730
Epoch: [23]  [ 930/2001]  eta: 0:11:17  lr: 0.000089  loss: 3.2325 (3.0771)  time: 0.6385  data: 0.0001  max mem: 8730
Epoch: [23]  [ 940/2001]  eta: 0:11:11  lr: 0.000089  loss: 3.2394 (3.0784)  time: 0.6356  data: 0.0001  max mem: 8730
Epoch: [23]  [ 950/2001]  eta: 0:11:05  lr: 0.000089  loss: 3.1261 (3.0775)  time: 0.6299  data: 0.0001  max mem: 8730
Epoch: [23]  [ 960/2001]  eta: 0:10:58  lr: 0.000089  loss: 3.1344 (3.0781)  time: 0.6301  data: 0.0001  max mem: 8730
Epoch: [23]  [ 970/2001]  eta: 0:10:52  lr: 0.000089  loss: 3.0835 (3.0748)  time: 0.6311  data: 0.0001  max mem: 8730
Epoch: [23]  [ 980/2001]  eta: 0:10:46  lr: 0.000089  loss: 2.7166 (3.0731)  time: 0.6340  data: 0.0001  max mem: 8730
Epoch: [23]  [ 990/2001]  eta: 0:10:39  lr: 0.000089  loss: 3.0646 (3.0736)  time: 0.6397  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9335, ratio_loss=0.0412, cls_kl=0.0610, token_kl=0.0909
Epoch: [23]  [1000/2001]  eta: 0:10:33  lr: 0.000089  loss: 3.1934 (3.0733)  time: 0.6351  data: 0.0001  max mem: 8730
Epoch: [23]  [1010/2001]  eta: 0:10:27  lr: 0.000089  loss: 3.2504 (3.0736)  time: 0.6313  data: 0.0001  max mem: 8730
Epoch: [23]  [1020/2001]  eta: 0:10:20  lr: 0.000089  loss: 3.2504 (3.0732)  time: 0.6324  data: 0.0001  max mem: 8730
Epoch: [23]  [1030/2001]  eta: 0:10:14  lr: 0.000089  loss: 2.9900 (3.0725)  time: 0.6335  data: 0.0001  max mem: 8730
Epoch: [23]  [1040/2001]  eta: 0:10:08  lr: 0.000089  loss: 3.0404 (3.0728)  time: 0.6331  data: 0.0001  max mem: 8730
Epoch: [23]  [1050/2001]  eta: 0:10:01  lr: 0.000089  loss: 3.3195 (3.0766)  time: 0.6326  data: 0.0001  max mem: 8730
Epoch: [23]  [1060/2001]  eta: 0:09:55  lr: 0.000089  loss: 3.3052 (3.0748)  time: 0.6322  data: 0.0001  max mem: 8730
Epoch: [23]  [1070/2001]  eta: 0:09:49  lr: 0.000089  loss: 3.0743 (3.0735)  time: 0.6306  data: 0.0001  max mem: 8730
Epoch: [23]  [1080/2001]  eta: 0:09:42  lr: 0.000089  loss: 3.0743 (3.0748)  time: 0.6343  data: 0.0001  max mem: 8730
Epoch: [23]  [1090/2001]  eta: 0:09:36  lr: 0.000089  loss: 3.2647 (3.0758)  time: 0.6429  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9990, ratio_loss=0.0428, cls_kl=0.0631, token_kl=0.0922
Epoch: [23]  [1100/2001]  eta: 0:09:30  lr: 0.000089  loss: 3.2062 (3.0762)  time: 0.6398  data: 0.0001  max mem: 8730
Epoch: [23]  [1110/2001]  eta: 0:09:23  lr: 0.000089  loss: 3.1910 (3.0742)  time: 0.6337  data: 0.0001  max mem: 8730
Epoch: [23]  [1120/2001]  eta: 0:09:17  lr: 0.000089  loss: 3.2803 (3.0761)  time: 0.6363  data: 0.0001  max mem: 8730
Epoch: [23]  [1130/2001]  eta: 0:09:11  lr: 0.000089  loss: 3.2870 (3.0785)  time: 0.6376  data: 0.0001  max mem: 8730
Epoch: [23]  [1140/2001]  eta: 0:09:05  lr: 0.000089  loss: 3.4027 (3.0796)  time: 0.6344  data: 0.0001  max mem: 8730
Epoch: [23]  [1150/2001]  eta: 0:08:58  lr: 0.000089  loss: 3.2930 (3.0780)  time: 0.6321  data: 0.0001  max mem: 8730
Epoch: [23]  [1160/2001]  eta: 0:08:52  lr: 0.000089  loss: 3.2237 (3.0787)  time: 0.6344  data: 0.0001  max mem: 8730
Epoch: [23]  [1170/2001]  eta: 0:08:46  lr: 0.000089  loss: 3.2237 (3.0779)  time: 0.6368  data: 0.0001  max mem: 8730
Epoch: [23]  [1180/2001]  eta: 0:08:39  lr: 0.000089  loss: 3.2585 (3.0806)  time: 0.6348  data: 0.0001  max mem: 8730
Epoch: [23]  [1190/2001]  eta: 0:08:33  lr: 0.000089  loss: 3.3292 (3.0807)  time: 0.6316  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0226, ratio_loss=0.0475, cls_kl=0.0657, token_kl=0.0965
Epoch: [23]  [1200/2001]  eta: 0:08:27  lr: 0.000089  loss: 3.2441 (3.0811)  time: 0.6326  data: 0.0001  max mem: 8730
Epoch: [23]  [1210/2001]  eta: 0:08:20  lr: 0.000089  loss: 3.1486 (3.0809)  time: 0.6363  data: 0.0001  max mem: 8730
Epoch: [23]  [1220/2001]  eta: 0:08:14  lr: 0.000089  loss: 3.1486 (3.0801)  time: 0.6359  data: 0.0002  max mem: 8730
Epoch: [23]  [1230/2001]  eta: 0:08:08  lr: 0.000089  loss: 3.0790 (3.0803)  time: 0.6327  data: 0.0001  max mem: 8730
Epoch: [23]  [1240/2001]  eta: 0:08:01  lr: 0.000089  loss: 2.9884 (3.0799)  time: 0.6339  data: 0.0001  max mem: 8730
Epoch: [23]  [1250/2001]  eta: 0:07:55  lr: 0.000089  loss: 3.0150 (3.0801)  time: 0.6396  data: 0.0001  max mem: 8730
Epoch: [23]  [1260/2001]  eta: 0:07:49  lr: 0.000089  loss: 3.1495 (3.0801)  time: 0.6418  data: 0.0001  max mem: 8730
Epoch: [23]  [1270/2001]  eta: 0:07:42  lr: 0.000089  loss: 3.1495 (3.0801)  time: 0.6400  data: 0.0001  max mem: 8730
Epoch: [23]  [1280/2001]  eta: 0:07:36  lr: 0.000089  loss: 3.2894 (3.0804)  time: 0.6374  data: 0.0001  max mem: 8730
Epoch: [23]  [1290/2001]  eta: 0:07:30  lr: 0.000089  loss: 3.2641 (3.0802)  time: 0.6349  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9548, ratio_loss=0.0446, cls_kl=0.0640, token_kl=0.0946
Epoch: [23]  [1300/2001]  eta: 0:07:24  lr: 0.000089  loss: 3.2307 (3.0796)  time: 0.6353  data: 0.0001  max mem: 8730
Epoch: [23]  [1310/2001]  eta: 0:07:17  lr: 0.000089  loss: 3.1938 (3.0796)  time: 0.6355  data: 0.0001  max mem: 8730
Epoch: [23]  [1320/2001]  eta: 0:07:11  lr: 0.000089  loss: 2.9921 (3.0788)  time: 0.6341  data: 0.0001  max mem: 8730
Epoch: [23]  [1330/2001]  eta: 0:07:05  lr: 0.000089  loss: 2.9392 (3.0788)  time: 0.6331  data: 0.0001  max mem: 8730
Epoch: [23]  [1340/2001]  eta: 0:06:58  lr: 0.000089  loss: 3.1108 (3.0788)  time: 0.6322  data: 0.0001  max mem: 8730
Epoch: [23]  [1350/2001]  eta: 0:06:52  lr: 0.000089  loss: 3.1749 (3.0795)  time: 0.6373  data: 0.0001  max mem: 8730
Epoch: [23]  [1360/2001]  eta: 0:06:46  lr: 0.000089  loss: 3.1738 (3.0776)  time: 0.6431  data: 0.0001  max mem: 8730
Epoch: [23]  [1370/2001]  eta: 0:06:39  lr: 0.000089  loss: 2.9815 (3.0769)  time: 0.6377  data: 0.0001  max mem: 8730
Epoch: [23]  [1380/2001]  eta: 0:06:33  lr: 0.000089  loss: 3.2442 (3.0774)  time: 0.6328  data: 0.0001  max mem: 8730
Epoch: [23]  [1390/2001]  eta: 0:06:27  lr: 0.000089  loss: 3.2487 (3.0774)  time: 0.6325  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9361, ratio_loss=0.0428, cls_kl=0.0623, token_kl=0.0914
Epoch: [23]  [1400/2001]  eta: 0:06:20  lr: 0.000089  loss: 3.2406 (3.0773)  time: 0.6312  data: 0.0001  max mem: 8730
Epoch: [23]  [1410/2001]  eta: 0:06:14  lr: 0.000089  loss: 3.2632 (3.0774)  time: 0.6329  data: 0.0002  max mem: 8730
Epoch: [23]  [1420/2001]  eta: 0:06:08  lr: 0.000089  loss: 3.2850 (3.0777)  time: 0.6345  data: 0.0001  max mem: 8730
Epoch: [23]  [1430/2001]  eta: 0:06:01  lr: 0.000089  loss: 3.1680 (3.0767)  time: 0.6336  data: 0.0001  max mem: 8730
Epoch: [23]  [1440/2001]  eta: 0:05:55  lr: 0.000089  loss: 3.0328 (3.0766)  time: 0.6322  data: 0.0001  max mem: 8730
Epoch: [23]  [1450/2001]  eta: 0:05:49  lr: 0.000089  loss: 3.0926 (3.0753)  time: 0.6293  data: 0.0001  max mem: 8730
Epoch: [23]  [1460/2001]  eta: 0:05:42  lr: 0.000089  loss: 3.2250 (3.0758)  time: 0.6280  data: 0.0001  max mem: 8730
Epoch: [23]  [1470/2001]  eta: 0:05:36  lr: 0.000089  loss: 3.2538 (3.0764)  time: 0.6289  data: 0.0001  max mem: 8730
Epoch: [23]  [1480/2001]  eta: 0:05:29  lr: 0.000089  loss: 2.7550 (3.0724)  time: 0.6268  data: 0.0001  max mem: 8730
Epoch: [23]  [1490/2001]  eta: 0:05:23  lr: 0.000089  loss: 2.9165 (3.0733)  time: 0.6269  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9280, ratio_loss=0.0418, cls_kl=0.0610, token_kl=0.0902
Epoch: [23]  [1500/2001]  eta: 0:05:17  lr: 0.000089  loss: 3.2582 (3.0744)  time: 0.6328  data: 0.0001  max mem: 8730
Epoch: [23]  [1510/2001]  eta: 0:05:10  lr: 0.000089  loss: 3.2582 (3.0745)  time: 0.6341  data: 0.0001  max mem: 8730
Epoch: [23]  [1520/2001]  eta: 0:05:04  lr: 0.000089  loss: 3.2978 (3.0755)  time: 0.6323  data: 0.0001  max mem: 8730
Epoch: [23]  [1530/2001]  eta: 0:04:58  lr: 0.000089  loss: 3.3079 (3.0766)  time: 0.6320  data: 0.0001  max mem: 8730
Epoch: [23]  [1540/2001]  eta: 0:04:51  lr: 0.000089  loss: 3.1592 (3.0771)  time: 0.6263  data: 0.0001  max mem: 8730
Epoch: [23]  [1550/2001]  eta: 0:04:45  lr: 0.000089  loss: 3.1660 (3.0776)  time: 0.6253  data: 0.0001  max mem: 8730
Epoch: [23]  [1560/2001]  eta: 0:04:39  lr: 0.000089  loss: 3.1074 (3.0773)  time: 0.6272  data: 0.0001  max mem: 8730
Epoch: [23]  [1570/2001]  eta: 0:04:32  lr: 0.000089  loss: 3.1529 (3.0781)  time: 0.6267  data: 0.0001  max mem: 8730
Epoch: [23]  [1580/2001]  eta: 0:04:26  lr: 0.000089  loss: 3.2948 (3.0790)  time: 0.6267  data: 0.0001  max mem: 8730
Epoch: [23]  [1590/2001]  eta: 0:04:20  lr: 0.000089  loss: 3.1814 (3.0783)  time: 0.6249  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0327, ratio_loss=0.0459, cls_kl=0.0647, token_kl=0.0943
Epoch: [23]  [1600/2001]  eta: 0:04:13  lr: 0.000089  loss: 3.1602 (3.0785)  time: 0.6251  data: 0.0001  max mem: 8730
Epoch: [23]  [1610/2001]  eta: 0:04:07  lr: 0.000089  loss: 3.1620 (3.0785)  time: 0.6304  data: 0.0001  max mem: 8730
Epoch: [23]  [1620/2001]  eta: 0:04:01  lr: 0.000089  loss: 2.9920 (3.0783)  time: 0.6367  data: 0.0001  max mem: 8730
Epoch: [23]  [1630/2001]  eta: 0:03:54  lr: 0.000089  loss: 2.8808 (3.0768)  time: 0.6354  data: 0.0001  max mem: 8730
Epoch: [23]  [1640/2001]  eta: 0:03:48  lr: 0.000089  loss: 3.0047 (3.0772)  time: 0.6298  data: 0.0001  max mem: 8730
Epoch: [23]  [1650/2001]  eta: 0:03:42  lr: 0.000089  loss: 3.2610 (3.0765)  time: 0.6276  data: 0.0001  max mem: 8730
Epoch: [23]  [1660/2001]  eta: 0:03:35  lr: 0.000089  loss: 2.9300 (3.0768)  time: 0.6300  data: 0.0001  max mem: 8730
Epoch: [23]  [1670/2001]  eta: 0:03:29  lr: 0.000089  loss: 2.9300 (3.0766)  time: 0.6304  data: 0.0001  max mem: 8730
Epoch: [23]  [1680/2001]  eta: 0:03:23  lr: 0.000089  loss: 3.1537 (3.0770)  time: 0.6295  data: 0.0001  max mem: 8730
Epoch: [23]  [1690/2001]  eta: 0:03:16  lr: 0.000089  loss: 3.2072 (3.0772)  time: 0.6297  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9404, ratio_loss=0.0420, cls_kl=0.0636, token_kl=0.0934
Epoch: [23]  [1700/2001]  eta: 0:03:10  lr: 0.000089  loss: 3.2072 (3.0769)  time: 0.6275  data: 0.0001  max mem: 8730
Epoch: [23]  [1710/2001]  eta: 0:03:04  lr: 0.000089  loss: 2.9258 (3.0753)  time: 0.6240  data: 0.0001  max mem: 8730
Epoch: [23]  [1720/2001]  eta: 0:02:57  lr: 0.000089  loss: 3.1185 (3.0773)  time: 0.6224  data: 0.0001  max mem: 8730
Epoch: [23]  [1730/2001]  eta: 0:02:51  lr: 0.000089  loss: 3.3719 (3.0781)  time: 0.6231  data: 0.0001  max mem: 8730
Epoch: [23]  [1740/2001]  eta: 0:02:45  lr: 0.000089  loss: 3.2428 (3.0786)  time: 0.6224  data: 0.0001  max mem: 8730
Epoch: [23]  [1750/2001]  eta: 0:02:38  lr: 0.000089  loss: 3.1514 (3.0789)  time: 0.6239  data: 0.0001  max mem: 8730
Epoch: [23]  [1760/2001]  eta: 0:02:32  lr: 0.000089  loss: 3.1514 (3.0788)  time: 0.6216  data: 0.0001  max mem: 8730
Epoch: [23]  [1770/2001]  eta: 0:02:26  lr: 0.000089  loss: 3.0738 (3.0778)  time: 0.6232  data: 0.0001  max mem: 8730
Epoch: [23]  [1780/2001]  eta: 0:02:19  lr: 0.000089  loss: 3.1231 (3.0787)  time: 0.6323  data: 0.0001  max mem: 8730
Epoch: [23]  [1790/2001]  eta: 0:02:13  lr: 0.000089  loss: 3.1231 (3.0775)  time: 0.6346  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9534, ratio_loss=0.0448, cls_kl=0.0635, token_kl=0.0937
Epoch: [23]  [1800/2001]  eta: 0:02:07  lr: 0.000089  loss: 2.7567 (3.0754)  time: 0.6317  data: 0.0001  max mem: 8730
Epoch: [23]  [1810/2001]  eta: 0:02:00  lr: 0.000089  loss: 2.8914 (3.0760)  time: 0.6269  data: 0.0001  max mem: 8730
Epoch: [23]  [1820/2001]  eta: 0:01:54  lr: 0.000089  loss: 3.0821 (3.0759)  time: 0.6247  data: 0.0001  max mem: 8730
Epoch: [23]  [1830/2001]  eta: 0:01:48  lr: 0.000089  loss: 3.2108 (3.0766)  time: 0.6256  data: 0.0001  max mem: 8730
Epoch: [23]  [1840/2001]  eta: 0:01:41  lr: 0.000089  loss: 3.2241 (3.0767)  time: 0.6290  data: 0.0001  max mem: 8730
Epoch: [23]  [1850/2001]  eta: 0:01:35  lr: 0.000089  loss: 3.0893 (3.0766)  time: 0.6281  data: 0.0001  max mem: 8730
Epoch: [23]  [1860/2001]  eta: 0:01:29  lr: 0.000089  loss: 3.1992 (3.0774)  time: 0.6250  data: 0.0001  max mem: 8730
Epoch: [23]  [1870/2001]  eta: 0:01:22  lr: 0.000089  loss: 3.3091 (3.0770)  time: 0.6199  data: 0.0001  max mem: 8730
Epoch: [23]  [1880/2001]  eta: 0:01:16  lr: 0.000089  loss: 2.9862 (3.0762)  time: 0.6190  data: 0.0001  max mem: 8730
Epoch: [23]  [1890/2001]  eta: 0:01:10  lr: 0.000089  loss: 3.2247 (3.0764)  time: 0.6235  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9792, ratio_loss=0.0436, cls_kl=0.0635, token_kl=0.0938
Epoch: [23]  [1900/2001]  eta: 0:01:03  lr: 0.000089  loss: 3.0466 (3.0758)  time: 0.6235  data: 0.0001  max mem: 8730
Epoch: [23]  [1910/2001]  eta: 0:00:57  lr: 0.000089  loss: 2.8816 (3.0747)  time: 0.6259  data: 0.0001  max mem: 8730
Epoch: [23]  [1920/2001]  eta: 0:00:51  lr: 0.000089  loss: 2.8816 (3.0731)  time: 0.6276  data: 0.0001  max mem: 8730
Epoch: [23]  [1930/2001]  eta: 0:00:44  lr: 0.000089  loss: 2.7846 (3.0726)  time: 0.6286  data: 0.0001  max mem: 8730
Epoch: [23]  [1940/2001]  eta: 0:00:38  lr: 0.000089  loss: 2.8259 (3.0718)  time: 0.6316  data: 0.0001  max mem: 8730
Epoch: [23]  [1950/2001]  eta: 0:00:32  lr: 0.000089  loss: 3.0202 (3.0719)  time: 0.6318  data: 0.0001  max mem: 8730
Epoch: [23]  [1960/2001]  eta: 0:00:25  lr: 0.000089  loss: 3.0202 (3.0714)  time: 0.6289  data: 0.0001  max mem: 8730
Epoch: [23]  [1970/2001]  eta: 0:00:19  lr: 0.000089  loss: 2.9224 (3.0705)  time: 0.6254  data: 0.0001  max mem: 8730
Epoch: [23]  [1980/2001]  eta: 0:00:13  lr: 0.000089  loss: 3.1793 (3.0715)  time: 0.6259  data: 0.0001  max mem: 8730
Epoch: [23]  [1990/2001]  eta: 0:00:06  lr: 0.000089  loss: 3.2157 (3.0713)  time: 0.6239  data: 0.0004  max mem: 8730
loss info: cls_loss=2.8698, ratio_loss=0.0405, cls_kl=0.0618, token_kl=0.0931
Epoch: [23]  [2000/2001]  eta: 0:00:00  lr: 0.000089  loss: 3.1852 (3.0713)  time: 0.6184  data: 0.0003  max mem: 8730
Epoch: [23] Total time: 0:21:04 (0.6320 s / it)
Averaged stats: lr: 0.000089  loss: 3.1852 (3.0580)
Test:  [ 0/53]  eta: 0:04:45  loss: 0.3523 (0.3523)  acc1: 94.1667 (94.1667)  acc5: 99.1667 (99.1667)  time: 5.3893  data: 4.5911  max mem: 8730
Test:  [10/53]  eta: 0:00:35  loss: 0.7269 (0.7649)  acc1: 84.1667 (82.8030)  acc5: 96.6667 (96.5152)  time: 0.8284  data: 0.4388  max mem: 8730
Test:  [20/53]  eta: 0:00:19  loss: 0.7269 (0.7675)  acc1: 82.5000 (82.7778)  acc5: 96.6667 (96.6667)  time: 0.3539  data: 0.0119  max mem: 8730
Test:  [30/53]  eta: 0:00:11  loss: 0.8639 (0.8558)  acc1: 78.3333 (80.6720)  acc5: 95.0000 (95.6183)  time: 0.3401  data: 0.0002  max mem: 8730
Test:  [40/53]  eta: 0:00:05  loss: 1.1158 (0.9212)  acc1: 75.8333 (79.2683)  acc5: 92.5000 (94.7561)  time: 0.3005  data: 0.0002  max mem: 8730
Test:  [50/53]  eta: 0:00:01  loss: 1.1040 (0.9497)  acc1: 75.0000 (78.4641)  acc5: 92.5000 (94.4444)  time: 0.2557  data: 0.0001  max mem: 8730
Test:  [52/53]  eta: 0:00:00  loss: 1.0798 (0.9361)  acc1: 76.6667 (78.6560)  acc5: 92.5000 (94.5280)  time: 0.2445  data: 0.0001  max mem: 8730
Test: Total time: 0:00:21 (0.4042 s / it)
Sparsity0:0.291189494949495,Sparsity1:0.549915175879397,Sparsity2:0.7768032,
* Acc@1 78.990 Acc@5 94.580 loss 0.937
Accuracy of the network on the 50000 test images: 79.0%
Max accuracy: 79.06%
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0000687 for PREDICTOR
Epoch: [24]  [   0/2001]  eta: 2:40:21  lr: 0.000069  loss: 3.4982 (3.4982)  time: 4.8082  data: 3.9513  max mem: 8730
Epoch: [24]  [  10/2001]  eta: 0:33:07  lr: 0.000069  loss: 3.3105 (2.9485)  time: 0.9981  data: 0.3594  max mem: 8730
Epoch: [24]  [  20/2001]  eta: 0:26:52  lr: 0.000069  loss: 3.3105 (3.0051)  time: 0.6145  data: 0.0002  max mem: 8730
Epoch: [24]  [  30/2001]  eta: 0:24:34  lr: 0.000069  loss: 3.2721 (3.0210)  time: 0.6108  data: 0.0002  max mem: 8730
Epoch: [24]  [  40/2001]  eta: 0:23:24  lr: 0.000069  loss: 2.9199 (2.9510)  time: 0.6132  data: 0.0002  max mem: 8730
Epoch: [24]  [  50/2001]  eta: 0:22:40  lr: 0.000069  loss: 2.8495 (2.9564)  time: 0.6190  data: 0.0002  max mem: 8730
Epoch: [24]  [  60/2001]  eta: 0:22:09  lr: 0.000069  loss: 3.2367 (2.9895)  time: 0.6215  data: 0.0002  max mem: 8730
Epoch: [24]  [  70/2001]  eta: 0:21:46  lr: 0.000069  loss: 3.2535 (3.0240)  time: 0.6231  data: 0.0002  max mem: 8730
Epoch: [24]  [  80/2001]  eta: 0:21:27  lr: 0.000069  loss: 3.1951 (3.0215)  time: 0.6253  data: 0.0002  max mem: 8730
Epoch: [24]  [  90/2001]  eta: 0:21:13  lr: 0.000069  loss: 3.1951 (3.0323)  time: 0.6292  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9552, ratio_loss=0.0445, cls_kl=0.0631, token_kl=0.0909
Epoch: [24]  [ 100/2001]  eta: 0:20:59  lr: 0.000069  loss: 3.2853 (3.0496)  time: 0.6298  data: 0.0002  max mem: 8730
Epoch: [24]  [ 110/2001]  eta: 0:20:47  lr: 0.000069  loss: 3.1373 (3.0470)  time: 0.6291  data: 0.0002  max mem: 8730
Epoch: [24]  [ 120/2001]  eta: 0:20:35  lr: 0.000069  loss: 3.0706 (3.0510)  time: 0.6289  data: 0.0002  max mem: 8730
Epoch: [24]  [ 130/2001]  eta: 0:20:25  lr: 0.000069  loss: 3.2569 (3.0679)  time: 0.6293  data: 0.0002  max mem: 8730
Epoch: [24]  [ 140/2001]  eta: 0:20:15  lr: 0.000069  loss: 3.3036 (3.0881)  time: 0.6303  data: 0.0002  max mem: 8730
Epoch: [24]  [ 150/2001]  eta: 0:20:05  lr: 0.000069  loss: 3.2677 (3.0638)  time: 0.6292  data: 0.0002  max mem: 8730
Epoch: [24]  [ 160/2001]  eta: 0:19:58  lr: 0.000069  loss: 2.8949 (3.0626)  time: 0.6374  data: 0.0002  max mem: 8730
Epoch: [24]  [ 170/2001]  eta: 0:19:49  lr: 0.000069  loss: 3.1873 (3.0630)  time: 0.6365  data: 0.0002  max mem: 8730
Epoch: [24]  [ 180/2001]  eta: 0:19:40  lr: 0.000069  loss: 3.2490 (3.0750)  time: 0.6273  data: 0.0002  max mem: 8730
Epoch: [24]  [ 190/2001]  eta: 0:19:33  lr: 0.000069  loss: 3.1565 (3.0704)  time: 0.6306  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9657, ratio_loss=0.0429, cls_kl=0.0638, token_kl=0.0920
Epoch: [24]  [ 200/2001]  eta: 0:19:25  lr: 0.000069  loss: 3.0919 (3.0653)  time: 0.6335  data: 0.0002  max mem: 8730
Epoch: [24]  [ 210/2001]  eta: 0:19:17  lr: 0.000069  loss: 3.1613 (3.0735)  time: 0.6317  data: 0.0002  max mem: 8730
Epoch: [24]  [ 220/2001]  eta: 0:19:09  lr: 0.000069  loss: 3.2788 (3.0775)  time: 0.6311  data: 0.0002  max mem: 8730
Epoch: [24]  [ 230/2001]  eta: 0:19:02  lr: 0.000069  loss: 3.1276 (3.0774)  time: 0.6328  data: 0.0002  max mem: 8730
Epoch: [24]  [ 240/2001]  eta: 0:18:54  lr: 0.000069  loss: 3.0063 (3.0724)  time: 0.6327  data: 0.0002  max mem: 8730
Epoch: [24]  [ 250/2001]  eta: 0:18:47  lr: 0.000069  loss: 3.1325 (3.0798)  time: 0.6319  data: 0.0002  max mem: 8730
Epoch: [24]  [ 260/2001]  eta: 0:18:40  lr: 0.000069  loss: 3.2088 (3.0828)  time: 0.6318  data: 0.0002  max mem: 8730
Epoch: [24]  [ 270/2001]  eta: 0:18:33  lr: 0.000069  loss: 3.0486 (3.0699)  time: 0.6307  data: 0.0002  max mem: 8730
Epoch: [24]  [ 280/2001]  eta: 0:18:26  lr: 0.000069  loss: 2.8670 (3.0593)  time: 0.6318  data: 0.0002  max mem: 8730
Epoch: [24]  [ 290/2001]  eta: 0:18:18  lr: 0.000069  loss: 2.9584 (3.0534)  time: 0.6323  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9194, ratio_loss=0.0427, cls_kl=0.0623, token_kl=0.0942
Epoch: [24]  [ 300/2001]  eta: 0:18:11  lr: 0.000069  loss: 3.1592 (3.0489)  time: 0.6310  data: 0.0002  max mem: 8730
Epoch: [24]  [ 310/2001]  eta: 0:18:04  lr: 0.000069  loss: 3.1065 (3.0490)  time: 0.6318  data: 0.0002  max mem: 8730
Epoch: [24]  [ 320/2001]  eta: 0:17:58  lr: 0.000069  loss: 3.0555 (3.0454)  time: 0.6338  data: 0.0002  max mem: 8730
Epoch: [24]  [ 330/2001]  eta: 0:17:51  lr: 0.000069  loss: 3.2008 (3.0530)  time: 0.6335  data: 0.0002  max mem: 8730
Epoch: [24]  [ 340/2001]  eta: 0:17:44  lr: 0.000069  loss: 3.1645 (3.0459)  time: 0.6322  data: 0.0002  max mem: 8730
Epoch: [24]  [ 350/2001]  eta: 0:17:38  lr: 0.000069  loss: 3.1645 (3.0505)  time: 0.6418  data: 0.0002  max mem: 8730
Epoch: [24]  [ 360/2001]  eta: 0:17:31  lr: 0.000069  loss: 2.9072 (3.0449)  time: 0.6412  data: 0.0001  max mem: 8730
Epoch: [24]  [ 370/2001]  eta: 0:17:24  lr: 0.000069  loss: 2.8491 (3.0408)  time: 0.6323  data: 0.0001  max mem: 8730
Epoch: [24]  [ 380/2001]  eta: 0:17:18  lr: 0.000069  loss: 2.9463 (3.0361)  time: 0.6322  data: 0.0002  max mem: 8730
Epoch: [24]  [ 390/2001]  eta: 0:17:11  lr: 0.000069  loss: 2.9902 (3.0384)  time: 0.6319  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8925, ratio_loss=0.0411, cls_kl=0.0608, token_kl=0.0903
Epoch: [24]  [ 400/2001]  eta: 0:17:04  lr: 0.000069  loss: 2.9700 (3.0381)  time: 0.6338  data: 0.0001  max mem: 8730
Epoch: [24]  [ 410/2001]  eta: 0:16:58  lr: 0.000069  loss: 3.1234 (3.0433)  time: 0.6385  data: 0.0001  max mem: 8730
Epoch: [24]  [ 420/2001]  eta: 0:16:51  lr: 0.000069  loss: 3.3731 (3.0479)  time: 0.6362  data: 0.0001  max mem: 8730
Epoch: [24]  [ 430/2001]  eta: 0:16:45  lr: 0.000069  loss: 3.3503 (3.0517)  time: 0.6401  data: 0.0002  max mem: 8730
Epoch: [24]  [ 440/2001]  eta: 0:16:39  lr: 0.000069  loss: 3.2379 (3.0463)  time: 0.6416  data: 0.0002  max mem: 8730
Epoch: [24]  [ 450/2001]  eta: 0:16:32  lr: 0.000069  loss: 2.9528 (3.0439)  time: 0.6333  data: 0.0002  max mem: 8730
Epoch: [24]  [ 460/2001]  eta: 0:16:25  lr: 0.000069  loss: 2.9528 (3.0423)  time: 0.6322  data: 0.0001  max mem: 8730
Epoch: [24]  [ 470/2001]  eta: 0:16:19  lr: 0.000069  loss: 2.9103 (3.0385)  time: 0.6332  data: 0.0001  max mem: 8730
Epoch: [24]  [ 480/2001]  eta: 0:16:12  lr: 0.000069  loss: 2.9183 (3.0354)  time: 0.6345  data: 0.0001  max mem: 8730
Epoch: [24]  [ 490/2001]  eta: 0:16:05  lr: 0.000069  loss: 3.0117 (3.0360)  time: 0.6336  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9300, ratio_loss=0.0422, cls_kl=0.0619, token_kl=0.0930
Epoch: [24]  [ 500/2001]  eta: 0:15:59  lr: 0.000069  loss: 3.1578 (3.0388)  time: 0.6366  data: 0.0001  max mem: 8730
Epoch: [24]  [ 510/2001]  eta: 0:15:53  lr: 0.000069  loss: 3.0666 (3.0355)  time: 0.6447  data: 0.0002  max mem: 8730
Epoch: [24]  [ 520/2001]  eta: 0:15:47  lr: 0.000069  loss: 2.7780 (3.0329)  time: 0.6423  data: 0.0001  max mem: 8730
Epoch: [24]  [ 530/2001]  eta: 0:15:40  lr: 0.000069  loss: 3.0317 (3.0349)  time: 0.6343  data: 0.0001  max mem: 8730
Epoch: [24]  [ 540/2001]  eta: 0:15:33  lr: 0.000069  loss: 3.2040 (3.0334)  time: 0.6331  data: 0.0001  max mem: 8730
Epoch: [24]  [ 550/2001]  eta: 0:15:27  lr: 0.000069  loss: 3.0402 (3.0310)  time: 0.6320  data: 0.0001  max mem: 8730
Epoch: [24]  [ 560/2001]  eta: 0:15:20  lr: 0.000069  loss: 2.9812 (3.0314)  time: 0.6320  data: 0.0001  max mem: 8730
Epoch: [24]  [ 570/2001]  eta: 0:15:14  lr: 0.000069  loss: 3.0348 (3.0321)  time: 0.6371  data: 0.0001  max mem: 8730
Epoch: [24]  [ 580/2001]  eta: 0:15:08  lr: 0.000069  loss: 3.3417 (3.0387)  time: 0.6432  data: 0.0002  max mem: 8730
Epoch: [24]  [ 590/2001]  eta: 0:15:01  lr: 0.000069  loss: 3.3613 (3.0382)  time: 0.6398  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9485, ratio_loss=0.0452, cls_kl=0.0627, token_kl=0.0931
Epoch: [24]  [ 600/2001]  eta: 0:14:55  lr: 0.000069  loss: 2.8785 (3.0375)  time: 0.6347  data: 0.0001  max mem: 8730
Epoch: [24]  [ 610/2001]  eta: 0:14:48  lr: 0.000069  loss: 3.2099 (3.0395)  time: 0.6354  data: 0.0002  max mem: 8730
Epoch: [24]  [ 620/2001]  eta: 0:14:42  lr: 0.000069  loss: 3.2340 (3.0411)  time: 0.6351  data: 0.0002  max mem: 8730
Epoch: [24]  [ 630/2001]  eta: 0:14:35  lr: 0.000069  loss: 3.0478 (3.0398)  time: 0.6342  data: 0.0002  max mem: 8730
Epoch: [24]  [ 640/2001]  eta: 0:14:29  lr: 0.000069  loss: 3.0478 (3.0377)  time: 0.6342  data: 0.0002  max mem: 8730
Epoch: [24]  [ 650/2001]  eta: 0:14:22  lr: 0.000069  loss: 3.1505 (3.0366)  time: 0.6345  data: 0.0002  max mem: 8730
Epoch: [24]  [ 660/2001]  eta: 0:14:16  lr: 0.000069  loss: 3.1946 (3.0386)  time: 0.6375  data: 0.0001  max mem: 8730
Epoch: [24]  [ 670/2001]  eta: 0:14:09  lr: 0.000069  loss: 3.2741 (3.0400)  time: 0.6369  data: 0.0001  max mem: 8730
Epoch: [24]  [ 680/2001]  eta: 0:14:03  lr: 0.000069  loss: 3.3272 (3.0426)  time: 0.6344  data: 0.0002  max mem: 8730
Epoch: [24]  [ 690/2001]  eta: 0:13:57  lr: 0.000069  loss: 3.2154 (3.0407)  time: 0.6340  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9259, ratio_loss=0.0420, cls_kl=0.0614, token_kl=0.0912
Epoch: [24]  [ 700/2001]  eta: 0:13:50  lr: 0.000069  loss: 2.9343 (3.0384)  time: 0.6334  data: 0.0002  max mem: 8730
Epoch: [24]  [ 710/2001]  eta: 0:13:44  lr: 0.000069  loss: 3.0642 (3.0436)  time: 0.6337  data: 0.0001  max mem: 8730
Epoch: [24]  [ 720/2001]  eta: 0:13:37  lr: 0.000069  loss: 3.2648 (3.0427)  time: 0.6343  data: 0.0001  max mem: 8730
Epoch: [24]  [ 730/2001]  eta: 0:13:31  lr: 0.000069  loss: 3.0409 (3.0421)  time: 0.6346  data: 0.0001  max mem: 8730
Epoch: [24]  [ 740/2001]  eta: 0:13:24  lr: 0.000069  loss: 3.2193 (3.0444)  time: 0.6341  data: 0.0001  max mem: 8730
Epoch: [24]  [ 750/2001]  eta: 0:13:18  lr: 0.000069  loss: 3.3209 (3.0460)  time: 0.6338  data: 0.0001  max mem: 8730
Epoch: [24]  [ 760/2001]  eta: 0:13:11  lr: 0.000069  loss: 3.1881 (3.0464)  time: 0.6328  data: 0.0001  max mem: 8730
Epoch: [24]  [ 770/2001]  eta: 0:13:05  lr: 0.000069  loss: 3.1659 (3.0468)  time: 0.6344  data: 0.0001  max mem: 8730
Epoch: [24]  [ 780/2001]  eta: 0:12:59  lr: 0.000069  loss: 3.1140 (3.0467)  time: 0.6454  data: 0.0001  max mem: 8730
Epoch: [24]  [ 790/2001]  eta: 0:12:52  lr: 0.000069  loss: 3.0621 (3.0468)  time: 0.6428  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0024, ratio_loss=0.0449, cls_kl=0.0642, token_kl=0.0937
Epoch: [24]  [ 800/2001]  eta: 0:12:46  lr: 0.000069  loss: 3.2456 (3.0494)  time: 0.6334  data: 0.0001  max mem: 8730
Epoch: [24]  [ 810/2001]  eta: 0:12:39  lr: 0.000069  loss: 3.2461 (3.0497)  time: 0.6325  data: 0.0001  max mem: 8730
Epoch: [24]  [ 820/2001]  eta: 0:12:33  lr: 0.000069  loss: 2.9778 (3.0464)  time: 0.6282  data: 0.0002  max mem: 8730
Epoch: [24]  [ 830/2001]  eta: 0:12:26  lr: 0.000069  loss: 2.7918 (3.0443)  time: 0.6295  data: 0.0001  max mem: 8730
Epoch: [24]  [ 840/2001]  eta: 0:12:20  lr: 0.000069  loss: 2.8638 (3.0430)  time: 0.6340  data: 0.0001  max mem: 8730
Epoch: [24]  [ 850/2001]  eta: 0:12:14  lr: 0.000069  loss: 3.1261 (3.0418)  time: 0.6409  data: 0.0001  max mem: 8730
Epoch: [24]  [ 860/2001]  eta: 0:12:07  lr: 0.000069  loss: 3.2047 (3.0418)  time: 0.6377  data: 0.0001  max mem: 8730
Epoch: [24]  [ 870/2001]  eta: 0:12:01  lr: 0.000069  loss: 3.0800 (3.0388)  time: 0.6294  data: 0.0001  max mem: 8730
Epoch: [24]  [ 880/2001]  eta: 0:11:54  lr: 0.000069  loss: 3.1254 (3.0413)  time: 0.6314  data: 0.0002  max mem: 8730
Epoch: [24]  [ 890/2001]  eta: 0:11:48  lr: 0.000069  loss: 3.2987 (3.0423)  time: 0.6305  data: 0.0002  max mem: 8730
loss info: cls_loss=2.8781, ratio_loss=0.0424, cls_kl=0.0609, token_kl=0.0909
Epoch: [24]  [ 900/2001]  eta: 0:11:41  lr: 0.000069  loss: 3.0920 (3.0390)  time: 0.6291  data: 0.0001  max mem: 8730
Epoch: [24]  [ 910/2001]  eta: 0:11:35  lr: 0.000069  loss: 2.9333 (3.0390)  time: 0.6281  data: 0.0001  max mem: 8730
Epoch: [24]  [ 920/2001]  eta: 0:11:28  lr: 0.000069  loss: 2.9595 (3.0382)  time: 0.6269  data: 0.0001  max mem: 8730
Epoch: [24]  [ 930/2001]  eta: 0:11:22  lr: 0.000069  loss: 2.9487 (3.0351)  time: 0.6333  data: 0.0001  max mem: 8730
Epoch: [24]  [ 940/2001]  eta: 0:11:15  lr: 0.000069  loss: 2.9557 (3.0340)  time: 0.6345  data: 0.0001  max mem: 8730
Epoch: [24]  [ 950/2001]  eta: 0:11:09  lr: 0.000069  loss: 3.1223 (3.0339)  time: 0.6286  data: 0.0001  max mem: 8730
Epoch: [24]  [ 960/2001]  eta: 0:11:03  lr: 0.000069  loss: 3.1121 (3.0331)  time: 0.6270  data: 0.0001  max mem: 8730
Epoch: [24]  [ 970/2001]  eta: 0:10:56  lr: 0.000069  loss: 3.1161 (3.0351)  time: 0.6276  data: 0.0001  max mem: 8730
Epoch: [24]  [ 980/2001]  eta: 0:10:50  lr: 0.000069  loss: 3.2463 (3.0368)  time: 0.6268  data: 0.0001  max mem: 8730
Epoch: [24]  [ 990/2001]  eta: 0:10:43  lr: 0.000069  loss: 3.0674 (3.0369)  time: 0.6302  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9102, ratio_loss=0.0431, cls_kl=0.0633, token_kl=0.0933
Epoch: [24]  [1000/2001]  eta: 0:10:37  lr: 0.000069  loss: 3.0674 (3.0391)  time: 0.6318  data: 0.0001  max mem: 8730
Epoch: [24]  [1010/2001]  eta: 0:10:30  lr: 0.000069  loss: 3.3367 (3.0400)  time: 0.6310  data: 0.0001  max mem: 8730
Epoch: [24]  [1020/2001]  eta: 0:10:24  lr: 0.000069  loss: 2.9809 (3.0396)  time: 0.6282  data: 0.0001  max mem: 8730
Epoch: [24]  [1030/2001]  eta: 0:10:17  lr: 0.000069  loss: 2.9809 (3.0386)  time: 0.6249  data: 0.0001  max mem: 8730
Epoch: [24]  [1040/2001]  eta: 0:10:11  lr: 0.000069  loss: 3.3490 (3.0418)  time: 0.6242  data: 0.0001  max mem: 8730
Epoch: [24]  [1050/2001]  eta: 0:10:04  lr: 0.000069  loss: 3.3791 (3.0423)  time: 0.6233  data: 0.0001  max mem: 8730
Epoch: [24]  [1060/2001]  eta: 0:09:58  lr: 0.000069  loss: 3.1147 (3.0414)  time: 0.6233  data: 0.0001  max mem: 8730
Epoch: [24]  [1070/2001]  eta: 0:09:52  lr: 0.000069  loss: 2.6357 (3.0378)  time: 0.6269  data: 0.0001  max mem: 8730
Epoch: [24]  [1080/2001]  eta: 0:09:45  lr: 0.000069  loss: 2.8997 (3.0404)  time: 0.6317  data: 0.0001  max mem: 8730
Epoch: [24]  [1090/2001]  eta: 0:09:39  lr: 0.000069  loss: 3.3331 (3.0405)  time: 0.6310  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9524, ratio_loss=0.0441, cls_kl=0.0632, token_kl=0.0936
Epoch: [24]  [1100/2001]  eta: 0:09:32  lr: 0.000069  loss: 3.1839 (3.0402)  time: 0.6261  data: 0.0002  max mem: 8730
Epoch: [24]  [1110/2001]  eta: 0:09:26  lr: 0.000069  loss: 3.1839 (3.0429)  time: 0.6256  data: 0.0001  max mem: 8730
Epoch: [24]  [1120/2001]  eta: 0:09:19  lr: 0.000069  loss: 3.1560 (3.0415)  time: 0.6281  data: 0.0001  max mem: 8730
Epoch: [24]  [1130/2001]  eta: 0:09:13  lr: 0.000069  loss: 2.9055 (3.0394)  time: 0.6260  data: 0.0001  max mem: 8730
Epoch: [24]  [1140/2001]  eta: 0:09:07  lr: 0.000069  loss: 3.1852 (3.0412)  time: 0.6224  data: 0.0001  max mem: 8730
Epoch: [24]  [1150/2001]  eta: 0:09:00  lr: 0.000069  loss: 3.3209 (3.0426)  time: 0.6217  data: 0.0001  max mem: 8730
Epoch: [24]  [1160/2001]  eta: 0:08:54  lr: 0.000069  loss: 3.2841 (3.0425)  time: 0.6228  data: 0.0001  max mem: 8730
Epoch: [24]  [1170/2001]  eta: 0:08:47  lr: 0.000069  loss: 3.0762 (3.0417)  time: 0.6197  data: 0.0001  max mem: 8730
Epoch: [24]  [1180/2001]  eta: 0:08:41  lr: 0.000069  loss: 2.9816 (3.0407)  time: 0.6213  data: 0.0001  max mem: 8730
Epoch: [24]  [1190/2001]  eta: 0:08:34  lr: 0.000069  loss: 3.2163 (3.0420)  time: 0.6226  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9300, ratio_loss=0.0429, cls_kl=0.0620, token_kl=0.0927
Epoch: [24]  [1200/2001]  eta: 0:08:28  lr: 0.000069  loss: 3.2131 (3.0400)  time: 0.6273  data: 0.0001  max mem: 8730
Epoch: [24]  [1210/2001]  eta: 0:08:22  lr: 0.000069  loss: 3.2131 (3.0421)  time: 0.6328  data: 0.0001  max mem: 8730
Epoch: [24]  [1220/2001]  eta: 0:08:15  lr: 0.000069  loss: 3.1552 (3.0405)  time: 0.6255  data: 0.0001  max mem: 8730
Epoch: [24]  [1230/2001]  eta: 0:08:09  lr: 0.000069  loss: 3.0088 (3.0414)  time: 0.6211  data: 0.0001  max mem: 8730
Epoch: [24]  [1240/2001]  eta: 0:08:02  lr: 0.000069  loss: 3.3051 (3.0415)  time: 0.6242  data: 0.0001  max mem: 8730
Epoch: [24]  [1250/2001]  eta: 0:07:56  lr: 0.000069  loss: 3.1876 (3.0410)  time: 0.6256  data: 0.0001  max mem: 8730
Epoch: [24]  [1260/2001]  eta: 0:07:50  lr: 0.000069  loss: 3.2025 (3.0410)  time: 0.6296  data: 0.0001  max mem: 8730
Epoch: [24]  [1270/2001]  eta: 0:07:43  lr: 0.000069  loss: 3.0523 (3.0395)  time: 0.6304  data: 0.0001  max mem: 8730
Epoch: [24]  [1280/2001]  eta: 0:07:37  lr: 0.000069  loss: 2.9868 (3.0394)  time: 0.6362  data: 0.0002  max mem: 8730
Epoch: [24]  [1290/2001]  eta: 0:07:30  lr: 0.000069  loss: 3.1072 (3.0404)  time: 0.6329  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9483, ratio_loss=0.0484, cls_kl=0.0641, token_kl=0.0969
Epoch: [24]  [1300/2001]  eta: 0:07:24  lr: 0.000069  loss: 3.2475 (3.0423)  time: 0.6208  data: 0.0001  max mem: 8730
Epoch: [24]  [1310/2001]  eta: 0:07:18  lr: 0.000069  loss: 3.2728 (3.0430)  time: 0.6228  data: 0.0001  max mem: 8730
Epoch: [24]  [1320/2001]  eta: 0:07:11  lr: 0.000069  loss: 3.3414 (3.0445)  time: 0.6221  data: 0.0001  max mem: 8730
Epoch: [24]  [1330/2001]  eta: 0:07:05  lr: 0.000069  loss: 3.3793 (3.0453)  time: 0.6227  data: 0.0001  max mem: 8730
Epoch: [24]  [1340/2001]  eta: 0:06:58  lr: 0.000069  loss: 3.0026 (3.0438)  time: 0.6249  data: 0.0001  max mem: 8730
Epoch: [24]  [1350/2001]  eta: 0:06:52  lr: 0.000069  loss: 2.8288 (3.0429)  time: 0.6261  data: 0.0001  max mem: 8730
Epoch: [24]  [1360/2001]  eta: 0:06:46  lr: 0.000069  loss: 2.8288 (3.0412)  time: 0.6338  data: 0.0001  max mem: 8730
Epoch: [24]  [1370/2001]  eta: 0:06:39  lr: 0.000069  loss: 2.6872 (3.0395)  time: 0.6352  data: 0.0001  max mem: 8730
Epoch: [24]  [1380/2001]  eta: 0:06:33  lr: 0.000069  loss: 2.7224 (3.0390)  time: 0.6289  data: 0.0001  max mem: 8730
Epoch: [24]  [1390/2001]  eta: 0:06:27  lr: 0.000069  loss: 3.1808 (3.0395)  time: 0.6246  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8986, ratio_loss=0.0424, cls_kl=0.0613, token_kl=0.0929
Epoch: [24]  [1400/2001]  eta: 0:06:20  lr: 0.000069  loss: 3.2093 (3.0397)  time: 0.6275  data: 0.0001  max mem: 8730
Epoch: [24]  [1410/2001]  eta: 0:06:14  lr: 0.000069  loss: 3.2593 (3.0417)  time: 0.6282  data: 0.0002  max mem: 8730
Epoch: [24]  [1420/2001]  eta: 0:06:08  lr: 0.000069  loss: 3.2024 (3.0422)  time: 0.6283  data: 0.0001  max mem: 8730
Epoch: [24]  [1430/2001]  eta: 0:06:01  lr: 0.000069  loss: 2.9765 (3.0405)  time: 0.6303  data: 0.0001  max mem: 8730
Epoch: [24]  [1440/2001]  eta: 0:05:55  lr: 0.000069  loss: 3.2121 (3.0418)  time: 0.6344  data: 0.0001  max mem: 8730
Epoch: [24]  [1450/2001]  eta: 0:05:49  lr: 0.000069  loss: 3.3147 (3.0416)  time: 0.6362  data: 0.0001  max mem: 8730
Epoch: [24]  [1460/2001]  eta: 0:05:42  lr: 0.000069  loss: 3.1812 (3.0413)  time: 0.6347  data: 0.0001  max mem: 8730
Epoch: [24]  [1470/2001]  eta: 0:05:36  lr: 0.000069  loss: 3.2836 (3.0427)  time: 0.6320  data: 0.0002  max mem: 8730
Epoch: [24]  [1480/2001]  eta: 0:05:30  lr: 0.000069  loss: 3.2972 (3.0421)  time: 0.6305  data: 0.0001  max mem: 8730
Epoch: [24]  [1490/2001]  eta: 0:05:23  lr: 0.000069  loss: 3.0592 (3.0411)  time: 0.6294  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9649, ratio_loss=0.0440, cls_kl=0.0639, token_kl=0.0957
Epoch: [24]  [1500/2001]  eta: 0:05:17  lr: 0.000069  loss: 3.2200 (3.0414)  time: 0.6268  data: 0.0001  max mem: 8730
Epoch: [24]  [1510/2001]  eta: 0:05:11  lr: 0.000069  loss: 2.9938 (3.0402)  time: 0.6260  data: 0.0001  max mem: 8730
Epoch: [24]  [1520/2001]  eta: 0:05:04  lr: 0.000069  loss: 2.8977 (3.0395)  time: 0.6280  data: 0.0001  max mem: 8730
Epoch: [24]  [1530/2001]  eta: 0:04:58  lr: 0.000069  loss: 3.1535 (3.0403)  time: 0.6311  data: 0.0001  max mem: 8730
Epoch: [24]  [1540/2001]  eta: 0:04:51  lr: 0.000069  loss: 3.2173 (3.0407)  time: 0.6294  data: 0.0001  max mem: 8730
Epoch: [24]  [1550/2001]  eta: 0:04:45  lr: 0.000069  loss: 3.1608 (3.0422)  time: 0.6295  data: 0.0001  max mem: 8730
Epoch: [24]  [1560/2001]  eta: 0:04:39  lr: 0.000069  loss: 3.1929 (3.0417)  time: 0.6285  data: 0.0002  max mem: 8730
Epoch: [24]  [1570/2001]  eta: 0:04:32  lr: 0.000069  loss: 3.0199 (3.0410)  time: 0.6278  data: 0.0002  max mem: 8730
Epoch: [24]  [1580/2001]  eta: 0:04:26  lr: 0.000069  loss: 3.1637 (3.0421)  time: 0.6258  data: 0.0001  max mem: 8730
Epoch: [24]  [1590/2001]  eta: 0:04:20  lr: 0.000069  loss: 3.2975 (3.0427)  time: 0.6287  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9543, ratio_loss=0.0461, cls_kl=0.0661, token_kl=0.0979
Epoch: [24]  [1600/2001]  eta: 0:04:13  lr: 0.000069  loss: 3.2975 (3.0433)  time: 0.6322  data: 0.0001  max mem: 8730
Epoch: [24]  [1610/2001]  eta: 0:04:07  lr: 0.000069  loss: 3.2078 (3.0433)  time: 0.6295  data: 0.0001  max mem: 8730
Epoch: [24]  [1620/2001]  eta: 0:04:01  lr: 0.000069  loss: 3.1728 (3.0433)  time: 0.6272  data: 0.0001  max mem: 8730
Epoch: [24]  [1630/2001]  eta: 0:03:54  lr: 0.000069  loss: 3.2735 (3.0450)  time: 0.6351  data: 0.0002  max mem: 8730
Epoch: [24]  [1640/2001]  eta: 0:03:48  lr: 0.000069  loss: 3.0683 (3.0428)  time: 0.6361  data: 0.0001  max mem: 8730
Epoch: [24]  [1650/2001]  eta: 0:03:42  lr: 0.000069  loss: 2.8099 (3.0422)  time: 0.6311  data: 0.0001  max mem: 8730
Epoch: [24]  [1660/2001]  eta: 0:03:35  lr: 0.000069  loss: 2.9723 (3.0424)  time: 0.6353  data: 0.0001  max mem: 8730
Epoch: [24]  [1670/2001]  eta: 0:03:29  lr: 0.000069  loss: 3.0633 (3.0429)  time: 0.6335  data: 0.0001  max mem: 8730
Epoch: [24]  [1680/2001]  eta: 0:03:23  lr: 0.000069  loss: 3.0184 (3.0418)  time: 0.6299  data: 0.0001  max mem: 8730
Epoch: [24]  [1690/2001]  eta: 0:03:16  lr: 0.000069  loss: 3.1157 (3.0437)  time: 0.6333  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9555, ratio_loss=0.0450, cls_kl=0.0633, token_kl=0.0935
Epoch: [24]  [1700/2001]  eta: 0:03:10  lr: 0.000069  loss: 3.0464 (3.0439)  time: 0.6343  data: 0.0001  max mem: 8730
Epoch: [24]  [1710/2001]  eta: 0:03:04  lr: 0.000069  loss: 2.9922 (3.0426)  time: 0.6371  data: 0.0001  max mem: 8730
Epoch: [24]  [1720/2001]  eta: 0:02:57  lr: 0.000069  loss: 2.8462 (3.0408)  time: 0.6378  data: 0.0001  max mem: 8730
Epoch: [24]  [1730/2001]  eta: 0:02:51  lr: 0.000069  loss: 2.6949 (3.0394)  time: 0.6326  data: 0.0001  max mem: 8730
Epoch: [24]  [1740/2001]  eta: 0:02:45  lr: 0.000069  loss: 2.9485 (3.0386)  time: 0.6322  data: 0.0001  max mem: 8730
Epoch: [24]  [1750/2001]  eta: 0:02:38  lr: 0.000069  loss: 3.1823 (3.0406)  time: 0.6321  data: 0.0001  max mem: 8730
Epoch: [24]  [1760/2001]  eta: 0:02:32  lr: 0.000069  loss: 3.1421 (3.0392)  time: 0.6319  data: 0.0001  max mem: 8730
Epoch: [24]  [1770/2001]  eta: 0:02:26  lr: 0.000069  loss: 3.1421 (3.0401)  time: 0.6326  data: 0.0001  max mem: 8730
Epoch: [24]  [1780/2001]  eta: 0:02:19  lr: 0.000069  loss: 3.2587 (3.0391)  time: 0.6339  data: 0.0001  max mem: 8730
Epoch: [24]  [1790/2001]  eta: 0:02:13  lr: 0.000069  loss: 3.1481 (3.0400)  time: 0.6397  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8619, ratio_loss=0.0421, cls_kl=0.0625, token_kl=0.0911
Epoch: [24]  [1800/2001]  eta: 0:02:07  lr: 0.000069  loss: 3.2216 (3.0399)  time: 0.6404  data: 0.0001  max mem: 8730
Epoch: [24]  [1810/2001]  eta: 0:02:00  lr: 0.000069  loss: 2.9391 (3.0389)  time: 0.6341  data: 0.0001  max mem: 8730
Epoch: [24]  [1820/2001]  eta: 0:01:54  lr: 0.000069  loss: 3.0690 (3.0390)  time: 0.6315  data: 0.0001  max mem: 8730
Epoch: [24]  [1830/2001]  eta: 0:01:48  lr: 0.000069  loss: 3.1065 (3.0387)  time: 0.6295  data: 0.0001  max mem: 8730
Epoch: [24]  [1840/2001]  eta: 0:01:41  lr: 0.000069  loss: 3.2789 (3.0391)  time: 0.6298  data: 0.0001  max mem: 8730
Epoch: [24]  [1850/2001]  eta: 0:01:35  lr: 0.000069  loss: 3.2789 (3.0383)  time: 0.6346  data: 0.0001  max mem: 8730
Epoch: [24]  [1860/2001]  eta: 0:01:29  lr: 0.000069  loss: 3.1639 (3.0390)  time: 0.6421  data: 0.0001  max mem: 8730
Epoch: [24]  [1870/2001]  eta: 0:01:22  lr: 0.000069  loss: 3.1665 (3.0388)  time: 0.6406  data: 0.0001  max mem: 8730
Epoch: [24]  [1880/2001]  eta: 0:01:16  lr: 0.000069  loss: 3.2393 (3.0394)  time: 0.6339  data: 0.0001  max mem: 8730
Epoch: [24]  [1890/2001]  eta: 0:01:10  lr: 0.000069  loss: 3.2393 (3.0386)  time: 0.6333  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8978, ratio_loss=0.0438, cls_kl=0.0614, token_kl=0.0922
Epoch: [24]  [1900/2001]  eta: 0:01:03  lr: 0.000069  loss: 3.1622 (3.0380)  time: 0.6343  data: 0.0001  max mem: 8730
Epoch: [24]  [1910/2001]  eta: 0:00:57  lr: 0.000069  loss: 3.0481 (3.0370)  time: 0.6370  data: 0.0001  max mem: 8730
Epoch: [24]  [1920/2001]  eta: 0:00:51  lr: 0.000069  loss: 3.0481 (3.0371)  time: 0.6368  data: 0.0001  max mem: 8730
Epoch: [24]  [1930/2001]  eta: 0:00:44  lr: 0.000069  loss: 3.1926 (3.0366)  time: 0.6329  data: 0.0001  max mem: 8730
Epoch: [24]  [1940/2001]  eta: 0:00:38  lr: 0.000069  loss: 3.2154 (3.0373)  time: 0.6360  data: 0.0001  max mem: 8730
Epoch: [24]  [1950/2001]  eta: 0:00:32  lr: 0.000069  loss: 3.2490 (3.0367)  time: 0.6352  data: 0.0001  max mem: 8730
Epoch: [24]  [1960/2001]  eta: 0:00:25  lr: 0.000069  loss: 3.1503 (3.0370)  time: 0.6321  data: 0.0001  max mem: 8730
Epoch: [24]  [1970/2001]  eta: 0:00:19  lr: 0.000069  loss: 3.2108 (3.0371)  time: 0.6350  data: 0.0001  max mem: 8730
Epoch: [24]  [1980/2001]  eta: 0:00:13  lr: 0.000069  loss: 3.2776 (3.0373)  time: 0.6383  data: 0.0001  max mem: 8730
Epoch: [24]  [1990/2001]  eta: 0:00:06  lr: 0.000069  loss: 3.2559 (3.0381)  time: 0.6347  data: 0.0004  max mem: 8730
loss info: cls_loss=2.9222, ratio_loss=0.0451, cls_kl=0.0650, token_kl=0.0957
Epoch: [24]  [2000/2001]  eta: 0:00:00  lr: 0.000069  loss: 3.0897 (3.0376)  time: 0.6307  data: 0.0003  max mem: 8730
Epoch: [24] Total time: 0:21:08 (0.6337 s / it)
Averaged stats: lr: 0.000069  loss: 3.0897 (3.0394)
Test:  [ 0/53]  eta: 0:05:00  loss: 0.3779 (0.3779)  acc1: 92.5000 (92.5000)  acc5: 99.1667 (99.1667)  time: 5.6695  data: 5.2308  max mem: 8730
Test:  [10/53]  eta: 0:00:38  loss: 0.7516 (0.7708)  acc1: 84.1667 (83.3333)  acc5: 96.6667 (96.5152)  time: 0.8909  data: 0.4963  max mem: 8730
Test:  [20/53]  eta: 0:00:21  loss: 0.7352 (0.7736)  acc1: 81.6667 (83.0159)  acc5: 96.6667 (96.6270)  time: 0.3939  data: 0.0122  max mem: 8730
Test:  [30/53]  eta: 0:00:12  loss: 0.9098 (0.8586)  acc1: 78.3333 (80.6452)  acc5: 95.0000 (95.3495)  time: 0.3491  data: 0.0009  max mem: 8730
Test:  [40/53]  eta: 0:00:06  loss: 1.1172 (0.9254)  acc1: 75.0000 (79.0447)  acc5: 91.6667 (94.4106)  time: 0.2916  data: 0.0002  max mem: 8730
Test:  [50/53]  eta: 0:00:01  loss: 1.1128 (0.9573)  acc1: 75.0000 (78.4150)  acc5: 92.5000 (94.0360)  time: 0.2557  data: 0.0001  max mem: 8730
Test:  [52/53]  eta: 0:00:00  loss: 1.0980 (0.9442)  acc1: 75.0000 (78.5760)  acc5: 92.5000 (94.1120)  time: 0.2445  data: 0.0000  max mem: 8730
Test: Total time: 0:00:22 (0.4216 s / it)
Sparsity0:0.2942989898989899,Sparsity1:0.5506596984924623,Sparsity2:0.7838464,
* Acc@1 78.962 Acc@5 94.512 loss 0.942
Accuracy of the network on the 50000 test images: 79.0%
Max accuracy: 79.06%
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0000512 for PREDICTOR
Epoch: [25]  [   0/2001]  eta: 2:24:11  lr: 0.000051  loss: 3.6815 (3.6815)  time: 4.3238  data: 2.7080  max mem: 8730
Epoch: [25]  [  10/2001]  eta: 0:32:23  lr: 0.000051  loss: 3.4076 (3.1619)  time: 0.9763  data: 0.2463  max mem: 8730
Epoch: [25]  [  20/2001]  eta: 0:26:35  lr: 0.000051  loss: 3.2097 (3.1025)  time: 0.6297  data: 0.0001  max mem: 8730
Epoch: [25]  [  30/2001]  eta: 0:24:26  lr: 0.000051  loss: 3.2390 (3.0615)  time: 0.6162  data: 0.0001  max mem: 8730
Epoch: [25]  [  40/2001]  eta: 0:23:22  lr: 0.000051  loss: 3.2540 (3.0834)  time: 0.6206  data: 0.0002  max mem: 8730
Epoch: [25]  [  50/2001]  eta: 0:22:41  lr: 0.000051  loss: 3.0634 (3.0633)  time: 0.6269  data: 0.0001  max mem: 8730
Epoch: [25]  [  60/2001]  eta: 0:22:14  lr: 0.000051  loss: 3.0634 (3.0862)  time: 0.6301  data: 0.0001  max mem: 8730
Epoch: [25]  [  70/2001]  eta: 0:21:52  lr: 0.000051  loss: 3.1080 (3.0693)  time: 0.6331  data: 0.0001  max mem: 8730
Epoch: [25]  [  80/2001]  eta: 0:21:37  lr: 0.000051  loss: 2.7893 (3.0198)  time: 0.6385  data: 0.0001  max mem: 8730
Epoch: [25]  [  90/2001]  eta: 0:21:21  lr: 0.000051  loss: 2.9629 (3.0240)  time: 0.6389  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9128, ratio_loss=0.0422, cls_kl=0.0612, token_kl=0.0915
Epoch: [25]  [ 100/2001]  eta: 0:21:08  lr: 0.000051  loss: 3.1272 (3.0157)  time: 0.6346  data: 0.0001  max mem: 8730
Epoch: [25]  [ 110/2001]  eta: 0:20:56  lr: 0.000051  loss: 3.2443 (3.0344)  time: 0.6358  data: 0.0001  max mem: 8730
Epoch: [25]  [ 120/2001]  eta: 0:20:45  lr: 0.000051  loss: 3.2208 (3.0299)  time: 0.6367  data: 0.0001  max mem: 8730
Epoch: [25]  [ 130/2001]  eta: 0:20:35  lr: 0.000051  loss: 2.9743 (3.0250)  time: 0.6361  data: 0.0001  max mem: 8730
Epoch: [25]  [ 140/2001]  eta: 0:20:25  lr: 0.000051  loss: 3.1101 (3.0321)  time: 0.6344  data: 0.0001  max mem: 8730
Epoch: [25]  [ 150/2001]  eta: 0:20:15  lr: 0.000051  loss: 3.1582 (3.0111)  time: 0.6331  data: 0.0001  max mem: 8730
Epoch: [25]  [ 160/2001]  eta: 0:20:08  lr: 0.000051  loss: 3.1905 (3.0224)  time: 0.6425  data: 0.0001  max mem: 8730
Epoch: [25]  [ 170/2001]  eta: 0:19:59  lr: 0.000051  loss: 3.1905 (3.0180)  time: 0.6452  data: 0.0002  max mem: 8730
Epoch: [25]  [ 180/2001]  eta: 0:19:50  lr: 0.000051  loss: 3.1320 (3.0317)  time: 0.6357  data: 0.0001  max mem: 8730
Epoch: [25]  [ 190/2001]  eta: 0:19:42  lr: 0.000051  loss: 3.1320 (3.0320)  time: 0.6344  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9439, ratio_loss=0.0430, cls_kl=0.0644, token_kl=0.0919
Epoch: [25]  [ 200/2001]  eta: 0:19:34  lr: 0.000051  loss: 3.2062 (3.0399)  time: 0.6366  data: 0.0001  max mem: 8730
Epoch: [25]  [ 210/2001]  eta: 0:19:27  lr: 0.000051  loss: 3.2148 (3.0422)  time: 0.6390  data: 0.0001  max mem: 8730
Epoch: [25]  [ 220/2001]  eta: 0:19:19  lr: 0.000051  loss: 3.2838 (3.0508)  time: 0.6366  data: 0.0001  max mem: 8730
Epoch: [25]  [ 230/2001]  eta: 0:19:11  lr: 0.000051  loss: 3.3625 (3.0497)  time: 0.6324  data: 0.0001  max mem: 8730
Epoch: [25]  [ 240/2001]  eta: 0:19:03  lr: 0.000051  loss: 3.2741 (3.0509)  time: 0.6300  data: 0.0001  max mem: 8730
Epoch: [25]  [ 250/2001]  eta: 0:18:55  lr: 0.000051  loss: 3.3108 (3.0602)  time: 0.6324  data: 0.0001  max mem: 8730
Epoch: [25]  [ 260/2001]  eta: 0:18:49  lr: 0.000051  loss: 3.2040 (3.0573)  time: 0.6408  data: 0.0001  max mem: 8730
Epoch: [25]  [ 270/2001]  eta: 0:18:41  lr: 0.000051  loss: 3.0298 (3.0479)  time: 0.6387  data: 0.0001  max mem: 8730
Epoch: [25]  [ 280/2001]  eta: 0:18:33  lr: 0.000051  loss: 3.0572 (3.0453)  time: 0.6300  data: 0.0001  max mem: 8730
Epoch: [25]  [ 290/2001]  eta: 0:18:26  lr: 0.000051  loss: 3.0572 (3.0413)  time: 0.6306  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9385, ratio_loss=0.0433, cls_kl=0.0644, token_kl=0.0925
Epoch: [25]  [ 300/2001]  eta: 0:18:19  lr: 0.000051  loss: 3.0461 (3.0383)  time: 0.6337  data: 0.0002  max mem: 8730
Epoch: [25]  [ 310/2001]  eta: 0:18:12  lr: 0.000051  loss: 3.0720 (3.0365)  time: 0.6322  data: 0.0001  max mem: 8730
Epoch: [25]  [ 320/2001]  eta: 0:18:04  lr: 0.000051  loss: 3.1811 (3.0340)  time: 0.6296  data: 0.0001  max mem: 8730
Epoch: [25]  [ 330/2001]  eta: 0:17:57  lr: 0.000051  loss: 3.1811 (3.0386)  time: 0.6282  data: 0.0001  max mem: 8730
Epoch: [25]  [ 340/2001]  eta: 0:17:50  lr: 0.000051  loss: 3.3077 (3.0372)  time: 0.6303  data: 0.0001  max mem: 8730
Epoch: [25]  [ 350/2001]  eta: 0:17:43  lr: 0.000051  loss: 3.3077 (3.0473)  time: 0.6373  data: 0.0001  max mem: 8730
Epoch: [25]  [ 360/2001]  eta: 0:17:36  lr: 0.000051  loss: 3.2026 (3.0425)  time: 0.6330  data: 0.0001  max mem: 8730
Epoch: [25]  [ 370/2001]  eta: 0:17:29  lr: 0.000051  loss: 3.1156 (3.0386)  time: 0.6260  data: 0.0001  max mem: 8730
Epoch: [25]  [ 380/2001]  eta: 0:17:21  lr: 0.000051  loss: 3.1685 (3.0480)  time: 0.6249  data: 0.0001  max mem: 8730
Epoch: [25]  [ 390/2001]  eta: 0:17:14  lr: 0.000051  loss: 3.3970 (3.0473)  time: 0.6254  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9696, ratio_loss=0.0438, cls_kl=0.0633, token_kl=0.0928
Epoch: [25]  [ 400/2001]  eta: 0:17:08  lr: 0.000051  loss: 3.2605 (3.0512)  time: 0.6339  data: 0.0001  max mem: 8730
Epoch: [25]  [ 410/2001]  eta: 0:17:01  lr: 0.000051  loss: 3.1945 (3.0522)  time: 0.6340  data: 0.0001  max mem: 8730
Epoch: [25]  [ 420/2001]  eta: 0:16:54  lr: 0.000051  loss: 3.1703 (3.0552)  time: 0.6327  data: 0.0001  max mem: 8730
Epoch: [25]  [ 430/2001]  eta: 0:16:48  lr: 0.000051  loss: 3.1466 (3.0519)  time: 0.6351  data: 0.0001  max mem: 8730
Epoch: [25]  [ 440/2001]  eta: 0:16:41  lr: 0.000051  loss: 3.1149 (3.0511)  time: 0.6332  data: 0.0002  max mem: 8730
Epoch: [25]  [ 450/2001]  eta: 0:16:34  lr: 0.000051  loss: 3.3059 (3.0578)  time: 0.6294  data: 0.0001  max mem: 8730
Epoch: [25]  [ 460/2001]  eta: 0:16:27  lr: 0.000051  loss: 3.3059 (3.0578)  time: 0.6288  data: 0.0001  max mem: 8730
Epoch: [25]  [ 470/2001]  eta: 0:16:20  lr: 0.000051  loss: 3.2216 (3.0581)  time: 0.6300  data: 0.0001  max mem: 8730
Epoch: [25]  [ 480/2001]  eta: 0:16:14  lr: 0.000051  loss: 3.2216 (3.0600)  time: 0.6283  data: 0.0001  max mem: 8730
Epoch: [25]  [ 490/2001]  eta: 0:16:07  lr: 0.000051  loss: 3.1680 (3.0584)  time: 0.6256  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9829, ratio_loss=0.0463, cls_kl=0.0644, token_kl=0.0956
Epoch: [25]  [ 500/2001]  eta: 0:16:00  lr: 0.000051  loss: 3.0960 (3.0599)  time: 0.6263  data: 0.0002  max mem: 8730
Epoch: [25]  [ 510/2001]  eta: 0:15:53  lr: 0.000051  loss: 3.0733 (3.0543)  time: 0.6258  data: 0.0001  max mem: 8730
Epoch: [25]  [ 520/2001]  eta: 0:15:46  lr: 0.000051  loss: 3.0383 (3.0546)  time: 0.6200  data: 0.0001  max mem: 8730
Epoch: [25]  [ 530/2001]  eta: 0:15:39  lr: 0.000051  loss: 3.3045 (3.0601)  time: 0.6214  data: 0.0001  max mem: 8730
Epoch: [25]  [ 540/2001]  eta: 0:15:32  lr: 0.000051  loss: 3.3045 (3.0590)  time: 0.6253  data: 0.0001  max mem: 8730
Epoch: [25]  [ 550/2001]  eta: 0:15:26  lr: 0.000051  loss: 3.0203 (3.0557)  time: 0.6253  data: 0.0001  max mem: 8730
Epoch: [25]  [ 560/2001]  eta: 0:15:19  lr: 0.000051  loss: 3.0596 (3.0576)  time: 0.6266  data: 0.0001  max mem: 8730
Epoch: [25]  [ 570/2001]  eta: 0:15:12  lr: 0.000051  loss: 3.3638 (3.0627)  time: 0.6253  data: 0.0001  max mem: 8730
Epoch: [25]  [ 580/2001]  eta: 0:15:06  lr: 0.000051  loss: 3.4064 (3.0648)  time: 0.6285  data: 0.0001  max mem: 8730
Epoch: [25]  [ 590/2001]  eta: 0:14:59  lr: 0.000051  loss: 3.3329 (3.0665)  time: 0.6264  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0018, ratio_loss=0.0461, cls_kl=0.0656, token_kl=0.0947
Epoch: [25]  [ 600/2001]  eta: 0:14:52  lr: 0.000051  loss: 3.1415 (3.0657)  time: 0.6224  data: 0.0001  max mem: 8730
Epoch: [25]  [ 610/2001]  eta: 0:14:46  lr: 0.000051  loss: 3.2521 (3.0704)  time: 0.6249  data: 0.0001  max mem: 8730
Epoch: [25]  [ 620/2001]  eta: 0:14:39  lr: 0.000051  loss: 3.2725 (3.0689)  time: 0.6234  data: 0.0001  max mem: 8730
Epoch: [25]  [ 630/2001]  eta: 0:14:32  lr: 0.000051  loss: 2.9937 (3.0674)  time: 0.6241  data: 0.0001  max mem: 8730
Epoch: [25]  [ 640/2001]  eta: 0:14:26  lr: 0.000051  loss: 2.9937 (3.0676)  time: 0.6277  data: 0.0001  max mem: 8730
Epoch: [25]  [ 650/2001]  eta: 0:14:19  lr: 0.000051  loss: 2.8711 (3.0631)  time: 0.6256  data: 0.0001  max mem: 8730
Epoch: [25]  [ 660/2001]  eta: 0:14:13  lr: 0.000051  loss: 2.8711 (3.0629)  time: 0.6227  data: 0.0001  max mem: 8730
Epoch: [25]  [ 670/2001]  eta: 0:14:06  lr: 0.000051  loss: 3.1098 (3.0636)  time: 0.6238  data: 0.0001  max mem: 8730
Epoch: [25]  [ 680/2001]  eta: 0:13:59  lr: 0.000051  loss: 3.1046 (3.0613)  time: 0.6225  data: 0.0001  max mem: 8730
Epoch: [25]  [ 690/2001]  eta: 0:13:53  lr: 0.000051  loss: 3.1046 (3.0610)  time: 0.6285  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9319, ratio_loss=0.0420, cls_kl=0.0633, token_kl=0.0938
Epoch: [25]  [ 700/2001]  eta: 0:13:46  lr: 0.000051  loss: 3.2312 (3.0628)  time: 0.6289  data: 0.0001  max mem: 8730
Epoch: [25]  [ 710/2001]  eta: 0:13:40  lr: 0.000051  loss: 3.1943 (3.0614)  time: 0.6228  data: 0.0001  max mem: 8730
Epoch: [25]  [ 720/2001]  eta: 0:13:33  lr: 0.000051  loss: 2.9617 (3.0608)  time: 0.6240  data: 0.0001  max mem: 8730
Epoch: [25]  [ 730/2001]  eta: 0:13:27  lr: 0.000051  loss: 2.9617 (3.0568)  time: 0.6218  data: 0.0001  max mem: 8730
Epoch: [25]  [ 740/2001]  eta: 0:13:20  lr: 0.000051  loss: 2.9256 (3.0544)  time: 0.6207  data: 0.0001  max mem: 8730
Epoch: [25]  [ 750/2001]  eta: 0:13:14  lr: 0.000051  loss: 2.9256 (3.0553)  time: 0.6243  data: 0.0001  max mem: 8730
Epoch: [25]  [ 760/2001]  eta: 0:13:07  lr: 0.000051  loss: 3.0610 (3.0561)  time: 0.6273  data: 0.0001  max mem: 8730
Epoch: [25]  [ 770/2001]  eta: 0:13:01  lr: 0.000051  loss: 3.1357 (3.0595)  time: 0.6366  data: 0.0001  max mem: 8730
Epoch: [25]  [ 780/2001]  eta: 0:12:54  lr: 0.000051  loss: 3.2446 (3.0587)  time: 0.6333  data: 0.0001  max mem: 8730
Epoch: [25]  [ 790/2001]  eta: 0:12:48  lr: 0.000051  loss: 3.2446 (3.0610)  time: 0.6234  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9309, ratio_loss=0.0436, cls_kl=0.0624, token_kl=0.0930
Epoch: [25]  [ 800/2001]  eta: 0:12:41  lr: 0.000051  loss: 3.1957 (3.0593)  time: 0.6227  data: 0.0001  max mem: 8730
Epoch: [25]  [ 810/2001]  eta: 0:12:35  lr: 0.000051  loss: 2.9741 (3.0581)  time: 0.6230  data: 0.0001  max mem: 8730
Epoch: [25]  [ 820/2001]  eta: 0:12:28  lr: 0.000051  loss: 3.0135 (3.0568)  time: 0.6262  data: 0.0001  max mem: 8730
Epoch: [25]  [ 830/2001]  eta: 0:12:22  lr: 0.000051  loss: 3.1459 (3.0563)  time: 0.6295  data: 0.0001  max mem: 8730
Epoch: [25]  [ 840/2001]  eta: 0:12:16  lr: 0.000051  loss: 3.1162 (3.0554)  time: 0.6324  data: 0.0001  max mem: 8730
Epoch: [25]  [ 850/2001]  eta: 0:12:09  lr: 0.000051  loss: 3.1377 (3.0592)  time: 0.6371  data: 0.0001  max mem: 8730
Epoch: [25]  [ 860/2001]  eta: 0:12:03  lr: 0.000051  loss: 3.0942 (3.0553)  time: 0.6330  data: 0.0001  max mem: 8730
Epoch: [25]  [ 870/2001]  eta: 0:11:57  lr: 0.000051  loss: 2.8774 (3.0532)  time: 0.6269  data: 0.0001  max mem: 8730
Epoch: [25]  [ 880/2001]  eta: 0:11:50  lr: 0.000051  loss: 2.9647 (3.0552)  time: 0.6270  data: 0.0001  max mem: 8730
Epoch: [25]  [ 890/2001]  eta: 0:11:44  lr: 0.000051  loss: 3.0393 (3.0529)  time: 0.6261  data: 0.0002  max mem: 8730
loss info: cls_loss=2.8792, ratio_loss=0.0429, cls_kl=0.0617, token_kl=0.0937
Epoch: [25]  [ 900/2001]  eta: 0:11:37  lr: 0.000051  loss: 2.9135 (3.0520)  time: 0.6284  data: 0.0001  max mem: 8730
Epoch: [25]  [ 910/2001]  eta: 0:11:31  lr: 0.000051  loss: 3.0885 (3.0521)  time: 0.6300  data: 0.0001  max mem: 8730
Epoch: [25]  [ 920/2001]  eta: 0:11:24  lr: 0.000051  loss: 3.2815 (3.0518)  time: 0.6289  data: 0.0001  max mem: 8730
Epoch: [25]  [ 930/2001]  eta: 0:11:18  lr: 0.000051  loss: 2.9675 (3.0504)  time: 0.6310  data: 0.0001  max mem: 8730
Epoch: [25]  [ 940/2001]  eta: 0:11:12  lr: 0.000051  loss: 2.7839 (3.0472)  time: 0.6303  data: 0.0001  max mem: 8730
Epoch: [25]  [ 950/2001]  eta: 0:11:05  lr: 0.000051  loss: 3.0085 (3.0472)  time: 0.6259  data: 0.0001  max mem: 8730
Epoch: [25]  [ 960/2001]  eta: 0:10:59  lr: 0.000051  loss: 3.2436 (3.0501)  time: 0.6289  data: 0.0001  max mem: 8730
Epoch: [25]  [ 970/2001]  eta: 0:10:53  lr: 0.000051  loss: 3.2611 (3.0514)  time: 0.6327  data: 0.0001  max mem: 8730
Epoch: [25]  [ 980/2001]  eta: 0:10:46  lr: 0.000051  loss: 3.2611 (3.0524)  time: 0.6315  data: 0.0001  max mem: 8730
Epoch: [25]  [ 990/2001]  eta: 0:10:40  lr: 0.000051  loss: 3.1699 (3.0523)  time: 0.6335  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9542, ratio_loss=0.0459, cls_kl=0.0641, token_kl=0.0944
Epoch: [25]  [1000/2001]  eta: 0:10:34  lr: 0.000051  loss: 3.1775 (3.0542)  time: 0.6343  data: 0.0001  max mem: 8730
Epoch: [25]  [1010/2001]  eta: 0:10:27  lr: 0.000051  loss: 3.1775 (3.0539)  time: 0.6335  data: 0.0001  max mem: 8730
Epoch: [25]  [1020/2001]  eta: 0:10:21  lr: 0.000051  loss: 3.0838 (3.0540)  time: 0.6338  data: 0.0001  max mem: 8730
Epoch: [25]  [1030/2001]  eta: 0:10:15  lr: 0.000051  loss: 3.1410 (3.0549)  time: 0.6297  data: 0.0001  max mem: 8730
Epoch: [25]  [1040/2001]  eta: 0:10:08  lr: 0.000051  loss: 3.1149 (3.0529)  time: 0.6318  data: 0.0001  max mem: 8730
Epoch: [25]  [1050/2001]  eta: 0:10:02  lr: 0.000051  loss: 3.1791 (3.0534)  time: 0.6320  data: 0.0001  max mem: 8730
Epoch: [25]  [1060/2001]  eta: 0:09:55  lr: 0.000051  loss: 3.2893 (3.0556)  time: 0.6288  data: 0.0001  max mem: 8730
Epoch: [25]  [1070/2001]  eta: 0:09:49  lr: 0.000051  loss: 3.3012 (3.0564)  time: 0.6331  data: 0.0001  max mem: 8730
Epoch: [25]  [1080/2001]  eta: 0:09:43  lr: 0.000051  loss: 3.3292 (3.0589)  time: 0.6326  data: 0.0001  max mem: 8730
Epoch: [25]  [1090/2001]  eta: 0:09:36  lr: 0.000051  loss: 3.3453 (3.0616)  time: 0.6307  data: 0.0001  max mem: 8730
loss info: cls_loss=3.0490, ratio_loss=0.0471, cls_kl=0.0650, token_kl=0.0945
Epoch: [25]  [1100/2001]  eta: 0:09:30  lr: 0.000051  loss: 3.3286 (3.0612)  time: 0.6315  data: 0.0001  max mem: 8730
Epoch: [25]  [1110/2001]  eta: 0:09:24  lr: 0.000051  loss: 3.0610 (3.0609)  time: 0.6341  data: 0.0001  max mem: 8730
Epoch: [25]  [1120/2001]  eta: 0:09:18  lr: 0.000051  loss: 3.0951 (3.0608)  time: 0.6377  data: 0.0001  max mem: 8730
Epoch: [25]  [1130/2001]  eta: 0:09:11  lr: 0.000051  loss: 3.1442 (3.0621)  time: 0.6334  data: 0.0001  max mem: 8730
Epoch: [25]  [1140/2001]  eta: 0:09:05  lr: 0.000051  loss: 3.2127 (3.0618)  time: 0.6301  data: 0.0001  max mem: 8730
Epoch: [25]  [1150/2001]  eta: 0:08:58  lr: 0.000051  loss: 3.0513 (3.0608)  time: 0.6309  data: 0.0001  max mem: 8730
Epoch: [25]  [1160/2001]  eta: 0:08:52  lr: 0.000051  loss: 2.9223 (3.0592)  time: 0.6294  data: 0.0001  max mem: 8730
Epoch: [25]  [1170/2001]  eta: 0:08:46  lr: 0.000051  loss: 3.0240 (3.0610)  time: 0.6294  data: 0.0001  max mem: 8730
Epoch: [25]  [1180/2001]  eta: 0:08:39  lr: 0.000051  loss: 3.1917 (3.0611)  time: 0.6350  data: 0.0001  max mem: 8730
Epoch: [25]  [1190/2001]  eta: 0:08:33  lr: 0.000051  loss: 3.0837 (3.0603)  time: 0.6363  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9493, ratio_loss=0.0466, cls_kl=0.0641, token_kl=0.0958
Epoch: [25]  [1200/2001]  eta: 0:08:27  lr: 0.000051  loss: 3.1980 (3.0614)  time: 0.6357  data: 0.0001  max mem: 8730
Epoch: [25]  [1210/2001]  eta: 0:08:20  lr: 0.000051  loss: 3.2233 (3.0627)  time: 0.6355  data: 0.0001  max mem: 8730
Epoch: [25]  [1220/2001]  eta: 0:08:14  lr: 0.000051  loss: 3.2530 (3.0634)  time: 0.6328  data: 0.0001  max mem: 8730
Epoch: [25]  [1230/2001]  eta: 0:08:08  lr: 0.000051  loss: 3.3936 (3.0650)  time: 0.6325  data: 0.0001  max mem: 8730
Epoch: [25]  [1240/2001]  eta: 0:08:01  lr: 0.000051  loss: 3.1781 (3.0648)  time: 0.6340  data: 0.0001  max mem: 8730
Epoch: [25]  [1250/2001]  eta: 0:07:55  lr: 0.000051  loss: 3.1487 (3.0654)  time: 0.6360  data: 0.0001  max mem: 8730
Epoch: [25]  [1260/2001]  eta: 0:07:49  lr: 0.000051  loss: 3.0487 (3.0645)  time: 0.6375  data: 0.0001  max mem: 8730
Epoch: [25]  [1270/2001]  eta: 0:07:43  lr: 0.000051  loss: 3.0322 (3.0659)  time: 0.6425  data: 0.0001  max mem: 8730
Epoch: [25]  [1280/2001]  eta: 0:07:36  lr: 0.000051  loss: 3.0322 (3.0646)  time: 0.6453  data: 0.0001  max mem: 8730
Epoch: [25]  [1290/2001]  eta: 0:07:30  lr: 0.000051  loss: 3.1149 (3.0649)  time: 0.6389  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9614, ratio_loss=0.0457, cls_kl=0.0649, token_kl=0.0953
Epoch: [25]  [1300/2001]  eta: 0:07:24  lr: 0.000051  loss: 3.1149 (3.0633)  time: 0.6321  data: 0.0001  max mem: 8730
Epoch: [25]  [1310/2001]  eta: 0:07:17  lr: 0.000051  loss: 3.0343 (3.0636)  time: 0.6311  data: 0.0001  max mem: 8730
Epoch: [25]  [1320/2001]  eta: 0:07:11  lr: 0.000051  loss: 3.3244 (3.0661)  time: 0.6343  data: 0.0001  max mem: 8730
Epoch: [25]  [1330/2001]  eta: 0:07:05  lr: 0.000051  loss: 3.2481 (3.0660)  time: 0.6359  data: 0.0001  max mem: 8730
Epoch: [25]  [1340/2001]  eta: 0:06:58  lr: 0.000051  loss: 2.6913 (3.0623)  time: 0.6362  data: 0.0001  max mem: 8730
Epoch: [25]  [1350/2001]  eta: 0:06:52  lr: 0.000051  loss: 2.6029 (3.0615)  time: 0.6374  data: 0.0001  max mem: 8730
Epoch: [25]  [1360/2001]  eta: 0:06:46  lr: 0.000051  loss: 3.0149 (3.0602)  time: 0.6381  data: 0.0001  max mem: 8730
Epoch: [25]  [1370/2001]  eta: 0:06:39  lr: 0.000051  loss: 2.7529 (3.0591)  time: 0.6370  data: 0.0001  max mem: 8730
Epoch: [25]  [1380/2001]  eta: 0:06:33  lr: 0.000051  loss: 2.9846 (3.0581)  time: 0.6337  data: 0.0001  max mem: 8730
Epoch: [25]  [1390/2001]  eta: 0:06:27  lr: 0.000051  loss: 3.2630 (3.0599)  time: 0.6354  data: 0.0001  max mem: 8730
loss info: cls_loss=2.8988, ratio_loss=0.0438, cls_kl=0.0631, token_kl=0.0942
Epoch: [25]  [1400/2001]  eta: 0:06:20  lr: 0.000051  loss: 3.3356 (3.0598)  time: 0.6365  data: 0.0001  max mem: 8730
Epoch: [25]  [1410/2001]  eta: 0:06:14  lr: 0.000051  loss: 3.2426 (3.0598)  time: 0.6390  data: 0.0001  max mem: 8730
Epoch: [25]  [1420/2001]  eta: 0:06:08  lr: 0.000051  loss: 3.0670 (3.0580)  time: 0.6385  data: 0.0001  max mem: 8730
Epoch: [25]  [1430/2001]  eta: 0:06:01  lr: 0.000051  loss: 3.0711 (3.0578)  time: 0.6370  data: 0.0001  max mem: 8730
Epoch: [25]  [1440/2001]  eta: 0:05:55  lr: 0.000051  loss: 3.2169 (3.0594)  time: 0.6434  data: 0.0001  max mem: 8730
Epoch: [25]  [1450/2001]  eta: 0:05:49  lr: 0.000051  loss: 3.3470 (3.0592)  time: 0.6410  data: 0.0001  max mem: 8730
Epoch: [25]  [1460/2001]  eta: 0:05:42  lr: 0.000051  loss: 3.2077 (3.0598)  time: 0.6359  data: 0.0001  max mem: 8730
Epoch: [25]  [1470/2001]  eta: 0:05:36  lr: 0.000051  loss: 3.0707 (3.0592)  time: 0.6368  data: 0.0001  max mem: 8730
Epoch: [25]  [1480/2001]  eta: 0:05:30  lr: 0.000051  loss: 3.0707 (3.0592)  time: 0.6363  data: 0.0001  max mem: 8730
Epoch: [25]  [1490/2001]  eta: 0:05:23  lr: 0.000051  loss: 3.1447 (3.0598)  time: 0.6372  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9703, ratio_loss=0.0422, cls_kl=0.0657, token_kl=0.0948
Epoch: [25]  [1500/2001]  eta: 0:05:17  lr: 0.000051  loss: 3.1447 (3.0606)  time: 0.6387  data: 0.0001  max mem: 8730
Epoch: [25]  [1510/2001]  eta: 0:05:11  lr: 0.000051  loss: 3.1359 (3.0609)  time: 0.6378  data: 0.0001  max mem: 8730
Epoch: [25]  [1520/2001]  eta: 0:05:04  lr: 0.000051  loss: 3.0810 (3.0600)  time: 0.6360  data: 0.0001  max mem: 8730
Epoch: [25]  [1530/2001]  eta: 0:04:58  lr: 0.000051  loss: 3.1226 (3.0603)  time: 0.6358  data: 0.0001  max mem: 8730
Epoch: [25]  [1540/2001]  eta: 0:04:52  lr: 0.000051  loss: 3.2376 (3.0606)  time: 0.6426  data: 0.0001  max mem: 8730
Epoch: [25]  [1550/2001]  eta: 0:04:46  lr: 0.000051  loss: 3.2177 (3.0607)  time: 0.6443  data: 0.0001  max mem: 8730
Epoch: [25]  [1560/2001]  eta: 0:04:39  lr: 0.000051  loss: 3.1368 (3.0588)  time: 0.6381  data: 0.0001  max mem: 8730
Epoch: [25]  [1570/2001]  eta: 0:04:33  lr: 0.000051  loss: 3.2131 (3.0589)  time: 0.6364  data: 0.0001  max mem: 8730
Epoch: [25]  [1580/2001]  eta: 0:04:27  lr: 0.000051  loss: 3.3286 (3.0600)  time: 0.6375  data: 0.0001  max mem: 8730
Epoch: [25]  [1590/2001]  eta: 0:04:20  lr: 0.000051  loss: 3.2887 (3.0608)  time: 0.6363  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9462, ratio_loss=0.0440, cls_kl=0.0646, token_kl=0.0949
Epoch: [25]  [1600/2001]  eta: 0:04:14  lr: 0.000051  loss: 3.1894 (3.0607)  time: 0.6350  data: 0.0001  max mem: 8730
Epoch: [25]  [1610/2001]  eta: 0:04:08  lr: 0.000051  loss: 3.2058 (3.0618)  time: 0.6355  data: 0.0001  max mem: 8730
Epoch: [25]  [1620/2001]  eta: 0:04:01  lr: 0.000051  loss: 3.0446 (3.0606)  time: 0.6347  data: 0.0001  max mem: 8730
Epoch: [25]  [1630/2001]  eta: 0:03:55  lr: 0.000051  loss: 2.8996 (3.0594)  time: 0.6378  data: 0.0001  max mem: 8730
Epoch: [25]  [1640/2001]  eta: 0:03:48  lr: 0.000051  loss: 3.0693 (3.0597)  time: 0.6371  data: 0.0001  max mem: 8730
Epoch: [25]  [1650/2001]  eta: 0:03:42  lr: 0.000051  loss: 3.1549 (3.0594)  time: 0.6335  data: 0.0001  max mem: 8730
Epoch: [25]  [1660/2001]  eta: 0:03:36  lr: 0.000051  loss: 3.1549 (3.0603)  time: 0.6358  data: 0.0001  max mem: 8730
Epoch: [25]  [1670/2001]  eta: 0:03:29  lr: 0.000051  loss: 2.9374 (3.0580)  time: 0.6353  data: 0.0001  max mem: 8730
Epoch: [25]  [1680/2001]  eta: 0:03:23  lr: 0.000051  loss: 2.7481 (3.0569)  time: 0.6361  data: 0.0001  max mem: 8730
Epoch: [25]  [1690/2001]  eta: 0:03:17  lr: 0.000051  loss: 3.0432 (3.0578)  time: 0.6348  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9211, ratio_loss=0.0412, cls_kl=0.0609, token_kl=0.0923
Epoch: [25]  [1700/2001]  eta: 0:03:10  lr: 0.000051  loss: 3.3149 (3.0582)  time: 0.6388  data: 0.0001  max mem: 8730
Epoch: [25]  [1710/2001]  eta: 0:03:04  lr: 0.000051  loss: 2.9275 (3.0567)  time: 0.6452  data: 0.0001  max mem: 8730
Epoch: [25]  [1720/2001]  eta: 0:02:58  lr: 0.000051  loss: 2.9740 (3.0566)  time: 0.6372  data: 0.0001  max mem: 8730
Epoch: [25]  [1730/2001]  eta: 0:02:51  lr: 0.000051  loss: 3.0360 (3.0565)  time: 0.6325  data: 0.0001  max mem: 8730
Epoch: [25]  [1740/2001]  eta: 0:02:45  lr: 0.000051  loss: 2.9813 (3.0569)  time: 0.6374  data: 0.0001  max mem: 8730
Epoch: [25]  [1750/2001]  eta: 0:02:39  lr: 0.000051  loss: 3.1407 (3.0581)  time: 0.6360  data: 0.0001  max mem: 8730
Epoch: [25]  [1760/2001]  eta: 0:02:32  lr: 0.000051  loss: 3.1131 (3.0563)  time: 0.6322  data: 0.0001  max mem: 8730
Epoch: [25]  [1770/2001]  eta: 0:02:26  lr: 0.000051  loss: 3.0434 (3.0569)  time: 0.6315  data: 0.0001  max mem: 8730
Epoch: [25]  [1780/2001]  eta: 0:02:20  lr: 0.000051  loss: 3.1412 (3.0571)  time: 0.6295  data: 0.0001  max mem: 8730
Epoch: [25]  [1790/2001]  eta: 0:02:13  lr: 0.000051  loss: 3.1882 (3.0578)  time: 0.6346  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9296, ratio_loss=0.0441, cls_kl=0.0623, token_kl=0.0929
Epoch: [25]  [1800/2001]  eta: 0:02:07  lr: 0.000051  loss: 3.0922 (3.0560)  time: 0.6360  data: 0.0001  max mem: 8730
Epoch: [25]  [1810/2001]  eta: 0:02:01  lr: 0.000051  loss: 2.7490 (3.0553)  time: 0.6338  data: 0.0001  max mem: 8730
Epoch: [25]  [1820/2001]  eta: 0:01:54  lr: 0.000051  loss: 2.9974 (3.0553)  time: 0.6326  data: 0.0001  max mem: 8730
Epoch: [25]  [1830/2001]  eta: 0:01:48  lr: 0.000051  loss: 2.9974 (3.0555)  time: 0.6284  data: 0.0001  max mem: 8730
Epoch: [25]  [1840/2001]  eta: 0:01:42  lr: 0.000051  loss: 3.2439 (3.0555)  time: 0.6290  data: 0.0001  max mem: 8730
Epoch: [25]  [1850/2001]  eta: 0:01:35  lr: 0.000051  loss: 3.1883 (3.0553)  time: 0.6316  data: 0.0001  max mem: 8730
Epoch: [25]  [1860/2001]  eta: 0:01:29  lr: 0.000051  loss: 3.1829 (3.0563)  time: 0.6281  data: 0.0001  max mem: 8730
Epoch: [25]  [1870/2001]  eta: 0:01:23  lr: 0.000051  loss: 3.2967 (3.0577)  time: 0.6311  data: 0.0001  max mem: 8730
Epoch: [25]  [1880/2001]  eta: 0:01:16  lr: 0.000051  loss: 3.4147 (3.0593)  time: 0.6298  data: 0.0001  max mem: 8730
Epoch: [25]  [1890/2001]  eta: 0:01:10  lr: 0.000051  loss: 3.2924 (3.0595)  time: 0.6222  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9869, ratio_loss=0.0441, cls_kl=0.0637, token_kl=0.0932
Epoch: [25]  [1900/2001]  eta: 0:01:04  lr: 0.000051  loss: 3.0081 (3.0592)  time: 0.6243  data: 0.0001  max mem: 8730
Epoch: [25]  [1910/2001]  eta: 0:00:57  lr: 0.000051  loss: 3.2628 (3.0597)  time: 0.6252  data: 0.0001  max mem: 8730
Epoch: [25]  [1920/2001]  eta: 0:00:51  lr: 0.000051  loss: 2.9266 (3.0575)  time: 0.6288  data: 0.0001  max mem: 8730
Epoch: [25]  [1930/2001]  eta: 0:00:45  lr: 0.000051  loss: 2.7855 (3.0565)  time: 0.6293  data: 0.0001  max mem: 8730
Epoch: [25]  [1940/2001]  eta: 0:00:38  lr: 0.000051  loss: 2.9014 (3.0559)  time: 0.6224  data: 0.0001  max mem: 8730
Epoch: [25]  [1950/2001]  eta: 0:00:32  lr: 0.000051  loss: 2.9447 (3.0554)  time: 0.6225  data: 0.0001  max mem: 8730
Epoch: [25]  [1960/2001]  eta: 0:00:25  lr: 0.000051  loss: 3.1248 (3.0562)  time: 0.6244  data: 0.0001  max mem: 8730
Epoch: [25]  [1970/2001]  eta: 0:00:19  lr: 0.000051  loss: 3.1248 (3.0555)  time: 0.6296  data: 0.0001  max mem: 8730
Epoch: [25]  [1980/2001]  eta: 0:00:13  lr: 0.000051  loss: 3.0775 (3.0562)  time: 0.6300  data: 0.0001  max mem: 8730
Epoch: [25]  [1990/2001]  eta: 0:00:06  lr: 0.000051  loss: 3.2762 (3.0557)  time: 0.6202  data: 0.0004  max mem: 8730
loss info: cls_loss=2.8907, ratio_loss=0.0424, cls_kl=0.0616, token_kl=0.0919
Epoch: [25]  [2000/2001]  eta: 0:00:00  lr: 0.000051  loss: 2.9165 (3.0551)  time: 0.6153  data: 0.0003  max mem: 8730
Epoch: [25] Total time: 0:21:08 (0.6339 s / it)
Averaged stats: lr: 0.000051  loss: 2.9165 (3.0435)
Test:  [ 0/53]  eta: 0:04:35  loss: 0.3716 (0.3716)  acc1: 92.5000 (92.5000)  acc5: 99.1667 (99.1667)  time: 5.1940  data: 4.7022  max mem: 8730
Test:  [10/53]  eta: 0:00:36  loss: 0.7898 (0.7685)  acc1: 81.6667 (82.6515)  acc5: 96.6667 (96.7424)  time: 0.8427  data: 0.4277  max mem: 8730
Test:  [20/53]  eta: 0:00:19  loss: 0.7118 (0.7679)  acc1: 81.6667 (82.9365)  acc5: 96.6667 (96.6270)  time: 0.3760  data: 0.0003  max mem: 8730
Test:  [30/53]  eta: 0:00:12  loss: 0.8509 (0.8493)  acc1: 80.0000 (81.2903)  acc5: 95.0000 (95.4301)  time: 0.3604  data: 0.0003  max mem: 8730
Test:  [40/53]  eta: 0:00:06  loss: 1.1005 (0.9245)  acc1: 75.0000 (79.4106)  acc5: 91.6667 (94.5529)  time: 0.3198  data: 0.0002  max mem: 8730
Test:  [50/53]  eta: 0:00:01  loss: 1.1111 (0.9530)  acc1: 75.0000 (78.7092)  acc5: 92.5000 (94.2974)  time: 0.2580  data: 0.0001  max mem: 8730
Test:  [52/53]  eta: 0:00:00  loss: 1.0936 (0.9388)  acc1: 75.0000 (78.8960)  acc5: 92.5000 (94.3520)  time: 0.2455  data: 0.0001  max mem: 8730
Test: Total time: 0:00:22 (0.4162 s / it)
Sparsity0:0.2893058585858586,Sparsity1:0.5554685427135678,Sparsity2:0.7859712,
* Acc@1 79.072 Acc@5 94.494 loss 0.938
Accuracy of the network on the 50000 test images: 79.1%
Max accuracy: 79.07%
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0000366 for PREDICTOR
Epoch: [26]  [   0/2001]  eta: 2:39:49  lr: 0.000037  loss: 3.2450 (3.2450)  time: 4.7926  data: 4.1550  max mem: 8730
Epoch: [26]  [  10/2001]  eta: 0:32:54  lr: 0.000037  loss: 3.1811 (3.0394)  time: 0.9917  data: 0.3778  max mem: 8730
Epoch: [26]  [  20/2001]  eta: 0:26:52  lr: 0.000037  loss: 3.1032 (3.0514)  time: 0.6151  data: 0.0001  max mem: 8730
Epoch: [26]  [  30/2001]  eta: 0:24:43  lr: 0.000037  loss: 3.1032 (3.0163)  time: 0.6210  data: 0.0001  max mem: 8730
Epoch: [26]  [  40/2001]  eta: 0:23:30  lr: 0.000037  loss: 3.1752 (3.0712)  time: 0.6198  data: 0.0001  max mem: 8730
Epoch: [26]  [  50/2001]  eta: 0:22:44  lr: 0.000037  loss: 3.3023 (3.1144)  time: 0.6167  data: 0.0001  max mem: 8730
Epoch: [26]  [  60/2001]  eta: 0:22:10  lr: 0.000037  loss: 3.1965 (3.1095)  time: 0.6168  data: 0.0001  max mem: 8730
Epoch: [26]  [  70/2001]  eta: 0:21:49  lr: 0.000037  loss: 3.1965 (3.1245)  time: 0.6233  data: 0.0001  max mem: 8730
Epoch: [26]  [  80/2001]  eta: 0:21:29  lr: 0.000037  loss: 3.1956 (3.0897)  time: 0.6266  data: 0.0001  max mem: 8730
Epoch: [26]  [  90/2001]  eta: 0:21:11  lr: 0.000037  loss: 2.8139 (3.0677)  time: 0.6198  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9524, ratio_loss=0.0454, cls_kl=0.0633, token_kl=0.0948
Epoch: [26]  [ 100/2001]  eta: 0:20:57  lr: 0.000037  loss: 2.9275 (3.0539)  time: 0.6222  data: 0.0001  max mem: 8730
Epoch: [26]  [ 110/2001]  eta: 0:20:43  lr: 0.000037  loss: 2.9286 (3.0475)  time: 0.6235  data: 0.0001  max mem: 8730
Epoch: [26]  [ 120/2001]  eta: 0:20:32  lr: 0.000037  loss: 3.1670 (3.0552)  time: 0.6229  data: 0.0001  max mem: 8730
Epoch: [26]  [ 130/2001]  eta: 0:20:21  lr: 0.000037  loss: 3.2677 (3.0570)  time: 0.6252  data: 0.0001  max mem: 8730
Epoch: [26]  [ 140/2001]  eta: 0:20:11  lr: 0.000037  loss: 2.9703 (3.0399)  time: 0.6255  data: 0.0001  max mem: 8730
Epoch: [26]  [ 150/2001]  eta: 0:20:01  lr: 0.000037  loss: 2.8732 (3.0428)  time: 0.6257  data: 0.0001  max mem: 8730
Epoch: [26]  [ 160/2001]  eta: 0:19:55  lr: 0.000037  loss: 3.2210 (3.0432)  time: 0.6370  data: 0.0001  max mem: 8730
Epoch: [26]  [ 170/2001]  eta: 0:19:47  lr: 0.000037  loss: 3.1508 (3.0426)  time: 0.6461  data: 0.0001  max mem: 8730
Epoch: [26]  [ 180/2001]  eta: 0:19:39  lr: 0.000037  loss: 3.2397 (3.0489)  time: 0.6346  data: 0.0001  max mem: 8730
Epoch: [26]  [ 190/2001]  eta: 0:19:30  lr: 0.000037  loss: 3.2397 (3.0499)  time: 0.6267  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9120, ratio_loss=0.0418, cls_kl=0.0608, token_kl=0.0906
Epoch: [26]  [ 200/2001]  eta: 0:19:22  lr: 0.000037  loss: 3.1091 (3.0505)  time: 0.6271  data: 0.0001  max mem: 8730
Epoch: [26]  [ 210/2001]  eta: 0:19:14  lr: 0.000037  loss: 3.3116 (3.0588)  time: 0.6280  data: 0.0001  max mem: 8730
Epoch: [26]  [ 220/2001]  eta: 0:19:07  lr: 0.000037  loss: 3.1625 (3.0476)  time: 0.6317  data: 0.0001  max mem: 8730
Epoch: [26]  [ 230/2001]  eta: 0:18:59  lr: 0.000037  loss: 3.1167 (3.0523)  time: 0.6314  data: 0.0001  max mem: 8730
Epoch: [26]  [ 240/2001]  eta: 0:18:52  lr: 0.000037  loss: 3.1841 (3.0522)  time: 0.6273  data: 0.0001  max mem: 8730
Epoch: [26]  [ 250/2001]  eta: 0:18:44  lr: 0.000037  loss: 3.0357 (3.0496)  time: 0.6290  data: 0.0001  max mem: 8730
Epoch: [26]  [ 260/2001]  eta: 0:18:37  lr: 0.000037  loss: 3.0357 (3.0508)  time: 0.6275  data: 0.0001  max mem: 8730
Epoch: [26]  [ 270/2001]  eta: 0:18:30  lr: 0.000037  loss: 2.9934 (3.0439)  time: 0.6274  data: 0.0001  max mem: 8730
Epoch: [26]  [ 280/2001]  eta: 0:18:23  lr: 0.000037  loss: 3.1997 (3.0492)  time: 0.6336  data: 0.0001  max mem: 8730
Epoch: [26]  [ 290/2001]  eta: 0:18:16  lr: 0.000037  loss: 3.1662 (3.0458)  time: 0.6331  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9571, ratio_loss=0.0442, cls_kl=0.0639, token_kl=0.0943
Epoch: [26]  [ 300/2001]  eta: 0:18:09  lr: 0.000037  loss: 3.0532 (3.0452)  time: 0.6306  data: 0.0002  max mem: 8730
Epoch: [26]  [ 310/2001]  eta: 0:18:02  lr: 0.000037  loss: 3.0789 (3.0427)  time: 0.6298  data: 0.0002  max mem: 8730
Epoch: [26]  [ 320/2001]  eta: 0:17:55  lr: 0.000037  loss: 3.1439 (3.0456)  time: 0.6325  data: 0.0002  max mem: 8730
Epoch: [26]  [ 330/2001]  eta: 0:17:48  lr: 0.000037  loss: 3.2340 (3.0537)  time: 0.6312  data: 0.0002  max mem: 8730
Epoch: [26]  [ 340/2001]  eta: 0:17:41  lr: 0.000037  loss: 3.2564 (3.0517)  time: 0.6277  data: 0.0002  max mem: 8730
Epoch: [26]  [ 350/2001]  eta: 0:17:35  lr: 0.000037  loss: 3.0437 (3.0511)  time: 0.6314  data: 0.0002  max mem: 8730
Epoch: [26]  [ 360/2001]  eta: 0:17:28  lr: 0.000037  loss: 3.0437 (3.0526)  time: 0.6317  data: 0.0002  max mem: 8730
Epoch: [26]  [ 370/2001]  eta: 0:17:21  lr: 0.000037  loss: 3.1632 (3.0544)  time: 0.6321  data: 0.0001  max mem: 8730
Epoch: [26]  [ 380/2001]  eta: 0:17:14  lr: 0.000037  loss: 3.1845 (3.0571)  time: 0.6328  data: 0.0002  max mem: 8730
Epoch: [26]  [ 390/2001]  eta: 0:17:08  lr: 0.000037  loss: 3.0063 (3.0498)  time: 0.6338  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9318, ratio_loss=0.0428, cls_kl=0.0623, token_kl=0.0930
Epoch: [26]  [ 400/2001]  eta: 0:17:01  lr: 0.000037  loss: 2.8915 (3.0475)  time: 0.6320  data: 0.0002  max mem: 8730
Epoch: [26]  [ 410/2001]  eta: 0:16:54  lr: 0.000037  loss: 3.0655 (3.0461)  time: 0.6291  data: 0.0002  max mem: 8730
Epoch: [26]  [ 420/2001]  eta: 0:16:48  lr: 0.000037  loss: 3.1292 (3.0455)  time: 0.6304  data: 0.0002  max mem: 8730
Epoch: [26]  [ 430/2001]  eta: 0:16:41  lr: 0.000037  loss: 2.9347 (3.0428)  time: 0.6344  data: 0.0001  max mem: 8730
Epoch: [26]  [ 440/2001]  eta: 0:16:35  lr: 0.000037  loss: 3.0989 (3.0428)  time: 0.6402  data: 0.0002  max mem: 8730
Epoch: [26]  [ 450/2001]  eta: 0:16:29  lr: 0.000037  loss: 3.0989 (3.0381)  time: 0.6369  data: 0.0002  max mem: 8730
Epoch: [26]  [ 460/2001]  eta: 0:16:22  lr: 0.000037  loss: 3.0625 (3.0366)  time: 0.6309  data: 0.0002  max mem: 8730
Epoch: [26]  [ 470/2001]  eta: 0:16:15  lr: 0.000037  loss: 3.0720 (3.0394)  time: 0.6301  data: 0.0001  max mem: 8730
Epoch: [26]  [ 480/2001]  eta: 0:16:09  lr: 0.000037  loss: 3.2658 (3.0473)  time: 0.6299  data: 0.0001  max mem: 8730
Epoch: [26]  [ 490/2001]  eta: 0:16:02  lr: 0.000037  loss: 3.3117 (3.0480)  time: 0.6319  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9546, ratio_loss=0.0421, cls_kl=0.0627, token_kl=0.0922
Epoch: [26]  [ 500/2001]  eta: 0:15:56  lr: 0.000037  loss: 3.2273 (3.0476)  time: 0.6333  data: 0.0002  max mem: 8730
Epoch: [26]  [ 510/2001]  eta: 0:15:49  lr: 0.000037  loss: 3.0567 (3.0473)  time: 0.6325  data: 0.0002  max mem: 8730
Epoch: [26]  [ 520/2001]  eta: 0:15:43  lr: 0.000037  loss: 3.1260 (3.0508)  time: 0.6325  data: 0.0002  max mem: 8730
Epoch: [26]  [ 530/2001]  eta: 0:15:36  lr: 0.000037  loss: 3.3352 (3.0524)  time: 0.6337  data: 0.0002  max mem: 8730
Epoch: [26]  [ 540/2001]  eta: 0:15:30  lr: 0.000037  loss: 3.0591 (3.0500)  time: 0.6351  data: 0.0002  max mem: 8730
Epoch: [26]  [ 550/2001]  eta: 0:15:24  lr: 0.000037  loss: 3.0405 (3.0470)  time: 0.6375  data: 0.0002  max mem: 8730
Epoch: [26]  [ 560/2001]  eta: 0:15:17  lr: 0.000037  loss: 3.2727 (3.0511)  time: 0.6358  data: 0.0002  max mem: 8730
Epoch: [26]  [ 570/2001]  eta: 0:15:11  lr: 0.000037  loss: 3.2225 (3.0488)  time: 0.6329  data: 0.0002  max mem: 8730
Epoch: [26]  [ 580/2001]  eta: 0:15:04  lr: 0.000037  loss: 3.1554 (3.0516)  time: 0.6371  data: 0.0002  max mem: 8730
Epoch: [26]  [ 590/2001]  eta: 0:14:58  lr: 0.000037  loss: 3.2222 (3.0543)  time: 0.6432  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9874, ratio_loss=0.0437, cls_kl=0.0638, token_kl=0.0926
Epoch: [26]  [ 600/2001]  eta: 0:14:52  lr: 0.000037  loss: 3.3242 (3.0590)  time: 0.6427  data: 0.0002  max mem: 8730
Epoch: [26]  [ 610/2001]  eta: 0:14:46  lr: 0.000037  loss: 3.3976 (3.0592)  time: 0.6378  data: 0.0002  max mem: 8730
Epoch: [26]  [ 620/2001]  eta: 0:14:39  lr: 0.000037  loss: 2.9658 (3.0585)  time: 0.6336  data: 0.0002  max mem: 8730
Epoch: [26]  [ 630/2001]  eta: 0:14:33  lr: 0.000037  loss: 2.9323 (3.0577)  time: 0.6314  data: 0.0002  max mem: 8730
Epoch: [26]  [ 640/2001]  eta: 0:14:26  lr: 0.000037  loss: 3.0613 (3.0580)  time: 0.6354  data: 0.0002  max mem: 8730
Epoch: [26]  [ 650/2001]  eta: 0:14:20  lr: 0.000037  loss: 3.3346 (3.0613)  time: 0.6370  data: 0.0001  max mem: 8730
Epoch: [26]  [ 660/2001]  eta: 0:14:13  lr: 0.000037  loss: 3.3380 (3.0641)  time: 0.6344  data: 0.0001  max mem: 8730
Epoch: [26]  [ 670/2001]  eta: 0:14:07  lr: 0.000037  loss: 3.2115 (3.0635)  time: 0.6354  data: 0.0002  max mem: 8730
Epoch: [26]  [ 680/2001]  eta: 0:14:01  lr: 0.000037  loss: 3.1724 (3.0645)  time: 0.6372  data: 0.0002  max mem: 8730
Epoch: [26]  [ 690/2001]  eta: 0:13:54  lr: 0.000037  loss: 3.1694 (3.0599)  time: 0.6372  data: 0.0002  max mem: 8730
loss info: cls_loss=2.9572, ratio_loss=0.0462, cls_kl=0.0653, token_kl=0.0965
Epoch: [26]  [ 700/2001]  eta: 0:13:48  lr: 0.000037  loss: 3.1694 (3.0609)  time: 0.6380  data: 0.0002  max mem: 8730
Epoch: [26]  [ 710/2001]  eta: 0:13:42  lr: 0.000037  loss: 3.2570 (3.0619)  time: 0.6395  data: 0.0002  max mem: 8730
Epoch: [26]  [ 720/2001]  eta: 0:13:35  lr: 0.000037  loss: 3.1383 (3.0613)  time: 0.6368  data: 0.0002  max mem: 8730
Epoch: [26]  [ 730/2001]  eta: 0:13:29  lr: 0.000037  loss: 3.1489 (3.0631)  time: 0.6334  data: 0.0002  max mem: 8730
Epoch: [26]  [ 740/2001]  eta: 0:13:23  lr: 0.000037  loss: 3.1489 (3.0628)  time: 0.6387  data: 0.0002  max mem: 8730
Epoch: [26]  [ 750/2001]  eta: 0:13:16  lr: 0.000037  loss: 3.1032 (3.0625)  time: 0.6378  data: 0.0001  max mem: 8730
Epoch: [26]  [ 760/2001]  eta: 0:13:10  lr: 0.000037  loss: 3.1738 (3.0629)  time: 0.6324  data: 0.0001  max mem: 8730
Epoch: [26]  [ 770/2001]  eta: 0:13:03  lr: 0.000037  loss: 3.2295 (3.0647)  time: 0.6352  data: 0.0002  max mem: 8730
Epoch: [26]  [ 780/2001]  eta: 0:12:57  lr: 0.000037  loss: 3.2550 (3.0647)  time: 0.6395  data: 0.0001  max mem: 8730
Epoch: [26]  [ 790/2001]  eta: 0:12:51  lr: 0.000037  loss: 3.2528 (3.0638)  time: 0.6397  data: 0.0001  max mem: 8730
loss info: cls_loss=2.9944, ratio_loss=0.0477, cls_kl=0.0670, token_kl=0.0978
Epoch: [26]  [ 800/2001]  eta: 0:12:44  lr: 0.000037  loss: 3.1286 (3.0631)  time: 0.6405  data: 0.0001  max mem: 8730
| distributed init (rank 5): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
| distributed init (rank 4): env://
| distributed init (rank 7): env://
| distributed init (rank 6): env://
| distributed init (rank 1): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp-3keep/checkpoint.pth', sched='cosine', seed=42, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0000366 for PREDICTOR
Failed to find state_dict_ema, starting from loaded model weights
Epoch: [26]  [   0/2001]  eta: 3:37:31  lr: 0.000037  loss: 3.5472 (3.5472)  time: 6.5226  data: 3.2035  max mem: 8647
Epoch: [26]  [  10/2001]  eta: 0:38:06  lr: 0.000037  loss: 3.0544 (2.9215)  time: 1.1485  data: 0.2914  max mem: 8728
Epoch: [26]  [  20/2001]  eta: 0:29:07  lr: 0.000037  loss: 3.1268 (3.1081)  time: 0.6001  data: 0.0001  max mem: 8728
Epoch: [26]  [  30/2001]  eta: 0:26:03  lr: 0.000037  loss: 3.2736 (3.1109)  time: 0.5979  data: 0.0001  max mem: 8728
Epoch: [26]  [  40/2001]  eta: 0:24:19  lr: 0.000037  loss: 3.3948 (3.1491)  time: 0.5991  data: 0.0001  max mem: 8728
Epoch: [26]  [  50/2001]  eta: 0:23:15  lr: 0.000037  loss: 3.2590 (3.1524)  time: 0.5938  data: 0.0002  max mem: 8728
Epoch: [26]  [  60/2001]  eta: 0:22:29  lr: 0.000037  loss: 3.2590 (3.1643)  time: 0.5952  data: 0.0002  max mem: 8728
Epoch: [26]  [  70/2001]  eta: 0:21:56  lr: 0.000037  loss: 3.2589 (3.1377)  time: 0.5966  data: 0.0001  max mem: 8728
Epoch: [26]  [  80/2001]  eta: 0:21:28  lr: 0.000037  loss: 3.2243 (3.1505)  time: 0.5967  data: 0.0002  max mem: 8728
Epoch: [26]  [  90/2001]  eta: 0:21:07  lr: 0.000037  loss: 3.1512 (3.1412)  time: 0.5968  data: 0.0001  max mem: 8728
loss info: cls_loss=3.0179, ratio_loss=0.0431, cls_kl=0.0648, token_kl=0.0933
Epoch: [26]  [ 100/2001]  eta: 0:20:48  lr: 0.000037  loss: 3.0369 (3.1210)  time: 0.5990  data: 0.0001  max mem: 8728
Epoch: [26]  [ 110/2001]  eta: 0:20:34  lr: 0.000037  loss: 2.9625 (3.1149)  time: 0.6069  data: 0.0001  max mem: 8728
Epoch: [26]  [ 120/2001]  eta: 0:20:21  lr: 0.000037  loss: 3.0689 (3.1272)  time: 0.6134  data: 0.0001  max mem: 8728
Epoch: [26]  [ 130/2001]  eta: 0:20:09  lr: 0.000037  loss: 3.0215 (3.1143)  time: 0.6116  data: 0.0001  max mem: 8728
Epoch: [26]  [ 140/2001]  eta: 0:19:59  lr: 0.000037  loss: 2.9079 (3.1011)  time: 0.6125  data: 0.0001  max mem: 8728
Epoch: [26]  [ 150/2001]  eta: 0:19:49  lr: 0.000037  loss: 3.2941 (3.1069)  time: 0.6146  data: 0.0001  max mem: 8728
Epoch: [26]  [ 160/2001]  eta: 0:19:39  lr: 0.000037  loss: 3.3051 (3.0939)  time: 0.6151  data: 0.0001  max mem: 8728
Epoch: [26]  [ 170/2001]  eta: 0:19:30  lr: 0.000037  loss: 3.0704 (3.0873)  time: 0.6150  data: 0.0001  max mem: 8728
Epoch: [26]  [ 180/2001]  eta: 0:19:22  lr: 0.000037  loss: 3.1050 (3.0934)  time: 0.6193  data: 0.0001  max mem: 8728
Epoch: [26]  [ 190/2001]  eta: 0:19:15  lr: 0.000037  loss: 3.2523 (3.0817)  time: 0.6273  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9487, ratio_loss=0.0438, cls_kl=0.0646, token_kl=0.0933
Epoch: [26]  [ 200/2001]  eta: 0:19:07  lr: 0.000037  loss: 3.2788 (3.0933)  time: 0.6267  data: 0.0001  max mem: 8728
Epoch: [26]  [ 210/2001]  eta: 0:19:00  lr: 0.000037  loss: 3.2788 (3.0968)  time: 0.6232  data: 0.0001  max mem: 8728
Epoch: [26]  [ 220/2001]  eta: 0:18:52  lr: 0.000037  loss: 3.2089 (3.1033)  time: 0.6225  data: 0.0001  max mem: 8728
Epoch: [26]  [ 230/2001]  eta: 0:18:44  lr: 0.000037  loss: 3.1653 (3.1050)  time: 0.6213  data: 0.0001  max mem: 8728
Epoch: [26]  [ 240/2001]  eta: 0:18:38  lr: 0.000037  loss: 3.1566 (3.1042)  time: 0.6266  data: 0.0001  max mem: 8728
Epoch: [26]  [ 250/2001]  eta: 0:18:31  lr: 0.000037  loss: 3.1071 (3.1004)  time: 0.6290  data: 0.0001  max mem: 8728
Epoch: [26]  [ 260/2001]  eta: 0:18:24  lr: 0.000037  loss: 3.0897 (3.0980)  time: 0.6258  data: 0.0001  max mem: 8728
Epoch: [26]  [ 270/2001]  eta: 0:18:17  lr: 0.000037  loss: 3.0897 (3.0915)  time: 0.6277  data: 0.0001  max mem: 8728
Epoch: [26]  [ 280/2001]  eta: 0:18:11  lr: 0.000037  loss: 3.1915 (3.0940)  time: 0.6365  data: 0.0001  max mem: 8728
Epoch: [26]  [ 290/2001]  eta: 0:18:05  lr: 0.000037  loss: 3.1527 (3.0862)  time: 0.6384  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9600, ratio_loss=0.0437, cls_kl=0.0644, token_kl=0.0943
Epoch: [26]  [ 300/2001]  eta: 0:17:59  lr: 0.000037  loss: 3.0693 (3.0838)  time: 0.6336  data: 0.0001  max mem: 8728
Epoch: [26]  [ 310/2001]  eta: 0:17:52  lr: 0.000037  loss: 3.1228 (3.0894)  time: 0.6339  data: 0.0001  max mem: 8728
Epoch: [26]  [ 320/2001]  eta: 0:17:46  lr: 0.000037  loss: 3.1118 (3.0854)  time: 0.6333  data: 0.0001  max mem: 8728
Epoch: [26]  [ 330/2001]  eta: 0:17:39  lr: 0.000037  loss: 2.9917 (3.0800)  time: 0.6323  data: 0.0001  max mem: 8728
| distributed init (rank 2): env://
| distributed init (rank 7): env://
| distributed init (rank 6): env://
| distributed init (rank 3): env://
| distributed init (rank 4): env://
| distributed init (rank 1): env://
| distributed init (rank 5): env://
| distributed init (rank 0): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp-3keep/checkpoint.pth', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0000366 for PREDICTOR
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Epoch: [26]  [   0/2001]  eta: 3:41:16  lr: 0.000037  loss: 3.5764 (3.5764)  time: 6.6350  data: 3.0395  max mem: 8647
Epoch: [26]  [  10/2001]  eta: 0:38:27  lr: 0.000037  loss: 3.5318 (3.3030)  time: 1.1591  data: 0.2765  max mem: 8728
Epoch: [26]  [  20/2001]  eta: 0:29:19  lr: 0.000037  loss: 3.2893 (3.2350)  time: 0.6009  data: 0.0001  max mem: 8728
Epoch: [26]  [  30/2001]  eta: 0:26:08  lr: 0.000037  loss: 3.2893 (3.2820)  time: 0.5961  data: 0.0002  max mem: 8728
Epoch: [26]  [  40/2001]  eta: 0:24:25  lr: 0.000037  loss: 3.1615 (3.2368)  time: 0.5995  data: 0.0002  max mem: 8728
Epoch: [26]  [  50/2001]  eta: 0:23:20  lr: 0.000037  loss: 3.0904 (3.2067)  time: 0.5968  data: 0.0002  max mem: 8728
Epoch: [26]  [  60/2001]  eta: 0:22:33  lr: 0.000037  loss: 3.2227 (3.1892)  time: 0.5941  data: 0.0002  max mem: 8728
Epoch: [26]  [  70/2001]  eta: 0:21:57  lr: 0.000037  loss: 3.2227 (3.1558)  time: 0.5914  data: 0.0002  max mem: 8728
Epoch: [26]  [  80/2001]  eta: 0:21:29  lr: 0.000037  loss: 3.1473 (3.1493)  time: 0.5928  data: 0.0001  max mem: 8728
Epoch: [26]  [  90/2001]  eta: 0:21:08  lr: 0.000037  loss: 3.1942 (3.1379)  time: 0.5984  data: 0.0002  max mem: 8728
loss info: cls_loss=3.0325, ratio_loss=0.0455, cls_kl=0.0652, token_kl=0.0937
Epoch: [26]  [ 100/2001]  eta: 0:20:49  lr: 0.000037  loss: 3.1942 (3.1425)  time: 0.6001  data: 0.0002  max mem: 8728
Epoch: [26]  [ 110/2001]  eta: 0:20:34  lr: 0.000037  loss: 3.1707 (3.1465)  time: 0.6023  data: 0.0001  max mem: 8728
Epoch: [26]  [ 120/2001]  eta: 0:20:20  lr: 0.000037  loss: 3.2071 (3.1461)  time: 0.6078  data: 0.0002  max mem: 8728
Epoch: [26]  [ 130/2001]  eta: 0:20:08  lr: 0.000037  loss: 3.2071 (3.1368)  time: 0.6094  data: 0.0002  max mem: 8728
Epoch: [26]  [ 140/2001]  eta: 0:19:57  lr: 0.000037  loss: 3.0364 (3.1223)  time: 0.6112  data: 0.0001  max mem: 8728
Epoch: [26]  [ 150/2001]  eta: 0:19:48  lr: 0.000037  loss: 3.1797 (3.1239)  time: 0.6173  data: 0.0001  max mem: 8728
Epoch: [26]  [ 160/2001]  eta: 0:19:39  lr: 0.000037  loss: 3.2083 (3.1267)  time: 0.6182  data: 0.0002  max mem: 8728
Epoch: [26]  [ 170/2001]  eta: 0:19:30  lr: 0.000037  loss: 3.0879 (3.1223)  time: 0.6150  data: 0.0002  max mem: 8728
Epoch: [26]  [ 180/2001]  eta: 0:19:21  lr: 0.000037  loss: 2.9970 (3.1138)  time: 0.6159  data: 0.0001  max mem: 8728
Epoch: [26]  [ 190/2001]  eta: 0:19:14  lr: 0.000037  loss: 2.9767 (3.1072)  time: 0.6214  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9480, ratio_loss=0.0430, cls_kl=0.0625, token_kl=0.0918
Epoch: [26]  [ 200/2001]  eta: 0:19:05  lr: 0.000037  loss: 3.0056 (3.0978)  time: 0.6218  data: 0.0002  max mem: 8728
Epoch: [26]  [ 210/2001]  eta: 0:18:57  lr: 0.000037  loss: 3.0490 (3.0933)  time: 0.6175  data: 0.0002  max mem: 8728
Epoch: [26]  [ 220/2001]  eta: 0:18:50  lr: 0.000037  loss: 3.1674 (3.0853)  time: 0.6191  data: 0.0001  max mem: 8728
Epoch: [26]  [ 230/2001]  eta: 0:18:42  lr: 0.000037  loss: 3.1678 (3.0787)  time: 0.6201  data: 0.0001  max mem: 8728
Epoch: [26]  [ 240/2001]  eta: 0:18:36  lr: 0.000037  loss: 3.1678 (3.0749)  time: 0.6237  data: 0.0001  max mem: 8728
Epoch: [26]  [ 250/2001]  eta: 0:18:29  lr: 0.000037  loss: 3.1279 (3.0706)  time: 0.6258  data: 0.0002  max mem: 8728
Epoch: [26]  [ 260/2001]  eta: 0:18:22  lr: 0.000037  loss: 2.8660 (3.0603)  time: 0.6249  data: 0.0002  max mem: 8728
Epoch: [26]  [ 270/2001]  eta: 0:18:15  lr: 0.000037  loss: 2.8660 (3.0556)  time: 0.6244  data: 0.0001  max mem: 8728
Epoch: [26]  [ 280/2001]  eta: 0:18:08  lr: 0.000037  loss: 3.1874 (3.0600)  time: 0.6247  data: 0.0001  max mem: 8728
Epoch: [26]  [ 290/2001]  eta: 0:18:01  lr: 0.000037  loss: 3.0414 (3.0499)  time: 0.6244  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8190, ratio_loss=0.0411, cls_kl=0.0612, token_kl=0.0912
Epoch: [26]  [ 300/2001]  eta: 0:17:55  lr: 0.000037  loss: 2.7424 (3.0386)  time: 0.6259  data: 0.0001  max mem: 8728
Epoch: [26]  [ 310/2001]  eta: 0:17:48  lr: 0.000037  loss: 2.7509 (3.0385)  time: 0.6279  data: 0.0002  max mem: 8728
Epoch: [26]  [ 320/2001]  eta: 0:17:42  lr: 0.000037  loss: 3.3781 (3.0509)  time: 0.6279  data: 0.0001  max mem: 8728
Epoch: [26]  [ 330/2001]  eta: 0:17:35  lr: 0.000037  loss: 3.3848 (3.0497)  time: 0.6302  data: 0.0001  max mem: 8728
Epoch: [26]  [ 340/2001]  eta: 0:17:29  lr: 0.000037  loss: 3.2456 (3.0544)  time: 0.6297  data: 0.0002  max mem: 8728
Epoch: [26]  [ 350/2001]  eta: 0:17:23  lr: 0.000037  loss: 3.2036 (3.0548)  time: 0.6316  data: 0.0002  max mem: 8728
Epoch: [26]  [ 360/2001]  eta: 0:17:16  lr: 0.000037  loss: 3.1278 (3.0566)  time: 0.6313  data: 0.0002  max mem: 8728
Epoch: [26]  [ 370/2001]  eta: 0:17:10  lr: 0.000037  loss: 3.0351 (3.0524)  time: 0.6286  data: 0.0002  max mem: 8728
Epoch: [26]  [ 380/2001]  eta: 0:17:03  lr: 0.000037  loss: 3.0351 (3.0506)  time: 0.6299  data: 0.0002  max mem: 8728
Epoch: [26]  [ 390/2001]  eta: 0:16:57  lr: 0.000037  loss: 3.0576 (3.0454)  time: 0.6291  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9743, ratio_loss=0.0435, cls_kl=0.0632, token_kl=0.0940
Epoch: [26]  [ 400/2001]  eta: 0:16:50  lr: 0.000037  loss: 3.2483 (3.0519)  time: 0.6282  data: 0.0002  max mem: 8728
Epoch: [26]  [ 410/2001]  eta: 0:16:44  lr: 0.000037  loss: 3.2702 (3.0574)  time: 0.6324  data: 0.0002  max mem: 8728
Epoch: [26]  [ 420/2001]  eta: 0:16:38  lr: 0.000037  loss: 3.1574 (3.0565)  time: 0.6355  data: 0.0002  max mem: 8728
Epoch: [26]  [ 430/2001]  eta: 0:16:32  lr: 0.000037  loss: 3.1574 (3.0595)  time: 0.6341  data: 0.0002  max mem: 8728
Epoch: [26]  [ 440/2001]  eta: 0:16:26  lr: 0.000037  loss: 3.1339 (3.0604)  time: 0.6352  data: 0.0002  max mem: 8728
Epoch: [26]  [ 450/2001]  eta: 0:16:19  lr: 0.000037  loss: 2.9978 (3.0601)  time: 0.6351  data: 0.0001  max mem: 8728
Epoch: [26]  [ 460/2001]  eta: 0:16:14  lr: 0.000037  loss: 2.9353 (3.0556)  time: 0.6400  data: 0.0001  max mem: 8728
Epoch: [26]  [ 470/2001]  eta: 0:16:07  lr: 0.000037  loss: 2.7388 (3.0472)  time: 0.6395  data: 0.0001  max mem: 8728
Epoch: [26]  [ 480/2001]  eta: 0:16:01  lr: 0.000037  loss: 2.8026 (3.0455)  time: 0.6333  data: 0.0001  max mem: 8728
Epoch: [26]  [ 490/2001]  eta: 0:15:55  lr: 0.000037  loss: 3.2107 (3.0515)  time: 0.6348  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9389, ratio_loss=0.0444, cls_kl=0.0647, token_kl=0.0948
Epoch: [26]  [ 500/2001]  eta: 0:15:49  lr: 0.000037  loss: 3.2150 (3.0503)  time: 0.6368  data: 0.0001  max mem: 8728
Epoch: [26]  [ 510/2001]  eta: 0:15:42  lr: 0.000037  loss: 3.1442 (3.0527)  time: 0.6360  data: 0.0001  max mem: 8728
Epoch: [26]  [ 520/2001]  eta: 0:15:36  lr: 0.000037  loss: 3.1442 (3.0548)  time: 0.6344  data: 0.0001  max mem: 8728
Epoch: [26]  [ 530/2001]  eta: 0:15:30  lr: 0.000037  loss: 3.0220 (3.0481)  time: 0.6365  data: 0.0001  max mem: 8728
Epoch: [26]  [ 540/2001]  eta: 0:15:24  lr: 0.000037  loss: 2.9752 (3.0479)  time: 0.6390  data: 0.0001  max mem: 8728
Epoch: [26]  [ 550/2001]  eta: 0:15:18  lr: 0.000037  loss: 3.1996 (3.0476)  time: 0.6389  data: 0.0001  max mem: 8728
Epoch: [26]  [ 560/2001]  eta: 0:15:11  lr: 0.000037  loss: 3.4181 (3.0523)  time: 0.6387  data: 0.0001  max mem: 8728
Epoch: [26]  [ 570/2001]  eta: 0:15:05  lr: 0.000037  loss: 3.3573 (3.0533)  time: 0.6382  data: 0.0001  max mem: 8728
Epoch: [26]  [ 580/2001]  eta: 0:14:59  lr: 0.000037  loss: 3.2287 (3.0546)  time: 0.6397  data: 0.0001  max mem: 8728
Epoch: [26]  [ 590/2001]  eta: 0:14:53  lr: 0.000037  loss: 3.1651 (3.0565)  time: 0.6390  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9940, ratio_loss=0.0435, cls_kl=0.0639, token_kl=0.0941
Epoch: [26]  [ 600/2001]  eta: 0:14:47  lr: 0.000037  loss: 3.2577 (3.0565)  time: 0.6404  data: 0.0001  max mem: 8728
Epoch: [26]  [ 610/2001]  eta: 0:14:41  lr: 0.000037  loss: 3.1198 (3.0569)  time: 0.6432  data: 0.0001  max mem: 8728
Epoch: [26]  [ 620/2001]  eta: 0:14:35  lr: 0.000037  loss: 3.1839 (3.0599)  time: 0.6458  data: 0.0001  max mem: 8728
Epoch: [26]  [ 630/2001]  eta: 0:14:29  lr: 0.000037  loss: 3.1839 (3.0611)  time: 0.6451  data: 0.0001  max mem: 8728
Epoch: [26]  [ 640/2001]  eta: 0:14:23  lr: 0.000037  loss: 2.9421 (3.0575)  time: 0.6476  data: 0.0001  max mem: 8728
Epoch: [26]  [ 650/2001]  eta: 0:14:17  lr: 0.000037  loss: 3.0846 (3.0602)  time: 0.6528  data: 0.0001  max mem: 8728
Epoch: [26]  [ 660/2001]  eta: 0:14:10  lr: 0.000037  loss: 3.0492 (3.0531)  time: 0.6442  data: 0.0002  max mem: 8728
Epoch: [26]  [ 670/2001]  eta: 0:14:04  lr: 0.000037  loss: 3.0492 (3.0556)  time: 0.6399  data: 0.0002  max mem: 8728
Epoch: [26]  [ 680/2001]  eta: 0:13:58  lr: 0.000037  loss: 3.1434 (3.0554)  time: 0.6409  data: 0.0001  max mem: 8728
Epoch: [26]  [ 690/2001]  eta: 0:13:52  lr: 0.000037  loss: 2.8929 (3.0523)  time: 0.6394  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8951, ratio_loss=0.0437, cls_kl=0.0633, token_kl=0.0954
Epoch: [26]  [ 700/2001]  eta: 0:13:45  lr: 0.000037  loss: 2.9215 (3.0514)  time: 0.6397  data: 0.0001  max mem: 8728
Epoch: [26]  [ 710/2001]  eta: 0:13:39  lr: 0.000037  loss: 3.2315 (3.0502)  time: 0.6380  data: 0.0001  max mem: 8728
Epoch: [26]  [ 720/2001]  eta: 0:13:33  lr: 0.000037  loss: 3.2042 (3.0474)  time: 0.6364  data: 0.0002  max mem: 8728
Epoch: [26]  [ 730/2001]  eta: 0:13:26  lr: 0.000037  loss: 2.9703 (3.0474)  time: 0.6386  data: 0.0001  max mem: 8728
Epoch: [26]  [ 740/2001]  eta: 0:13:20  lr: 0.000037  loss: 3.2298 (3.0520)  time: 0.6389  data: 0.0002  max mem: 8728
| distributed init (rank 3): env://
| distributed init (rank 5): env://
| distributed init (rank 6): env://
| distributed init (rank 4): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 7): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp-3keep/checkpoint.pth', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0000366 for PREDICTOR
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Epoch: [26]  [   0/2001]  eta: 3:37:11  lr: 0.000037  loss: 3.5764 (3.5764)  time: 6.5127  data: 2.9140  max mem: 8647
Epoch: [26]  [  10/2001]  eta: 0:37:59  lr: 0.000037  loss: 3.5318 (3.3030)  time: 1.1451  data: 0.2650  max mem: 8728
Epoch: [26]  [  20/2001]  eta: 0:29:01  lr: 0.000037  loss: 3.2893 (3.2350)  time: 0.5974  data: 0.0001  max mem: 8728
Epoch: [26]  [  30/2001]  eta: 0:25:56  lr: 0.000037  loss: 3.2893 (3.2821)  time: 0.5942  data: 0.0001  max mem: 8728
Epoch: [26]  [  40/2001]  eta: 0:24:12  lr: 0.000037  loss: 3.1615 (3.2369)  time: 0.5952  data: 0.0001  max mem: 8728
Epoch: [26]  [  50/2001]  eta: 0:23:07  lr: 0.000037  loss: 3.0904 (3.2067)  time: 0.5890  data: 0.0001  max mem: 8728
Epoch: [26]  [  60/2001]  eta: 0:22:20  lr: 0.000037  loss: 3.2227 (3.1893)  time: 0.5889  data: 0.0001  max mem: 8728
Epoch: [26]  [  70/2001]  eta: 0:21:47  lr: 0.000037  loss: 3.2227 (3.1558)  time: 0.5901  data: 0.0001  max mem: 8728
Epoch: [26]  [  80/2001]  eta: 0:21:20  lr: 0.000037  loss: 3.1480 (3.1493)  time: 0.5921  data: 0.0001  max mem: 8728
Epoch: [26]  [  90/2001]  eta: 0:20:57  lr: 0.000037  loss: 3.1947 (3.1379)  time: 0.5907  data: 0.0001  max mem: 8728
loss info: cls_loss=3.0325, ratio_loss=0.0455, cls_kl=0.0652, token_kl=0.0937
Epoch: [26]  [ 100/2001]  eta: 0:20:39  lr: 0.000037  loss: 3.1947 (3.1425)  time: 0.5943  data: 0.0001  max mem: 8728
Epoch: [26]  [ 110/2001]  eta: 0:20:25  lr: 0.000037  loss: 3.1710 (3.1465)  time: 0.6033  data: 0.0001  max mem: 8728
Epoch: [26]  [ 120/2001]  eta: 0:20:13  lr: 0.000037  loss: 3.2067 (3.1461)  time: 0.6096  data: 0.0001  max mem: 8728
Epoch: [26]  [ 130/2001]  eta: 0:20:01  lr: 0.000037  loss: 3.2067 (3.1368)  time: 0.6100  data: 0.0002  max mem: 8728
Epoch: [26]  [ 140/2001]  eta: 0:19:51  lr: 0.000037  loss: 3.0370 (3.1223)  time: 0.6108  data: 0.0002  max mem: 8728
Epoch: [26]  [ 150/2001]  eta: 0:19:42  lr: 0.000037  loss: 3.1800 (3.1239)  time: 0.6143  data: 0.0001  max mem: 8728
Epoch: [26]  [ 160/2001]  eta: 0:19:32  lr: 0.000037  loss: 3.2077 (3.1267)  time: 0.6134  data: 0.0001  max mem: 8728
Epoch: [26]  [ 170/2001]  eta: 0:19:23  lr: 0.000037  loss: 3.0873 (3.1223)  time: 0.6113  data: 0.0001  max mem: 8728
Epoch: [26]  [ 180/2001]  eta: 0:19:14  lr: 0.000037  loss: 2.9974 (3.1139)  time: 0.6103  data: 0.0001  max mem: 8728
Epoch: [26]  [ 190/2001]  eta: 0:19:07  lr: 0.000037  loss: 2.9769 (3.1072)  time: 0.6160  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9481, ratio_loss=0.0431, cls_kl=0.0625, token_kl=0.0918
Epoch: [26]  [ 200/2001]  eta: 0:18:59  lr: 0.000037  loss: 3.0050 (3.0978)  time: 0.6191  data: 0.0001  max mem: 8728
Epoch: [26]  [ 210/2001]  eta: 0:18:51  lr: 0.000037  loss: 3.0492 (3.0933)  time: 0.6165  data: 0.0001  max mem: 8728
Epoch: [26]  [ 220/2001]  eta: 0:18:43  lr: 0.000037  loss: 3.1676 (3.0852)  time: 0.6168  data: 0.0001  max mem: 8728
Epoch: [26]  [ 230/2001]  eta: 0:18:36  lr: 0.000037  loss: 3.1669 (3.0787)  time: 0.6167  data: 0.0001  max mem: 8728
Epoch: [26]  [ 240/2001]  eta: 0:18:29  lr: 0.000037  loss: 3.1669 (3.0749)  time: 0.6175  data: 0.0001  max mem: 8728
Epoch: [26]  [ 250/2001]  eta: 0:18:22  lr: 0.000037  loss: 3.1241 (3.0705)  time: 0.6190  data: 0.0001  max mem: 8728
Epoch: [26]  [ 260/2001]  eta: 0:18:15  lr: 0.000037  loss: 2.8655 (3.0602)  time: 0.6221  data: 0.0001  max mem: 8728
Epoch: [26]  [ 270/2001]  eta: 0:18:08  lr: 0.000037  loss: 2.8655 (3.0555)  time: 0.6221  data: 0.0001  max mem: 8728
Epoch: [26]  [ 280/2001]  eta: 0:18:02  lr: 0.000037  loss: 3.1852 (3.0600)  time: 0.6227  data: 0.0001  max mem: 8728
Epoch: [26]  [ 290/2001]  eta: 0:17:55  lr: 0.000037  loss: 3.0429 (3.0499)  time: 0.6240  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8189, ratio_loss=0.0411, cls_kl=0.0612, token_kl=0.0912
Epoch: [26]  [ 300/2001]  eta: 0:17:49  lr: 0.000037  loss: 2.7410 (3.0386)  time: 0.6265  data: 0.0001  max mem: 8728
Epoch: [26]  [ 310/2001]  eta: 0:17:43  lr: 0.000037  loss: 2.7495 (3.0384)  time: 0.6306  data: 0.0001  max mem: 8728
Epoch: [26]  [ 320/2001]  eta: 0:17:37  lr: 0.000037  loss: 3.3757 (3.0508)  time: 0.6299  data: 0.0001  max mem: 8728
Epoch: [26]  [ 330/2001]  eta: 0:17:30  lr: 0.000037  loss: 3.3846 (3.0497)  time: 0.6300  data: 0.0001  max mem: 8728
Epoch: [26]  [ 340/2001]  eta: 0:17:24  lr: 0.000037  loss: 3.2454 (3.0544)  time: 0.6308  data: 0.0001  max mem: 8728
Epoch: [26]  [ 350/2001]  eta: 0:17:18  lr: 0.000037  loss: 3.2071 (3.0548)  time: 0.6306  data: 0.0001  max mem: 8728
Epoch: [26]  [ 360/2001]  eta: 0:17:12  lr: 0.000037  loss: 3.1267 (3.0566)  time: 0.6294  data: 0.0001  max mem: 8728
Epoch: [26]  [ 370/2001]  eta: 0:17:05  lr: 0.000037  loss: 3.0366 (3.0525)  time: 0.6296  data: 0.0001  max mem: 8728
Epoch: [26]  [ 380/2001]  eta: 0:16:59  lr: 0.000037  loss: 3.0366 (3.0506)  time: 0.6306  data: 0.0001  max mem: 8728
Epoch: [26]  [ 390/2001]  eta: 0:16:53  lr: 0.000037  loss: 3.0583 (3.0455)  time: 0.6314  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9747, ratio_loss=0.0435, cls_kl=0.0633, token_kl=0.0940
Epoch: [26]  [ 400/2001]  eta: 0:16:47  lr: 0.000037  loss: 3.2484 (3.0520)  time: 0.6325  data: 0.0001  max mem: 8728
Epoch: [26]  [ 410/2001]  eta: 0:16:41  lr: 0.000037  loss: 3.2701 (3.0575)  time: 0.6350  data: 0.0001  max mem: 8728
Epoch: [26]  [ 420/2001]  eta: 0:16:35  lr: 0.000037  loss: 3.1585 (3.0565)  time: 0.6346  data: 0.0001  max mem: 8728
Epoch: [26]  [ 430/2001]  eta: 0:16:28  lr: 0.000037  loss: 3.1585 (3.0596)  time: 0.6316  data: 0.0001  max mem: 8728
Epoch: [26]  [ 440/2001]  eta: 0:16:22  lr: 0.000037  loss: 3.1342 (3.0604)  time: 0.6321  data: 0.0001  max mem: 8728
Epoch: [26]  [ 450/2001]  eta: 0:16:16  lr: 0.000037  loss: 2.9975 (3.0601)  time: 0.6320  data: 0.0001  max mem: 8728
Epoch: [26]  [ 460/2001]  eta: 0:16:10  lr: 0.000037  loss: 2.9345 (3.0556)  time: 0.6358  data: 0.0001  max mem: 8728
Epoch: [26]  [ 470/2001]  eta: 0:16:04  lr: 0.000037  loss: 2.7405 (3.0473)  time: 0.6364  data: 0.0001  max mem: 8728
Epoch: [26]  [ 480/2001]  eta: 0:15:58  lr: 0.000037  loss: 2.8017 (3.0456)  time: 0.6334  data: 0.0001  max mem: 8728
Epoch: [26]  [ 490/2001]  eta: 0:15:52  lr: 0.000037  loss: 3.2012 (3.0515)  time: 0.6359  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9387, ratio_loss=0.0444, cls_kl=0.0647, token_kl=0.0948
Epoch: [26]  [ 500/2001]  eta: 0:15:46  lr: 0.000037  loss: 3.2139 (3.0503)  time: 0.6364  data: 0.0001  max mem: 8728
Epoch: [26]  [ 510/2001]  eta: 0:15:39  lr: 0.000037  loss: 3.1440 (3.0527)  time: 0.6353  data: 0.0001  max mem: 8728
Epoch: [26]  [ 520/2001]  eta: 0:15:33  lr: 0.000037  loss: 3.1452 (3.0548)  time: 0.6343  data: 0.0001  max mem: 8728
Epoch: [26]  [ 530/2001]  eta: 0:15:27  lr: 0.000037  loss: 3.0210 (3.0481)  time: 0.6349  data: 0.0001  max mem: 8728
Epoch: [26]  [ 540/2001]  eta: 0:15:21  lr: 0.000037  loss: 2.9818 (3.0479)  time: 0.6357  data: 0.0001  max mem: 8728
Epoch: [26]  [ 550/2001]  eta: 0:15:15  lr: 0.000037  loss: 3.1991 (3.0476)  time: 0.6357  data: 0.0001  max mem: 8728
Epoch: [26]  [ 560/2001]  eta: 0:15:09  lr: 0.000037  loss: 3.4198 (3.0524)  time: 0.6366  data: 0.0001  max mem: 8728
Epoch: [26]  [ 570/2001]  eta: 0:15:02  lr: 0.000037  loss: 3.3566 (3.0534)  time: 0.6376  data: 0.0001  max mem: 8728
Epoch: [26]  [ 580/2001]  eta: 0:14:56  lr: 0.000037  loss: 3.2269 (3.0546)  time: 0.6374  data: 0.0001  max mem: 8728
Epoch: [26]  [ 590/2001]  eta: 0:14:50  lr: 0.000037  loss: 3.1621 (3.0565)  time: 0.6403  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9942, ratio_loss=0.0436, cls_kl=0.0639, token_kl=0.0941
Epoch: [26]  [ 600/2001]  eta: 0:14:44  lr: 0.000037  loss: 3.2571 (3.0566)  time: 0.6411  data: 0.0001  max mem: 8728
Epoch: [26]  [ 610/2001]  eta: 0:14:38  lr: 0.000037  loss: 3.1200 (3.0570)  time: 0.6371  data: 0.0001  max mem: 8728
Epoch: [26]  [ 620/2001]  eta: 0:14:32  lr: 0.000037  loss: 3.1840 (3.0599)  time: 0.6402  data: 0.0001  max mem: 8728
Epoch: [26]  [ 630/2001]  eta: 0:14:26  lr: 0.000037  loss: 3.1840 (3.0612)  time: 0.6419  data: 0.0001  max mem: 8728
Epoch: [26]  [ 640/2001]  eta: 0:14:19  lr: 0.000037  loss: 2.9395 (3.0575)  time: 0.6381  data: 0.0001  max mem: 8728
Epoch: [26]  [ 650/2001]  eta: 0:14:13  lr: 0.000037  loss: 3.0861 (3.0602)  time: 0.6354  data: 0.0001  max mem: 8728
Epoch: [26]  [ 660/2001]  eta: 0:14:07  lr: 0.000037  loss: 3.0502 (3.0531)  time: 0.6355  data: 0.0001  max mem: 8728
Epoch: [26]  [ 670/2001]  eta: 0:14:01  lr: 0.000037  loss: 3.0502 (3.0556)  time: 0.6372  data: 0.0001  max mem: 8728
Epoch: [26]  [ 680/2001]  eta: 0:13:55  lr: 0.000037  loss: 3.1420 (3.0555)  time: 0.6376  data: 0.0001  max mem: 8728
Epoch: [26]  [ 690/2001]  eta: 0:13:48  lr: 0.000037  loss: 2.8930 (3.0523)  time: 0.6375  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8951, ratio_loss=0.0437, cls_kl=0.0634, token_kl=0.0954
Epoch: [26]  [ 700/2001]  eta: 0:13:42  lr: 0.000037  loss: 2.9221 (3.0515)  time: 0.6384  data: 0.0001  max mem: 8728
Epoch: [26]  [ 710/2001]  eta: 0:13:36  lr: 0.000037  loss: 3.2307 (3.0503)  time: 0.6387  data: 0.0001  max mem: 8728
Epoch: [26]  [ 720/2001]  eta: 0:13:30  lr: 0.000037  loss: 3.2037 (3.0475)  time: 0.6380  data: 0.0001  max mem: 8728
Epoch: [26]  [ 730/2001]  eta: 0:13:23  lr: 0.000037  loss: 2.9732 (3.0475)  time: 0.6383  data: 0.0001  max mem: 8728
Epoch: [26]  [ 740/2001]  eta: 0:13:17  lr: 0.000037  loss: 3.2296 (3.0520)  time: 0.6375  data: 0.0001  max mem: 8728
| distributed init (rank 6): env://
| distributed init (rank 3): env://
| distributed init (rank 0): env://
| distributed init (rank 4): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 5): env://
| distributed init (rank 7): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp-3keep/checkpoint.pth', sched='cosine', seed=42, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0000366 for PREDICTOR
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Epoch: [26]  [   0/2001]  eta: 3:41:08  lr: 0.000037  loss: 3.5472 (3.5472)  time: 6.6308  data: 3.6468  max mem: 8647
Epoch: [26]  [  10/2001]  eta: 0:38:27  lr: 0.000037  loss: 3.0544 (2.9215)  time: 1.1590  data: 0.3317  max mem: 8728
Epoch: [26]  [  20/2001]  eta: 0:29:19  lr: 0.000037  loss: 3.1268 (3.1081)  time: 0.6011  data: 0.0001  max mem: 8728
Epoch: [26]  [  30/2001]  eta: 0:26:12  lr: 0.000037  loss: 3.2736 (3.1109)  time: 0.5989  data: 0.0001  max mem: 8728
Epoch: [26]  [  40/2001]  eta: 0:24:28  lr: 0.000037  loss: 3.3944 (3.1491)  time: 0.6026  data: 0.0001  max mem: 8728
Epoch: [26]  [  50/2001]  eta: 0:23:27  lr: 0.000037  loss: 3.2649 (3.1525)  time: 0.6028  data: 0.0001  max mem: 8728
Epoch: [26]  [  60/2001]  eta: 0:22:46  lr: 0.000037  loss: 3.2649 (3.1644)  time: 0.6128  data: 0.0002  max mem: 8728
Epoch: [26]  [  70/2001]  eta: 0:22:15  lr: 0.000037  loss: 3.2584 (3.1378)  time: 0.6167  data: 0.0002  max mem: 8728
Epoch: [26]  [  80/2001]  eta: 0:21:51  lr: 0.000037  loss: 3.2243 (3.1506)  time: 0.6174  data: 0.0002  max mem: 8728
Epoch: [26]  [  90/2001]  eta: 0:21:33  lr: 0.000037  loss: 3.1517 (3.1413)  time: 0.6245  data: 0.0002  max mem: 8728
loss info: cls_loss=3.0180, ratio_loss=0.0431, cls_kl=0.0648, token_kl=0.0932
Epoch: [26]  [ 100/2001]  eta: 0:21:17  lr: 0.000037  loss: 3.0347 (3.1211)  time: 0.6280  data: 0.0002  max mem: 8728
Epoch: [26]  [ 110/2001]  eta: 0:21:04  lr: 0.000037  loss: 2.9614 (3.1150)  time: 0.6295  data: 0.0002  max mem: 8728
Epoch: [26]  [ 120/2001]  eta: 0:20:52  lr: 0.000037  loss: 3.0688 (3.1273)  time: 0.6348  data: 0.0002  max mem: 8728
Epoch: [26]  [ 130/2001]  eta: 0:20:42  lr: 0.000037  loss: 3.0220 (3.1144)  time: 0.6384  data: 0.0002  max mem: 8728
Epoch: [26]  [ 140/2001]  eta: 0:20:32  lr: 0.000037  loss: 2.9066 (3.1011)  time: 0.6394  data: 0.0002  max mem: 8728
Epoch: [26]  [ 150/2001]  eta: 0:20:22  lr: 0.000037  loss: 3.2926 (3.1070)  time: 0.6372  data: 0.0002  max mem: 8728
Epoch: [26]  [ 160/2001]  eta: 0:20:12  lr: 0.000037  loss: 3.3064 (3.0940)  time: 0.6350  data: 0.0002  max mem: 8728
Epoch: [26]  [ 170/2001]  eta: 0:20:03  lr: 0.000037  loss: 3.0668 (3.0874)  time: 0.6346  data: 0.0002  max mem: 8728
Epoch: [26]  [ 180/2001]  eta: 0:19:54  lr: 0.000037  loss: 3.1053 (3.0934)  time: 0.6362  data: 0.0002  max mem: 8728
Epoch: [26]  [ 190/2001]  eta: 0:19:47  lr: 0.000037  loss: 3.2513 (3.0817)  time: 0.6442  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9486, ratio_loss=0.0439, cls_kl=0.0646, token_kl=0.0933
Epoch: [26]  [ 200/2001]  eta: 0:19:39  lr: 0.000037  loss: 3.2777 (3.0933)  time: 0.6432  data: 0.0002  max mem: 8728
Epoch: [26]  [ 210/2001]  eta: 0:19:31  lr: 0.000037  loss: 3.2777 (3.0968)  time: 0.6351  data: 0.0002  max mem: 8728
Epoch: [26]  [ 220/2001]  eta: 0:19:23  lr: 0.000037  loss: 3.2099 (3.1033)  time: 0.6396  data: 0.0002  max mem: 8728
Epoch: [26]  [ 230/2001]  eta: 0:19:16  lr: 0.000037  loss: 3.1646 (3.1050)  time: 0.6418  data: 0.0002  max mem: 8728
Epoch: [26]  [ 240/2001]  eta: 0:19:08  lr: 0.000037  loss: 3.1538 (3.1042)  time: 0.6387  data: 0.0002  max mem: 8728
Epoch: [26]  [ 250/2001]  eta: 0:19:00  lr: 0.000037  loss: 3.1070 (3.1005)  time: 0.6361  data: 0.0002  max mem: 8728
Epoch: [26]  [ 260/2001]  eta: 0:18:53  lr: 0.000037  loss: 3.0904 (3.0980)  time: 0.6374  data: 0.0002  max mem: 8728
Epoch: [26]  [ 270/2001]  eta: 0:18:46  lr: 0.000037  loss: 3.0904 (3.0915)  time: 0.6392  data: 0.0002  max mem: 8728
Epoch: [26]  [ 280/2001]  eta: 0:18:38  lr: 0.000037  loss: 3.1944 (3.0940)  time: 0.6373  data: 0.0002  max mem: 8728
Epoch: [26]  [ 290/2001]  eta: 0:18:32  lr: 0.000037  loss: 3.1545 (3.0863)  time: 0.6399  data: 0.0002  max mem: 8728
loss info: cls_loss=2.9602, ratio_loss=0.0437, cls_kl=0.0644, token_kl=0.0943
Epoch: [26]  [ 300/2001]  eta: 0:18:24  lr: 0.000037  loss: 3.0681 (3.0839)  time: 0.6402  data: 0.0002  max mem: 8728
Epoch: [26]  [ 310/2001]  eta: 0:18:17  lr: 0.000037  loss: 3.1238 (3.0895)  time: 0.6403  data: 0.0002  max mem: 8728
Epoch: [26]  [ 320/2001]  eta: 0:18:10  lr: 0.000037  loss: 3.1138 (3.0856)  time: 0.6413  data: 0.0002  max mem: 8728
Epoch: [26]  [ 330/2001]  eta: 0:18:04  lr: 0.000037  loss: 2.9918 (3.0801)  time: 0.6417  data: 0.0002  max mem: 8728
Traceback (most recent call last):
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 253, in main
    process.wait()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/subprocess.py", line 1477, in wait
    (pid, sts) = self._try_wait(0)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/subprocess.py", line 1424, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 6): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 7): env://
| distributed init (rank 4): env://
| distributed init (rank 3): env://
| distributed init (rank 5): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp-3keep/checkpoint.pth', sched='cosine', seed=10, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0000366 for PREDICTOR
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Epoch: [26]  [   0/2001]  eta: 3:39:46  lr: 0.000037  loss: 3.0667 (3.0667)  time: 6.5898  data: 3.4479  max mem: 8647
Epoch: [26]  [  10/2001]  eta: 0:38:12  lr: 0.000037  loss: 2.8953 (2.8296)  time: 1.1513  data: 0.3136  max mem: 8728
Epoch: [26]  [  20/2001]  eta: 0:29:11  lr: 0.000037  loss: 2.9000 (2.9851)  time: 0.5987  data: 0.0001  max mem: 8728
Epoch: [26]  [  30/2001]  eta: 0:26:11  lr: 0.000037  loss: 3.1806 (3.0642)  time: 0.6025  data: 0.0001  max mem: 8728
Epoch: [26]  [  40/2001]  eta: 0:24:26  lr: 0.000037  loss: 3.2369 (3.1123)  time: 0.6045  data: 0.0001  max mem: 8728
Epoch: [26]  [  50/2001]  eta: 0:23:17  lr: 0.000037  loss: 3.1321 (3.0521)  time: 0.5907  data: 0.0001  max mem: 8728
Epoch: [26]  [  60/2001]  eta: 0:22:29  lr: 0.000037  loss: 3.3287 (3.1267)  time: 0.5881  data: 0.0001  max mem: 8728
Epoch: [26]  [  70/2001]  eta: 0:21:53  lr: 0.000037  loss: 3.3699 (3.1177)  time: 0.5892  data: 0.0001  max mem: 8728
Epoch: [26]  [  80/2001]  eta: 0:21:26  lr: 0.000037  loss: 3.2225 (3.1163)  time: 0.5922  data: 0.0001  max mem: 8728
Epoch: [26]  [  90/2001]  eta: 0:21:06  lr: 0.000037  loss: 3.2452 (3.1189)  time: 0.5995  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9876, ratio_loss=0.0452, cls_kl=0.0652, token_kl=0.0962
Epoch: [26]  [ 100/2001]  eta: 0:20:49  lr: 0.000037  loss: 3.2452 (3.1006)  time: 0.6071  data: 0.0001  max mem: 8728
Epoch: [26]  [ 110/2001]  eta: 0:20:35  lr: 0.000037  loss: 3.2697 (3.1034)  time: 0.6101  data: 0.0001  max mem: 8728
Epoch: [26]  [ 120/2001]  eta: 0:20:21  lr: 0.000037  loss: 3.2447 (3.1043)  time: 0.6102  data: 0.0001  max mem: 8728
Epoch: [26]  [ 130/2001]  eta: 0:20:09  lr: 0.000037  loss: 3.1607 (3.1089)  time: 0.6090  data: 0.0001  max mem: 8728
Epoch: [26]  [ 140/2001]  eta: 0:19:58  lr: 0.000037  loss: 3.1607 (3.0982)  time: 0.6083  data: 0.0001  max mem: 8728
Epoch: [26]  [ 150/2001]  eta: 0:19:47  lr: 0.000037  loss: 3.1360 (3.1053)  time: 0.6103  data: 0.0001  max mem: 8728
Epoch: [26]  [ 160/2001]  eta: 0:19:38  lr: 0.000037  loss: 3.0630 (3.0882)  time: 0.6131  data: 0.0001  max mem: 8728
Epoch: [26]  [ 170/2001]  eta: 0:19:29  lr: 0.000037  loss: 3.0630 (3.0854)  time: 0.6153  data: 0.0001  max mem: 8728
Epoch: [26]  [ 180/2001]  eta: 0:19:20  lr: 0.000037  loss: 2.9847 (3.0784)  time: 0.6162  data: 0.0001  max mem: 8728
Epoch: [26]  [ 190/2001]  eta: 0:19:14  lr: 0.000037  loss: 2.8421 (3.0625)  time: 0.6264  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9262, ratio_loss=0.0434, cls_kl=0.0609, token_kl=0.0928
Epoch: [26]  [ 200/2001]  eta: 0:19:06  lr: 0.000037  loss: 3.0917 (3.0665)  time: 0.6297  data: 0.0001  max mem: 8728
Epoch: [26]  [ 210/2001]  eta: 0:18:58  lr: 0.000037  loss: 3.2039 (3.0646)  time: 0.6229  data: 0.0001  max mem: 8728
Epoch: [26]  [ 220/2001]  eta: 0:18:51  lr: 0.000037  loss: 3.1826 (3.0674)  time: 0.6251  data: 0.0001  max mem: 8728
Epoch: [26]  [ 230/2001]  eta: 0:18:44  lr: 0.000037  loss: 3.1653 (3.0631)  time: 0.6275  data: 0.0001  max mem: 8728
Epoch: [26]  [ 240/2001]  eta: 0:18:37  lr: 0.000037  loss: 3.1477 (3.0654)  time: 0.6261  data: 0.0001  max mem: 8728
Epoch: [26]  [ 250/2001]  eta: 0:18:31  lr: 0.000037  loss: 3.1761 (3.0712)  time: 0.6271  data: 0.0001  max mem: 8728
Epoch: [26]  [ 260/2001]  eta: 0:18:24  lr: 0.000037  loss: 3.1761 (3.0678)  time: 0.6338  data: 0.0001  max mem: 8728
Epoch: [26]  [ 270/2001]  eta: 0:18:18  lr: 0.000037  loss: 2.9432 (3.0643)  time: 0.6342  data: 0.0001  max mem: 8728
Epoch: [26]  [ 280/2001]  eta: 0:18:11  lr: 0.000037  loss: 2.8628 (3.0531)  time: 0.6308  data: 0.0001  max mem: 8728
Epoch: [26]  [ 290/2001]  eta: 0:18:05  lr: 0.000037  loss: 2.8265 (3.0517)  time: 0.6308  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9084, ratio_loss=0.0447, cls_kl=0.0619, token_kl=0.0937
Epoch: [26]  [ 300/2001]  eta: 0:17:58  lr: 0.000037  loss: 2.9721 (3.0473)  time: 0.6329  data: 0.0001  max mem: 8728
Epoch: [26]  [ 310/2001]  eta: 0:17:52  lr: 0.000037  loss: 3.0475 (3.0467)  time: 0.6340  data: 0.0001  max mem: 8728
Epoch: [26]  [ 320/2001]  eta: 0:17:46  lr: 0.000037  loss: 3.1474 (3.0483)  time: 0.6341  data: 0.0001  max mem: 8728
Epoch: [26]  [ 330/2001]  eta: 0:17:40  lr: 0.000037  loss: 3.2355 (3.0425)  time: 0.6368  data: 0.0001  max mem: 8728
Epoch: [26]  [ 340/2001]  eta: 0:17:34  lr: 0.000037  loss: 3.2355 (3.0418)  time: 0.6392  data: 0.0001  max mem: 8728
Epoch: [26]  [ 350/2001]  eta: 0:17:27  lr: 0.000037  loss: 2.9849 (3.0327)  time: 0.6374  data: 0.0001  max mem: 8728
Epoch: [26]  [ 360/2001]  eta: 0:17:21  lr: 0.000037  loss: 3.1266 (3.0373)  time: 0.6356  data: 0.0001  max mem: 8728
Epoch: [26]  [ 370/2001]  eta: 0:17:15  lr: 0.000037  loss: 3.2510 (3.0388)  time: 0.6371  data: 0.0001  max mem: 8728
Epoch: [26]  [ 380/2001]  eta: 0:17:09  lr: 0.000037  loss: 3.1185 (3.0378)  time: 0.6392  data: 0.0001  max mem: 8728
Epoch: [26]  [ 390/2001]  eta: 0:17:02  lr: 0.000037  loss: 2.8417 (3.0299)  time: 0.6401  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8816, ratio_loss=0.0420, cls_kl=0.0617, token_kl=0.0927
Epoch: [26]  [ 400/2001]  eta: 0:16:56  lr: 0.000037  loss: 3.1226 (3.0317)  time: 0.6387  data: 0.0001  max mem: 8728
Epoch: [26]  [ 410/2001]  eta: 0:16:50  lr: 0.000037  loss: 3.2238 (3.0359)  time: 0.6368  data: 0.0001  max mem: 8728
Epoch: [26]  [ 420/2001]  eta: 0:16:44  lr: 0.000037  loss: 3.2023 (3.0312)  time: 0.6359  data: 0.0001  max mem: 8728
Epoch: [26]  [ 430/2001]  eta: 0:16:37  lr: 0.000037  loss: 2.8444 (3.0256)  time: 0.6364  data: 0.0001  max mem: 8728
Epoch: [26]  [ 440/2001]  eta: 0:16:31  lr: 0.000037  loss: 3.1014 (3.0266)  time: 0.6387  data: 0.0001  max mem: 8728
Epoch: [26]  [ 450/2001]  eta: 0:16:25  lr: 0.000037  loss: 3.3843 (3.0306)  time: 0.6404  data: 0.0001  max mem: 8728
Epoch: [26]  [ 460/2001]  eta: 0:16:19  lr: 0.000037  loss: 3.1768 (3.0257)  time: 0.6419  data: 0.0001  max mem: 8728
Epoch: [26]  [ 470/2001]  eta: 0:16:13  lr: 0.000037  loss: 2.7376 (3.0227)  time: 0.6405  data: 0.0001  max mem: 8728
Epoch: [26]  [ 480/2001]  eta: 0:16:06  lr: 0.000037  loss: 2.9970 (3.0233)  time: 0.6388  data: 0.0001  max mem: 8728
Epoch: [26]  [ 490/2001]  eta: 0:16:00  lr: 0.000037  loss: 3.0722 (3.0196)  time: 0.6377  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8636, ratio_loss=0.0415, cls_kl=0.0616, token_kl=0.0936
Epoch: [26]  [ 500/2001]  eta: 0:15:54  lr: 0.000037  loss: 2.9671 (3.0182)  time: 0.6360  data: 0.0001  max mem: 8728
Epoch: [26]  [ 510/2001]  eta: 0:15:47  lr: 0.000037  loss: 3.0157 (3.0161)  time: 0.6346  data: 0.0001  max mem: 8728
Epoch: [26]  [ 520/2001]  eta: 0:15:41  lr: 0.000037  loss: 2.8879 (3.0103)  time: 0.6317  data: 0.0001  max mem: 8728
Epoch: [26]  [ 530/2001]  eta: 0:15:34  lr: 0.000037  loss: 2.6062 (3.0046)  time: 0.6329  data: 0.0001  max mem: 8728
Epoch: [26]  [ 540/2001]  eta: 0:15:28  lr: 0.000037  loss: 2.9800 (3.0051)  time: 0.6337  data: 0.0001  max mem: 8728
Epoch: [26]  [ 550/2001]  eta: 0:15:21  lr: 0.000037  loss: 2.9274 (3.0024)  time: 0.6322  data: 0.0001  max mem: 8728
Epoch: [26]  [ 560/2001]  eta: 0:15:15  lr: 0.000037  loss: 2.9606 (3.0035)  time: 0.6342  data: 0.0001  max mem: 8728
Epoch: [26]  [ 570/2001]  eta: 0:15:09  lr: 0.000037  loss: 3.2137 (3.0032)  time: 0.6385  data: 0.0001  max mem: 8728
Epoch: [26]  [ 580/2001]  eta: 0:15:03  lr: 0.000037  loss: 3.2362 (3.0062)  time: 0.6402  data: 0.0001  max mem: 8728
Epoch: [26]  [ 590/2001]  eta: 0:14:56  lr: 0.000037  loss: 3.1617 (3.0096)  time: 0.6373  data: 0.0002  max mem: 8728
loss info: cls_loss=2.8662, ratio_loss=0.0416, cls_kl=0.0609, token_kl=0.0917
Epoch: [26]  [ 600/2001]  eta: 0:14:50  lr: 0.000037  loss: 3.1982 (3.0115)  time: 0.6343  data: 0.0002  max mem: 8728
Epoch: [26]  [ 610/2001]  eta: 0:14:44  lr: 0.000037  loss: 3.0566 (3.0068)  time: 0.6342  data: 0.0001  max mem: 8728
Epoch: [26]  [ 620/2001]  eta: 0:14:37  lr: 0.000037  loss: 3.1243 (3.0070)  time: 0.6375  data: 0.0001  max mem: 8728
Epoch: [26]  [ 630/2001]  eta: 0:14:31  lr: 0.000037  loss: 3.1877 (3.0066)  time: 0.6363  data: 0.0001  max mem: 8728
Epoch: [26]  [ 640/2001]  eta: 0:14:24  lr: 0.000037  loss: 3.0616 (3.0063)  time: 0.6318  data: 0.0001  max mem: 8728
Epoch: [26]  [ 650/2001]  eta: 0:14:18  lr: 0.000037  loss: 3.1210 (3.0103)  time: 0.6333  data: 0.0001  max mem: 8728
Epoch: [26]  [ 660/2001]  eta: 0:14:12  lr: 0.000037  loss: 3.3163 (3.0122)  time: 0.6347  data: 0.0001  max mem: 8728
Epoch: [26]  [ 670/2001]  eta: 0:14:05  lr: 0.000037  loss: 3.2167 (3.0127)  time: 0.6331  data: 0.0001  max mem: 8728
Epoch: [26]  [ 680/2001]  eta: 0:13:59  lr: 0.000037  loss: 2.9718 (3.0118)  time: 0.6321  data: 0.0001  max mem: 8728
Epoch: [26]  [ 690/2001]  eta: 0:13:52  lr: 0.000037  loss: 2.9718 (3.0127)  time: 0.6326  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9031, ratio_loss=0.0410, cls_kl=0.0617, token_kl=0.0918
Epoch: [26]  [ 700/2001]  eta: 0:13:46  lr: 0.000037  loss: 2.9404 (3.0106)  time: 0.6352  data: 0.0001  max mem: 8728
Epoch: [26]  [ 710/2001]  eta: 0:13:40  lr: 0.000037  loss: 3.2381 (3.0160)  time: 0.6348  data: 0.0001  max mem: 8728
Epoch: [26]  [ 720/2001]  eta: 0:13:33  lr: 0.000037  loss: 3.2707 (3.0186)  time: 0.6319  data: 0.0001  max mem: 8728
Epoch: [26]  [ 730/2001]  eta: 0:13:27  lr: 0.000037  loss: 3.2506 (3.0179)  time: 0.6343  data: 0.0001  max mem: 8728
Epoch: [26]  [ 740/2001]  eta: 0:13:21  lr: 0.000037  loss: 3.2168 (3.0196)  time: 0.6376  data: 0.0001  max mem: 8728
Epoch: [26]  [ 750/2001]  eta: 0:13:14  lr: 0.000037  loss: 3.1315 (3.0160)  time: 0.6322  data: 0.0001  max mem: 8728
Epoch: [26]  [ 760/2001]  eta: 0:13:08  lr: 0.000037  loss: 3.0228 (3.0174)  time: 0.6270  data: 0.0001  max mem: 8728
Epoch: [26]  [ 770/2001]  eta: 0:13:01  lr: 0.000037  loss: 3.1898 (3.0199)  time: 0.6292  data: 0.0001  max mem: 8728
Epoch: [26]  [ 780/2001]  eta: 0:12:55  lr: 0.000037  loss: 3.1732 (3.0196)  time: 0.6298  data: 0.0001  max mem: 8728
Epoch: [26]  [ 790/2001]  eta: 0:12:48  lr: 0.000037  loss: 3.1334 (3.0210)  time: 0.6279  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9873, ratio_loss=0.0456, cls_kl=0.0649, token_kl=0.0934
Epoch: [26]  [ 800/2001]  eta: 0:12:42  lr: 0.000037  loss: 3.1334 (3.0226)  time: 0.6251  data: 0.0001  max mem: 8728
Epoch: [26]  [ 810/2001]  eta: 0:12:35  lr: 0.000037  loss: 2.9054 (3.0214)  time: 0.6260  data: 0.0001  max mem: 8728
Epoch: [26]  [ 820/2001]  eta: 0:12:29  lr: 0.000037  loss: 3.1103 (3.0231)  time: 0.6259  data: 0.0001  max mem: 8728
Epoch: [26]  [ 830/2001]  eta: 0:12:22  lr: 0.000037  loss: 3.1813 (3.0230)  time: 0.6236  data: 0.0001  max mem: 8728
Epoch: [26]  [ 840/2001]  eta: 0:12:16  lr: 0.000037  loss: 3.0732 (3.0236)  time: 0.6253  data: 0.0001  max mem: 8728
Epoch: [26]  [ 850/2001]  eta: 0:12:09  lr: 0.000037  loss: 3.0367 (3.0216)  time: 0.6248  data: 0.0001  max mem: 8728
Epoch: [26]  [ 860/2001]  eta: 0:12:03  lr: 0.000037  loss: 3.1182 (3.0221)  time: 0.6257  data: 0.0001  max mem: 8728
Epoch: [26]  [ 870/2001]  eta: 0:11:57  lr: 0.000037  loss: 3.1130 (3.0216)  time: 0.6284  data: 0.0001  max mem: 8728
Epoch: [26]  [ 880/2001]  eta: 0:11:50  lr: 0.000037  loss: 2.8336 (3.0192)  time: 0.6260  data: 0.0001  max mem: 8728
Epoch: [26]  [ 890/2001]  eta: 0:11:44  lr: 0.000037  loss: 2.9578 (3.0203)  time: 0.6283  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9330, ratio_loss=0.0425, cls_kl=0.0621, token_kl=0.0919
Epoch: [26]  [ 900/2001]  eta: 0:11:37  lr: 0.000037  loss: 3.3097 (3.0235)  time: 0.6278  data: 0.0001  max mem: 8728
Epoch: [26]  [ 910/2001]  eta: 0:11:31  lr: 0.000037  loss: 3.2747 (3.0232)  time: 0.6222  data: 0.0001  max mem: 8728
Epoch: [26]  [ 920/2001]  eta: 0:11:24  lr: 0.000037  loss: 3.0488 (3.0233)  time: 0.6221  data: 0.0001  max mem: 8728
Epoch: [26]  [ 930/2001]  eta: 0:11:18  lr: 0.000037  loss: 3.0488 (3.0253)  time: 0.6239  data: 0.0001  max mem: 8728
Epoch: [26]  [ 940/2001]  eta: 0:11:11  lr: 0.000037  loss: 2.9872 (3.0243)  time: 0.6241  data: 0.0001  max mem: 8728
Epoch: [26]  [ 950/2001]  eta: 0:11:05  lr: 0.000037  loss: 3.0441 (3.0258)  time: 0.6244  data: 0.0001  max mem: 8728
Epoch: [26]  [ 960/2001]  eta: 0:10:59  lr: 0.000037  loss: 3.3368 (3.0268)  time: 0.6236  data: 0.0001  max mem: 8728
Epoch: [26]  [ 970/2001]  eta: 0:10:52  lr: 0.000037  loss: 3.2209 (3.0266)  time: 0.6207  data: 0.0001  max mem: 8728
Epoch: [26]  [ 980/2001]  eta: 0:10:46  lr: 0.000037  loss: 3.0904 (3.0272)  time: 0.6237  data: 0.0001  max mem: 8728
Epoch: [26]  [ 990/2001]  eta: 0:10:39  lr: 0.000037  loss: 3.3346 (3.0304)  time: 0.6257  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9643, ratio_loss=0.0455, cls_kl=0.0647, token_kl=0.0938
Epoch: [26]  [1000/2001]  eta: 0:10:33  lr: 0.000037  loss: 3.2216 (3.0279)  time: 0.6265  data: 0.0001  max mem: 8728
Epoch: [26]  [1010/2001]  eta: 0:10:27  lr: 0.000037  loss: 3.0368 (3.0279)  time: 0.6286  data: 0.0001  max mem: 8728
Epoch: [26]  [1020/2001]  eta: 0:10:20  lr: 0.000037  loss: 3.2261 (3.0297)  time: 0.6247  data: 0.0001  max mem: 8728
Epoch: [26]  [1030/2001]  eta: 0:10:14  lr: 0.000037  loss: 3.2294 (3.0298)  time: 0.6212  data: 0.0001  max mem: 8728
Epoch: [26]  [1040/2001]  eta: 0:10:07  lr: 0.000037  loss: 3.1973 (3.0296)  time: 0.6277  data: 0.0001  max mem: 8728
Epoch: [26]  [1050/2001]  eta: 0:10:01  lr: 0.000037  loss: 3.1533 (3.0303)  time: 0.6275  data: 0.0001  max mem: 8728
Epoch: [26]  [1060/2001]  eta: 0:09:55  lr: 0.000037  loss: 3.1533 (3.0304)  time: 0.6208  data: 0.0001  max mem: 8728
Epoch: [26]  [1070/2001]  eta: 0:09:48  lr: 0.000037  loss: 3.1844 (3.0319)  time: 0.6204  data: 0.0001  max mem: 8728
Epoch: [26]  [1080/2001]  eta: 0:09:42  lr: 0.000037  loss: 3.2347 (3.0326)  time: 0.6207  data: 0.0001  max mem: 8728
Epoch: [26]  [1090/2001]  eta: 0:09:35  lr: 0.000037  loss: 3.2068 (3.0319)  time: 0.6210  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9424, ratio_loss=0.0453, cls_kl=0.0639, token_kl=0.0946
Epoch: [26]  [1100/2001]  eta: 0:09:29  lr: 0.000037  loss: 2.9631 (3.0314)  time: 0.6216  data: 0.0001  max mem: 8728
Epoch: [26]  [1110/2001]  eta: 0:09:22  lr: 0.000037  loss: 2.9631 (3.0290)  time: 0.6232  data: 0.0001  max mem: 8728
Epoch: [26]  [1120/2001]  eta: 0:09:16  lr: 0.000037  loss: 3.0649 (3.0302)  time: 0.6244  data: 0.0001  max mem: 8728
Epoch: [26]  [1130/2001]  eta: 0:09:10  lr: 0.000037  loss: 3.3611 (3.0285)  time: 0.6249  data: 0.0001  max mem: 8728
Epoch: [26]  [1140/2001]  eta: 0:09:03  lr: 0.000037  loss: 3.0453 (3.0290)  time: 0.6234  data: 0.0001  max mem: 8728
Epoch: [26]  [1150/2001]  eta: 0:08:57  lr: 0.000037  loss: 3.1934 (3.0292)  time: 0.6225  data: 0.0001  max mem: 8728
Epoch: [26]  [1160/2001]  eta: 0:08:51  lr: 0.000037  loss: 3.1314 (3.0293)  time: 0.6223  data: 0.0001  max mem: 8728
Epoch: [26]  [1170/2001]  eta: 0:08:44  lr: 0.000037  loss: 3.2130 (3.0294)  time: 0.6229  data: 0.0001  max mem: 8728
Epoch: [26]  [1180/2001]  eta: 0:08:38  lr: 0.000037  loss: 3.2238 (3.0307)  time: 0.6231  data: 0.0001  max mem: 8728
Epoch: [26]  [1190/2001]  eta: 0:08:31  lr: 0.000037  loss: 3.2121 (3.0305)  time: 0.6214  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9076, ratio_loss=0.0440, cls_kl=0.0637, token_kl=0.0937
Epoch: [26]  [1200/2001]  eta: 0:08:25  lr: 0.000037  loss: 3.1558 (3.0302)  time: 0.6212  data: 0.0001  max mem: 8728
Epoch: [26]  [1210/2001]  eta: 0:08:19  lr: 0.000037  loss: 3.1558 (3.0321)  time: 0.6229  data: 0.0001  max mem: 8728
Traceback (most recent call last):
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 253, in main
    process.wait()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/subprocess.py", line 1477, in wait
    (pid, sts) = self._try_wait(0)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/subprocess.py", line 1424, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 3): env://
| distributed init (rank 1): env://
| distributed init (rank 6): env://
| distributed init (rank 7): env://
| distributed init (rank 0): env://
| distributed init (rank 5): env://
| distributed init (rank 4): env://
| distributed init (rank 2): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp-3keep/checkpoint.pth', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000063 for BACKBONE, cosine lr = 0.0000366 for PREDICTOR
Epoch: [26]  [   0/2001]  eta: 3:46:00  lr: 0.000037  loss: 3.5764 (3.5764)  time: 6.7767  data: 3.1111  max mem: 8647
Epoch: [26]  [  10/2001]  eta: 0:38:51  lr: 0.000037  loss: 3.5318 (3.3030)  time: 1.1711  data: 0.2830  max mem: 8728
Traceback (most recent call last):
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 253, in main
    process.wait()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/subprocess.py", line 1477, in wait
    (pid, sts) = self._try_wait(0)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/subprocess.py", line 1424, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Exception in thread Thread-1:
Traceback (most recent call last):
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py", line 25, in _pin_memory_loop
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/multiprocessing/queues.py", line 113, in get
    return _ForkingPickler.loads(res)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/multiprocessing/reductions.py", line 282, in rebuild_storage_fd
    fd = df.detach()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/multiprocessing/connection.py", line 487, in Client
    c = SocketClient(address)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/multiprocessing/connection.py", line 614, in SocketClient
    s.connect(address)
FileNotFoundError: [Errno 2] No such file or directory

Traceback (most recent call last):
  File "main_l2_vit_3keep.py", line 566, in <module>
    main(args)
  File "main_l2_vit_3keep.py", line 513, in main
    set_training_mode=args.finetune == '' # keep in eval mode during finetuning
  File "/home/zlkong/DynamicVit_Soft_Mask/engine_l2.py", line 57, in train_one_epoch
    parameters=model.parameters(), create_graph=is_second_order)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/timm/utils/cuda.py", line 43, in __call__
    self._scaler.scale(loss).backward(create_graph=create_graph)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/autograd/__init__.py", line 132, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt
Traceback (most recent call last):
  File "main_l2_vit_3keep.py", line 566, in <module>
    main(args)
  File "main_l2_vit_3keep.py", line 513, in main
    set_training_mode=args.finetune == '' # keep in eval mode during finetuning
  File "/home/zlkong/DynamicVit_Soft_Mask/engine_l2.py", line 57, in train_one_epoch
    parameters=model.parameters(), create_graph=is_second_order)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/timm/utils/cuda.py", line 43, in __call__
    self._scaler.scale(loss).backward(create_graph=create_graph)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/autograd/__init__.py", line 132, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt
Traceback (most recent call last):
  File "main_l2_vit_3keep.py", line 566, in <module>
    main(args)
  File "main_l2_vit_3keep.py", line 513, in main
    set_training_mode=args.finetune == '' # keep in eval mode during finetuning
  File "/home/zlkong/DynamicVit_Soft_Mask/engine_l2.py", line 57, in train_one_epoch
    parameters=model.parameters(), create_graph=is_second_order)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/timm/utils/cuda.py", line 43, in __call__
    self._scaler.scale(loss).backward(create_graph=create_graph)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/autograd/__init__.py", line 132, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt
Traceback (most recent call last):
  File "main_l2_vit_3keep.py", line 566, in <module>
    main(args)
  File "main_l2_vit_3keep.py", line 513, in main
    set_training_mode=args.finetune == '' # keep in eval mode during finetuning
  File "/home/zlkong/DynamicVit_Soft_Mask/engine_l2.py", line 57, in train_one_epoch
    parameters=model.parameters(), create_graph=is_second_order)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/timm/utils/cuda.py", line 43, in __call__
    self._scaler.scale(loss).backward(create_graph=create_graph)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/autograd/__init__.py", line 132, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt
Traceback (most recent call last):
  File "main_l2_vit_3keep.py", line 566, in <module>
    main(args)
  File "main_l2_vit_3keep.py", line 513, in main
    set_training_mode=args.finetune == '' # keep in eval mode during finetuning
  File "/home/zlkong/DynamicVit_Soft_Mask/engine_l2.py", line 57, in train_one_epoch
    parameters=model.parameters(), create_graph=is_second_order)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/timm/utils/cuda.py", line 43, in __call__
    self._scaler.scale(loss).backward(create_graph=create_graph)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/autograd/__init__.py", line 132, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt
Traceback (most recent call last):
  File "main_l2_vit_3keep.py", line 566, in <module>
    main(args)
  File "main_l2_vit_3keep.py", line 513, in main
    set_training_mode=args.finetune == '' # keep in eval mode during finetuning
  File "/home/zlkong/DynamicVit_Soft_Mask/engine_l2.py", line 57, in train_one_epoch
    parameters=model.parameters(), create_graph=is_second_order)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/timm/utils/cuda.py", line 43, in __call__
    self._scaler.scale(loss).backward(create_graph=create_graph)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/autograd/__init__.py", line 132, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt
Traceback (most recent call last):
  File "main_l2_vit_3keep.py", line 566, in <module>
    main(args)
  File "main_l2_vit_3keep.py", line 513, in main
    set_training_mode=args.finetune == '' # keep in eval mode during finetuning
  File "/home/zlkong/DynamicVit_Soft_Mask/engine_l2.py", line 57, in train_one_epoch
Traceback (most recent call last):
  File "main_l2_vit_3keep.py", line 566, in <module>
    parameters=model.parameters(), create_graph=is_second_order)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/timm/utils/cuda.py", line 43, in __call__
    self._scaler.scale(loss).backward(create_graph=create_graph)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/autograd/__init__.py", line 132, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt
    main(args)
  File "main_l2_vit_3keep.py", line 513, in main
    set_training_mode=args.finetune == '' # keep in eval mode during finetuning
  File "/home/zlkong/DynamicVit_Soft_Mask/engine_l2.py", line 57, in train_one_epoch
    parameters=model.parameters(), create_graph=is_second_order)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/timm/utils/cuda.py", line 43, in __call__
    self._scaler.scale(loss).backward(create_graph=create_graph)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/autograd/__init__.py", line 132, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt
| distributed init (rank 6): env://
| distributed init (rank 2): env://
| distributed init (rank 5): env://
| distributed init (rank 0): env://
| distributed init (rank 4): env://
| distributed init (rank 3): env://
| distributed init (rank 1): env://
| distributed init (rank 7): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp-3keep/checkpoint.pth', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000060 for BACKBONE, cosine lr = 0.0000355 for PREDICTOR
Failed to find state_dict_ema, starting from loaded model weights
Epoch: [26]  [   0/2001]  eta: 3:45:46  lr: 0.000036  loss: 3.5764 (3.5764)  time: 6.7700  data: 2.8991  max mem: 8647
Epoch: [26]  [  10/2001]  eta: 0:38:49  lr: 0.000036  loss: 3.5318 (3.3030)  time: 1.1702  data: 0.2637  max mem: 8728
Epoch: [26]  [  20/2001]  eta: 0:29:29  lr: 0.000036  loss: 3.2894 (3.2349)  time: 0.5993  data: 0.0001  max mem: 8728
Epoch: [26]  [  30/2001]  eta: 0:26:19  lr: 0.000036  loss: 3.2894 (3.2818)  time: 0.5988  data: 0.0002  max mem: 8728
Epoch: [26]  [  40/2001]  eta: 0:24:28  lr: 0.000036  loss: 3.1607 (3.2364)  time: 0.5969  data: 0.0001  max mem: 8728
Epoch: [26]  [  50/2001]  eta: 0:23:16  lr: 0.000036  loss: 3.0908 (3.2064)  time: 0.5835  data: 0.0001  max mem: 8728
Epoch: [26]  [  60/2001]  eta: 0:22:28  lr: 0.000036  loss: 3.2232 (3.1889)  time: 0.5846  data: 0.0001  max mem: 8728
Epoch: [26]  [  70/2001]  eta: 0:21:54  lr: 0.000036  loss: 3.2232 (3.1553)  time: 0.5914  data: 0.0001  max mem: 8728
Epoch: [26]  [  80/2001]  eta: 0:21:26  lr: 0.000036  loss: 3.1423 (3.1488)  time: 0.5933  data: 0.0001  max mem: 8728
Epoch: [26]  [  90/2001]  eta: 0:21:02  lr: 0.000036  loss: 3.1957 (3.1375)  time: 0.5882  data: 0.0001  max mem: 8728
loss info: cls_loss=3.0322, ratio_loss=0.0455, cls_kl=0.0651, token_kl=0.0936
Epoch: [26]  [ 100/2001]  eta: 0:20:42  lr: 0.000036  loss: 3.1957 (3.1421)  time: 0.5874  data: 0.0001  max mem: 8728
Epoch: [26]  [ 110/2001]  eta: 0:20:25  lr: 0.000036  loss: 3.1728 (3.1462)  time: 0.5915  data: 0.0001  max mem: 8728
Epoch: [26]  [ 120/2001]  eta: 0:20:10  lr: 0.000036  loss: 3.2067 (3.1457)  time: 0.5936  data: 0.0001  max mem: 8728
Epoch: [26]  [ 130/2001]  eta: 0:19:56  lr: 0.000036  loss: 3.2067 (3.1364)  time: 0.5916  data: 0.0001  max mem: 8728
Epoch: [26]  [ 140/2001]  eta: 0:19:46  lr: 0.000036  loss: 3.0344 (3.1219)  time: 0.6011  data: 0.0001  max mem: 8728
Epoch: [26]  [ 150/2001]  eta: 0:19:36  lr: 0.000036  loss: 3.1788 (3.1235)  time: 0.6097  data: 0.0001  max mem: 8728
Epoch: [26]  [ 160/2001]  eta: 0:19:26  lr: 0.000036  loss: 3.2073 (3.1263)  time: 0.6043  data: 0.0001  max mem: 8728
Epoch: [26]  [ 170/2001]  eta: 0:19:16  lr: 0.000036  loss: 3.0865 (3.1219)  time: 0.6028  data: 0.0001  max mem: 8728
Epoch: [26]  [ 180/2001]  eta: 0:19:07  lr: 0.000036  loss: 2.9958 (3.1135)  time: 0.6047  data: 0.0001  max mem: 8728
Epoch: [26]  [ 190/2001]  eta: 0:19:00  lr: 0.000036  loss: 2.9772 (3.1068)  time: 0.6121  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9477, ratio_loss=0.0430, cls_kl=0.0624, token_kl=0.0917
Epoch: [26]  [ 200/2001]  eta: 0:18:52  lr: 0.000036  loss: 3.0049 (3.0974)  time: 0.6155  data: 0.0001  max mem: 8728
Epoch: [26]  [ 210/2001]  eta: 0:18:44  lr: 0.000036  loss: 3.0499 (3.0928)  time: 0.6120  data: 0.0001  max mem: 8728
Epoch: [26]  [ 220/2001]  eta: 0:18:37  lr: 0.000036  loss: 3.1666 (3.0848)  time: 0.6125  data: 0.0001  max mem: 8728
Epoch: [26]  [ 230/2001]  eta: 0:18:30  lr: 0.000036  loss: 3.1648 (3.0783)  time: 0.6174  data: 0.0001  max mem: 8728
Epoch: [26]  [ 240/2001]  eta: 0:18:23  lr: 0.000036  loss: 3.1648 (3.0745)  time: 0.6172  data: 0.0001  max mem: 8728
Epoch: [26]  [ 250/2001]  eta: 0:18:16  lr: 0.000036  loss: 3.1247 (3.0702)  time: 0.6161  data: 0.0001  max mem: 8728
Epoch: [26]  [ 260/2001]  eta: 0:18:09  lr: 0.000036  loss: 2.8656 (3.0599)  time: 0.6200  data: 0.0001  max mem: 8728
Epoch: [26]  [ 270/2001]  eta: 0:18:03  lr: 0.000036  loss: 2.8656 (3.0552)  time: 0.6206  data: 0.0001  max mem: 8728
Epoch: [26]  [ 280/2001]  eta: 0:17:56  lr: 0.000036  loss: 3.1868 (3.0596)  time: 0.6193  data: 0.0001  max mem: 8728
Epoch: [26]  [ 290/2001]  eta: 0:17:49  lr: 0.000036  loss: 3.0437 (3.0495)  time: 0.6196  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8189, ratio_loss=0.0411, cls_kl=0.0611, token_kl=0.0910
Epoch: [26]  [ 300/2001]  eta: 0:17:43  lr: 0.000036  loss: 2.7457 (3.0382)  time: 0.6241  data: 0.0001  max mem: 8728
Epoch: [26]  [ 310/2001]  eta: 0:17:37  lr: 0.000036  loss: 2.7496 (3.0381)  time: 0.6270  data: 0.0001  max mem: 8728
Epoch: [26]  [ 320/2001]  eta: 0:17:31  lr: 0.000036  loss: 3.3780 (3.0505)  time: 0.6291  data: 0.0001  max mem: 8728
Epoch: [26]  [ 330/2001]  eta: 0:17:25  lr: 0.000036  loss: 3.3863 (3.0494)  time: 0.6290  data: 0.0001  max mem: 8728
Epoch: [26]  [ 340/2001]  eta: 0:17:19  lr: 0.000036  loss: 3.2419 (3.0541)  time: 0.6260  data: 0.0001  max mem: 8728
Epoch: [26]  [ 350/2001]  eta: 0:17:12  lr: 0.000036  loss: 3.2059 (3.0544)  time: 0.6246  data: 0.0001  max mem: 8728
Epoch: [26]  [ 360/2001]  eta: 0:17:06  lr: 0.000036  loss: 3.1264 (3.0563)  time: 0.6258  data: 0.0001  max mem: 8728
Epoch: [26]  [ 370/2001]  eta: 0:17:00  lr: 0.000036  loss: 3.0364 (3.0521)  time: 0.6278  data: 0.0001  max mem: 8728
Epoch: [26]  [ 380/2001]  eta: 0:16:54  lr: 0.000036  loss: 3.0364 (3.0502)  time: 0.6278  data: 0.0001  max mem: 8728
Epoch: [26]  [ 390/2001]  eta: 0:16:48  lr: 0.000036  loss: 3.0581 (3.0451)  time: 0.6276  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9744, ratio_loss=0.0435, cls_kl=0.0632, token_kl=0.0939
Epoch: [26]  [ 400/2001]  eta: 0:16:42  lr: 0.000036  loss: 3.2558 (3.0516)  time: 0.6281  data: 0.0001  max mem: 8728
Epoch: [26]  [ 410/2001]  eta: 0:16:35  lr: 0.000036  loss: 3.2697 (3.0571)  time: 0.6297  data: 0.0001  max mem: 8728
Epoch: [26]  [ 420/2001]  eta: 0:16:29  lr: 0.000036  loss: 3.1582 (3.0561)  time: 0.6315  data: 0.0001  max mem: 8728
Epoch: [26]  [ 430/2001]  eta: 0:16:24  lr: 0.000036  loss: 3.1582 (3.0591)  time: 0.6338  data: 0.0001  max mem: 8728
Epoch: [26]  [ 440/2001]  eta: 0:16:18  lr: 0.000036  loss: 3.1318 (3.0600)  time: 0.6346  data: 0.0001  max mem: 8728
Epoch: [26]  [ 450/2001]  eta: 0:16:11  lr: 0.000036  loss: 2.9948 (3.0597)  time: 0.6322  data: 0.0001  max mem: 8728
Epoch: [26]  [ 460/2001]  eta: 0:16:05  lr: 0.000036  loss: 2.9323 (3.0552)  time: 0.6341  data: 0.0001  max mem: 8728
Epoch: [26]  [ 470/2001]  eta: 0:15:59  lr: 0.000036  loss: 2.7359 (3.0469)  time: 0.6329  data: 0.0001  max mem: 8728
Epoch: [26]  [ 480/2001]  eta: 0:15:53  lr: 0.000036  loss: 2.8016 (3.0452)  time: 0.6294  data: 0.0001  max mem: 8728
Epoch: [26]  [ 490/2001]  eta: 0:15:47  lr: 0.000036  loss: 3.2103 (3.0511)  time: 0.6311  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9383, ratio_loss=0.0443, cls_kl=0.0646, token_kl=0.0946
Epoch: [26]  [ 500/2001]  eta: 0:15:41  lr: 0.000036  loss: 3.2151 (3.0499)  time: 0.6304  data: 0.0001  max mem: 8728
Epoch: [26]  [ 510/2001]  eta: 0:15:35  lr: 0.000036  loss: 3.1429 (3.0523)  time: 0.6282  data: 0.0001  max mem: 8728
Epoch: [26]  [ 520/2001]  eta: 0:15:28  lr: 0.000036  loss: 3.1459 (3.0544)  time: 0.6273  data: 0.0001  max mem: 8728
Epoch: [26]  [ 530/2001]  eta: 0:15:22  lr: 0.000036  loss: 3.0213 (3.0477)  time: 0.6277  data: 0.0001  max mem: 8728
Epoch: [26]  [ 540/2001]  eta: 0:15:16  lr: 0.000036  loss: 2.9806 (3.0475)  time: 0.6267  data: 0.0001  max mem: 8728
Epoch: [26]  [ 550/2001]  eta: 0:15:09  lr: 0.000036  loss: 3.1979 (3.0472)  time: 0.6257  data: 0.0001  max mem: 8728
Epoch: [26]  [ 560/2001]  eta: 0:15:03  lr: 0.000036  loss: 3.4211 (3.0519)  time: 0.6278  data: 0.0001  max mem: 8728
Epoch: [26]  [ 570/2001]  eta: 0:14:57  lr: 0.000036  loss: 3.3544 (3.0530)  time: 0.6289  data: 0.0001  max mem: 8728
Epoch: [26]  [ 580/2001]  eta: 0:14:51  lr: 0.000036  loss: 3.2269 (3.0542)  time: 0.6291  data: 0.0001  max mem: 8728
Epoch: [26]  [ 590/2001]  eta: 0:14:44  lr: 0.000036  loss: 3.1622 (3.0561)  time: 0.6284  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9939, ratio_loss=0.0436, cls_kl=0.0638, token_kl=0.0939
Epoch: [26]  [ 600/2001]  eta: 0:14:38  lr: 0.000036  loss: 3.2517 (3.0561)  time: 0.6263  data: 0.0001  max mem: 8728
Epoch: [26]  [ 610/2001]  eta: 0:14:32  lr: 0.000036  loss: 3.1195 (3.0565)  time: 0.6258  data: 0.0001  max mem: 8728
Epoch: [26]  [ 620/2001]  eta: 0:14:26  lr: 0.000036  loss: 3.1807 (3.0595)  time: 0.6310  data: 0.0001  max mem: 8728
Epoch: [26]  [ 630/2001]  eta: 0:14:20  lr: 0.000036  loss: 3.1807 (3.0607)  time: 0.6320  data: 0.0001  max mem: 8728
Epoch: [26]  [ 640/2001]  eta: 0:14:13  lr: 0.000036  loss: 2.9379 (3.0570)  time: 0.6276  data: 0.0001  max mem: 8728
Epoch: [26]  [ 650/2001]  eta: 0:14:07  lr: 0.000036  loss: 3.0837 (3.0598)  time: 0.6259  data: 0.0001  max mem: 8728
Epoch: [26]  [ 660/2001]  eta: 0:14:01  lr: 0.000036  loss: 3.0487 (3.0526)  time: 0.6252  data: 0.0001  max mem: 8728
Epoch: [26]  [ 670/2001]  eta: 0:13:54  lr: 0.000036  loss: 3.0487 (3.0552)  time: 0.6289  data: 0.0001  max mem: 8728
Epoch: [26]  [ 680/2001]  eta: 0:13:48  lr: 0.000036  loss: 3.1470 (3.0550)  time: 0.6331  data: 0.0001  max mem: 8728
Epoch: [26]  [ 690/2001]  eta: 0:13:42  lr: 0.000036  loss: 2.8975 (3.0518)  time: 0.6321  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8946, ratio_loss=0.0437, cls_kl=0.0632, token_kl=0.0951
Epoch: [26]  [ 700/2001]  eta: 0:13:36  lr: 0.000036  loss: 2.9239 (3.0510)  time: 0.6275  data: 0.0001  max mem: 8728
Epoch: [26]  [ 710/2001]  eta: 0:13:30  lr: 0.000036  loss: 3.2298 (3.0498)  time: 0.6269  data: 0.0001  max mem: 8728
Epoch: [26]  [ 720/2001]  eta: 0:13:23  lr: 0.000036  loss: 3.2017 (3.0470)  time: 0.6319  data: 0.0001  max mem: 8728
Epoch: [26]  [ 730/2001]  eta: 0:13:17  lr: 0.000036  loss: 2.9711 (3.0470)  time: 0.6389  data: 0.0001  max mem: 8728
Epoch: [26]  [ 740/2001]  eta: 0:13:11  lr: 0.000036  loss: 3.2275 (3.0515)  time: 0.6416  data: 0.0001  max mem: 8728
| distributed init (rank 3): env://
| distributed init (rank 4): env://
| distributed init (rank 5): env://
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 7): env://
| distributed init (rank 1): env://
| distributed init (rank 6): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp-3keep/checkpoint.pth', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
## Using lr  0.0000030 for BACKBONE, cosine lr = 0.0000225 for PREDICTOR
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Epoch: [26]  [   0/2001]  eta: 3:40:25  lr: 0.000023  loss: 3.5764 (3.5764)  time: 6.6096  data: 3.0186  max mem: 8647
Epoch: [26]  [  10/2001]  eta: 0:38:05  lr: 0.000023  loss: 3.5316 (3.3016)  time: 1.1479  data: 0.2745  max mem: 8728
Epoch: [26]  [  20/2001]  eta: 0:28:57  lr: 0.000023  loss: 3.2859 (3.2332)  time: 0.5904  data: 0.0001  max mem: 8728
Epoch: [26]  [  30/2001]  eta: 0:25:48  lr: 0.000023  loss: 3.2859 (3.2798)  time: 0.5863  data: 0.0001  max mem: 8728
Epoch: [26]  [  40/2001]  eta: 0:24:04  lr: 0.000023  loss: 3.1584 (3.2350)  time: 0.5888  data: 0.0001  max mem: 8728
Epoch: [26]  [  50/2001]  eta: 0:22:58  lr: 0.000023  loss: 3.0894 (3.2052)  time: 0.5839  data: 0.0001  max mem: 8728
Epoch: [26]  [  60/2001]  eta: 0:22:11  lr: 0.000023  loss: 3.2239 (3.1878)  time: 0.5829  data: 0.0001  max mem: 8728
Epoch: [26]  [  70/2001]  eta: 0:21:39  lr: 0.000023  loss: 3.2239 (3.1541)  time: 0.5867  data: 0.0001  max mem: 8728
Epoch: [26]  [  80/2001]  eta: 0:21:12  lr: 0.000023  loss: 3.1533 (3.1478)  time: 0.5900  data: 0.0001  max mem: 8728
Epoch: [26]  [  90/2001]  eta: 0:20:50  lr: 0.000023  loss: 3.1959 (3.1362)  time: 0.5887  data: 0.0001  max mem: 8728
loss info: cls_loss=3.0314, ratio_loss=0.0457, cls_kl=0.0645, token_kl=0.0927
Epoch: [26]  [ 100/2001]  eta: 0:20:32  lr: 0.000023  loss: 3.1950 (3.1408)  time: 0.5919  data: 0.0001  max mem: 8728
Epoch: [26]  [ 110/2001]  eta: 0:20:16  lr: 0.000023  loss: 3.1753 (3.1447)  time: 0.5942  data: 0.0001  max mem: 8728
Epoch: [26]  [ 120/2001]  eta: 0:20:02  lr: 0.000023  loss: 3.2056 (3.1442)  time: 0.5933  data: 0.0001  max mem: 8728
Epoch: [26]  [ 130/2001]  eta: 0:19:50  lr: 0.000023  loss: 3.2056 (3.1349)  time: 0.5952  data: 0.0001  max mem: 8728
Epoch: [26]  [ 140/2001]  eta: 0:19:39  lr: 0.000023  loss: 3.0333 (3.1203)  time: 0.5987  data: 0.0001  max mem: 8728
Epoch: [26]  [ 150/2001]  eta: 0:19:29  lr: 0.000023  loss: 3.1769 (3.1220)  time: 0.6019  data: 0.0001  max mem: 8728
Epoch: [26]  [ 160/2001]  eta: 0:19:19  lr: 0.000023  loss: 3.2053 (3.1247)  time: 0.6053  data: 0.0001  max mem: 8728
Epoch: [26]  [ 170/2001]  eta: 0:19:11  lr: 0.000023  loss: 3.0807 (3.1203)  time: 0.6067  data: 0.0001  max mem: 8728
Epoch: [26]  [ 180/2001]  eta: 0:19:03  lr: 0.000023  loss: 3.0027 (3.1119)  time: 0.6099  data: 0.0001  max mem: 8728
Epoch: [26]  [ 190/2001]  eta: 0:18:56  lr: 0.000023  loss: 2.9650 (3.1053)  time: 0.6164  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9472, ratio_loss=0.0430, cls_kl=0.0617, token_kl=0.0905
Epoch: [26]  [ 200/2001]  eta: 0:18:48  lr: 0.000023  loss: 3.0130 (3.0960)  time: 0.6134  data: 0.0001  max mem: 8728
Epoch: [26]  [ 210/2001]  eta: 0:18:40  lr: 0.000023  loss: 3.0516 (3.0912)  time: 0.6084  data: 0.0001  max mem: 8728
Epoch: [26]  [ 220/2001]  eta: 0:18:32  lr: 0.000023  loss: 3.1684 (3.0832)  time: 0.6089  data: 0.0001  max mem: 8728
Epoch: [26]  [ 230/2001]  eta: 0:18:25  lr: 0.000023  loss: 3.1595 (3.0766)  time: 0.6079  data: 0.0001  max mem: 8728
Epoch: [26]  [ 240/2001]  eta: 0:18:17  lr: 0.000023  loss: 3.1595 (3.0727)  time: 0.6077  data: 0.0001  max mem: 8728
Epoch: [26]  [ 250/2001]  eta: 0:18:10  lr: 0.000023  loss: 3.1114 (3.0683)  time: 0.6093  data: 0.0001  max mem: 8728
Epoch: [26]  [ 260/2001]  eta: 0:18:03  lr: 0.000023  loss: 2.8604 (3.0580)  time: 0.6115  data: 0.0001  max mem: 8728
Epoch: [26]  [ 270/2001]  eta: 0:17:56  lr: 0.000023  loss: 2.8604 (3.0533)  time: 0.6116  data: 0.0001  max mem: 8728
Epoch: [26]  [ 280/2001]  eta: 0:17:49  lr: 0.000023  loss: 3.1764 (3.0577)  time: 0.6105  data: 0.0001  max mem: 8728
Epoch: [26]  [ 290/2001]  eta: 0:17:42  lr: 0.000023  loss: 3.0298 (3.0475)  time: 0.6109  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8168, ratio_loss=0.0412, cls_kl=0.0602, token_kl=0.0894
Epoch: [26]  [ 300/2001]  eta: 0:17:36  lr: 0.000023  loss: 2.7337 (3.0362)  time: 0.6124  data: 0.0001  max mem: 8728
Epoch: [26]  [ 310/2001]  eta: 0:17:29  lr: 0.000023  loss: 2.7438 (3.0361)  time: 0.6142  data: 0.0001  max mem: 8728
Epoch: [26]  [ 320/2001]  eta: 0:17:23  lr: 0.000023  loss: 3.3687 (3.0485)  time: 0.6148  data: 0.0001  max mem: 8728
Epoch: [26]  [ 330/2001]  eta: 0:17:17  lr: 0.000023  loss: 3.3847 (3.0474)  time: 0.6181  data: 0.0001  max mem: 8728
Epoch: [26]  [ 340/2001]  eta: 0:17:11  lr: 0.000023  loss: 3.2476 (3.0521)  time: 0.6251  data: 0.0001  max mem: 8728
Epoch: [26]  [ 350/2001]  eta: 0:17:04  lr: 0.000023  loss: 3.2071 (3.0524)  time: 0.6230  data: 0.0001  max mem: 8728
Epoch: [26]  [ 360/2001]  eta: 0:16:58  lr: 0.000023  loss: 3.1261 (3.0541)  time: 0.6208  data: 0.0001  max mem: 8728
Epoch: [26]  [ 370/2001]  eta: 0:16:52  lr: 0.000023  loss: 3.0251 (3.0499)  time: 0.6248  data: 0.0001  max mem: 8728
Epoch: [26]  [ 380/2001]  eta: 0:16:46  lr: 0.000023  loss: 3.0251 (3.0481)  time: 0.6241  data: 0.0001  max mem: 8728
Epoch: [26]  [ 390/2001]  eta: 0:16:40  lr: 0.000023  loss: 3.0524 (3.0430)  time: 0.6232  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9730, ratio_loss=0.0435, cls_kl=0.0622, token_kl=0.0923
Epoch: [26]  [ 400/2001]  eta: 0:16:34  lr: 0.000023  loss: 3.2565 (3.0494)  time: 0.6219  data: 0.0001  max mem: 8728
Epoch: [26]  [ 410/2001]  eta: 0:16:28  lr: 0.000023  loss: 3.2661 (3.0549)  time: 0.6218  data: 0.0001  max mem: 8728
Epoch: [26]  [ 420/2001]  eta: 0:16:22  lr: 0.000023  loss: 3.1554 (3.0540)  time: 0.6224  data: 0.0001  max mem: 8728
Epoch: [26]  [ 430/2001]  eta: 0:16:15  lr: 0.000023  loss: 3.1554 (3.0569)  time: 0.6223  data: 0.0001  max mem: 8728
Epoch: [26]  [ 440/2001]  eta: 0:16:09  lr: 0.000023  loss: 3.1166 (3.0578)  time: 0.6240  data: 0.0001  max mem: 8728
Epoch: [26]  [ 450/2001]  eta: 0:16:03  lr: 0.000023  loss: 2.9917 (3.0575)  time: 0.6245  data: 0.0001  max mem: 8728
Epoch: [26]  [ 460/2001]  eta: 0:15:57  lr: 0.000023  loss: 2.9263 (3.0530)  time: 0.6272  data: 0.0001  max mem: 8728
Epoch: [26]  [ 470/2001]  eta: 0:15:51  lr: 0.000023  loss: 2.7389 (3.0446)  time: 0.6279  data: 0.0001  max mem: 8728
Epoch: [26]  [ 480/2001]  eta: 0:15:45  lr: 0.000023  loss: 2.7915 (3.0428)  time: 0.6240  data: 0.0001  max mem: 8728
Epoch: [26]  [ 490/2001]  eta: 0:15:39  lr: 0.000023  loss: 3.2005 (3.0487)  time: 0.6229  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9365, ratio_loss=0.0445, cls_kl=0.0632, token_kl=0.0929
Epoch: [26]  [ 500/2001]  eta: 0:15:33  lr: 0.000023  loss: 3.2096 (3.0475)  time: 0.6245  data: 0.0001  max mem: 8728
Epoch: [26]  [ 510/2001]  eta: 0:15:27  lr: 0.000023  loss: 3.1387 (3.0498)  time: 0.6252  data: 0.0001  max mem: 8728
Epoch: [26]  [ 520/2001]  eta: 0:15:21  lr: 0.000023  loss: 3.1387 (3.0518)  time: 0.6255  data: 0.0001  max mem: 8728
Epoch: [26]  [ 530/2001]  eta: 0:15:15  lr: 0.000023  loss: 3.0203 (3.0451)  time: 0.6278  data: 0.0001  max mem: 8728
Epoch: [26]  [ 540/2001]  eta: 0:15:08  lr: 0.000023  loss: 2.9715 (3.0449)  time: 0.6282  data: 0.0001  max mem: 8728
Epoch: [26]  [ 550/2001]  eta: 0:15:02  lr: 0.000023  loss: 3.1903 (3.0446)  time: 0.6264  data: 0.0001  max mem: 8728
Epoch: [26]  [ 560/2001]  eta: 0:14:56  lr: 0.000023  loss: 3.4158 (3.0493)  time: 0.6261  data: 0.0001  max mem: 8728
Epoch: [26]  [ 570/2001]  eta: 0:14:50  lr: 0.000023  loss: 3.3518 (3.0503)  time: 0.6256  data: 0.0001  max mem: 8728
Epoch: [26]  [ 580/2001]  eta: 0:14:44  lr: 0.000023  loss: 3.2182 (3.0516)  time: 0.6271  data: 0.0001  max mem: 8728
Epoch: [26]  [ 590/2001]  eta: 0:14:38  lr: 0.000023  loss: 3.1616 (3.0535)  time: 0.6285  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9917, ratio_loss=0.0436, cls_kl=0.0623, token_kl=0.0919
Epoch: [26]  [ 600/2001]  eta: 0:14:32  lr: 0.000023  loss: 3.2436 (3.0535)  time: 0.6266  data: 0.0001  max mem: 8728
Epoch: [26]  [ 610/2001]  eta: 0:14:26  lr: 0.000023  loss: 3.1117 (3.0539)  time: 0.6269  data: 0.0001  max mem: 8728
Epoch: [26]  [ 620/2001]  eta: 0:14:20  lr: 0.000023  loss: 3.1792 (3.0569)  time: 0.6324  data: 0.0001  max mem: 8728
Epoch: [26]  [ 630/2001]  eta: 0:14:14  lr: 0.000023  loss: 3.1792 (3.0581)  time: 0.6320  data: 0.0001  max mem: 8728
Epoch: [26]  [ 640/2001]  eta: 0:14:08  lr: 0.000023  loss: 2.9420 (3.0545)  time: 0.6293  data: 0.0001  max mem: 8728
Epoch: [26]  [ 650/2001]  eta: 0:14:01  lr: 0.000023  loss: 3.0832 (3.0572)  time: 0.6315  data: 0.0001  max mem: 8728
Epoch: [26]  [ 660/2001]  eta: 0:13:55  lr: 0.000023  loss: 3.0417 (3.0501)  time: 0.6321  data: 0.0001  max mem: 8728
Epoch: [26]  [ 670/2001]  eta: 0:13:49  lr: 0.000023  loss: 3.0417 (3.0526)  time: 0.6323  data: 0.0001  max mem: 8728
Epoch: [26]  [ 680/2001]  eta: 0:13:43  lr: 0.000023  loss: 3.1498 (3.0525)  time: 0.6337  data: 0.0001  max mem: 8728
Epoch: [26]  [ 690/2001]  eta: 0:13:37  lr: 0.000023  loss: 2.8921 (3.0493)  time: 0.6325  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8943, ratio_loss=0.0438, cls_kl=0.0620, token_kl=0.0930
Epoch: [26]  [ 700/2001]  eta: 0:13:31  lr: 0.000023  loss: 2.9192 (3.0485)  time: 0.6301  data: 0.0001  max mem: 8728
Epoch: [26]  [ 710/2001]  eta: 0:13:25  lr: 0.000023  loss: 3.2338 (3.0472)  time: 0.6297  data: 0.0001  max mem: 8728
Epoch: [26]  [ 720/2001]  eta: 0:13:19  lr: 0.000023  loss: 3.1911 (3.0444)  time: 0.6322  data: 0.0001  max mem: 8728
Epoch: [26]  [ 730/2001]  eta: 0:13:13  lr: 0.000023  loss: 2.9727 (3.0444)  time: 0.6339  data: 0.0001  max mem: 8728
Epoch: [26]  [ 740/2001]  eta: 0:13:07  lr: 0.000023  loss: 3.2288 (3.0489)  time: 0.6331  data: 0.0001  max mem: 8728
Traceback (most recent call last):
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 253, in main
    process.wait()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/subprocess.py", line 1477, in wait
    (pid, sts) = self._try_wait(0)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/subprocess.py", line 1424, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 3): env://
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 6): env://
| distributed init (rank 5): env://
| distributed init (rank 4): env://
| distributed init (rank 7): env://
Namespace(aa='rand-m9-mstd0.5-inc1', arch='deit_small', base_rate=0.7, batch_size=80, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data/ImageNet_new/', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distill=True, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distillw=0.5, distributed=True, drop=0.0, drop_path=0.1, epochs=30, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='logs/no-amp-3keep', patience_epochs=10, pin_mem=True, rank=0, ratiow=2.0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='logs/no-amp-3keep/checkpoint.pth', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=8)
Creating model: deit_small
token_ratio = [0.617, 0.369, 0.137] at layer [3, 6, 9]
## diff vit pruning method
# missing keys= ['score_predictor.0.in_conv.0.0.weight', 'score_predictor.0.in_conv.0.0.bias', 'score_predictor.0.in_conv.0.1.weight', 'score_predictor.0.in_conv.0.1.bias', 'score_predictor.0.in_conv.1.0.weight', 'score_predictor.0.in_conv.1.0.bias', 'score_predictor.0.in_conv.1.1.weight', 'score_predictor.0.in_conv.1.1.bias', 'score_predictor.0.in_conv.2.0.weight', 'score_predictor.0.in_conv.2.0.bias', 'score_predictor.0.in_conv.2.1.weight', 'score_predictor.0.in_conv.2.1.bias', 'score_predictor.0.in_conv.3.0.weight', 'score_predictor.0.in_conv.3.0.bias', 'score_predictor.0.in_conv.3.1.weight', 'score_predictor.0.in_conv.3.1.bias', 'score_predictor.0.in_conv.4.0.weight', 'score_predictor.0.in_conv.4.0.bias', 'score_predictor.0.in_conv.4.1.weight', 'score_predictor.0.in_conv.4.1.bias', 'score_predictor.0.in_conv.5.0.weight', 'score_predictor.0.in_conv.5.0.bias', 'score_predictor.0.in_conv.5.1.weight', 'score_predictor.0.in_conv.5.1.bias', 'score_predictor.0.out_conv.0.0.weight', 'score_predictor.0.out_conv.0.0.bias', 'score_predictor.0.out_conv.0.2.weight', 'score_predictor.0.out_conv.0.2.bias', 'score_predictor.0.out_conv.0.4.weight', 'score_predictor.0.out_conv.0.4.bias', 'score_predictor.0.out_conv.1.0.weight', 'score_predictor.0.out_conv.1.0.bias', 'score_predictor.0.out_conv.1.2.weight', 'score_predictor.0.out_conv.1.2.bias', 'score_predictor.0.out_conv.1.4.weight', 'score_predictor.0.out_conv.1.4.bias', 'score_predictor.0.out_conv.2.0.weight', 'score_predictor.0.out_conv.2.0.bias', 'score_predictor.0.out_conv.2.2.weight', 'score_predictor.0.out_conv.2.2.bias', 'score_predictor.0.out_conv.2.4.weight', 'score_predictor.0.out_conv.2.4.bias', 'score_predictor.0.out_conv.3.0.weight', 'score_predictor.0.out_conv.3.0.bias', 'score_predictor.0.out_conv.3.2.weight', 'score_predictor.0.out_conv.3.2.bias', 'score_predictor.0.out_conv.3.4.weight', 'score_predictor.0.out_conv.3.4.bias', 'score_predictor.0.out_conv.4.0.weight', 'score_predictor.0.out_conv.4.0.bias', 'score_predictor.0.out_conv.4.2.weight', 'score_predictor.0.out_conv.4.2.bias', 'score_predictor.0.out_conv.4.4.weight', 'score_predictor.0.out_conv.4.4.bias', 'score_predictor.0.out_conv.5.0.weight', 'score_predictor.0.out_conv.5.0.bias', 'score_predictor.0.out_conv.5.2.weight', 'score_predictor.0.out_conv.5.2.bias', 'score_predictor.0.out_conv.5.4.weight', 'score_predictor.0.out_conv.5.4.bias', 'score_predictor.1.in_conv.0.0.weight', 'score_predictor.1.in_conv.0.0.bias', 'score_predictor.1.in_conv.0.1.weight', 'score_predictor.1.in_conv.0.1.bias', 'score_predictor.1.in_conv.1.0.weight', 'score_predictor.1.in_conv.1.0.bias', 'score_predictor.1.in_conv.1.1.weight', 'score_predictor.1.in_conv.1.1.bias', 'score_predictor.1.in_conv.2.0.weight', 'score_predictor.1.in_conv.2.0.bias', 'score_predictor.1.in_conv.2.1.weight', 'score_predictor.1.in_conv.2.1.bias', 'score_predictor.1.in_conv.3.0.weight', 'score_predictor.1.in_conv.3.0.bias', 'score_predictor.1.in_conv.3.1.weight', 'score_predictor.1.in_conv.3.1.bias', 'score_predictor.1.in_conv.4.0.weight', 'score_predictor.1.in_conv.4.0.bias', 'score_predictor.1.in_conv.4.1.weight', 'score_predictor.1.in_conv.4.1.bias', 'score_predictor.1.in_conv.5.0.weight', 'score_predictor.1.in_conv.5.0.bias', 'score_predictor.1.in_conv.5.1.weight', 'score_predictor.1.in_conv.5.1.bias', 'score_predictor.1.out_conv.0.0.weight', 'score_predictor.1.out_conv.0.0.bias', 'score_predictor.1.out_conv.0.2.weight', 'score_predictor.1.out_conv.0.2.bias', 'score_predictor.1.out_conv.0.4.weight', 'score_predictor.1.out_conv.0.4.bias', 'score_predictor.1.out_conv.1.0.weight', 'score_predictor.1.out_conv.1.0.bias', 'score_predictor.1.out_conv.1.2.weight', 'score_predictor.1.out_conv.1.2.bias', 'score_predictor.1.out_conv.1.4.weight', 'score_predictor.1.out_conv.1.4.bias', 'score_predictor.1.out_conv.2.0.weight', 'score_predictor.1.out_conv.2.0.bias', 'score_predictor.1.out_conv.2.2.weight', 'score_predictor.1.out_conv.2.2.bias', 'score_predictor.1.out_conv.2.4.weight', 'score_predictor.1.out_conv.2.4.bias', 'score_predictor.1.out_conv.3.0.weight', 'score_predictor.1.out_conv.3.0.bias', 'score_predictor.1.out_conv.3.2.weight', 'score_predictor.1.out_conv.3.2.bias', 'score_predictor.1.out_conv.3.4.weight', 'score_predictor.1.out_conv.3.4.bias', 'score_predictor.1.out_conv.4.0.weight', 'score_predictor.1.out_conv.4.0.bias', 'score_predictor.1.out_conv.4.2.weight', 'score_predictor.1.out_conv.4.2.bias', 'score_predictor.1.out_conv.4.4.weight', 'score_predictor.1.out_conv.4.4.bias', 'score_predictor.1.out_conv.5.0.weight', 'score_predictor.1.out_conv.5.0.bias', 'score_predictor.1.out_conv.5.2.weight', 'score_predictor.1.out_conv.5.2.bias', 'score_predictor.1.out_conv.5.4.weight', 'score_predictor.1.out_conv.5.4.bias', 'score_predictor.2.in_conv.0.0.weight', 'score_predictor.2.in_conv.0.0.bias', 'score_predictor.2.in_conv.0.1.weight', 'score_predictor.2.in_conv.0.1.bias', 'score_predictor.2.in_conv.1.0.weight', 'score_predictor.2.in_conv.1.0.bias', 'score_predictor.2.in_conv.1.1.weight', 'score_predictor.2.in_conv.1.1.bias', 'score_predictor.2.in_conv.2.0.weight', 'score_predictor.2.in_conv.2.0.bias', 'score_predictor.2.in_conv.2.1.weight', 'score_predictor.2.in_conv.2.1.bias', 'score_predictor.2.in_conv.3.0.weight', 'score_predictor.2.in_conv.3.0.bias', 'score_predictor.2.in_conv.3.1.weight', 'score_predictor.2.in_conv.3.1.bias', 'score_predictor.2.in_conv.4.0.weight', 'score_predictor.2.in_conv.4.0.bias', 'score_predictor.2.in_conv.4.1.weight', 'score_predictor.2.in_conv.4.1.bias', 'score_predictor.2.in_conv.5.0.weight', 'score_predictor.2.in_conv.5.0.bias', 'score_predictor.2.in_conv.5.1.weight', 'score_predictor.2.in_conv.5.1.bias', 'score_predictor.2.out_conv.0.0.weight', 'score_predictor.2.out_conv.0.0.bias', 'score_predictor.2.out_conv.0.2.weight', 'score_predictor.2.out_conv.0.2.bias', 'score_predictor.2.out_conv.0.4.weight', 'score_predictor.2.out_conv.0.4.bias', 'score_predictor.2.out_conv.1.0.weight', 'score_predictor.2.out_conv.1.0.bias', 'score_predictor.2.out_conv.1.2.weight', 'score_predictor.2.out_conv.1.2.bias', 'score_predictor.2.out_conv.1.4.weight', 'score_predictor.2.out_conv.1.4.bias', 'score_predictor.2.out_conv.2.0.weight', 'score_predictor.2.out_conv.2.0.bias', 'score_predictor.2.out_conv.2.2.weight', 'score_predictor.2.out_conv.2.2.bias', 'score_predictor.2.out_conv.2.4.weight', 'score_predictor.2.out_conv.2.4.bias', 'score_predictor.2.out_conv.3.0.weight', 'score_predictor.2.out_conv.3.0.bias', 'score_predictor.2.out_conv.3.2.weight', 'score_predictor.2.out_conv.3.2.bias', 'score_predictor.2.out_conv.3.4.weight', 'score_predictor.2.out_conv.3.4.bias', 'score_predictor.2.out_conv.4.0.weight', 'score_predictor.2.out_conv.4.0.bias', 'score_predictor.2.out_conv.4.2.weight', 'score_predictor.2.out_conv.4.2.bias', 'score_predictor.2.out_conv.4.4.weight', 'score_predictor.2.out_conv.4.4.bias', 'score_predictor.2.out_conv.5.0.weight', 'score_predictor.2.out_conv.5.0.bias', 'score_predictor.2.out_conv.5.2.weight', 'score_predictor.2.out_conv.5.2.bias', 'score_predictor.2.out_conv.5.4.weight', 'score_predictor.2.out_conv.5.4.bias']
# unexpected keys= []
sucessfully loaded from pre-trained weights: ./deit_small_patch16_224-cd65a155.pth
## Distillation Pruning Mode
## diff vit pruning method
sucessfully loaded from pre-trained weights for the teach model
number of params: 22071454
ratio_weight= 2.0 distill_weight 0.5
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Start training for 30 epochs
change lr
## Using lr  0.0000020 for BACKBONE, cosine lr = 0.0000182 for PREDICTOR
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Failed to find state_dict_ema, starting from loaded model weights
Epoch: [26]  [   0/2001]  eta: 3:39:29  lr: 0.000018  loss: 3.5764 (3.5764)  time: 6.5815  data: 2.8523  max mem: 8647
Epoch: [26]  [  10/2001]  eta: 0:38:05  lr: 0.000018  loss: 3.5314 (3.3014)  time: 1.1479  data: 0.2594  max mem: 8728
Epoch: [26]  [  20/2001]  eta: 0:29:02  lr: 0.000018  loss: 3.2894 (3.2334)  time: 0.5947  data: 0.0001  max mem: 8728
Epoch: [26]  [  30/2001]  eta: 0:25:59  lr: 0.000018  loss: 3.2894 (3.2797)  time: 0.5952  data: 0.0002  max mem: 8728
Epoch: [26]  [  40/2001]  eta: 0:24:12  lr: 0.000018  loss: 3.1568 (3.2348)  time: 0.5949  data: 0.0002  max mem: 8728
Epoch: [26]  [  50/2001]  eta: 0:23:08  lr: 0.000018  loss: 3.0883 (3.2048)  time: 0.5885  data: 0.0001  max mem: 8728
Epoch: [26]  [  60/2001]  eta: 0:22:21  lr: 0.000018  loss: 3.2206 (3.1872)  time: 0.5892  data: 0.0001  max mem: 8728
Epoch: [26]  [  70/2001]  eta: 0:21:47  lr: 0.000018  loss: 3.2206 (3.1535)  time: 0.5879  data: 0.0001  max mem: 8728
Epoch: [26]  [  80/2001]  eta: 0:21:19  lr: 0.000018  loss: 3.1513 (3.1475)  time: 0.5906  data: 0.0001  max mem: 8728
Epoch: [26]  [  90/2001]  eta: 0:20:57  lr: 0.000018  loss: 3.1953 (3.1357)  time: 0.5922  data: 0.0001  max mem: 8728
loss info: cls_loss=3.0311, ratio_loss=0.0456, cls_kl=0.0642, token_kl=0.0928
Epoch: [26]  [ 100/2001]  eta: 0:20:41  lr: 0.000018  loss: 3.1953 (3.1403)  time: 0.5988  data: 0.0001  max mem: 8728
Epoch: [26]  [ 110/2001]  eta: 0:20:26  lr: 0.000018  loss: 3.1732 (3.1441)  time: 0.6044  data: 0.0001  max mem: 8728
Epoch: [26]  [ 120/2001]  eta: 0:20:13  lr: 0.000018  loss: 3.2054 (3.1435)  time: 0.6057  data: 0.0001  max mem: 8728
Epoch: [26]  [ 130/2001]  eta: 0:20:01  lr: 0.000018  loss: 3.2054 (3.1343)  time: 0.6078  data: 0.0001  max mem: 8728
Epoch: [26]  [ 140/2001]  eta: 0:19:51  lr: 0.000018  loss: 3.0387 (3.1198)  time: 0.6101  data: 0.0001  max mem: 8728
Epoch: [26]  [ 150/2001]  eta: 0:19:41  lr: 0.000018  loss: 3.1783 (3.1214)  time: 0.6109  data: 0.0001  max mem: 8728
Epoch: [26]  [ 160/2001]  eta: 0:19:31  lr: 0.000018  loss: 3.2068 (3.1242)  time: 0.6117  data: 0.0001  max mem: 8728
Epoch: [26]  [ 170/2001]  eta: 0:19:23  lr: 0.000018  loss: 3.0807 (3.1199)  time: 0.6136  data: 0.0001  max mem: 8728
Epoch: [26]  [ 180/2001]  eta: 0:19:14  lr: 0.000018  loss: 3.0044 (3.1114)  time: 0.6144  data: 0.0001  max mem: 8728
Epoch: [26]  [ 190/2001]  eta: 0:19:08  lr: 0.000018  loss: 2.9583 (3.1049)  time: 0.6233  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9472, ratio_loss=0.0429, cls_kl=0.0617, token_kl=0.0903
Epoch: [26]  [ 200/2001]  eta: 0:19:00  lr: 0.000018  loss: 3.0118 (3.0957)  time: 0.6261  data: 0.0001  max mem: 8728
Epoch: [26]  [ 210/2001]  eta: 0:18:53  lr: 0.000018  loss: 3.0536 (3.0908)  time: 0.6219  data: 0.0001  max mem: 8728
Epoch: [26]  [ 220/2001]  eta: 0:18:46  lr: 0.000018  loss: 3.1652 (3.0827)  time: 0.6239  data: 0.0001  max mem: 8728
Epoch: [26]  [ 230/2001]  eta: 0:18:39  lr: 0.000018  loss: 3.1590 (3.0762)  time: 0.6242  data: 0.0001  max mem: 8728
Epoch: [26]  [ 240/2001]  eta: 0:18:32  lr: 0.000018  loss: 3.1590 (3.0723)  time: 0.6250  data: 0.0001  max mem: 8728
Epoch: [26]  [ 250/2001]  eta: 0:18:26  lr: 0.000018  loss: 3.1160 (3.0679)  time: 0.6259  data: 0.0001  max mem: 8728
Epoch: [26]  [ 260/2001]  eta: 0:18:19  lr: 0.000018  loss: 2.8627 (3.0576)  time: 0.6280  data: 0.0001  max mem: 8728
Epoch: [26]  [ 270/2001]  eta: 0:18:12  lr: 0.000018  loss: 2.8627 (3.0530)  time: 0.6276  data: 0.0001  max mem: 8728
Epoch: [26]  [ 280/2001]  eta: 0:18:06  lr: 0.000018  loss: 3.1723 (3.0573)  time: 0.6247  data: 0.0001  max mem: 8728
Epoch: [26]  [ 290/2001]  eta: 0:17:59  lr: 0.000018  loss: 3.0319 (3.0471)  time: 0.6254  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8165, ratio_loss=0.0411, cls_kl=0.0603, token_kl=0.0892
Epoch: [26]  [ 300/2001]  eta: 0:17:53  lr: 0.000018  loss: 2.7336 (3.0358)  time: 0.6272  data: 0.0001  max mem: 8728
Epoch: [26]  [ 310/2001]  eta: 0:17:46  lr: 0.000018  loss: 2.7442 (3.0357)  time: 0.6267  data: 0.0001  max mem: 8728
Epoch: [26]  [ 320/2001]  eta: 0:17:40  lr: 0.000018  loss: 3.3660 (3.0482)  time: 0.6285  data: 0.0001  max mem: 8728
Epoch: [26]  [ 330/2001]  eta: 0:17:33  lr: 0.000018  loss: 3.3834 (3.0470)  time: 0.6283  data: 0.0001  max mem: 8728
Epoch: [26]  [ 340/2001]  eta: 0:17:27  lr: 0.000018  loss: 3.2453 (3.0517)  time: 0.6268  data: 0.0001  max mem: 8728
Epoch: [26]  [ 350/2001]  eta: 0:17:20  lr: 0.000018  loss: 3.2064 (3.0520)  time: 0.6280  data: 0.0001  max mem: 8728
Epoch: [26]  [ 360/2001]  eta: 0:17:14  lr: 0.000018  loss: 3.1253 (3.0537)  time: 0.6282  data: 0.0001  max mem: 8728
Epoch: [26]  [ 370/2001]  eta: 0:17:07  lr: 0.000018  loss: 3.0200 (3.0495)  time: 0.6283  data: 0.0001  max mem: 8728
Epoch: [26]  [ 380/2001]  eta: 0:17:01  lr: 0.000018  loss: 3.0200 (3.0477)  time: 0.6287  data: 0.0001  max mem: 8728
Epoch: [26]  [ 390/2001]  eta: 0:16:55  lr: 0.000018  loss: 3.0460 (3.0425)  time: 0.6295  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9724, ratio_loss=0.0435, cls_kl=0.0618, token_kl=0.0919
Epoch: [26]  [ 400/2001]  eta: 0:16:48  lr: 0.000018  loss: 3.2472 (3.0489)  time: 0.6284  data: 0.0001  max mem: 8728
Epoch: [26]  [ 410/2001]  eta: 0:16:42  lr: 0.000018  loss: 3.2639 (3.0544)  time: 0.6281  data: 0.0001  max mem: 8728
Epoch: [26]  [ 420/2001]  eta: 0:16:36  lr: 0.000018  loss: 3.1635 (3.0535)  time: 0.6296  data: 0.0001  max mem: 8728
Epoch: [26]  [ 430/2001]  eta: 0:16:29  lr: 0.000018  loss: 3.1635 (3.0564)  time: 0.6288  data: 0.0001  max mem: 8728
Epoch: [26]  [ 440/2001]  eta: 0:16:23  lr: 0.000018  loss: 3.1116 (3.0574)  time: 0.6273  data: 0.0001  max mem: 8728
Epoch: [26]  [ 450/2001]  eta: 0:16:17  lr: 0.000018  loss: 2.9903 (3.0570)  time: 0.6267  data: 0.0001  max mem: 8728
Epoch: [26]  [ 460/2001]  eta: 0:16:10  lr: 0.000018  loss: 2.9223 (3.0525)  time: 0.6322  data: 0.0001  max mem: 8728
Epoch: [26]  [ 470/2001]  eta: 0:16:04  lr: 0.000018  loss: 2.7374 (3.0441)  time: 0.6323  data: 0.0001  max mem: 8728
Epoch: [26]  [ 480/2001]  eta: 0:15:58  lr: 0.000018  loss: 2.7977 (3.0424)  time: 0.6262  data: 0.0001  max mem: 8728
Epoch: [26]  [ 490/2001]  eta: 0:15:51  lr: 0.000018  loss: 3.2021 (3.0483)  time: 0.6297  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9364, ratio_loss=0.0445, cls_kl=0.0630, token_kl=0.0927
Epoch: [26]  [ 500/2001]  eta: 0:15:45  lr: 0.000018  loss: 3.2057 (3.0470)  time: 0.6307  data: 0.0001  max mem: 8728
Epoch: [26]  [ 510/2001]  eta: 0:15:39  lr: 0.000018  loss: 3.1352 (3.0493)  time: 0.6274  data: 0.0001  max mem: 8728
Epoch: [26]  [ 520/2001]  eta: 0:15:32  lr: 0.000018  loss: 3.1352 (3.0513)  time: 0.6274  data: 0.0001  max mem: 8728
Epoch: [26]  [ 530/2001]  eta: 0:15:26  lr: 0.000018  loss: 3.0200 (3.0446)  time: 0.6271  data: 0.0001  max mem: 8728
Epoch: [26]  [ 540/2001]  eta: 0:15:19  lr: 0.000018  loss: 2.9699 (3.0444)  time: 0.6251  data: 0.0001  max mem: 8728
Epoch: [26]  [ 550/2001]  eta: 0:15:13  lr: 0.000018  loss: 3.1922 (3.0441)  time: 0.6229  data: 0.0001  max mem: 8728
Epoch: [26]  [ 560/2001]  eta: 0:15:07  lr: 0.000018  loss: 3.4096 (3.0488)  time: 0.6239  data: 0.0001  max mem: 8728
Epoch: [26]  [ 570/2001]  eta: 0:15:00  lr: 0.000018  loss: 3.3477 (3.0498)  time: 0.6256  data: 0.0001  max mem: 8728
Epoch: [26]  [ 580/2001]  eta: 0:14:54  lr: 0.000018  loss: 3.2184 (3.0511)  time: 0.6257  data: 0.0001  max mem: 8728
Epoch: [26]  [ 590/2001]  eta: 0:14:47  lr: 0.000018  loss: 3.1633 (3.0530)  time: 0.6248  data: 0.0001  max mem: 8728
loss info: cls_loss=2.9914, ratio_loss=0.0436, cls_kl=0.0620, token_kl=0.0916
Epoch: [26]  [ 600/2001]  eta: 0:14:41  lr: 0.000018  loss: 3.2382 (3.0530)  time: 0.6248  data: 0.0001  max mem: 8728
Epoch: [26]  [ 610/2001]  eta: 0:14:35  lr: 0.000018  loss: 3.1066 (3.0534)  time: 0.6240  data: 0.0001  max mem: 8728
Epoch: [26]  [ 620/2001]  eta: 0:14:28  lr: 0.000018  loss: 3.1766 (3.0564)  time: 0.6302  data: 0.0001  max mem: 8728
Epoch: [26]  [ 630/2001]  eta: 0:14:22  lr: 0.000018  loss: 3.1766 (3.0577)  time: 0.6320  data: 0.0001  max mem: 8728
Epoch: [26]  [ 640/2001]  eta: 0:14:16  lr: 0.000018  loss: 2.9407 (3.0540)  time: 0.6282  data: 0.0001  max mem: 8728
Epoch: [26]  [ 650/2001]  eta: 0:14:10  lr: 0.000018  loss: 3.0795 (3.0567)  time: 0.6299  data: 0.0001  max mem: 8728
Epoch: [26]  [ 660/2001]  eta: 0:14:03  lr: 0.000018  loss: 3.0446 (3.0495)  time: 0.6280  data: 0.0001  max mem: 8728
Epoch: [26]  [ 670/2001]  eta: 0:13:57  lr: 0.000018  loss: 3.0446 (3.0521)  time: 0.6257  data: 0.0001  max mem: 8728
Epoch: [26]  [ 680/2001]  eta: 0:13:50  lr: 0.000018  loss: 3.1462 (3.0519)  time: 0.6233  data: 0.0001  max mem: 8728
Epoch: [26]  [ 690/2001]  eta: 0:13:44  lr: 0.000018  loss: 2.8878 (3.0488)  time: 0.6245  data: 0.0001  max mem: 8728
loss info: cls_loss=2.8938, ratio_loss=0.0439, cls_kl=0.0618, token_kl=0.0926
Epoch: [26]  [ 700/2001]  eta: 0:13:38  lr: 0.000018  loss: 2.9155 (3.0479)  time: 0.6248  data: 0.0001  max mem: 8728
Epoch: [26]  [ 710/2001]  eta: 0:13:31  lr: 0.000018  loss: 3.2333 (3.0467)  time: 0.6247  data: 0.0001  max mem: 8728
Epoch: [26]  [ 720/2001]  eta: 0:13:25  lr: 0.000018  loss: 3.1935 (3.0438)  time: 0.6247  data: 0.0001  max mem: 8728
Epoch: [26]  [ 730/2001]  eta: 0:13:19  lr: 0.000018  loss: 2.9559 (3.0438)  time: 0.6253  data: 0.0001  max mem: 8728
Epoch: [26]  [ 740/2001]  eta: 0:13:12  lr: 0.000018  loss: 3.2286 (3.0483)  time: 0.6259  data: 0.0001  max mem: 8728
Traceback (most recent call last):
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/site-packages/torch/distributed/launch.py", line 253, in main
    process.wait()
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/subprocess.py", line 1477, in wait
    (pid, sts) = self._try_wait(0)
  File "/home/zlkong/anaconda3/envs/DynamicVit/lib/python3.6/subprocess.py", line 1424, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
